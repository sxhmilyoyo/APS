"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5368942,5369246,5369070,5360952,5369516,5369075,5369403,5367886,5369484,5368179,5368983,5370097,5369503,5370018,5370426,5369550,5369135,5370159,5372150,5370169,5370130,5368662,5370392,5368834,5368030,5369419,5368948,5369315,5369327,5363314,5360274,5364086,5360244,5366554,5357843,5362573,5360439,5361127,5367100,5366626,5360311,5365756,5362169,5362553,5358643,5360718,5364367,5360265,5365786,5365508,5365897,5360268,5363936,5359599,5364897,5357942,5360418,5360283,5358553,5362148,5362526,5361254,5360431,5364636,5362321,5360527,5365019,5365160,5366784,5360238,5365471,5364774,5365807,5358389,5360286,5358393,5363083,5366721,5359021,5357812,5361721,5360530,5360059,5367092,5360338,5361278,5360342,5358593,5364790,5362581,5363321,5364778,5365771,5358646,5360514,5364919,5358645,5363900,5365884,5365387",2017/05/05 23:02:01
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Parallel Training Strategy Based on Support Vector Regression Machine","Y. m. Lei; Y. Yan; S. j. Chen","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2009 15th IEEE Pacific Rim International Symposium on Dependable Computing","20091231","2009","","","159","164","In this paper, we investigate the parallel training strategy and propose a parallel support vector regression machine algorithm that integrates model segmentation and data space decomposition. The major aim is to explore the new data space decomposition scheme that can solve computation intensive problem about the long time training based on SVR's classification by using low-dimension algorithms. The strategy, which divides the whole task into several sub-tasks based on the sample division strategy, uses master-slave mode on the design of parallel program, and finally the master node produce a regression mode by collecting training results. The performance of this algorithm has been analyzed and evaluated with KDD99 data on the high-performance computer of ZQ3000 cluster. The results on this paper prove that the algorithm can guarantee the high precision in the regression and reduce the training time.","","POD:978-0-7695-3849-5","10.1109/PRDC.2009.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368942","KDD99 data;network intrusion detection;parallel computing;regression prediction;support vector regression machine (SVR)","Algorithm design and analysis;Clustering algorithms;Concurrent computing;Data engineering;High performance computing;Machine learning algorithms;Master-slave;Performance analysis;Support vector machine classification;Support vector machines","parallel programming;pattern clustering;regression analysis;support vector machines","KDD99 data;ZQ3000 cluster;computation intensive problem;data space decomposition;master-slave mode;model segmentation;parallel program;parallel training strategy;regression mode;support vector regression machine","","1","","13","","","16-18 Nov. 2009","","IEEE","IEEE Conference Publications"
"Selection of Minimum Support Degree with Rate of Frequent Items","Z. Haiyan; C. Xiaobing; Y. Yunyang","Dept. of Comput. Eng., Huaiyin Inst. of Technol., Huaian, China","2009 Second International Symposium on Computational Intelligence and Design","20091231","2009","1","","235","236","Association rules mining is an important branch of data mining research, which affords interesting relations between items of data sets. Minimum support degree is an important reference value in association rules mining and its threshold is usually given by user. The problem of how to determine the threshold when data mining is not researched until nowadays. So a selection mining support degree algorithm is put forwarded in this paper, and it has important significance in practical application.","","POD:978-0-7695-3865-5","10.1109/ISCID.2009.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369246","association rules;data mining;minimum support degree","Algorithm design and analysis;Association rules;Computational intelligence;Data engineering;Data mining;Design engineering;Machine learning;Pattern recognition;Performance analysis;Transaction databases","data mining","association rules mining;data mining;frequent items;minimum support degree","","0","","7","","","12-14 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Combination of Modified Particle Swarm Optimization Algorithm and Support Vector Machine for Pattern Classification","Z. Liu; C. Wang; S. Yi","Hubei Key Lab. of Digital Valley Sci. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","3","","126","129","Support vector machine for pattern classification is motivated by linear machines, but rely on preprocessing the data to represent in a high dimension with an appropriate nonlinear mapping, data from two categories can by separated by a hyperplane. To make certain the hyperplane, the key problem is selecting appropriate criterion and algorithm. To find out the appropriate solution vector in solution spaces, fixed increment, variable increment, relaxation, and stochastic approximation etc. may be selected, this article provide a novel method-modified general particle swarm optimization for finding the solution vector. The proposed method enhances performance and avoid over fitness effectively.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369070","Particle swarm optimization;Pattern Classification;support vector machine","Appropriate technology;Fingerprint recognition;Genetics;Machine learning;Particle swarm optimization;Pattern classification;Pattern recognition;Stochastic processes;Support vector machine classification;Support vector machines","particle swarm optimisation;pattern classification;support vector machines","fixed increment;modified particle swarm optimization;nonlinear mapping;pattern classification;solution spaces;stochastic approximation;support vector machine;variable increment","","1","","14","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Modulation Classification of MPSK Signals Based on Relevance Vector Machines","X. Zhou; Y. Wu; G. Yang","Zhengzhou Inf. Sci. & Technol. Inst., Zhengzhou, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","5","In this paper, a new classification method based on relevance vector machine (RVM) is used in the MPSK signals classification. Compared with the support vector machine (SVM), RVM is sparse model in the Bayesian framework, not only the solution is highly sparse, but also it does not need to adjust model parameter and its kernel functions don't need to satisfy Mercer's condition. The fourth order cumulants of the received signals are used as the classification vector firstly, and then multi-class classifier of RVM is designed. We first introduce the sparse Bayesian classification model, then transform the RVM learning to the maximization of marginal likelihood, and select the fast sequential sparse Bayesian learning algorithm. Through the experiment compared with SVM classifier proves the advantage of RVM.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5362553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362553","","Bayesian methods;Information science;Kernel;Machine learning;Machine learning algorithms;Neural networks;Pattern analysis;Pattern classification;Support vector machine classification;Support vector machines","Bayes methods;phase shift keying;signal classification;support vector machines","M-ary phase shift keying;MPSK;fourth order cumulants;relevance vector machine;sequential sparse Bayesian learning;signal classification;support vector machine","","2","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Operator matching in fuzzy decision tree based on sound logic","Jialin Chen; Huacan He","Center for Intelligence Science and Technology Research, Beijing University of Posts and Telecommunications, China","2009 IEEE International Conference on Network Infrastructure and Digital Content","20091231","2009","","","344","348","This paper discusses properties of sound logic based on flexible logic, computing model of sound fuzzy logic system, sound probability logic system and sound Luckasiewicz logic system are derived. In the practical application of fuzzy decision tree, algorithm of matching operator in the fuzzy decision tree is improved based on sound logic. Compared with the traditional matching algorithms, the experiments show that the proposed algorithm can obtain a higher accuracy.","2374-0272;23740272","POD:978-1-4244-4898-2","10.1109/ICNIDC.2009.5360952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360952","Sound logic;fuzzy decision tree;matching operator;testing accuracy","Clustering algorithms;Decision trees;Extraterrestrial measurements;Fuzzy logic;Fuzzy systems;Helium;Logic testing;Machine learning algorithms;Probabilistic logic;Telecommunication computing","decision trees;fuzzy logic;probabilistic logic","flexible logic;fuzzy decision tree;operator matching;sound Luckasiewicz logic system;sound fuzzy logic system;sound probability logic system","","0","","14","","","6-8 Nov. 2009","","IEEE","IEEE Conference Publications"
"Association Rules Mining Based on the Improved Immune Algorithm","Y. Zhang; S. Bu; Y. Zhang","Hebei Univ. of Eng., Handan, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","2","","453","456","Firstly, in this paper we propose an improved immune algorithm, that is, introduce the Metropolis criterion into the selection operation of immune algorithm, and the Metropolis immune algorithm (MIA) is formed, then we carry out the theoretical analysis and experimental simulation aiming at the performance of the MIA; secondly, we use this algorithm to excavate association rules, and propose a new algorithm of association rule mining, then we can verify that the algorithm is feasible and effective through theoretical analysis and experimental results.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.260","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369516","Association rule mining;Immune algorithm;MIA;Metropolis criterion","Algorithm design and analysis;Association rules;Biology computing;Convergence;Data mining;Immune system;Machine learning algorithms;Performance analysis;Random number generation;Simulated annealing","artificial immune systems;data mining;database management systems;transaction processing","Metropolis immune algorithm;association rules mining;selection operation;transaction database","","1","","7","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Synthesizing Novel Dimension Reduction Algorithms in Matrix Trace Oriented Optimization Framework","J. Yan; N. Liu; S. Yan; Q. Yang; Z. Chen","Sigma Center, Microsoft Res. Asia, Beijing, China","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","598","606","Dimension reduction (DR) algorithms are generally categorized into feature extraction and feature selection algorithms. In the past, few works have been done to contrast and unify the two algorithm categories. In this work, we introduce a matrix trace oriented optimization framework to provide a unifying view for both feature extraction and selection algorithms. We show that the unified view of DR algorithms allows us to discover some essential relationships among many state-of- the-art DR algorithms. Inspired by these essential insights, we propose to synthesize unlimited number of novel DR algorithms by combining, mapping and integrating the state-of-the-art algorithms. We present examples of newly synthesized DR algorithms with experimental results to show the effectiveness of our automatically synthesized algorithms.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360286","dimension reduction;feature extraction;feature selection","Asia;Computer science;Data mining;Feature extraction;Filtering algorithms;Iron;Linear discriminant analysis;Machine learning;Machine learning algorithms;Principal component analysis","data reduction;feature extraction;learning (artificial intelligence)","dimension reduction algorithms;feature extraction algorithms;feature selection algorithms;machine learning;matrix trace oriented optimization framework","","1","","16","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Application of Alternative Covering Neural Networks in Data Classification Based on Rough Set","Q. Zhiming","Sch. of Civil Eng., Hebei Eng. Univ., Handan, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","1","","108","111","Based on discussing in the alternative covering neural networks (ACNN), the integrated algorithm are proposed based on rough set (RS) theory and ACNN. RS is applied to reduce and process the original data. While ensuring the integrity of information, the data dimension is reduced. ACNN is used to design multi-layer forward network. Through using RS to reduce data dimension, the calculation of ACNN is decreased to lower the complexity of network computing. The experimental results prove that the integrated approach is effective. Comparing with the results by K-W method, it is concluded that the importance of the data classification with RS is analyzed and the results are in keeping with the practical data operation, which directly approves better validity of RS in data classification.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369075","ACNN;Data Classification;RS","Artificial neural networks;Civil engineering;Computer networks;Data engineering;Databases;Decision making;Information technology;Intelligent networks;Machine learning algorithms;Neural networks","complex networks;data analysis;data integrity;neural nets;rough set theory","KW results method;alternative covering neural networks;complexity network computing;data classification;data dimension;effective integrated approach;integrity information;multilayer forward network;practical data operation;reduce process original data;rough set theory","","0","","10","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Proxy Signature Scheme Based on Bionic Evolution","X. Zhou","Key Lab. of Network & Inf. Security of the APF, Eng. Coll. of APF, Xi'an, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","3","","678","681","Bionic evolution is an adaptive artificial intelligence technique; it mimics natural evolution process to solve optimization problems. In the paper, we present an improved proxy signature scheme based on bionic evolution. In the scheme, the original private key is generated with bionic evolution algorithm by a successive optimizing process. The optimizing selection algorithm renders effective protection for the private key and the signature system, avoids the insecure randomness in secret parameter selection, and thus prevents generalized signature forgery and coalition attack of original signer and proxy signers. The algorithms of the scheme take great advantage of the superiority of ECC (elliptic curves cryptosystem), such as high efficiency, short key length and etc. The scheme can achieve the same security with less storing space, smaller communication band-width and less overheads of the system and thus proves to be applicable to such circumstances as with restricted computation ability and integrated space, circumstances with limited bandwidth yet requiring for high-speed operation.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.503","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369403","bionic evolution;elliptic curves;private key optimization;proxy signature;system efficiency","Artificial intelligence;Elliptic curve cryptography;Elliptic curves;Evolution (biology);Evolutionary computation;Forgery;Genetic mutations;Genetic programming;Machine learning algorithms;Security","artificial intelligence;digital signatures;evolutionary computation;public key cryptography","adaptive artificial intelligence technique;bionic evolution;coalition attack;elliptic curve cryptosystem;generalized signature forgery;optimizing selection algorithm;proxy signature scheme","","0","","19","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Forecasting Volatility of Stock Market Using Adaptive Fuzzy-GARCH Model","J. C. Hung","Dept. of Inf. Technol., Ling Tung Univ., Taichung, Taiwan","2009 Fourth International Conference on Computer Sciences and Convergence Information Technology","20091231","2009","","","583","587","In this paper, we study the problem of volatility forecasting of financial stock market. In general, stock market volatility is time-varying and nonlinear, and exhibits properties of clustering. This paper shows results from using the method of fuzzy systems to analyze the nonlinear in the case of generalized autoregressive conditional heteroskedasticity (GARCH) models and using the adaptive method of recursive least-squares (RLS) to forecast the stock market volatility. The joint the parameters of membership functions and GARCH model is a rather high nonlinear and complicated problem. This study presents an iterative algorithm based on genetic ones to estimate parameters of the membership functions and GARCH model. The genetic algorithm (GA) method aims to achieve a global optimal solution with a fast convergence rate for this Fuzzy-GARCH model estimation problem. From the simulation results, we have determined that the both estimation of in-sample and forecasting of out-of-sample volatility performance are significantly improved, if the both of leverage effect and adaptive forecast are considered in the GARCH model.","","POD:978-1-4244-5244-6","10.1109/ICCIT.2009.294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367886","GARCH model;forecasting volatility;fuzzy system;genetic algorithm;recursive least-squares","Autoregressive processes;Economic forecasting;Fuzzy systems;Genetics;Information technology;Machine learning algorithms;Parameter estimation;Predictive models;Stock markets;Technology forecasting","autoregressive processes;forecasting theory;fuzzy set theory;fuzzy systems;genetic algorithms;iterative methods;least squares approximations;recursive estimation;stock markets","adaptive fuzzy-GARCH model;convergence rate;financial stock market;fuzzy systems;fuzzy-GARCH model estimation;generalized autoregressive conditional heteroskedasticity models;genetic algorithm method;iterative algorithm;membership functions;parameter estimation;recursive least-squares;stock market volatility;volatility forecasting","","0","","11","","","24-26 Nov. 2009","","IEEE","IEEE Conference Publications"
"A learning classifier system for emergent team behavior in real-time POMDP","I. Anciutti","Knowledge-based Systems, University of Paderborn, 33098, Germany","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","733","738","Often the only solution for many complex and dynamic real-world situations is a crucial concurrent cooperation and coordination divided into tasks and subtasks, i.e. team behavior [1]. This research focus on such problems under real-time constraints, distributed control and decentralized knowledge. Existent frameworks and simulation systems were designed relying heavily on a priori knowledge of experts and introducing little or nothing of Machine Learning (ML). Therefore, the goal here is to develop a team of agents inspired by team behavior as found in Nature - emergent and adaptive - applying only ML on the action-selection decision process. Such team would reduce time and resources in the design of autonomous teamwork while keeping equivalent performance in comparison to a heuristic-based approach. Applying unbiased methods and a divide and conquer strategy, we achieved individual actions that emerge into the aimed collective behavior, not once requiring plans, common beliefs or agreed intentions.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358393","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358393","Genetic Algorithm;Learning Classifier System;Multi Agent Systems;POMDP;Team Behavior","Artificial intelligence;Distributed control;Humans;Knowledge based systems;Machine learning;Real time systems;Robot kinematics;Robustness;Teamwork;Testing","decision making;divide and conquer methods;learning (artificial intelligence);multi-agent systems;pattern classification;real-time systems","action selection decision process;autonomous teamwork design;decentralized knowledge;distributed control;divide and conquer strategy;emergent team behavior;experts priori knowledge;heuristic based approach;learning classifier system;machine learning;real-time POMDP;real-time constraint;unbiased method","","2","","18","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Chinese Text Clustering Method Based on Semantics and Special Domain","D. Jianquan; Z. Jinchao","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2009 International Conference on Web Information Systems and Mining","20091231","2009","","","195","199","In view of ignoring semantic relationship between words, high dimensionality of data and computational complexity when current text clustering algorithms deal with Chinese texts. This paper presents a new method to cluster Chinese texts based on semantics in a specific field-TCBS (Text Clustering Based on Semantics) algorithm. The algorithm is based on the agglomerative hierarchical clustering algorithm, it expresses Chinese texts with the characteristic words and sets relative threshold in order to improve the efficiency of clustering. Compared with the traditional algorithms, the experimental results show that TCBS has effectively enhanced the quality of the clustering.","","POD:978-0-7695-3817-4","10.1109/WISM.2009.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369484","TCBS;Text clustering;characteristic words;semantic;similarity","Algorithm design and analysis;Clustering algorithms;Clustering methods;Computational complexity;Data engineering;Data mining;Information systems;Machine learning;Sun;Text processing","natural language processing;pattern clustering;text analysis","Chinese text clustering;agglomerative hierarchical clustering algorithm;computational complexity;data dimensionality;word semantic relationship","","0","","14","","","7-8 Nov. 2009","","IEEE","IEEE Conference Publications"
"Study on the Damage Identification of Long-Span Cable-Stayed Bridge Based on Support Vector Machine","C. c. Liu; J. Liu; L. j. Liu","Sch. of Civil & Archit. Eng., Northeast Dianli Univ., Jilin, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Method of support vector machine (SVM) as a new machine learning algorithm has shown its superiority of the ability of regression in the fields of damage identification. Through setting variation displacement of mode shape to the feature parameters of damage identification, the method of the damage identification of long-span cable-stayed bridge based on SVM is presented. The method of least square support vector machine is used to cable-stayed bridge damage extent identification, and the identification results of this method which are very close to target are obtained under the condition of small sample. To compare with results from the BP neural network, the precision of the method in this paper is verified.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5366554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366554","","Bridges;Economic forecasting;Educational technology;Least squares methods;Machine learning;Machine learning algorithms;Monitoring;Risk management;Sea measurements;Support vector machines","bridges (structures);condition monitoring;least squares approximations;structural engineering computing;support vector machines","BP neural network;damage identification;least square support vector machine;long span cable stayed bridge;machine learning algorithm","","0","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Optimization of SVM Parameters Based on PSO Algorithm","X. Zhang; Y. Guo","Coll. of Inf. Eng., Taiyuan Univ. of Technol., Taiyuan, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","536","539","Parameters selection of support vector machine is a very important problem, which has great influence on the performance of support vector machine. Particle swarm optimization is an efficient algorithm and it is broadly used in many research areas like pattern recognition and so on. In order to improve the learning and generalization ability of support vector machine, a method for searching the optimal parameters based on particle swarm optimization is proposed in this paper. We constructed a speech recognition system based on support vector machine using the optimal parameters. The kernel function we used is radial basis function and the speech data is isolated, non-specific and middle vocabulary words. The speech feature we used is MFCC feature. Experiments indicate that the accuracy of speech recognition is efficiently improved by using support vector machine of the optimal parameters, which has practicability to some extent. This method provides an efficient approach for searching for optimal parameters of support vector machine.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367100","Particle Swarm Optimization;Support Vector Machine;parameters selection;speech recognition","Error correction;Kernel;Machine learning;Mel frequency cepstral coefficient;Particle swarm optimization;Pattern recognition;Speech recognition;Support vector machine classification;Support vector machines;Vocabulary","particle swarm optimisation;radial basis function networks;speech recognition;support vector machines","MFCC feature;PSO algorithm;SVM parameter optimisation;kernel function;mel-frequency cepstral coefficient;particle swarm optimization;radial basis function;speech recognition;support vector machine","","7","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"An Ensemble Method for Medicine Best Selling Prediction","C. Xiang; M. Chen; H. Wang","Comput. Sci. & Technol. Dept., Guizhou Univ., Guiyang, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","100","103","In this paper the author presents a data mining model based ensemble methodology in medicine selling prediction. The ANN algorithm is utilized for feature selection, and some machine learning techniques are constructed for ensemble model in medicine best selling and best sell season prediction. The verification is conducted on the real cases from GuiYang ZhiFuTang Pharmacy Company Sell data which consists of 63044 records and 17 fields. The real case experiments show that, our approach works effectively and could be used as an assistant approach for selling analysis in some circumstances.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.245","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358643","Data Mining;Ensemble;Prediction","Data mining;Databases;Decision making;Fuzzy systems;Input variables;Machine learning;Machine learning algorithms;Prediction algorithms;Predictive models;Stability","data mining;feature extraction;neural nets;pharmaceutical industry","artificial neural network algorithm;data mining model;ensemble method;feature selection;machine learning technique;medicine best selling prediction","","0","","10","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"An Improved Growing LVQ for Text Classification","X. Wang; H. Shen","Dept. of Comput. Sci. & Technol., Univ. of Sci. & Technol. of China, Hefei, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","114","118","KNN as a simple classification method has been widely applied in text classification. There are two problems in KNN-based text classification: the large computation load and the deterioration of classification accuracy caused by the uneven distribution of training samples. To solve these problems, we propose a new growing LVQ method and apply it to text classification based on minimizing the increment of learning errors. Our method can generate a representative sample (reference sample) set after one phase of training of sample set, and hence has a strong learning ability. The experiment shows the improvement on both time and accuracy. For our algorithm, we also proposed a learning sequence arrangement method which performs better than others.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.340","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358646","","Classification tree analysis;Computer science;Distributed computing;Electronic mail;Fuzzy systems;Machine learning;Machine learning algorithms;Support vector machines;Text categorization;Wavelet domain","learning (artificial intelligence);pattern classification;text analysis","KNN-based text classification;improved growing LVQ;learning errors;learning sequence arrangement;learning vector quantification","","0","","12","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A good all-around semi-supervised learning algorithm for information categorization","L. Liu; Hai Chen; Chao Du","Information Engineering College, CNU, Beijing, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","299","302","The paper reports a study on information categorizing based on high efficient feature selection and comprehensive semi-supervised learning algorithm. Feature selections or conversions are performed using maximum mutual information including linear and non-linear feature conversions. Entropy is made use of and extended to find right features commendably with machine learning method. Fuzzy partition clustering method is presented and used to obtain a few labeled samples and some external clusters automatically by measuring the similarity of clustering correlation documents. So categorization bases are found for supervised learning. Furthermore, naive Bayes augment learning is combined to design and learn categorizers. And the approach of estimating the loss of classifying error facilitates to balance the selection of candidates. The all-around learning algorithm can greatly improve the precision and efficiency of Web information categorization.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357843","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357843","component;dimensionality reduction;fuzzy clustering;web information categorization","Accuracy;Chaos;Clustering algorithms;Clustering methods;Information analysis;Machine learning algorithms;Mutual information;Partitioning algorithms;Semisupervised learning;Space technology","Bayes methods;Internet;classification;fuzzy set theory;learning (artificial intelligence)","Web information categorization;entropy;feature selection;fuzzy partition clustering;machine learning;maximum mutual information;naive Bayes augment learning;semisupervised learning algorithm","","0","","6","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Performance Evaluation of Rate Adaptation Algorithms in 802.11-Based Mesh Networks","S. M. Liu; Y. H. Lin; W. I. Chou; Z. Y. Chen; T. N. Lin","Grad. Inst. Of Commun. Eng., Nat. Taiwan Univ., Taipei, Taiwan","2009 IEEE Globecom Workshops","20091228","2009","","","1","5","Wireless mesh networks (WMNs) have experienced an enormous growth over the past few years. The performance of WMNs depends on the joint effect of both routing algorithms and rate adaptive algorithms. The performance of various routing algorithms has been studied extensively in the literature. However, little work has been done to evaluate the cross-layer impact of rate adaptive algorithms in WMN environments. In this paper, we compare the performance of several rate adaptive algorithms to exploit the multi-hop performance in WMN environments. In addition, a novel rate adaptive algorithm is proposed via the machine learning approach to robustly reflect the channel information. The goal of our design is to maximize the spectral efficiency. Through extensive computer simulations under different channel and topology environments, experimental results demonstrate the proposed algorithm outperforms other existing algorithms in WMN environments.","2166-0077;21660077","POD:978-1-4244-5626-0","10.1109/GLOCOMW.2009.5360718","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360718","","Adaptive algorithm;Fading;Machine learning;Machine learning algorithms;Mesh networks;Robustness;Routing;Signal to noise ratio;Statistics;Wireless mesh networks","adaptive signal processing;learning (artificial intelligence);telecommunication network routing;telecommunication standards;wireless LAN","802.11;channel information;machine learning;multihop performance;rate adaptation algorithm;rate adaptive algorithm;routing algorithm;wireless mesh network","","1","","16","","","Nov. 30 2009-Dec. 4 2009","","IEEE","IEEE Conference Publications"
"A Study on the Relationships of Classifier Performance Metrics","N. Seliya; T. M. Khoshgoftaar; J. V. Hulse","Comput. & Inf. Sci., Univ. of Michigan Dearborn, Dearborn, MI, USA","2009 21st IEEE International Conference on Tools with Artificial Intelligence","20091228","2009","","","59","66","There is no general consensus on which classifier performance metrics are better to use as compared to others. While some studies investigate a handful of such metrics in a comparative fashion, an evaluation of specific relationships among a large set of commonly-used performance metrics is much needed in the data mining and machine learning community. This study provides a unique insight into the underlying relationships among classifier performance metrics. We do so with a large case study involving 35 datasets from various domains and the C4.5 decision tree algorithm. A common property of the 35 datasets is that they suffer from the class imbalance problem. Our approach is based on applying factor analysis to the classifier performance space which is characterized by 22 performance metrics. It is shown that such a large number of performance metrics can be grouped into two-to-four relationship-based groups extracted by factor analysis. This work is a step in the direction of providing the analyst with an improved understanding about the different relationships and groupings among the performance metrics, thus facilitating the selection of performance metrics that capture relatively independent aspects of a classifier's performance.","1082-3409;10823409","POD:978-1-4244-5619-2","10.1109/ICTAI.2009.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364367","binary classification;factor analysis;metrics relationship;performance metrics","Artificial intelligence;Computer science;Data mining;Decision trees;Extraterrestrial measurements;Information science;Machine learning;Machine learning algorithms;Performance analysis;Performance evaluation","data mining;decision trees","classifier performance metrics;data mining;decision tree algorithm;factor analysis;group extraction;machine learning","","24","","20","","","2-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Video2Text: Learning to Annotate Video Content","H. Aradhye; G. Toderici; J. Yagnik","Google, Inc., Mountain View, CA, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","144","151","This paper discusses a new method for automatic discovery and organization of descriptive concepts (labels) within large real-world corpora of user-uploaded multimedia, such as YouTube. com. Conversely, it also provides validation of existing labels, if any. While training, our method does not assume any explicit manual annotation other than the weak labels already available in the form of video title, description, and tags. Prior work related to such auto-annotation assumed that a vocabulary of labels of interest (e. g., indoor, outdoor, city, landscape) is specified a priori. In contrast, the proposed method begins with an empty vocabulary. It analyzes audiovisual features of 25 million YouTube. com videos - nearly 150 years of video data -- effectively searching for consistent correlation between these features and text metadata. It autonomously extends the label vocabulary as and when it discovers concepts it can reliably identify, eventually leading to a vocabulary with thousands of labels and growing. We believe that this work significantly extends the state of the art in multimedia data mining, discovery, and organization based on the technical merit of the proposed ideas as well as the enormous scale of the mining exercise in a very challenging, unconstrained, noisy domain.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360514","","Cities and towns;Conferences;Data mining;Machine learning;Machine learning algorithms;Supervised learning;USA Councils;Videoconference;Vocabulary;YouTube","data mining;learning (artificial intelligence);multimedia computing;social networking (online)","Video2Text;YouTube;data discovery;data organization;multimedia data mining;text metadata;user-uploaded multimedia;video content annotation;video description;video tags;video title","","8","6","21","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Credit Risk Assessment Based on Fuzzy SVM and Principal Component Analysis","Z. Min","Sch. of Electron. & Inf. Eng., Sichuan Univ., Chengdu, China","2009 International Conference on Web Information Systems and Mining","20091231","2009","","","125","127","Credit risk assessment has been an important research topic in customer relationship management. It is also an important field for commercial banks because discriminating good creditors from bad ones is becoming more and more crucial for banks. A Fuzzy Support Vector Machine (FSVM) classification model based on principal component analysis (PCA-FSVM) was advanced, which adapted PCA to extract principal components to replace the original indexes, so that the processing speed and classification accuracy can be improved. Then credit risk assessment example that apply this classification model was provided and compared with the method of SVM and BP neural networks, which shows the better performance and better classification accuracy of PCA-FSVM.","","POD:978-0-7695-3817-4","10.1109/WISM.2009.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368179","credit risk assessment;fuzzy support vector machine;principal component analysis","Data mining;Fuzzy sets;Machine learning;Management information systems;Neural networks;Principal component analysis;Risk management;Support vector machine classification;Support vector machines;Training data","customer relationship management;principal component analysis;risk management;support vector machines","credit risk assessment;customer relationship management;fuzzy support vector machine;principal component analysis","","1","","8","","","7-8 Nov. 2009","","IEEE","IEEE Conference Publications"
"Music Emotion Identification from Lyrics","D. Yang; W. S. Lee","Syst. Sci., Univ. of Ottawa, Ottawa, ON, Canada","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","624","629","Very large online music databases have recently been created by vendors, but they generally lack content-based retrieval methods. One exception is Allmusic.com which offers browsing by musical emotion, using human experts to classify several thousand songs into 183 moods. In this paper, machine learning techniques are used instead of human experts to extract emotions in Music. The classification is based on a psychological model of emotion that is extended to 23 specific emotion categories. Our results for mining the lyrical text of songs for specific emotion are promising, generate classification models that are human-comprehensible, and generate results that correspond to commonsense intuitions about specific emotions. Mining lyrics focused in this paper is one aspect of research which combines different classifiers of musical emotion such as acoustics and lyrical text.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363083","Emotion;Lyrical Text;Music Information Retrieval;Text Classification;Text Mining","Content based retrieval;Data mining;Humans;Machine learning;Mood;Multimedia databases;Multimedia systems;Music information retrieval;Psychology;Text mining","content-based retrieval;data mining;emotion recognition;learning (artificial intelligence);music","content-based retrieval methods;lyrics mining;machine learning techniques;music emotion identification;online music databases","","9","","35","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"EBLearn: Open-Source Energy-Based Learning in C++","P. Sermanet; K. Kavukcuoglu; Y. LeCun","Comput. Sci. Dept., New York Univ., New York, NY, USA","2009 21st IEEE International Conference on Tools with Artificial Intelligence","20091228","2009","","","693","697","Energy-based learning (EBL) is a general framework to describe supervised and unsupervised training methods for probabilistic and non-probabilistic factor graphs. An energy-based model associates a scalar energy to configurations of inputs, outputs, and latent variables. Learning machines can be constructed by assembling modules and loss functions. Gradient-based learning procedures are easily implemented through semi-automatic differentiation of complex models constructed by assembling predefined modules. We introduce an open-source and cross-platform C++ library called EBLearn to enable the construction of energy-based learning models. EBLearn is composed of two major components, libidx: an efficient and flexible multi-dimensional tensor library, and libeblearn: an object-oriented library of trainable modules and learning algorithms. The latter has facilities for such models as convolutional networks, as well as for image processing. It also provides graphical display functions.","1082-3409;10823409","POD:978-1-4244-5619-2","10.1109/ICTAI.2009.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366626","convolutional neural netwoks;energy-based learning;open-source","Artificial intelligence;Assembly;Computer science;Libraries;Machine learning;Object oriented modeling;Open source software;Predictive models;Signal processing algorithms;Training data","C++ language;graph theory;probability;public domain software;unsupervised learning","EBLearn;convolutional networks;cross-platform C++ library;energy-based learning models;energy-based model;gradient-based learning;graphical display functions;image processing;learning algorithms;machine learning;multidimensional tensor library;nonprobabilistic factor graphs;object-oriented library;open-source energy-based learning;probabilistic factor graphs;semiautomatic differentiation;supervised training method;unsupervised training methods","","3","","18","","","2-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"VisGBT: Visually analyzing evolving datasets for adaptive learning","K. Chen; F. Tian","Department of Computer Science and Engineering, Wright State University, Dayton, OH 45435, USA","2009 5th International Conference on Collaborative Computing: Networking, Applications and Worksharing","20091228","2009","","","1","10","Many machine learning problems involve changes in both feature distribution and label distribution, such as domain adaptation and learning drifting concepts from data streams. Correctly detecting, identifying, and understanding the changes of data distributions can help us properly select data samples or algorithms for learning models. However, since the training datasets are often in high dimensionality and large size, it has been difficult to effectively analyze them. Furthermore, the joint distribution between features and labels makes the problem more difficult to handle. In this paper, we propose a visual analysis method (VisGBT) that combines the gradient-boosting-trees (GBT) modeling method, regression analysis, and multidimensional visualization to capture the mismatches between datasets and models. The GBT model consists of a series of trees with a predefined number of terminal (leaf) nodes per tree. These terminal nodes partition the high dimensional space with a few most informative features to minimize the label prediction error. VisGBT maps various kinds of detailed model information to the terminal node matrix (TNM) and visualizes it with an appropriate design. With this visual analysis method, we can easily find out the detailed differences between datasets with the help of a learned model. We will illustrate the use of various visual patterns and in particular show how this method can help us analyze domain similarity for domain adaptation.","","CD-ROM:978-963-9799-76-9","10.4108/ICST.COLLABORATECOM2009.8281","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362573","","Computer science;Costs;Data analysis;Data engineering;Data visualization;Machine learning;Machine learning algorithms;Multidimensional systems;Regression analysis;Training data","data visualisation;gradient methods;learning (artificial intelligence);matrix algebra;regression analysis;trees (mathematics)","VisGBT;adaptive machine learning;data streams;domain adaptation;evolving training datasets;feature distribution;gradient-boosting-trees modeling method;label distribution;label prediction error;learning drifting concepts;multidimensional visualization;regression analysis;terminal node matrix;tree nodes;visual analysis method;visual patterns","","0","","35","","","11-14 Nov. 2009","","IEEE","IEEE Conference Publications"
"Evaluating Statistical Tests for Within-Network Classifiers of Relational Data","J. Neville; B. Gallagher; T. Eliassi-Rad","Purdue Univ., West Lafayette, IN, USA","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","397","406","Recently a number of modeling techniques have been developed for data mining and machine learning in relational and network domains where the instances are not independent and identically distributed (i.i.d.). These methods specifically exploit the statistical dependencies among instances in order to improve classification accuracy. However, there has been little focus on how these same dependencies affect our ability to draw accurate conclusions about the performance of the models. More specifically, the complex link structure and attribute dependencies in network data violate the assumptions of many conventional statistical tests and make it difficult to use these tests to assess the models in an unbiased manner. In this work, we examine the task of within-network classification and the question of whether two algorithms will learn models which will result in significantly different levels of performance. We show that the commonly-used form of evaluation (paired t-test on overlapping network samples) can result in an unacceptable level of Type I error. Furthermore we show that Type I error increases as (1) the correlation among instances increases and (2) the size of the evaluation set increases (i.e., the proportion of labeled nodes in the network decreases). We propose a method for network cross-validation that combined with paired t-tests produces more acceptable levels of Type I error while still providing reasonable levels of statistical power (i.e., Type II error).","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360265","","Algorithm design and analysis;Data mining;Laboratories;Machine learning;Machine learning algorithms;Performance analysis;Probability;Standards development;Taxonomy;Testing","data mining;learning (artificial intelligence);pattern classification;relational databases;statistical testing","complex link structure;data mining;machine learning;network cross-validation;relational data;statistical test;within-network classifier","","4","","26","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"The Impact of Pruning BayesFuzzy Rule Set","I. H. Yin; E. R. Hruschka Jr.; H. d. A.","Fed. Univ. of Sao Carlos, Sao Carlos, Brazil","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","456","461","The use of Bayesian Network Classifiers (BCs) combined with the Fuzzy rule model to explain the learned BCs have been previously presented as the BayesFuzzy approach. This paper follows along BayesFuzzy lines of investigation aiming at improving the comprehensibility of a BC model and enhancing BayesFuzzy results by combining new pruning methods. In order to improve BayesFuzzy performance, in addition to the Markov Blanket-based pruning idea used by BayesFuzzy, two other pruning methods are proposed, implemented and empirically evaluated. The first pruning method is based on the conditional probability estimates given by the BC and the second one is the well-known post-rule pruning approach, usually used to prune rules extracted from decision trees. Also, three different Bayesian Networks induction algorithms, namely IC, K2 and Naive-Bayes, as well as, the C4.5 Decision Tree induction algorithms are employed in the empirical comparative analysis performed in the experiments. The obtained results reveal that BayesFuzzy combined with the new pruning methods can bring comprehensibility enhancements.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364919","Bayesian Networks;Fuzzy Classification Rules","Algorithm design and analysis;Bayesian methods;Decision trees;Fuzzy sets;Fuzzy systems;Intelligent systems;Learning systems;Machine learning;Performance analysis;Probability distribution","Bayes methods;Markov processes;belief networks;decision trees;estimation theory;fuzzy set theory;pattern classification","Bayes fuzzy rule set pruning;Bayesian network classifier;Bayesian networks induction algorithm;C4.5 decision tree induction algorithm;Markov blanket based pruning idea;Naive Bayes algorithm;conditional probability estimation;post rule pruning approach","","1","","18","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Workload modeling using pseudo2D-HMM","A. Moro; E. Mumolo; M. Nolich","DEEI, University of Trieste, Italy","2009 IEEE International Symposium on Modeling, Analysis & Simulation of Computer and Telecommunication Systems","20091228","2009","","","1","2","In this paper, we present a novel approach for accurate modeling of computer workloads. According to this approach, the sequences of features generated by a program during its execution are considered as time series and are processed with signal processing techniques both for feature extraction and statistical pattern matching. In the feature extraction phase we used spectral analysis for describing the sequence and to retain the important information. In the pattern matching phase we used a simplified form of bidimensional Hidden Markov Model, called pseudo2D-HMM, as Statistical Machine Learning Algorithm. Several processes of the same workload are necessary to obtain a 2D-HMM model of the workload. In this way, the models are obtained in an initial training phase; we developed techniques for on-line workload classification of a running process and for synthetic traces generation. The proposed algorithms is evaluated via trace-driven simulations using the SPEC 2000 workloads. We show that pseudo2D-HMMs accurately describe memory references sequences; the classification accuracy is about 92% with six different workloads.","1526-7539;15267539","POD:978-1-4244-4927-9","10.1109/MASCOT.2009.5366721","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366721","","Application software;Computational modeling;Feature extraction;Hidden Markov models;Machine learning algorithms;Pattern matching;Signal generators;Signal processing;Signal processing algorithms;Spectral analysis","feature extraction;hidden Markov models;learning (artificial intelligence);signal processing;time series","SPEC 2000 workloads;bidimensional Hidden Markov Model;computer workloads;feature extraction;on-line workload classification;pseudo2D-HMM;signal processing techniques;spectral analysis;statistical machine learning algorithm;statistical pattern matching;synthetic traces generation;time series;trace-driven simulations;workload modeling","","3","","9","","","21-23 Sept. 2009","","IEEE","IEEE Conference Publications"
"An Improved Cache-Based PTSVM Learning Algorithm","Y. Piao; P. Wu; X. k. Wang; Q. Sun","Software Sch., Dalian Univ. of Technol., Dalian, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Support vector machine is gaining popularity due to many attractive features and promising empirical performance in the fields of nonlinear and high dimensional pattern recognition. TSVM (transductive support vector machine) takes into account a particular test set and tries to minimize misclassifications of just those particular examples. PTSVM (progressive transductive support vector machine) can automatically adapt to different data distributions and realize a transductive learning of support vectors in a more general sense. However, the process of pairwise labeling of PTSVM in the margin band is unnatural and products errors more easily. Although dynamical adjusting offers some sort of error recovery function, its ability is limited. In allusion to the shortcomings of PTSVM learning algorithm, ICPTSVM (an improved cache-based PTSVM) learning algorithm is presented. The algorithm uses pairwise labeling in the range and error-correcting on cache to replace pairwise labeling in the margin band and dynamical adjusting. Then it greatly reduces the number of mis-labeling and improves the speed and accuracy. Experiments data show the validity of this algorithm.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365786","","Inference algorithms;Labeling;Machine learning;Pattern recognition;Software algorithms;Software performance;Statistical learning;Sun;Support vector machines;Testing","learning (artificial intelligence);pattern recognition;support vector machines","error recovery function;error-correcting;high dimensional pattern recognition;pairwise labeling;progressive transductive support vector machine;transductive learning algorithm","","0","","13","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Network Traffic Classification Based on Error-Correcting Output Codes and NN Ensemble","X. Xie; B. Yang; Y. Chen; L. Wang; Z. Chen","Sch. of Inf. Sci. & Eng., Univ. of Jinan, Jinan, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","3","","475","479","Classification of network traffic is basic and essential for many network researches and managements. However, classification of network traffic using port-based and simple payload-based methods is diminished with the rapid development of peer-to-peer (P2P) application using dynamic port, disguising techniques and encryption to avoid detection. An alternative method based on statistics and machine learning has attracted researchers' attention in recent years. In this paper, a new approach based on the implementation of artificial neural network ensemble with the error-correcting output codes (ECOC) is proposed for classification of multi-class network traffic. As the error-correcting output codes have error correcting ability and improve the generalization ability of the base classifiers the experiments show that the proposed method can improve the multi-class classification accuracy by 12%-20% on datasets captured on the backbone router of our campus through a week.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359021","ANN;ECOC;Network Traffic Classification","Cryptography;Error correction codes;Information science;Internet;Knowledge engineering;Machine learning;Neural networks;Peer to peer computing;Statistics;Telecommunication traffic","computer network management;computer network security;error correction codes;learning (artificial intelligence);neural nets;peer-to-peer computing;telecommunication computing;telecommunication traffic","artificial neural network;dynamic port;error correcting output code;machine learning;multiclass network traffic classification;peer-to-peer application;statistical method","","2","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Detection of Quantization Data Hiding","X. Y. Yu; A. Wang","Sch. of Comput. & Inf. Eng., Anyang Normal Univ., Anyang, China","2009 International Conference on Multimedia Information Networking and Security","20091231","2009","1","","45","47","We proposes a method to estimate secret message length of secret message embedded using quantization index modulation (QIM) based data hiding in digital images. The Secret Message Length estimation equation is constructed used for embedding ratio estimation. Our experimental results have demonstrated that the proposed steganalyzers can is a reliably way to estimate the secret message length of QIM based data hiding.","2162-8998;21628998","POD:978-0-7695-3843-3","10.1109/MINES.2009.272","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368983","steganalysis","Computer networks;Computer security;Data encapsulation;Data security;Discrete cosine transforms;Histograms;Information security;Machine learning algorithms;Quantization;Steganography","quantisation (signal);steganography","digital images;quantization data hiding;quantization index modulation;secret message length estimation equation;steganalyzers","","3","","7","","","18-20 Nov. 2009","","IEEE","IEEE Conference Publications"
"Estimation of Covering Number in Learning Theory","J. Wang; H. Huang; Z. Luo; B. Chen","Sch. of Math. & Stat., Southwest Univ., Chongqing, China","2009 Fifth International Conference on Semantics, Knowledge and Grid","20091231","2009","","","388","391","Using the Chebyshev nodes and methods in reference, we established the estimation of covering number of learning theory in reproducing kernel Hilbert space. A counter example is presented to show that the estimation of covering number of Gaussian kernel functions.","","POD:978-0-7695-3810-5","10.1109/SKG.2009.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370097","Covering number;Learning theory;Reproducing kernel Hilbert space","Art;Chebyshev approximation;Counting circuits;Extraterrestrial measurements;Hilbert space;Interpolation;Kernel;Machine learning;Mathematics;Statistics","Chebyshev approximation;Gaussian processes;Hilbert spaces;learning (artificial intelligence)","Chebyshev nodes;Gaussian kernel functions;covering number;kernel Hilbert space;learning theory","","0","","6","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A New Minimally Supervised Learning Method for Semantic Term Classification - Experimental Results on Classifying Ratable Aspects Discussed in Customer Reviews","T. P. T. Nguyen; T. Hayashi; R. Onai; Y. Nishioka; T. Takenaka; M. Mori","Univ. of Electro-Commun., Chofu, Japan","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","43","50","We present Bautext, a new minimally supervised approach for automatically extracting ratable aspects from customer reviews and classifying them to some previously defined categories. Bautext requires a small amount of seed words as supervised data and uses a bootstrapping mechanism o progressively collect new member for each category. Learning new category members and the category-specific terms for each category at the same time is the unique and featured classification mechanism of Bautext. Category-specific terms are terms that play important roles for properly extracting new category members. Furthermore, we proposed to use an additional trash category to filter non-purpose aspects, thus led to a significant improvement in precision score but could constrain the trade-off in decreasing recall score. Experimental results, conducted on a Japanese hotel review dataset, showed that Bautext outperforms the alternative techniques in all terms of precision, recall score and significantly in running time. And in the further comparison to Adaboost (as the state-of-the-art machine learning technique for semantic term classification task), we found that Adaboost require about 50% training data to deliver a similar performance as Bautext does with less than ten selective seed words for each category.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360527","","Conferences;Data mining;Digital cameras;Displays;Filters;Frequency;Machine learning;Measurement standards;Supervised learning;Training data","learning (artificial intelligence);pattern classification","Adaboost;Bautext;Japanese hotel review dataset;bootstrapping mechanism;both automatic extention;customer reviews;machine learning technique;minimally supervised learning method;ratable aspects extraction;seed words;semantic term classification task;supervised data;trash category","","0","","12","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"A method to enhance the efficiency of Markov blanket for BN in medical diagnosis","Yanping Yang; Enmin Song; Guangzhi Ma; Ming Li","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","411","415","Although successfully used in medical diagnosis, Bayesian network is facing great challenge due to the relatively small amount of diagnosed data and the large dimension of features. To address this issue, this paper presents an effective method for creating Markov blanket when building Bayesian network models. The proposed approach consists of two stages. In the first stage, a clustering based method is introduced to rebuild a representative training data by exploiting the undiagnosed data. In the second stage for feature selection, Markov blanket is built up with the consideration of feature interaction. To evaluate its performance, eight disease datasets from UCI machine learning database are chosen and four off-the-shelf classification algorithms are used for comparison. The test result showed that our approach has better classification accuracy than other traditional methods. Furthermore, two stages in our approaches are isolated in experiment to check their relative efficiency.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357812","Bayesian network;Markov blanket;Medical diagnosis","Bayesian methods;Diseases;Hospitals;Machine learning;Machine learning algorithms;Medical diagnosis;Probability distribution;Space technology;Testing;Training data","Markov processes;belief networks;diseases;medical diagnostic computing;pattern clustering","Bayesian network;Markov blanket;clustering based method;disease;feature interaction;feature selection;medical diagnosis;off-the-shelf classification algorithm;representative training data","","0","","19","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Ontology Learning Through Focused Crawling and Information Extraction","H. P. Luong; S. Gauch; Q. Wang","CSCE Dept., Univ. of Arkansas, Fayetteville, AR, USA","2009 International Conference on Knowledge and Systems Engineering","20091228","2009","","","106","112","Ontology learning aims to facilitate the construction of ontologies by decreasing the amount of effort required to produce an ontology for a new domain. However, there are few studies that attempt to automate the entire ontology learning process from the collection of domain-specific literature, to text mining to build new ontologies or enrich existing ones. In this paper, we present a complete framework for ontology learning that enables us to retrieve documents from the Web using focused crawling, and then use a SVM (support vector machine) classifier to identify domain-specific documents and perform text mining in order to extract useful information for the ontology enrichment process. We have carried out several experiments on components of this framework in a biological domain, amphibian morphology. This paper reports on the overall system architecture and our initial experiments on information extraction using text mining techniques to enrich the domain ontology.","","POD:978-1-4244-5086-2","10.1109/KSE.2009.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361721","SVM;focused crawling;information extraction;ontology learning;text mining","Data mining;Humans;Information retrieval;Machine learning;Morphology;Ontologies;Support vector machine classification;Support vector machines;Text mining;Vocabulary","biology computing;data mining;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);pattern classification;support vector machines;text analysis","SVM classifier;Web document retrieval;amphibian morphology;domain-specific documents;focused crawling;information extraction;ontology enrichment process;ontology learning;support vector machine;text mining","","4","","16","","","13-17 Oct. 2009","","IEEE","IEEE Conference Publications"
"An Improved AdaBoost Algorithm for Unbalanced Classification Data","J. Song; X. Lu; X. Wu","Sch. of Stat., Renmin Univ. of China, Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","109","113","AdaBoost algorithm is proved to be a very efficient classification method for the balanced dataset with all classes having similar proportions. However, in real application, it is quite common to have unbalanced dataset with a certain class of interest having very small size. It will be problematic since the algorithm might predict all the cases into majority classes without loss of overall accuracy. This paper proposes an improved AdaBoost algorithm called BABoost (Balanced AdaBoost), which gives higher weights to the misclassified examples from the minority class. Empirical results show that the new method decreases the prediction error of minority class significantly with increasing the prediction error of majority class a little bit. It can also produce higher values of margin which indicates a better classification method.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358645","AdaBoost;classification;multiclass;unbalanced data;within group error","Bagging;Classification algorithms;Fuzzy systems;Machine learning;Machine learning algorithms;Prediction algorithms;Probability;Sampling methods;Statistics;Voting","Ada;data handling;pattern classification","BABoost;balanced AdaBoost;unbalanced classification data","","5","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Information Extraction for Clinical Data Mining: A Mammography Case Study","H. Nassif; R. Woods; E. Burnside; M. Ayvaci; J. Shavlik; D. Page","Dept. of Comput. Sci., Univ. of Wisconsin-Madison, Madison, WI, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","37","42","Breast cancer is the leading cause of cancer mortality in women between the ages of 15 and 54. During mammography screening, radiologists use a strict lexicon (BI-RADS) to describe and report their findings. Mammography records are then stored in a well-defined database format (NMD). Lately, researchers have applied data mining and machine learning techniques to these databases. They successfully built breast cancer classifiers that can help in early detection of malignancy. However, the validity of these models depends on the quality of the underlying databases. Unfortunately, most databases suffer from inconsistencies, missing data, inter-observer variability and inappropriate term usage. In addition, many databases are not compliant with the NMD format and/or solely consist of text reports. BI-RADS feature extraction from free text and consistency checks between recorded predictive variables and text reports are crucial to addressing this problem. We describe a general scheme for concept information retrieval from free text given a lexicon, and present a BI-RADS features extraction algorithm for clinical data mining. It consists of a syntax analyzer, a concept finder and a negation detector. The syntax analyzer preprocesses the input into individual sentences. The concept finder uses a semantic grammar based on the BI-RADS lexicon and the experts' input. It parses sentences detecting BI-RADS concepts. Once a concept is located, a lexical scanner checks for negation. Our method can handle multiple latent concepts within the text, filtering out ultrasound concepts. On our dataset, our algorithm achieves 97.7% precision, 95.5% recall and an F<sub>1</sub>-score of 0.97. It outperforms manual feature extraction at the 5% statistical significance level.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360530","","Breast cancer;Cancer detection;Data mining;Data preprocessing;Detectors;Feature extraction;Information retrieval;Machine learning;Mammography;Spatial databases","cancer;data mining;feature extraction;information retrieval;learning (artificial intelligence);mammography","BI-RADS feature extraction;breast cancer classifiers;clinical data mining;concept finder;free text;information extraction;machine learning techniques;mammography case study;negation detector;semantic grammar;syntax analyzer","","7","","34","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Novel Ant Colony Optimization Approach to Feature Selection Based on Fuzzy Entropy","X. Li; H. Xi; H. Lin","Sch. of Comput. Sci., Northeast Normal Univ., Changchun, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Feature selection is a most important procedure which can affect the performance of pattern recognition systems. Since most feature selection algorithms easily fall into local optimum, a novel ant colony optimization approach to feature selection based on fuzzy entropy is proposed (ACOFE). In the proposed algorithm, fuzzy entropy is adopted as pheromone information for ant colony optimization. In order to verify the proposed approach, datasets in UCI Machine Learning Repository are used to test the performance. Simulation experiment results demonstrate that this approach provides higher classification accuracy.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365508","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365508","","Ant colony optimization;Computer science;Entropy;Fuzzy set theory;Fuzzy sets;Fuzzy systems;Machine learning;Machine learning algorithms;Pattern recognition;Testing","entropy;fuzzy set theory;learning (artificial intelligence);optimisation;pattern recognition","UCI machine learning repository;ant colony optimization;feature selection;fuzzy entropy;pattern recognition systems","","1","","24","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Novel Gaussian Kernel Paramter Choosing Method","B. Yang; Y. Bu","Coll. of Mech. & Electr. Eng., Central South Univ., Changsha, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","3","","83","86","Choosing appropriate values for kernel parameters is one of the key problems in many kernel-based methods. Beside common used cross validation method which is time-consuming, another kind of rapid methods using kernel matrix evaluation criteria such as kernel target alignment(KTA) and Feature space-based kernel matrix evaluation measurement(FSM) criteria were proposed by researchers. However, we find KTA and FSM maybe failing in learning Gaussian kernel parameter in the case of small sampling size and tend to obtain an overfit solution. In this paper, a novel approach is proposed to learn Gaussian the kernel parameter which works in reproducing kernel mapping space and can avoid above problem. Experiments on real-world datasets show that the proposed approach using the two proposed criteria in this paper works well on learning Gaussian kernel parameter.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369503","","Educational institutions;Eigenvalues and eigenfunctions;Information technology;Kernel;Machine learning;Matrix decomposition;Performance analysis;Sampling methods;Support vector machines","Gaussian processes;learning (artificial intelligence);matrix algebra","Gaussian kernel parameter choosing method;cross validation method;feature space-based kernel matrix evaluation measurement criteria;kernel mapping space;kernel matrix evaluation criteria;kernel target alignment;kernel-based methods;learning Gaussian kernel parameter","","0","","7","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"A Chinese Classifier Research for Query Intention and Non-query Intention","W. Xiaohui; G. Allan; S. Pingping; Z. Rongxin","Dept. of Inf. Manage., Hubei Univ. of Automotive Technol., Shiyan, China","2009 Fifth International Conference on Semantics, Knowledge and Grid","20091231","2009","","","366","370","Previous research to improve the performance of Internet search engines has focused on classifying questions, sentences and user-goals but not the classification of sentences and phrases based on query intention and non-query intention. This paper investigates a classification system of query intention and non-query intention of sentences and phrases by firstly analyzing previous work and based on this we move on to designing an implementation framework model that improves the efficiency and effectiveness of using search engines. Testing was carried out and comparisons analyzed between the known Liner, Polynomial, RBF and Sigmoid categorizations and our new framework under strict laboratory conditions. The test results show that the accuracy of classifier classification is improved by up to 2.1% and recall is improved by up to 2%.","","POD:978-0-7695-3810-5","10.1109/SKG.2009.1","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370018","","Automotive engineering;Classification tree analysis;Influenza;Information retrieval;Internet;Machine learning;Search engines;Support vector machine classification;Support vector machines;Testing","Internet;classification;natural language processing;polynomials;query processing;radial basis function networks;search engines","Chinese classifier research;Internet search engines;RBF;Sigmoid categorizations;classification system;non-query intention;polynomial","","0","","15","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A New Topic Filter Based on Maximum Entropy Model","C. Chen; H. Liu; G. Wang; L. Yu","Key Lab. of Med. Image Comput., Northeastern Univ., Shenyang, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","7","","495","499","Because of the large web scale and the information requirement for special field, focuse2825453011d search has attracted more and more people. For the complexity of natural language, there are ambiguous for a word itself, and which will take some trouble for topic filter. For the two main problems, false positive and false negative, this paper proposes two new methods separately. By machine learning, we construct a guide model with the maximum entropy principle, by which we can filter the noise pages out easily and by KNN method, the false negative problem will be solved easily. The experiment shows that our model or method really out performs the base-line method.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.709","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360059","","Biomedical imaging;Educational institutions;Entropy;Fuzzy systems;Information filtering;Information filters;Laboratories;Machine learning;Search engines;Systems engineering education","information filters;learning (artificial intelligence);maximum entropy methods;natural languages","KNN method;base-line method;focuse2825453011d search;information requirement;machine learning;maximum entropy model;natural language;noise pages;topic filter;web scale","","0","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Marrow Cell Segmentation by Simulating Visual System","C. Pan; F. Cao","Coll. of Inf. Eng., China Jiliang Univ., Hangzhou, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","189","194","This paper presents a two-stage machine learning method by simulating visual system for segmentation of marrow cell image. Firstly, the scale space clustering is employed to simulate primary visual system to separate image into series regions with similar colours. Different from traditional methods, we focus on a few significant clusters rather than all of them. Priori knowledge is considered to group useful samples for machine learning to simulate visual attention. Secondly, SVM classifier is used to discriminate the pixels of object from background. We could control the performance of classifier by constructing the training set of SVM according to priori knowledge and the characteristics of cell structure. So visual attention could be realized in some degree in our method. Experimental results demonstrate the new method is more accurate and robust than standard SSF (Scale space filter) and mean-shift based algorithm without attention.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365897","Image segmentation;SVM;marrow cell;scale-space clustering;visual system","Brain modeling;Computational modeling;Eyes;Humans;Image segmentation;Learning systems;Machine learning;Support vector machine classification;Support vector machines;Visual system","bone;image classification;image segmentation;learning (artificial intelligence);medical image processing;support vector machines","SVM classifier;machine learning method;marrow cell image segmentation;scale space clustering;simulating visual system","","0","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Multiple Instance Transfer Learning","D. Zhang; L. Si","Comput. Sci. Dept., Purdue Univ., West Lafayette, IN, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","406","411","Transfer Learning is a very important branch in both machine learning and data mining. Its main objective is to transfer knowledge across domains, tasks and distributions that are similar but not the same. Currently, almost all of the transfer learning methods are designed to deal with the traditional single instance learning problems. However, in many real-world applications, such as drug design, localized content based image retrieval (LCBIR), text categorization, we have to deal with multiple instance problems, where training patterns are given as bags and each bag consists of some emph{instances}. This paper formulates a novel multiple instance transfer learning (MITL) problem and suggests a method to solve it. An extensive set of empirical results demonstrate the advantages of the proposed method against several existed ones.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360439","","Computer science;Content based retrieval;Data mining;Design methodology;Drugs;Image retrieval;Learning systems;Machine learning;Text categorization;USA Councils","data mining;learning (artificial intelligence)","data mining;machine learning;multiple instance transfer learning;single instance learning;training patterns;transfer knowledge","","3","","17","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Information Transparency Evaluation Method Based on SVM","W. Hang; D. Junfa","Hangzhou Inst. of Commerce, Zhejiang Gongshang Univ., Hangzhou, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","1","","630","633","Nowadays, information disclosure is a noticeable topic to both practice and academy since it has significant effect on corporate governance and capital market operation. Open and transparent information disclosure can reduce the information asymmetry between insiders and outsiders. The main purpose of this study is to construct an information transparency evaluation model. In this paper, we used the information disclosure record obtained from the website of the Shenzhen Stock Exchange (SSE) as the level of listed companies information transparency and employed the support vector machine technique for building classification model. Experimental results demonstrate that the SVM has better performance than other methods and it is a considerable approach for information transparency research.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370426","SVM;classification;information disclosure;transparency","Buildings;Business;Educational institutions;Guidelines;Information technology;Machine learning;Manufacturing;Stock markets;Support vector machine classification;Support vector machines","information management;pattern classification;stock markets;support vector machines","Shenzhen Stock Exchange;capital market operation;classification model;corporate governance;information asymmetry;information disclosure;information transparency evaluation;support vector machine","","0","","11","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Backpropagation-Based Non Linear PCA for Biomedical Applications","A. Landi; P. Piaggi; G. Pioggia","Dep. of Electr. Syst. & Autom., Univ. of Pisa, Pisa, Italy","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","635","640","Machine learning methodologies such as artificial neural networks (ANN), fuzzy logic or genetic programming, as well as principal component analysis (PCA) and intelligent control have been recently introduced in medicine. ANNs imitate the structure and workings of the human brain by means of mathematical models able to adapt several parameters. ANNs learn the input/output behavior of a system through a supervised or an unsupervised learning algorithm. In this work, we present and demonstrate a new pre-processing algorithm able to improve the performance of an ANN in the processing of biomedical datasets. The algorithm was tested analyzing lung function and fractional exhaled nitric oxide differences in the breath in children with allergic bronchial asthma and in normal population. Classification obtained using non linear PCA based on the new algorithm shows a better precision in separating asthmatic and control subjects.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365019","Neural networks;back-propagation;nonlinear PCA","Artificial neural networks;Fuzzy logic;Genetic programming;Humans;Intelligent control;Machine learning;Mathematical model;Principal component analysis;Testing;Unsupervised learning","medical computing;neural nets;principal component analysis;unsupervised learning","allergic bronchial asthma;artificial neural networks;backpropagation-based non linear PCA;biomedical applications;fractional exhaled nitric oxide differences;fuzzy logic;genetic programming;human brain;intelligent control;lung function;machine learning methodologies;mathematical models;principal component analysis;supervised learning algorithm;unsupervised learning algorithm","","0","","9","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Rule-Based Extraction of Spatial Relations in Natural Language Text","C. Zhang; X. Zhang; W. Jiang; Q. Shen; S. Zhang","Key Lab. of Virtual Geogr. Environ., Nanjing Normal Univ., Nanjing, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Intelligent geographical information systems (GISs) have been paid much attention in recent years, and the ultimate goal is to realize the natural language interaction between users and GISs. However, there is still a significant challenge for bridging the semantic gap between structured geospatial data in GISs and un-analytical spatial information in natural language. The representation and analysis of spatial relations has been one of generic issues in geographical information science. This paper presents a rule-based approach to spatial relation extraction in natural language text. Based on geographical named entity recognition technology and a spatial relation annotation corpus, syntactical rules of spatial relations are induced and then formalized into JAPE of the natural language processing platform GATE. Geographical named entities and spatial relations in new documents can be detected effectively in GATE. The experimental results indicate that spatial relations are usually described with several syntactical patterns in natural language, especially directional spatial relations, but topological relations are much more complicated. The fact is that rule-based extraction approaches can be implemented and integrated by means of fewer efforts than machine learning algorithms. It is known that directional spatial relations are more popularly used in natural language than topological spatial relations. Therefore, we conclude that it is practical and effective to extract spatial relations in natural language with rule-based approaches.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5363900","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363900","","Cities and towns;Data mining;Geography;Information analysis;Information science;Information systems;Layout;Machine learning algorithms;Natural language processing;Natural languages","geographic information systems;knowledge based systems;natural language processing","GATE;GIS;JAPE;geographical named entity recognition technology;intelligent geographical information system;natural language text;rule-based extraction;spatial relation annotation corpus;spatial relation extraction;structured geospatial data","","5","","18","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Semi-Supervised Sequence Labeling with Self-Learned Features","Y. Qi; P. Kuksa; R. Collobert; K. Sadamasa; K. Kavukcuoglu; J. Weston","Machine Learning Dept., NEC Labs. America Inc., Princeton, NJ, USA","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","428","437","Typical information extraction (IE) systems can be seen as tasks assigning labels to words in a natural language sequence. The performance is restricted by the availability of labeled words. To tackle this issue, we propose a semi-supervised approach to improve the sequence labeling procedure in IE through a class of algorithms with self-learned features (SLF). A supervised classifier can be trained with annotated text sequences and used to classify each word in a large set of unannotated sentences. By averaging predicted labels over all cases in the unlabeled corpus, SLF training builds class label distribution patterns for each word (or word attribute) in the dictionary and re-trains the current model iteratively adding these distributions as extra word features. Basic SLF models how likely a word could be assigned to target class types. Several extensions are proposed, such as learning words' class boundary distributions. SLF exhibits robust and scalable behaviour and is easy to tune. We applied this approach on four classical IE tasks: named entity recognition (German and English), part-of-speech tagging (English) and one gene name recognition corpus. Experimental results show effective improvements over the supervised baselines on all tasks. In addition, when compared with the closely related self-training idea, this approach shows favorable advantages.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360268","information extraction;self-learned features;semi-supervised feature learning;semi-supervised learning;sequence labeling;structural output learning","Computer science;Data mining;Labeling;Machine learning;National electric code;Natural language processing;Neural networks;Predictive models;Tagging;USA Councils","learning (artificial intelligence);natural language processing","annotated text sequences;gene name recognition corpus;information extraction systems;named entity recognition;natural language sequence;part-of-speech tagging;self-learned features;semisupervised sequence labeling;supervised classifier;tasks assigning labels","","1","","37","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Stochastic Offline Programming","Y. Malitsky; M. Sellmann","Dept. of Comput. Sci., Brown Univ., Providence, RI, USA","2009 21st IEEE International Conference on Tools with Artificial Intelligence","20091228","2009","","","784","791","We propose a framework which we call stochastic off-line programming (SOP). The idea is to embed the development of combinatorial algorithms in an off-line learning environment which helps the developer choose heuristic advisors that guide the search for satisfying or optimal solutions. In particular, we consider the case where the developer has several heuristic advisors available. Rather than selecting a single heuristics, we propose that one of the heuristics is chosen randomly whenever the heuristic guidance is sought. The task of SOP is to learn favorable instance-specific distributions of the heuristic advisors in order to boost the average-case performance of the resulting combinatorial algorithm.","1082-3409;10823409","POD:978-1-4244-5619-2","10.1109/ICTAI.2009.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365884","","Artificial intelligence;Automatic programming;Computer science;History;Machine learning;Machine learning algorithms;Portfolios;Programming profession;Statistics;Stochastic processes","algorithm theory;heuristic programming;stochastic programming","average case performance;choose heuristic advisors;combinatorial algorithms development;heuristic guidance sought;instance specific distributions;offline learning environment;resulting combinatorial algorithm;satisfying optimal solutions;stochastic offline programming","","1","","16","","","2-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Using Smart Sampling to Discover Promising Regions and Increase the Efficiency of Differential Evolution","V. V. Melo; A. C. B. Delbem","Inst. of Math. & Comput. Sci., Univ. of Sao Paulo, Sao Carlos, Brazil","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","1394","1399","This paper presents a novel method to discover promising regions in a continuous search space. Using machine learning techniques, the algorithm named smart sampling was tested in hard known benchmark functions, and was able to find promising regions with solutions very close to the global optimum, significantly decreasing the number of evaluations needed by a metaheuristic to finally find this global optimum, when heuristically started inside a promising region. Results show favorable agreement with theories which state the importance of an adequate starting population. The results also present significant improvement in the efficiency of the tested metaheuristic, without adding any parameter, operator or strategy. Being a technique which can be used by any populational metaheuristic, the work presented here has profound implications for future studies of global optimization and may help solve considerably difficult optimization problems.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363936","Differential Evolution;Global Numerical Optimization;Promising Regions;Smart Sampling","Application software;Benchmark testing;Clustering algorithms;Intelligent systems;Iterative algorithms;Machine learning;Machine learning algorithms;Mathematics;Sampling methods;Space exploration","evolutionary computation;learning (artificial intelligence);sampling methods","continuous search space;differential evolution;global optimization;machine learning;populational metaheuristic;promising regions;smart sampling","","0","","18","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Malware Detection Using Perceptrons and Support Vector Machines","D. Gavrilut; M. Cimpoesu; D. Anton; L. Ciortuz","Fac. of Comput. Sci., Al. I. Cuza Univ. of Iasi, Iasi, Romania","2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns","20091228","2009","","","283","288","In this paper we explore the capabilities of a framework that can use different machine learning algorithms to successfully detect malware files, aiming to minimize the number of false positives. We report the results obtained in our framework, working firstly with cascades of one-sided perceptron and kernelized one-sides perceptrons and secondly with cascade of one-sided support vector machines.","","POD:978-1-4244-5166-1","10.1109/ComputationWorld.2009.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359599","malware;perceptrons;support vector machines;viruses","Application software;Computer displays;Computer networks;Computer science;Face detection;Machine learning;Machine learning algorithms;Support vector machine classification;Support vector machines;Testing","invasive software;multilayer perceptrons;support vector machines","machine learning algorithms;malware detection;malware files;one-sided perceptron;support vector machines","","4","1","17","","","15-20 Nov. 2009","","IEEE","IEEE Conference Publications"
"Matrix Algorithm for Computing Pawlak Reduction","W. Cui; Z. Xu","Sch. of Humanities & Economic Manage., China Univ. of Geosci.(Beijing), Beijing, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","5","Rough set theory is emerging as a powerful toll for reasoning about data. Attribute reduction is one of important topics in the research on the rough set theory. Heuristic, discernibility matrix and matrix method are three usually methods for designing attribute reduction algorithm in attribute reduction based on rough set. Some researchers use matrix method to design attribute reduction algorithm. The time complexity of the algorithm is O(|C|<sup>3</sup>|U|<sup>2</sup>), and the computation of the algorithm is time consuming. To lower the time complexity, it was first proposed a new matrix, and provided an attribute reduction definition based on the new matrix. Then it was proved that the new attribute reduction definition is the same as the old reduction. At last, we used the matrix of attribute to define the significance of attribute, and designed a new attribute reduction algorithm, which time complexity is cut to O(|C||U|)+O(|C|<sup>2</sup>|U/C|<sup>2</sup>). At the same time, an example was used to illustrate the new algorithm.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365387","","Algorithm design and analysis;Design methodology;Educational institutions;Energy management;Geology;Information systems;Machine learning;Machine learning algorithms;Power generation economics;Set theory","data mining;matrix algebra;rough set theory","Pawlak reduction;attribute reduction algorithm;data reasoning;matrix algorithm;rough set theory;time complexity","","0","","12","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Improved Research Method about the Similarity Calculation of Ontology","X. f. Li; P. Yin; M. Zheng","Key Lab. in Machine Learning and Computational, Intelligence, College of Mathematics and Computer Science Hebei University Baoding, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Ontology mapping has been widely used in ontology application, but the similarity calculation becomes a thorny issue in the process of ontology mapping. In this paper, the different elements of ontology are considered. Semantic similarity and concept similarity are integrated to get the ontology similarity. During the similarity calculation of the concept attributes, filter strategy is used to reduce the number of concept attributes, and a method of attributes similarity calculation is proposed. In addition, comprehensive similarity calculation method is given including the semantic and the concept of ontology. The experiment results show that this approach can improve the precision effectively.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5367092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367092","concept similarity;ontology;ontology mapping;similarity calculation","Competitive intelligence;Computational intelligence;Computer science;Computer science education;Dictionaries;Filters;Learning systems;Machine learning;Mathematics;Ontologies","information filtering;ontologies (artificial intelligence)","attributes similarity calculation method;comprehensive similarity calculation method;concept similarity calculation;filter strategy;ontology mapping process;semantic similarity calculation","","0","","13","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Application of RS Theory and SVM in the Ore-Rock Classification","D. Seng; W. Chen","Dept. of Comput. & Inf. Eng., Zhejiang Water Conservancy & Hydropower Coll., Hangzhou, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","One of the main goals in machine learning is the general functional dependencies. Recent advances in kernel-based methods are focused on designing flexible and powerful input and output representations. This paper describes how rough set (RS) and support vector machine (SVM) can be practically implemented in ore-rock classification, and discusses the kernel mapping technique which is used to construct SVM solutions. In ore-rock classification using RS theory and SVM, original sample data is preprocessed with the knowledge reduction algorithm of RS theory, and the redundant condition attributes and conflicting samples are eliminated from the training sample sets to reduce space dimension of the data. Preprocessed data is used as training data of SVM, and fuzzy discrete model is used as training model. The results show that the RS and SVM can improve the training speed and precision of ore-rock classification.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365160","","Application software;Data analysis;Machine learning;Ores;Power engineering and energy;Power engineering computing;Set theory;Support vector machine classification;Support vector machines;Water conservation","learning (artificial intelligence);minerals;mining;pattern classification;production engineering computing;rocks;rough set theory;support vector machines","RS theory;SVM;data preprocessing;kernel mapping technique;kernel-based methods;machine learning;mining engineering;ore-rock classification;rough set theory","","0","","12","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Design of Artificial Neural Networks Using a Memetic Pareto Evolutionary Algorithm Using as Objectives Entropy versus Variation Coefficient","J. C. Fernndez; C. Hervs; F. J. Martnez; M. Cruz","Dept. of Comput. Sci., Univ. of Cordoba, Cordoba, Spain","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","408","413","This paper proposes a multi-classification pattern algorithm using multilayer perceptron neural network models which try to boost two conflicting main objectives of a classifier, a high correct classification rate and a high classification rate for each class. To solve this machine learning problem, we consider a memetic Pareto evolutionary approach based on the NSGA2 algorithm (MPENSGA2), where we defined two objectives for determining the goodness of a classifier: the cross-entropy error function and the variation coefficient of its sensitivities, because both measures are continuous functions, making the convergence more robust. Once the Pareto front is built, we use an automatic selection methodology of individuals: the best model in accuracy (upper extreme in the Pareto front). This methodology is applied to solve six benchmark classification problems, obtaining promising results and achieving a high classification rate in the generalization set with an acceptable level of accuracy for each class.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364897","Classification;Entropy;Multi-objective;Neural Networks;Variation Coefficient","Algorithm design and analysis;Artificial neural networks;Convergence;Entropy;Evolutionary computation;Machine learning;Machine learning algorithms;Multi-layer neural network;Multilayer perceptrons;Neural networks","Pareto optimisation;entropy;evolutionary computation;generalisation (artificial intelligence);learning (artificial intelligence);multilayer perceptrons;pattern classification","NSGA2 algorithm;Pareto front;artificial neural networks;automatic selection methodology;benchmark classification problems;cross-entropy error function;generalization set;machine learning problem;memetic Pareto evolutionary algorithm;memetic Pareto evolutionary approach;multiclassification pattern algorithm;multilayer perceptron neural network models;objectives entropy;variation coefficient","","0","","19","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Naive Bayes Classification of Uncertain Data","J. Ren; S. D. Lee; X. Chen; B. Kao; R. Cheng; D. Cheung","Dept. of Comput. Sci., Sun Yat-sen Univ., Guangzhou, China","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","944","949","Traditional machine learning algorithms assume that data are exact or precise. However, this assumption may not hold in some situations because of data uncertainty arising from measurement errors, data staleness, and repeated measurements, etc. With uncertainty, the value of each data item is represented by a probability distribution function (pdf). In this paper, we propose a novel naive Bayes classification algorithm for uncertain data with a pdf. Our key solution is to extend the class conditional probability estimation in the Bayes model to handle pdf's. Extensive experiments on UCI datasets show that the accuracy of naive Bayes model can be improved by taking into account the uncertainty information.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360338","Uncertain data mining;naive Bayes model","Classification algorithms;Computer science;Data mining;Kernel;Machine learning algorithms;Measurement errors;Probability distribution;Sun;Testing;Uncertainty","belief networks;learning (artificial intelligence);probability","machine learning algorithms;naive Bayes classification;probability distribution function;uncertain data classification","","18","","16","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Prediction of Concrete Carbonation Depth Based on Support Vector Regression","R. Xiang","Dept. of Geotechnical Eng., Tongji Univ., Shanghai, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","3","","172","175","Concrete carbonation depth forecasting is significant to avoid the cracking of concrete. In the study, support vector regression (SVR) which is the regression model of support vector machine (SVM) is proposed to forecast concrete carbonation depth. Water cement ratio, cement consumption and service time have an important influence on concrete carbonation depth, so they are important features in concrete carbonation depth forecasting. Real case data from historical concrete carbonation depth are used in the paper. The experimental results indicate that the proposed SVR model has higher forecasting accuracy than artificial neural network.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369550","concrete carbonation depth;forecasting accuracy;forecasting method;support vector regression","Artificial neural networks;Civil engineering;Concrete;Cost function;Information technology;Machine learning;Predictive models;Support vector machines;Technology forecasting;Training data","civil engineering computing;concrete;regression analysis;support vector machines","artificial neural network;cement consumption;concrete carbonation depth forecasting;service time;support vector machine;support vector regression;water cement ratio","","0","","5","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Fast SVM incremental learning based on clustering algorithm","Du Hongle; Teng Shaohua; Zhu Qingfang","Faculty of Computer, Guangdong University of technology, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","13","17","In the incremental learning process of support vector machines, the non-support vectors which is close to support vector samples are discarded in tradition method. But it is likely to change into the support vector after adding new training samples. To resolve this problem, this paper proposes a new method that combines support vector machine with clustering algorithm. In this method, firstly, use clustering algorithm to cluster the training sample set and get clustering particles ; secondly, look all centers of clustering particles as new samples training set and reconstruct the training samples set; then, train the new training samples set with fuzzy support vector machine (FSVM) and obtain the support vectors, and discard the samples that satisfy KKT conditions, put the samples that don not meet the KKT conditions and the support vectors together to reconstitute a new training set, train them again . Experimental results show that this method can enhance the classification accuracy rate and improve the speed of SVM training and classification speed, as keeping the generalization ability of SVM incremental learning.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357942","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357942","Incremental learning;KKT condition;Support vector machine;cluster algorithm","Clustering algorithms;Educational institutions;Fuzzy sets;Machine learning;Machine learning algorithms;Mathematics;Pattern recognition;Statistical learning;Support vector machine classification;Support vector machines","fuzzy set theory;learning (artificial intelligence);pattern clustering;support vector machines","classification speed;clustering algorithm;fast SVM incremental learning process;fuzzy support vector machine","","1","","15","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"An efficient algorithm for modeling spatially-correlated process variation in statistical full-chip leakage analysis","Z. Ye; Z. Yu","Tsinghua University","2009 IEEE/ACM International Conference on Computer-Aided Design - Digest of Technical Papers","20091228","2009","","","295","301","Statistical full-chip leakage analysis considering spatial correlation is highly expensive due to its O(N<sup>2</sup>) complexity for logic circuits with N gates. Although efforts have been made to reduce the cost at the loss of accuracy, existing methods are still unsuitable for large-scale problems. In this paper we resolve the problem by re-formulating the computation to one that can be done efficiently using a well-developed technique that has been widely used in fast EM simulation and machine learning areas. The resulting algorithm is provably of O(N) or O(N log N) complexity with well-defined and easily-controlled error bounds. Experiments show that using the proposed method it is feasible to handle million-gate circuits within only a few minutes on a regular desktop PC. The corresponding error is less than 0.5% compared to exhausted computation that takes more than 3 days. The proposed method is about 300 faster and 10 more accurate compared to existing grid-approximation method.","1092-3152;10923152","CD-ROM:978-1-60558-800-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361278","","Algorithm design and analysis;Circuit simulation;Computational modeling;Costs;Large-scale systems;Leakage current;Logic circuits;Machine learning;Machine learning algorithms;Spatial resolution","computational complexity;electrical engineering computing;integrated circuit modelling;leakage currents","O(N log N) complexity;O(N) complexity;O(N<sup>2</sup>) complexity;efficient algorithm;error bounds;logic circuits;spatially-correlated process variation;statistical full-chip leakage analysis","","0","","17","","","2-5 Nov. 2009","","IEEE","IEEE Conference Publications"
"Hierarchical Probabilistic Segmentation of Discrete Events","G. Shani; C. Meek; A. Gunawardana","Inf. Syst. Engineeering, Ben-Gurion Univ., Beer-Sheva, Israel","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","974","979","Segmentation, the task of splitting a long sequence of discrete symbols into chunks, can provide important information about the nature of the sequence that is understandable to humans. Algorithms for segmenting mostly belong to the supervised learning family, where a labeled corpus is available to the algorithm in the learning phase. We are interested, however, in the unsupervised scenario, where the algorithm never sees examples of successful segmentation, but still needs to discover meaningful segments. In this paper we present an unsupervised learning algorithm for segmenting sequences of symbols or categorical events. Our algorithm, Hierarchical Multigram, hierarchically builds a lexicon of segments and computes a maximum likelihood segmentation given the current lexicon. Thus, our algorithm is most appropriate to hierarchical sequences, where smaller segments are grouped into larger segments. Our probabilistic approach also allows us to suggest conditional entropy as a measurement of the quality of a segmentation in the absence of labeled data. We compare our algorithm to two previous approaches from the unsupervised segmentation literature, showing it to provide superior segmentation over a number of benchmarks. We also compare our algorithm to previous approaches over a segmentation of the unlabeled interactions of a web service and its client.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.87","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360342","Multigram;Segmentation;Software analysis","Application software;Data mining;Entropy;Humans;Information systems;Instruments;Machine learning;Software maintenance;Voting;Web services","Web services;discrete event systems;entropy;hierarchical systems;unsupervised learning","benchmarks;conditional entropy;discrete events;discrete symbols;hierarchical multigram;hierarchical probabilistic segmentation;lexicon;maximum likelihood segmentation;supervised learning family;unsupervised learning algorithm;unsupervised segmentation literature;web service","","0","","10","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"HOCT: A Highly Scalable Algorithm for Training Linear CRF on Modern Hardware","T. Chen; L. Chang; J. Ma; W. Zhang; F. Gao","Fudan Univ., Shanghai, China","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","276","281","Conditional Random Fields (CRFs) are widely used in machine learning and natural language processing fields. A number of methods have been developed for CRF training. However, even with state-of-the-art algorithms, the training of CRF is still very time and space consuming. This make it infeasible to use CRFs in large-scale data analysis tasks. This paper proposes an efficient algorithm, HOCT, for CRF training on modern computer architectures. First, software prefetching techniques are utilized to hide cache miss latency. Second, we exploit SIMD to process data in parallel. Third, when dealing with large data sets, we let HOCT instead of operating system to manage swapping operations. Our experiments on various real data sets show that HOCT yields a fourfold speedup when the data can fit in memory, and over a 30-fold speedup when the memory requirement exceeds the physical memory.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360418","","Computer architecture;Data analysis;Delay;Hardware;Large-scale systems;Machine learning;Machine learning algorithms;Management training;Natural language processing;Prefetching","data analysis;learning (artificial intelligence);natural language processing;parallel processing;storage management","CRF training;HOCT algorithm;SIMD process;conditional random fields;large-scale data analysis tasks;machine learning;natural language processing;parallel processing;software prefetching techniques","","0","","12","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Multi-agent Co-evolutionary Scheduling Approach Based on Genetic Reinforcement Learning","W. Yingzi; J. Xinli; H. Pingbo; G. Kanfeng","Shenyang Ligong Univ., Shenyang, China","2009 Fifth International Conference on Natural Computation","20091228","2009","5","","573","577","The paper presents an adaptive iterative distributed scheduling algorithm that operates dynamically to schedule the job in the dynamic job-shop. The manufacturing system is scheduled by the multi-agent system where every machine and job is associated with its own software agent. Each agent learns how to select presumably good schedules, by this way the size of the search space can be reduced. In order to get adaptive behavior, genetic algorithm is incorporated to drive parallel search and the evolution direction. Meanwhile, the reinforcement learning system is done with the phased Q-learning by defining the intermediate state pattern. The paper suggests a cooperation technique for the agents, as well. We also analyze the time and the solution and present some experimental results.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366784","","Biological cells;Dispatching;Dynamic scheduling;Genetic algorithms;Job shop scheduling;Machine learning;Machine learning algorithms;Optimal scheduling;Processor scheduling;Scheduling algorithm","genetic algorithms;job shop scheduling;learning (artificial intelligence);multi-agent systems","Q-learning;distributed scheduling algorithm;dynamic job-shop;genetic algorithm;genetic reinforcement learning;multi-agent co-evolutionary scheduling;multi-agent system","","0","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"GSML: A Unified Framework for Sparse Metric Learning","K. Huang; Y. Ying; C. Campbell","Nat. Lab. of Pattern Recognition, Chinese Acad. of Sci., Beijing, China","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","189","198","There has been significant recent interest in sparse metric learning (SML) in which we simultaneously learn both a good distance metric and a low-dimensional representation. Unfortunately, the performance of existing sparse metric learning approaches is usually limited because the authors assumed certain problem relaxations or they target the SML objective indirectly. In this paper, we propose a generalized sparse metric learning method (GSML). This novel framework offers a unified view for understanding many of the popular sparse metric learning algorithms including the sparse metric learning framework proposed, the large margin nearest neighbor (LMNN), and the D-ranking vector machine (D-ranking VM). Moreover, GSML also establishes a close relationship with the pairwise support vector machine. Furthermore, the proposed framework is capable of extending many current non-sparse metric learning models such as relevant vector machine (RCA) and a state-of-the-art method proposed into their sparse versions. We present the detailed framework, provide theoretical justifications, build various connections with other models, and propose a practical iterative optimization method, making the framework both theoretically important and practically scalable for medium or large datasets. A series of experiments show that the proposed approach can outperform previous methods in terms of both test accuracy and dimension reduction, on six real-world benchmark datasets.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360244","Metric Learning;Sparse;Unified Framework","Automation;Data engineering;Data mining;Laboratories;Machine learning;Nearest neighbor searches;Pattern recognition;Sparse matrices;Support vector machines;Virtual manufacturing","iterative methods;learning (artificial intelligence);optimisation;support vector machines","D-ranking vector machine;GSML;iterative optimization;large margin nearest neighbor;pairwise support vector machine;relevant vector machine;sparse metric learning","","12","","23","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Fast Online Training of Ramp Loss Support Vector Machines","Z. Wang; S. Vucetic","Dept. of Comput. & Inf. Sci., Temple Univ., Philadelphia, PA, USA","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","569","577","A fast online algorithm OnlineSVM<sup>R</sup> for training Ramp-Loss Support Vector Machines (SVM<sup>R</sup>s) is proposed. It finds the optimal SVM<sup>R</sup> for t + 1 training examples using SVMR built on t previous examples. The algorithm retains the Karush-Kuhn-Tucker conditions on all previously observed examples. This is achieved by an SMO-style incremental learning and decremental unlearning under the Concave-Convex Procedure framework. Further speedup of training time could be achieved by dropping the requirement of optimality. A variant, called OnlineASVM<sup>R</sup>, is a greedy approach that approximately optimizes the SVM<sup>R</sup> objective function and is suitable for online active learning. The proposed algorithms were comprehensively evaluated on 9 large benchmark data sets. The results demonstrate that OnlineSVM<sup>R</sup> (1) has the similar computational cost as its offline counterpart; (2) outperforms IDSVM, its competing online algorithm that uses hinge-loss, in terms of accuracy, model sparsity and training time. The experiments on online active learning show that for a fixed number of label queries OnlineASVM<sup>R</sup> (1) achieves consistently better accuracy than QueryAll and competitive accuracy to Greedy approach; (2) outperforms the active learning version of IDSVM.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360283","CCCP;SMO;SVM;active learning;online learning;ramp loss","Computational efficiency;Cost function;Data mining;Fasteners;Large-scale systems;Machine learning;Machine learning algorithms;Support vector machines;Training data;USA Councils","computer aided instruction;concave programming;convex programming;learning (artificial intelligence);support vector machines","Karush-Kuhn-Tucker conditions;concave-convex procedure framework;decremental unlearning;incremental learning;online active learning;online training;onlineSVMR;ramp loss support vector machines","","0","","17","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Conditional Models for Non-smooth Ranking Loss Functions","A. Dubey; J. Machchhar; C. Bhattacharyya; S. Chakrabarti","IBM Res., India","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","129","138","Learning to rank is an important area at the interface of machine learning, information retrieval and Web search. The central challenge in optimizing various measures of ranking loss is that the objectives tend to be non-convex and discontinuous. To make such functions amenable to gradient based optimization procedures one needs to design clever bounds. In recent years, boosting, neural networks, support vector machines, and many other techniques have been applied. However, there is little work on directly modeling a conditional probability Pr(y|x<sub>q</sub>) where y is a permutation of the documents to be ranked and x<sub>q</sub> represents their feature vectors with respect to a query q. A major reason is that the space of y is huge: n! if n documents must be ranked. We first propose an intuitive and appealing expected loss minimization objective, and give an efficient shortcut to evaluate it despite the huge space of ys. Unfortunately, the optimization is non-convex, so we propose a convex approximation. We give a new, efficient Monte Carlo sampling method to compute the objective and gradient of this approximation, which can then be used in a quasi-Newton optimizer like LBFGS. Extensive experiments with the widely-used LETOR dataset show large ranking accuracy improvements beyond recent and competitive algorithms.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360238","Conditional Models;Learning to Rank;Monte Carlo Sampling","Boosting;Design optimization;Information retrieval;Loss measurement;Machine learning;Monte Carlo methods;Neural networks;Optimization methods;Support vector machines;Web search","Monte Carlo methods;convex programming;information retrieval;learning (artificial intelligence);neural nets;support vector machines","LETOR dataset;Monte Carlo sampling method;Web search;boosting;conditional probability;convex approximation;information retrieval;machine learning;neural networks;non-convex optimization;nonsmooth ranking loss functions;quasi-Newton optimizer;support vector machines","","2","","20","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Semi-supervised Learning Applied to Large Data Sets with Very Few Labeled Examples","H. Chen; G. Guo","Sch. of Math. & Comput. Sci., Fujian Normal Univ., Fuzhou, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","281","285","A semi-supervised classification approach, SS-LFL, is proposed. In SS-LFL, some weak binary classifiers, each of which can identify instances of one particular class, are firstly trained on the labeled data, and the whole data set is then clustered into partitions until they are tight and pure enough. SS-LFL alternates between assigning imperfect-classes to the unlabeled data in these partitions and constructing the next weak binary classifiers using both the labeled and imperfect data. It works well in large data sets with very few labeled examples, moreover, it neither requires known parametric distributions of data nor participation of an expert. Experimental results carried out on some public datasets collected from the UCI machine learning repository show that SS-LFL is a promising method.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358593","Large Data Sets;Semi-Supervised Learning;Very Few Labeled Examples","Application software;Computer science;Content based retrieval;Fuzzy systems;Humans;Image retrieval;Information retrieval;Machine learning;Mathematics;Semisupervised learning","learning (artificial intelligence);pattern classification;pattern clustering","UCI machine learning repository;binary classifiers;semisupervised classification approach;semisupervised learning","","0","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Extending Semi-supervised Learning Methods for Inductive Transfer Learning","Y. Shi; Z. Lan; W. Liu; W. Bi","Sch. of Software, Sun Yat-sen Univ. Guangzhou, Guangzhou, China","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","483","492","Inductive transfer learning and semi-supervised learning are two different branches of machine learning. The former tries to reuse knowledge in labeled out-of-domain instances while the later attempts to exploit the usefulness of unlabeled in-domain instances. In this paper, we bridge the two branches by pointing out that many semi-supervised learning methods can be extended for inductive transfer learning, if the step of labeling an unlabeled instance is replaced by re-weighting a diff-distribution instance. Based on this recognition, we develop a new transfer learning method, namely COITL, by extending the co-training method in semi-supervised learning. Experimental results reveal that COITL can achieve significantly higher generalization and robustness, compared with two state-of-the-art methods in inductive transfer learning.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360274","Inductive transfer learning;co-training;semi-supervised learning","Computer science;Data mining;Labeling;Learning systems;Machine learning;Robustness;Semisupervised learning;Sun;Training data;Web pages","learning (artificial intelligence)","cotraining method;diff-distribution instance;inductive transfer learning;machine learning;re-weighting instance;semisupervised learning methods","","4","","18","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Novel Two-Phase Method for the Classification of Incomplete Data","X. Qu; B. Yuan; W. Liu","Grad. Sch. Shenzhen, Tsinghua Univ., Shenzhen, China","2009 International Conference on Information Management, Innovation Management and Industrial Engineering","20091231","2009","3","","452","455","The issue of incomplete data exists across the entire field of data mining. In this paper, a novel two-phase method is developed to deal with the challenge of incomplete data on classification problems. In phase I, the dataset is divided into disjoint subsets based on the attributes with missing values. In phase II, each subset is used to train appropriate classification algorithms respectively in parallel. Experimental results show that the proposed scheme works favorably compared to other techniques on both synthesized and real data sets.","2155-1456;21551456","POD:978-0-7695-3876-1","10.1109/ICIII.2009.418","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369135","classification;feature deletion;imputation;incomplete data;missing values","Accidents;Blood;Classification algorithms;Data mining;Industrial engineering;Information management;Innovation management;Loss measurement;Machine learning;Testing","data mining;pattern classification","data mining;data sets;feature deletion;incomplete data classification;missing values;two-phase method","","1","","19","","","26-27 Dec. 2009","","IEEE","IEEE Conference Publications"
"Churn Prediction in Telecom Using a Hybrid Two-phase Feature Selection Method","H. Xu; Z. Zhang; Y. Zhang","Sch. of Manage. Huazhong, Univ. of Sci. & Technol., Wuhan, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","3","","576","579","Costumer feature selection is one of the core issues of Costumer churn prediction in telecom industry. This paper proposes a hybrid two-phase feature selection method which can effectively reduce feature dimension and promote predicting performance by using both traditional expertise approach and Markov blanket discovery technique. Empirical results of a branch of a Chinese wireless telecom company show that it is a feasible and superior method for telecom costumer feature selection. The results also show better performance of our method than the method based on traditional expertise approach.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370159","Customer Relationship management;IAMB;Markov blanket discovery;churn prediction;two-phase feature selection method","Communication industry;Costs;Customer relationship management;Engineering management;Industrial relations;Information technology;Machine learning;Predictive models;Technology management;Telecommunications","Markov processes;telecommunication industry","Chinese wireless telecom company;Markov blanket discovery technique;costumer churn prediction;costumer feature selection;hybrid two-phase feature selection method;telecom industry;traditional expertise approach","","2","","11","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"A Novel Algorithm Based on Conditional Entropy Established by Clustering for Feature Selection","P. Yang; M. Yang","Sch. of Math. Sci., Nanjing Normal Univ. Nanjing, Nanjing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","410","415","Feature selection is an important issue in machine learning. Rough set theory is one of the important methods for feature selection. In rough set theory, feature selection has already been separately studied in algebra view and information view. Unfortunately, the previously proposed methods based on information entropy for feature selection only focus on the discrete datasets. However, how to effectively discretize the continuous datasets is also full of challenge, since this method may lead to loss of some useful information. To overcome this disadvantage, in this paper, we introduce a novel algorithm based on conditional entropy by clustering strategy for feature selection (ACECFS). In ACECFS, the projected data corresponding to each feature is appropriately separated into several clusters at first, and then the conditional entropy for a set of features is conveniently computed by the clusters and corresponding feature list is generated, hence an effectively relevant and compact feature subset can be obtained from the ranked feature list. Experiments show the effectiveness of ACECFS.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358553","Clustering;Conditional Entropy;Feature Selection","Algebra;Clustering algorithms;Entropy;Feature extraction;Filters;Fuzzy systems;Machine learning;Machine learning algorithms;Pattern recognition;Set theory","learning (artificial intelligence);pattern clustering;rough set theory","compact feature subset;conditional entropy;feature selection clustering;information entropy;machine learning;rough set theory","","0","","17","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A New Adaptive Immune Genetic Algorighm","Z. Chang; G. Zhu","Shandong Univ. of Technol., Zibo, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","1","","395","397","The theories of machine-learning are applied to the immune genetic algorithm. Chromosomes' immunity is enhanced and the average fitness of chromosomes is improved by using adaptive vaccine, so as to avoid the loss of the best solution, shrink the searching space and speed up the evolution, then the best solution can be get earlier. At the same time, the results are compared with each other through the optimization calculation of the modified immune genetic algorithm and the traditional genetic algorithm in solving classic 3  3 JSP problem.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362148","","Biological cells;Encoding;Flowcharts;Genetic algorithms;Machine learning;Machine learning algorithms;Scheduling algorithm;Space technology;Time factors;Vaccines","genetic algorithms;job shop scheduling;learning (artificial intelligence)","adaptive immune genetic algorithm;adaptive vaccine;chromosomes immunity;job shop scheduling problem;machine learning","","0","","7","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Erratum","","","IEEE Micro","20091231","2009","29","6","4","4","","0272-1732;02721732","","10.1109/MM.2009.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5372150","","Bandwidth;Frequency;Interference;Machine learning;Microarchitecture;Multicore processing;Power system management;Proposals;Resource management;Runtime","","","","0","","","","","Nov.-Dec. 2009","","IEEE","IEEE Journals & Magazines"
"Improving Academic Performance Prediction by Dealing with Class Imbalance","N. Thai-Nghe; A. Busche; L. Schmidt-Thieme","Inf. Syst. & Machine Learning Lab., Univ. of Hildesheim, Hildesheim, Germany","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","878","883","This paper introduces and compares some techniques used to predict the student performance at the university. Recently, researchers have focused on applying machine learning in higher education to support both the students and the instructors getting better in their performances. Some previous papers have introduced this problem but the prediction results were unsatisfactory because of the class imbalance problem, which causes the degradation of the classifiers. The purpose of this paper is to tackle the class imbalance for improving the prediction/classification results by over-sampling techniques as well as using cost-sensitive learning (CSL). The paper shows that the results have been improved when comparing with only using baseline classifiers such as Decision Tree (DT), Bayesian Networks (BN), and Support Vector Machines (SVM) to the original datasets.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364086","","Classification tree analysis;Data mining;Degradation;Information systems;Intelligent systems;Learning systems;Machine learning;Nearest neighbor searches;Support vector machine classification;Support vector machines","Bayes methods;belief networks;decision trees;education;support vector machines","Bayesian networks;academic performance prediction;class imbalance;cost-sensitive learning;decision tree;machine learning;support vector machines","","8","","23","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Augmenting Historical Manuscripts with Automatic Hyperlinks","X. Wang; E. Keogh","Dept. of Comput. Sci. & Eng., Univ. of California Riverside, Riverside, CA, USA","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","571","576","Hyperlinks are so useful for searching and browsing modern digital collections that researchers have longer wondered if it is possible to retroactively add hyperlinks to digitized historical documents. There has already been significant research into this endeavor for historical text; however, in this work we consider the problem of adding hyperlinks among graphic elements. While such a system would not have the ubiquitous utility of text-based hyperlinks, as we will show, there are several domains where it can significantly augment textual information. While OCR of historical text is known to be a difficult problem, the actual words themselves are inherently discrete. Thus, two words are either identical or not. This means that off-the-shelf machine learning algorithms, including semi-supervised learning, can be easily used. However, as we shall demonstrate, semi-supervised learning does not work well with images, because we cannot expect binary matching decisions. Rather we must deal with degrees of matching. In this work we make the novel observation that this degree of matching biased algorithms make overly confident predictions about simple shapes. We show that a simple technique for correcting this bias, and demonstrate through extensive experiments that our method significantly improves accuracy on diverse historical image collections.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362526","Historical Manuscripts;Hyperlinks;Semi-Supervised Learning","Books;Computer science;Euclidean distance;Graphics;Humans;Machine learning algorithms;Optical character recognition software;Semisupervised learning;Shape measurement;USA Councils","learning (artificial intelligence);text analysis","automatic hyperlinks;binary matching decisions;degree of matching biased algorithms;digital collection browsing;digitized historical documents;diverse historical image collections;historical manuscript augmentation;off-the-shelf machine learning algorithms;semisupervised learning;text-based hyperlinks;textual information augmentation;ubiquitous utility","","1","","23","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"Combining Uncertainty Sampling Methods for Active Meta-Learning","R. B. C. Prudncio; T. B. Ludermir","Center of Inf., Fed. Univ. of Pernambuco, Recife, Brazil","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","220","225","Meta-learning has been applied to acquire useful knowledge to predict learning performance. Each training example in meta-learning (i.e. each meta-example) is related to a learning problem and stores features of the problem plus the performance obtained by a set of candidate algorithms when evaluated on the problem. Based on a set of such meta-examples, a meta-learner will be used to predict algorithm performance for new problems. The generation of a set of meta-examples can be expensive, since for each problem it is necessary to perform an empirical evaluation of the candidate algorithms. In a previous work, we proposed the active meta-learning, in which active learning was used to reduce the set of meta-examples by selecting only the most relevant problems for meta-example generation. In the current work, we proposed the combination of different uncertainty sampling methods for active meta-learning, considering that each individual method will provide useful information that can be combined in order to have a better assessment of problem relevance for meta-example generation. In our experiments, we observed a gain in meta-learning performance when the proposed method was compared to the individual active methods being combined.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364790","active-learning;meta-learning","Intelligent systems;Machine learning;Machine learning algorithms;Multilayer perceptrons;Performance evaluation;Performance gain;Prediction algorithms;Proposals;Sampling methods;Uncertainty","learning (artificial intelligence);uncertainty handling","active meta-learning;meta-example generation;supervised machine learning;uncertainty sampling methods","","0","","17","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Constructing Weak Learner and Performance Evaluation in AdaBoost","M. Zhou; H. Wei","Dept. of Educ. Technol., Tianjin Foreign Studies Univ., Tianjin, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","This paper gives a deep investigation into AdaBoost algorithm, which is used to boost the performance of any given learning algorithm. Within AdaBoost, weak learners are crucial and primitive parts of the algorithm. Since weak learners are required to train with weights, two types of weak learners: artificial neural network weak learner and naive Bayes weak learner are designed. The results show AdaBoost by naive Bayes weak learners is superior to artificial neural network weak learners, it shares the same generalisation ability with support vector machine.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5362581","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362581","","Artificial neural networks;Boosting;Iris;Machine learning;Machine learning algorithms;Optical character recognition software;Optical noise;Probability distribution;Support vector machines;Testing","Bayes methods;learning (artificial intelligence);neural nets;support vector machines","AdaBoost;artificial neural network weak learner;learning algorithm;naive Bayes weak learner;support vector machine","","2","","17","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Dynamic Pricing Model for E-commerce Based on Data Mining","Y. Chen; F. Wang","Center for the Studies of Inf. Resources, Wuhan Univ., Wuhan, China","2009 Second International Symposium on Computational Intelligence and Design","20091231","2009","1","","363","366","In this paper, a dynamic pricing model for e-commerce based on data mining is proposed after the comprehensive analysis of data mining technology applications and e-commerce dynamic pricing strategies. The authors introduce this model into the pricing mechanisms of TaoBao, and discuss the application of the model in C2C and B2C modes, which has great reference value for e-commerce enterprise operation.","","POD:978-0-7695-3865-5","10.1109/ISCID.2009.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370169","TaoBao;data mining;dynamic pricing model;e-commerce","Computational intelligence;Data analysis;Data mining;Decision making;Electronic commerce;Game theory;Information analysis;Information resources;Machine learning;Pricing","data mining;electronic commerce;pricing","B2C modes;C2C modes;business-to-consumer modes;consumer-to-consumer modes;data mining;dynamic pricing model;e-commerce","","1","","10","","","12-14 Dec. 2009","","IEEE","IEEE Conference Publications"
"The Relationship between Generalization Error and the Training Sample Number of SVM","J. Bai; G. Yan; W. Mao","Key Lab. of Strength & Vibration of Minist. of Educ., Xi'an Jiaotong Univ., Xi'an, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","574","577","It is very important to construct the training set and determine the sample number in the regression problem. In this paper, a new idea of constructing the training set is elaborated. The key point of this idea is to choose the hyper-parameters before determining the training set. More importantly, a heuristic approach is proposed to select samples of support vector machine (SVM). Using these methods, the relationship between generalization error and the number of training samples on a given confidence level is computed. The empirical results on benchmark data (Boston Housing) and engineering data indicate that the proposed approach can give a reference to construct the proper training set. Moreover, the proposed approach has practical significance for other parametric learning machine.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.479","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365471","Generalization Error;Training Sample;support vector machine","Accuracy;Benchmark testing;Data engineering;Laboratories;Least squares methods;Machine learning;Predictive models;Support vector machines;System performance;System testing","generalisation (artificial intelligence);learning (artificial intelligence);regression analysis;support vector machines","SVM training sample;generalization error;heuristic approach;parametric learning machine;regression problem;sample number;support vector machine samples selection;training set construction","","0","","7","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Recursive Sparse, Spatiotemporal Coding","T. Dean; R. Washington; G. Corrado","Google Inc., Mountain View, CA, USA","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","645","650","We present a new approach to learning sparse, spatiotemporal codes in which the number of basis vectors, their orientations, velocities and the size of their receptive fields change over the duration of unsupervised training. The algorithm starts with a relatively small, initial basis with minimal temporal extent. This initial basis is obtained through conventional sparse coding techniques and is expanded over time by recursively constructing a new basis consisting of basis vectors with larger temporal extent that proportionally conserve regions of previously trained weights. These proportionally conserved weights are combined with the result of adjusting newly added weights to represent a greater range of primitive motion features. The size of the current basis is determined probabilistically by sampling from existing basis vectors according to their activation on the training set. The resulting algorithm produces bases consisting of filters that are bandpass, spatially oriented and temporally diverse in terms of their transformations and velocities. The basic methodology borrows inspiration from the layer-by-layer learning of multiple-layer restricted Boltzmann machines developed by Geoff Hinton and his students. Indeed, we can learn multiple-layer sparse codes by training a stack of denoising autoencoders, but we have had greater success using L<sub>1</sub> regularized regression in a variation on Olshausen and Field's original SPARSENET. To accelerate learning and focus attention, we apply a space-time interest-point operator that selects for periodic motion. This attentional mechanism enables us to efficiently compute and compactly represent a broad range of interesting motion. We demonstrate the utility of our approach by using it to recognize human activity in video. Our algorithm meets or exceeds the performance of state-of-the-art activity-recognition methods.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365771","human-activity recognition;sparse coding","Acceleration;Band pass filters;Humans;Machine learning;Motion pictures;Noise reduction;Sampling methods;Spatiotemporal phenomena;Statistics;USA Councils","image motion analysis;image recognition;unsupervised learning;video coding","Boltzmann machines;SPARSENET;activity recognition;basis vectors;denoising autoencoders;primitive motion features;space-time interest-point operator;sparse coding;spatiotemporal codes;training set;unsupervised training","","1","","17","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"Adaptive power management using reinforcement learning","Y. Tan; W. Liu; Q. Qiu","Department of Electrical and Computer Engineering, Binghamton University, State University of New York, Binghamton, New York 13902, USA","2009 IEEE/ACM International Conference on Computer-Aided Design - Digest of Technical Papers","20091228","2009","","","461","467","System level power management must consider the uncertainty and variability that comes from the environment, the application and the hardware. A robust power management technique must be able to learn the optimal decision from past history and improve itself as the environment changes. This paper presents a novel online power management technique based on model-free constrained reinforcement learning (RL). It learns the best power management policy that gives the minimum power consumption for a given performance constraint without any prior information of workload. Compared with existing machine learning based power management techniques, the RL based learning is capable of exploring the trade-off in the power-performance design space and converging to a better power management policy. Experimental results show that the proposed RL based power management achieves 24% and 3% reduction in power and latency respectively comparing to the existing expert based power management.","1092-3152;10923152","CD-ROM:978-1-60558-800-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361254","Power management;Q-learning;model-free;reinforcement learning","Delay;Energy consumption;Energy management;Environmental management;Hardware;History;Machine learning;Power system management;Robustness;Uncertainty","learning (artificial intelligence);power consumption;power engineering computing;power system management","adaptive power management;expert based power management;machine learning;model-free constrained reinforcement learning;online power management technique;performance constraint;power consumption;power management policy;power management techniques;power-performance design space;system level power management","","3","","16","","","2-5 Nov. 2009","","IEEE","IEEE Conference Publications"
"Kernel K-means Based Framework for Aggregate Outputs Classification","S. Chen; B. Liu; M. Qian; C. Zhang","Dept. of Autom., Tsinghua Univ., Beijing, China","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","356","361","Aggregate outputs learning is a newly proposed setting in data mining and machine learning. It differs from the classical supervised learning setting in that, training samples are packed into bags with only the aggregate outputs (labels for classification or real values for regression) provided. This problem is associated with several kinds of application background. We focus on the aggregate outputs classification problem in this paper, and set up a framework based on kernel K-means to solve it. Two concrete algorithms based on our framework are proposed, each of which can cope with both binary and multi-class scenarios. The experimental results suggest that our algorithms outperform the state-of-art technique. Also, we propose a new setting for patch extraction in the content based image retrieval procedure by using the algorithm.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360431","","Aggregates;Cloud computing;Clustering algorithms;Computer networks;Costs;Data mining;Data processing;Decision trees;Kernel;Machine learning algorithms","content-based retrieval;data mining;image retrieval;learning (artificial intelligence);pattern classification","aggregate outputs classification;aggregate outputs learning;content based image retrieval;data mining;kernel k-means based framework;machine learning;patch extraction","","2","","8","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Unsupervised Relation Extraction by Massive Clustering","E. Gonzlez; J. Turmo","TALP Res. Center, Univ. Politec. de Catalunya, Barcelona, Spain","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","782","787","The goal of Information Extraction is to automatically generate structured pieces of information from the relevant information contained in text documents. Machine Learning techniques have been applied to reduce the cost of Information Extraction system adaptation. However, elements of human supervision strongly bias the learning process. Unsupervised learning approaches can avoid these biases. In this paper, we propose an unsupervised approach to learning for Relation Detection, based on the use of massive clustering ensembles. The results obtained on the ACE Relation Mention Detection task outperform in terms of F1 score by 5 points the state of the art of unsupervised techniques for this evaluation framework, in addition to being simpler and more flexible.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360311","Ensemble Clustering;Relation Detection;Unsupervised Methods","Adaptive systems;Automatic testing;Costs;Data mining;Humans;Learning systems;Machine learning;Proposals;Text mining;Unsupervised learning","data mining;information retrieval;pattern clustering;text analysis;unsupervised learning","ACE relation mention detection;automatic content extraction;information extraction system adaptation;machine learning techniques;massive clustering;relation detection;text documents;unsupervised learning approach;unsupervised relation extraction","","2","","14","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Hybridizing Ensemble Classifiers with Individual Classifiers","G. Ramos-Jimnez; J. del Campo-vila; R. Morales-Bueno","Dept. de Lenguajes y Cienc. de la Comput., Univ. de Malaga, Malaga, Spain","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","199","202","Two extensive research areas in Machine Learning are classification and prediction. Many approaches have been focused in the induction of ensemble to increase learning accuracy of individual classifiers. Recently, new approaches, different to those that look for accurate and diverse base classifiers, are emerging. In this paper we present a system made up of two layers: in the first layer, one ensemble classifier process every example and tries to classify them; in the second layer, one individual classifier is induced using the examples that are not unanimously classified by the ensemble. In addition, the examples that reach to the second layer incorporate new information added in the ensemble. Thus, we can achieve some improvement in the accuracy level, because the second layer can do more informed classifications. In the experimental section we present some results that suggest that our proposal can actually improve the accuracy of the system.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364774","ensemble classifiers;hybrid learning;many-layered learning","Classification tree analysis;Decision trees;Hybrid intelligent systems;Machine learning;Proposals;Size control;Voting","learning (artificial intelligence);pattern classification","diverse base classifiers;ensemble classifiers;individual classifiers;informed classification;machine learning","","0","","16","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Exploiting tags for concept extraction and information integration","M. L. Escobar-Molano; A. Badia; R. Alonso","SET Corporation, 1005 Glebe Road, Suite 400, Arlington VA, USA","2009 5th International Conference on Collaborative Computing: Networking, Applications and Worksharing","20091228","2009","","","1","9","The use of tags to annotate content creates an opportunity to explore alternatives to automate the process of extracting semantics from data sources. Semantic information is needed for many complex tasks like concept extraction and information integration. In order to establish the value of user-generated annotation, this paper presents two experiments on which only user tags are used as input. At the core of semantic extraction is the identification of concepts and relationships that are present in the data. We show, through an experimental study on tagged photographs, how to extract concepts associated with photographs and their relationships. Our experiments demonstrate that supervised machine learning techniques can be used to extract a concept associated with a photograph with an overall precision score of 80%. Our experiments also show that a variation of the Jaccard similarity coefficient on sets of tags can be used to determine equivalence relationships between the concepts associated with these sets.","","CD-ROM:978-963-9799-76-9","10.4108/ICST.COLLABORATECOM2009.8330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363321","","Centralized control;Collaboration;Computer science;Data analysis;Data engineering;Data mining;Machine learning;Ontologies;Tagging;Vocabulary","digital photography;information filtering;learning (artificial intelligence)","Jaccard similarity coefficient;data sources;information integration;semantic information extraction;supervised machine learning techniques;tagged photographs;user-generated annotation","","0","","15","","","11-14 Nov. 2009","","IEEE","IEEE Conference Publications"
"SHC: A Spectral Algorithm for Hierarchical Clustering","X. Li; J. Huang","Sch. of Comput., Wuhan Univ., Wuhan, China","2009 International Conference on Multimedia Information Networking and Security","20091231","2009","2","","197","200","Hierarchical clustering (HC) is a widely used approach both in pattern recognition and data mining and has rich solutions in the literature. But all these existing solutions have some restrictions when the clustered dataset has complex structure. Spectral clustering is a graph-based, simple and outperforming method with the ability to find complex structure in dataset using spectral properties of the dataset-associated affinity matrix. In this paper, we propose a novel effective HC algorithm called SHC base on the techniques of spectral method. The experiment results both on artificial and real data sets show that our algorithm can hierarchically cluster complex data effectively and naturally.","2162-8998;21628998","POD:978-0-7695-3843-3","10.1109/MINES.2009.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370130","eigengap;hierarchical clustering (HC);spectral clustering","Clustering algorithms;Clustering methods;Computer networks;Data mining;Information security;Machine learning algorithms;Multimedia computing;Partitioning algorithms;Pattern recognition;Shape","matrix algebra;pattern clustering","clustered dataset;complex structure;data mining;dataset-associated affinity matrix;hierarchical clustering;pattern recognition;spectral algorithm;spectral clustering;spectral properties","","0","","18","","","18-20 Nov. 2009","","IEEE","IEEE Conference Publications"
"YAPS: Yet Another Protein Similarity","T. Novosd; V. Snel; A. Abraham; J. Y. Yang","Dept. of Comput. Sci., VSB Tech. Univ. of Ostrava, Ostrava, Czech Republic","2009 International Conference of Soft Computing and Pattern Recognition","20091231","2009","","","497","504","In this article we present a novel method for measuring protein similarity based on their tertiary structure. Our new method deals with suffix trees and classical information retrieval tasks, such as the vector space model, using tf-idf term weighing schema or using various types of similarity measures. Our goal to use the whole PDB database of known proteins, not just some kinds of selections, which have been studied in other works. For verification of our algorithm we are using comparisons with the SCOP database which is maintained primarily by humans. The next goal is to be able to categorize proteins not included in the latest version of the SCOP database with nearly 100% accuracy.","","POD:978-1-4244-5330-6","10.1109/SoCPaR.2009.101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368662","Information Retrieval;Proteins;Similarity;Suffix Trees","Amino acids;Databases;Information retrieval;Machine learning algorithms;Nuclear magnetic resonance;Pattern recognition;Protein engineering;Sequences;Spine;Support vector machines","biology computing;information retrieval;proteins;tree data structures","PDB database;SCOP database;information retrieval tasks;suffix trees;tertiary structure;tf-idf term weighing schema;vector space model;yet another protein similarity","","1","","26","","","4-7 Dec. 2009","","IEEE","IEEE Conference Publications"
"Tree-Structured Learning of Multi-class SVMs with Triple Learning Units","X. L. Xia; K. Li","Sch. of Electron., Electr. Eng. & Comput. Sci., Queen's Univ. Belfast, Belfast, UK","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","363","367","To reduce the computational complexity of multi-class Support Vector Machines (SVM), this paper presents a multi-class algorithm in which a triple classifier is included as a second learning unit. This triple learning unit is a regression model for three classes and is based on Least-Squares SVMs (LS-SVMs). To train the triple learning unit, binary target values are first expanded with a third optional output, then an advanced LS-SVM algorithm is used to guarantee the sparseness of the solution. An ensemble of all learning units are placed at nodes of a Directed Decision Tree (DDT), leading to proposal of a Directed Decision Tree SVM (DDTSVM). DDTSVMs can improve the learning efficiency in classifying unlabelled data, a drawback for both 1-v-r and 1-v-1methods. Empirical studies show that the proposed DDTSVM achieves excellent classification accuracy in comparison with the 1-v-1 method.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.426","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365807","","Classification tree analysis;Computational complexity;Computer science;Decision trees;Decoding;Machine learning;Support vector machine classification;Support vector machines;Testing;Voting","computational complexity;decision trees;learning (artificial intelligence);least squares approximations;regression analysis;support vector machines","advanced LS-SVM algorithm;computational complexity;directed decision tree SVM;multiclass SVM;multiclass support vector machines;regression model;second learning unit;tree structured learning;triple classifier;triple learning units","","0","","11","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Anomaly detection based on contiguous expert voting algorithm","Min Yang; Da-peng Chen; Xiao-Song Zhang","Computer Science & Engineering Department, University of Electronics Science and Technology of China, China","2009 International Conference on Apperceiving Computing and Intelligence Analysis","20091228","2009","","","158","161","Malicious intrusion is the behavior that threats a large number of computers; therefore, recent research has focused on devising new techniques to detect and control internet intrusion with high efficiency and low cost. Unfortunately some anomaly detection system (ADS) over machine learning may get some false alarms if the results of machine learning cannot cover all the normal or abnormal data. In this paper, to solve this problem, we introduce a new approach for anomaly detection using contiguous expert voting algorithm (CEVS). At first, we present our framework of the anomaly detection system, and then we define a new algorithm based on data mining, at last we will use this algorithm to detect the internet anomaly and report our experimental result. The results show that the proposed approach can improve the detection performance of the ADS, where traditional anomaly detection system is used.","","POD:978-1-4244-5204-0","10.1109/ICACIA.2009.5361127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361127","Anomaly detection;Computer security;Contiguous expert voting algorithm;Data mining","Association rules;Computer security;Costs;Data mining;Face detection;Internet;Intrusion detection;Machine learning;Machine learning algorithms;Voting","data mining;learning (artificial intelligence);security of data","anomaly detection system;contiguous expert voting algorithm;data mining;machine learning;malicious intrusion","","1","","12","","","23-25 Oct. 2009","","IEEE","IEEE Conference Publications"
"Speech Recognition Method Based on Linear Descending Inertia Weight PSO Algorithm Optimizing SVM Kernel Parameters","J. Bai; Y. Guo","Coll. of Inf. Eng., Taiyuan Univ. of Technol. Taiyuan, Taiyuan, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","565","568","An important factor that influences the performance of support vector machine is how to select the parameters. Particle swarm optimization is an efficient algorithm and it is broadly used in many research areas like pattern recognition. In order to improve the learning and generalization ability of support vector machine and enhance the speech recognition system accuracy, a method for searching the Gaussian kernel support vector machine optimal parameters (C,) based on particle swarm optimization is proposed and a speech recognition system based on support vector machine using the optimal parameters is constructed in this paper. The inertia weight, a crucial parameter of the particle swarm optimization, is adopted in linear descending adjusting method. The speech data is isolated, non-specific and middle vocabulary words. The speech feature we used is modified MFCC feature. Experiments indicate that it is an efficient approach for parameters selection of support vector machine and has higher correct speech recognition rates than default parameters of the support vector machine open source software.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.261","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365756","Inertia Weight;Particle Swarm Optimization;Support Vector Machine;kernel parameters;speech recognition","Kernel;Machine learning;Mel frequency cepstral coefficient;Open source software;Optimization methods;Particle swarm optimization;Pattern recognition;Speech recognition;Support vector machines;Vocabulary","particle swarm optimisation;speech recognition;support vector machines","Gaussian kernel;MFCC speech feature;SVM optimal parameter;inertia weight parameter;linear descending adjusting method;particle swarm optimization;speech recognition method;support vector machine","","0","","7","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"An Efficient Knowledge Discovery Method Based on Swarm Intelligence","L. Ying; L. Peng; L. Chengzhi","Comput. Technol. Eng. Inst., Nanchang Univ., Nanchang, China","2009 Second International Symposium on Computational Intelligence and Design","20091231","2009","1","","337","340","Knowledge discovery has become of great importance owing to ever-increasing amounts of data collected by large organizations. This paper presents a knowledge discovery method called ant system, which is implemented by improving ant colony algorithm. Through specific application it has been proved that the algorithm is practical in knowledge discovery , and is a good method of knowledge discovery which has a higher accuracy.","","POD:978-0-7695-3865-5","10.1109/ISCID.2009.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370392","Ant colony algorithm(ACS);Ant-System;Knowledge discovery method","Algorithm design and analysis;Classification algorithms;Data mining;Databases;Design engineering;Knowledge engineering;Machine learning algorithms;Neural networks;Particle swarm optimization;Partitioning algorithms","data mining;optimisation","ant colony algorithm;knowledge discovery method;swarm intelligence","","0","","12","","","12-14 Dec. 2009","","IEEE","IEEE Conference Publications"
"Classification by Evolutionary Generalized Radial Basis Functions","A. Castao; C. Hervs-Martnez; P. A. Gutierrez; F. Fernndez-Navarro; M. M. Garca","Dept. of Inf., Univ. of Pinar del Rio, Pinar del Rio, Cuba","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","203","208","This paper proposes a novelty neural network model by using generalized kernel functions for the hidden layer of a feed forward network (Generalized Radial Basis Functions, GRBF), where the architecture, weights and node typology are learned through an evolutionary programming algorithm. This new kind of model is compared with the corresponding models with standard hidden nodes: Product Unit Neural Networks (PUNN), Multilayer Perceptrons (MLP) and the RBF neural networks. The methodology proposed is tested using six benchmark classification datasets from well-known machine learning problems. Generalized basis functions are found to present a better performance than the other standard basis functions for the task of classification.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364778","classification;evolutionary programming;generalized radial basis functions;radial basis functions","Feedforward neural networks;Feeds;Functional programming;Genetic programming;Kernel;Machine learning algorithms;Multi-layer neural network;Multilayer perceptrons;Neural networks;Testing","evolutionary computation;multilayer perceptrons;pattern classification;radial basis function networks","benchmark classification dataset;evolutionary generalized radial basis function;evolutionary programming algorithm;feedforward network;generalized kernel function;machine learning problem;multilayer perceptron;neural network model;pattern classification;product unit neural network","","1","","19","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Enhancing prediction understandability for transmembane segments by BoostingFOIL","Jieyue He; Pingping Chen; Dejing Zhao; Wei Zhong","School of Computer Science and Engineering, Southeast University, Nanjing 210096, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","739","743","In recent years, many studies have focused on improving the accuracy of prediction of trans-membrane segments, and many significant results have been achieved. In spite of these considerable results, the existing methods lack the ability to explain the process of how a learning result is reached and why a prediction decision is made. The explanation of the decision process is important for acceptance of machine learning technology in bioinformatics applications such as protein structure prediction. Decision trees provide insightful interpretation, with form of the propositional IF-THEN rules. The decision tree algorithm produces a large number of rules which is not easy to read and difficult to express adequately complex characteristics of biological sequence. First-order rules with variables have outstanding representation capability, and they can be used to reduce the number of rules. Therefore, in this paper, we present an innovative approach to generate rules for understanding prediction of transmembrane segments. This new approach combines the first-order inductive learning (FOIL) with enhancing techniques of Boosting to produce a new algorithm called BoostingFOIL. The experimental results for prediction of transmembrane segments on 165 low-resolution test data set show that not only the comprehensibility of BoostingFOIL is much better than that of decision tree, but also the test accuracy of these rules is higher as well. The most important contribution of our work is that the first-order rules produced by BoostingFOIL can be easily applied to advanced deduction in inductive learning procedure.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358389","Decision tree;First Order Inductive Learner;Transmembrane segments prediction","Bioinformatics;Computer science;Decision making;Decision trees;Hidden Markov models;Humans;Machine learning;Proteins;Support vector machines;Testing","bioinformatics;biomembranes;decision making;decision trees;learning (artificial intelligence);molecular biophysics;proteins","BoostingFOIL algorithm;bioinformatics;decision tree;first-order inductive learning;inductive learning procedure;transmembane segments;transmembrane proteins","","0","","25","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Recognition of SAR Image Based on SVM and New Invariant Moment Feature Extraction","Y. Fu; J. Lv","Dept. of Comput. Sci., Xi'an Univ. of Sci. & Technol., Xi'an, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","1","","15","18","Support vector machine (SVM) is regarded as a good alternative of the traditional learning classification. Because of its excellent learning performance, it has become a research hot spot in the field of machine learning. This paper describes the new invariant moment feature extraction of SAR objectives based on shape feature, then classify and train the eigenvectors by using SVM. The excellent recognition rates achieved in experiments indicate that SVM is well suited for SAR image target recognition.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362169","SAR;classification;support vector machine;target recognition;training","Equations;Feature extraction;Image recognition;Knowledge acquisition;Lagrangian functions;Machine learning;Optimization methods;Support vector machine classification;Support vector machines;Target recognition","feature extraction;learning (artificial intelligence);object recognition;radar imaging;support vector machines;synthetic aperture radar","SAR image target recognition;invariant moment feature extraction;machine learning;support vector machine;synthetic aperture radar","","1","","11","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Augmented BAN Classifier","X. Sun","Software Coll., Shenyang Normal Univ., Shenyang, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Learning machine is usually divided to strong learning machines and weak learning machines in machine learning. The result of most individual learning machine is output as while learning machine integration to used for a classification. BAN is an augmented Bayesian network classifier, whose accuracy can be improve by combining several weak learning machines. In this paper, a bagging classifier bagging-BAN-GBN which wraps around GBN and BAN is compared with the boosting-BAN classifier which is boosting based on BAN combination. Finally, experimental results show that the boosting-BAN has higher classification accuracy on most data sets.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5363314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363314","","Bagging;Bayesian methods;Body sensor networks;Boosting;Classification tree analysis;Fault diagnosis;Machine learning;Mutual information;Sun;Testing","Bayes methods;learning (artificial intelligence)","augmented BAN classifier;augmented Bayesian network classifier;bagging classifier bagging-BAN-GBN;boosting-BAN classifier;data sets;machine learning","","1","","10","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Novel Framework for Nominal Entity Recognition","W. Pang; X. Fan","Sch. of Comput. & Technol., Beijing Inst. of Technol., Beijing, China","2009 Second International Symposium on Computational Intelligence and Design","20091231","2009","1","","558","561","The re-ranking algorithm is a common method to use the results of subsequent stages, such as coreference resolution, to improve entity recognition. The nature of re-ranking is to select the most possible candidate from the entire candidate set. But if all of the candidates are incorrect, this method still can not give a right result. We propose a two-layer model to utilize the results of subsequent stages. This novel framework is able to overcome the disadvantage of re-ranking method, and correct the errors introduced by the first tagging. The experiments on the ACE2004 Chinese corpus show that the proposed framework are more effective than re-ranking method.","","POD:978-0-7695-3865-5","10.1109/ISCID.2009.146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368834","coreference resolution;information extraction;nominal entity recognition;two-layer model","Algorithm design and analysis;Character generation;Computational intelligence;Data mining;Error correction;Machine learning algorithms;Magnetic heads;Pipelines;Support vector machines;Tagging","algorithm theory;entity-relationship modelling","ACE2004 Chinese corpus show;coreference resolution;improve entity recognition;nominal entity recognition;novel framework;re ranking algorithm common method;results subsequent stages","","0","","12","","","12-14 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Novel Genetic Algorithm for Subspace Based Subclasssifier Selection","F. Wang; M. Yang","Sch. of Comput. Sci. & Technol., Nanjing Normal Univ., Nanjing, China","2009 Fifth International Conference on Natural Computation","20091228","2009","4","","513","517","Ensemble learning constitutes one of the most popular directions in machine learning and data mining currently. And in ensemble learning, feature subspace selection and corresponding classifier ensemble for classification becomes the principal topic, in which base classifiers(also called subclassifiers) are generated by different subspaces. However, very little work has been done for effectively selecting the subclassifiers induced by different subspaces. In this paper, we introduce a novel Genetic Algorithm for subspace ensemble based subclassifier selection, that is, the newly developed algorithm attempts to select significant and relevant subclassifiers using genetic algorithm for improving the classification performance of ensemble. The experimental results show that the algorithm of this paper has better or comparable performance than those obtained by the well-known ensemble methods such as Bagging, AdaBoost and Random Subspace. Of course, how to determine the number of subclassifiers and the parameters used in genetic algorithm is our ongoing work.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.376","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364636","Ensemble learning;Fitness Function;Genetic Algorithm;Subclassifier Selection","Accuracy;Ant colony optimization;Bagging;Classification tree analysis;Computer science;Data mining;Genetic algorithms;Learning systems;Machine learning;Partitioning algorithms","data mining;genetic algorithms;learning (artificial intelligence)","AdaBoost;bagging;data mining;genetic algorithm;machine learning;random subspace;subspace based subclasssifier selection","","1","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Inducing Uncertain Decision Tree via Cloud Model","T. Wu; K. Qin","State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China","2009 Fifth International Conference on Semantics, Knowledge and Grid","20091231","2009","","","85","91","This paper addresses the decision trees induction with uncertain data. In other words, it presents a novel method, called uncertain decision trees (UDT) to handle the uncertainty during the process of inducing decision trees. Here, uncertainty is depicted via cloud model theory, a quantitative-qualitative transforming model with uncertainty, which can well integrate the fuzziness and randomness of concepts in a unified way. In the learning stage, dataset is pre-processed by cloud transformation algorithm, which climbs data into class labels via histograms or frequency distribution, and the labels are expressed by cloud concepts. In this paper, some basic definitions are proposed, including cloud distance, cloud dissimilarity matrix, cloud index, and UDT, where cloud index is a novel splitting criterion of selecting attributes for handling uncertainty. Take data from UCI for example, this paper provided an algorithm inducing UDT, and checked its validity or appropriateness. In contrast to the classical approaches, both in the learning stage and classifying stage, the proposed method develops existing methods, and it is more consistent with the human cognition, which can support uncertainty, build UDT via cloud concepts, and classify the uncertain data. Moreover, experiments and results are compared with the current methods to illustrate the feasibility, accuracy and effectiveness of the cloud based algorithm.","","POD:978-0-7695-3810-5","10.1109/SKG.2009.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368030","classifier;cloud model;data mining;decision tree;knowledge discovery;uncertain systems","Classification tree analysis;Clouds;Decision trees;Fuzzy sets;Induction generators;Information science;Machine learning algorithms;Measurement uncertainty;Software engineering;Uncertain systems","data mining;decision trees;uncertainty handling","cloud model;human cognition;learning stage;uncertain data;uncertain decision tree","","0","","11","","","12-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"Real-time Traffic Flow Forecasting Based on MW-AOSVR","F. Wang; Y. Fang; G. Tan","Dept. of Comput. Sci. & Eng., Dalian Univ. of Technol., Dalian, China","2009 Third International Symposium on Intelligent Information Technology Application","20091231","2009","3","","323","326","Accurate traffic flow forecasting is the key to the development of intelligent transportation systems (ITS). However, the classical forecasting method using the support vector regression (SVR) based on RBF kernel does not support online learning and has the problems of information loss, long processing time, low robustness and so on. An effective Marr Wavelet kernel which we combine the wavelet theory with AOSVR (MW-AOSVR) to construct for traffic flow forecasting is presented in this paper. The forecasting performance of MW-AOSVR is evaluated by real-time traffic flow data of southbound US 101 Freeway, in Los Angeles, USA and a variety of experiments are carried out. The experimental results demonstrate that the proposed approach with Marr Wavelet kernel provides more optimal performance than that with radial basis function (RBF) kernel and has much more precise forecasting rate and higher efficiency, especially for boundary approximation.","","POD:978-0-7695-3859-4","10.1109/IITA.2009.423","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369419","#NAME?","Application software;Demand forecasting;Information technology;Intelligent transportation systems;Kernel;Machine learning;Space technology;Technology forecasting;Training data;Wavelet domain","radial basis function networks;regression analysis;support vector machines;traffic engineering computing;wavelet transforms","Marr wavelet kernel;boundary approximation;intelligent transportation systems;radial basis function kernel;realtime traffic flow forecasting;support vector regression;wavelet theory","","1","","9","","","21-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"A New Method for Initialising the K-Means Clustering Algorithm","X. Qin; S. Zheng","Dept. of Comput. Sci., Huazhong Nomal Univ., Wuhan, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","41","44","As a classic clustering method, the traditional K-means algorithm has been widely used in pattern recognition and machine learning. It is known that the performance of the K-means clustering algorithm depend highly on initial cluster centers. Generally initial cluster centers are selected randomly, so the algorithm could not lead to the unique result. In this paper, we present a method to compute initial cluster centers for K-means clustering. Our method is based on an efficient technique for estimating the modes of a distribution. We apply the new method to the K-means algorithm. The experimental results show better performance of the proposed method.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362321","K-Means algorithm;clustering;initial cluster centers","Clustering algorithms;Clustering methods;Computer science;Data mining;Iterative algorithms;Knowledge acquisition;Machine learning;Machine learning algorithms;Partitioning algorithms;Pattern recognition","pattern clustering;statistical analysis","K-means clustering algorithm;initial cluster centers;machine learning;pattern recognition","","2","","15","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Meteorological Data Analyze Base on K-means Algorithm","H. Jinghua; W. Zhenchong; Y. Mei; B. Youwen","Sch. of Mech., Electron. & Inf. Eng., China Univ. of Min. & Technol., Beijing, China","2009 Second International Symposium on Computational Intelligence and Design","20091231","2009","2","","60","63","The paper proposed a clustering method of decade observation data based on k-means algorithm, which adjusted the weight influence to similarity function by the missing values handling and scaling of range fields. This paper discussed the way to select initial cluster centers and the process of calculating cluster centers and assigning records to clusters. The test indicated the k-means algorithm had effective clustering result.","","POD:978-0-7695-3865-5","10.1109/ISCID.2009.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368948","clustering;k-means algorithm;meteorological data","Algorithm design and analysis;Clustering algorithms;Clustering methods;Data analysis;Euclidean distance;Iterative algorithms;Machine learning algorithms;Meteorology;Partitioning algorithms;Weather forecasting","data analysis;meteorology;statistical analysis","cluster centers;decade observation data;k-means algorithm;meteorological data analysis;missing values handling;range fields scaling;similarity function","","0","","6","","","12-14 Dec. 2009","","IEEE","IEEE Conference Publications"
"A New Clustering Method Based on Weighted Kernel K-Means for Non-linear Data","A. Rasouli; M. A. B. Maarof; M. Shamsi","Fac. of Comput. Sci. & Inf. Syst., Univ. Teknol. Malaysia, Skudai, Malaysia","2009 International Conference of Soft Computing and Pattern Recognition","20091231","2009","","","19","24","Clustering is the process of gathering objects into groups based on their feature's similarity. In this paper, we concentrate on Weighted Kernel K-Means method for its capability to manage nonlinear separability and high dimensionality in the data. A new slight modification of WKM algorithm has been proposed and tested on real Rice data. The results show that the accuracy of proposed algorithm is higher than other famous clustering algorithm and ensures that the WKM is a good solution for real world problems.","","POD:978-1-4244-5330-6","10.1109/SoCPaR.2009.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369315","Classification Accuracy;Clustering;Data Mining;F-Measure;WKM Algorithm;Weighted Kernel K-Means","Atmospheric modeling;Clustering algorithms;Clustering methods;Computer science;Data mining;Kernel;Machine learning algorithms;Management information systems;Pattern recognition;Vegetation mapping","data mining;pattern clustering","Rice data;clustering method;data mining;nonlinear separability;weighted kernel k-means methods","","1","","15","","","4-7 Dec. 2009","","IEEE","IEEE Conference Publications"
"User Modeling for Improving QoS Using Partial User-Supplied Information","R. Verschae; M. Koeppen; K. Yoshida","Network Design Res. Center, Kyushu Inst. of Technol., Iizuka, Japan","2009 International Conference on Intelligent Networking and Collaborative Systems","20091231","2009","","","387","390","For the improvement of QoS, incorporation of user-supplied information in the network design and control process has become mandatory. A problem arises for the handling of new users, when information about existing users is already available. In the work presented in this paper, we were following two approaches to derive information about new users, both based on prototype generation for existing user's answer pattern to a QoS related questionnaire. In the first approach, it was tried to classify user attributes to a fitting prototype. In the second approach, a mapping from partial answers to a prototype was used. As result, the first approach appeared to be infeasible, while the second one gave good results. In the resulting trade-off between the number of clusters and classification accuracy, this way it is possible, for example, with 8 prototypes for around 1000 users to issue a new user answer patterns by using only 30% of the questions, while reducing accuracy by only 13%.","","POD:978-1-4244-5165-4","10.1109/INCOS.2009.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5369327","","Communication networks;Communication system control;Context;Intelligent networks;International collaboration;Learning systems;Machine learning;Process control;Process design;Prototypes","pattern classification;quality of service;user modelling","partial user supplied information;quality of service;user attribute classification;user modeling","","0","","7","","","4-6 Nov. 2009","","IEEE","IEEE Conference Publications"
