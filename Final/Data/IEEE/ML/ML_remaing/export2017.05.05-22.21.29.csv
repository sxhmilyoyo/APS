"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=1642434,1642659,1634646,1637346,1637355,1637420,1631493,1631605,1630033,1632041,1631993,1632035,1626228,1624358,1621142,1621094,1515448,1617000,1615722,1608038,1605431,1597108,1593701,1583626,1583583,1580484,1580617,1571175,1570825,1571750,1571705,1571248,1570276,1570279,1570724,1573710,1564161,1563997,1564394,1561265,1556587,1547292,1549828,1545132,1546122,1541987,1542471,1542030,1542270,1542524,1532385,1530117,1524968,1524965,1524967,1509308,1522615,1512038,1512039,1510781,1510768,1508361,1504688,1504685,1498003,1498019,1504690,1495617,1495607,1488790,1490529,1490584,1471710,1487646,1471704,1468246,1461444,1458699,1360168,1458705,1453593,1443136,1439478,1435425,1438374,1438348,1438349,1432736,1432737,1408064,1407860,1403865,1403821,1403838,1386075,1403846,1403183,1402496,1401890,1401912",2017/05/05 22:21:29
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Instrument recognition in polyphonic music based on automatic taxonomies","S. Essid; G. Richard; B. David","LTCI-CNRS, Paris, France","IEEE Transactions on Audio, Speech, and Language Processing","20051219","2006","14","1","68","80","We propose a new approach to instrument recognition in the context of real music orchestrations ranging from solos to quartets. The strength of our approach is that it does not require prior musical source separation. Thanks to a hierarchical clustering algorithm exploiting robust probabilistic distances, we obtain a taxonomy of musical ensembles which is used to efficiently classify possible combinations of instruments played simultaneously. Moreover, a wide set of acoustic features is studied including some new proposals. In particular, signal to mask ratios are found to be useful features for audio classification. This study focuses on a single music genre (i.e., jazz) but combines a variety of instruments among which are percussion and singing voice. Using a varied database of sound excerpts from commercial recordings, we show that the segmentation of music with respect to the instruments played can be achieved with an average accuracy of 53%.","1558-7916;15587916","","10.1109/TSA.2005.860351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1561265","Hierarchical taxonomy;instrument recognition;machine learning;pairwise classification;pairwise feature selection;polyphonic music;probabilistic distances;support vector machines","Audio recording;Clustering algorithms;Frequency;Instruments;Multiple signal classification;Music;Proposals;Source separation;Streaming media;Taxonomy","acoustic signal processing;audio signal processing;music;pattern classification;source separation","audio classification;automatic taxonomies;hierarchical clustering algorithm;instrument recognition;music orchestrations;music segmentation;percussion;polyphonic music;singing voice","","43","","60","","","Jan. 2006","","IEEE","IEEE Journals & Magazines"
"Scoring and selecting terms for text categorization","E. Montanes; I. Diaz; J. Ranilla; E. F. Combarro; J. Fernandez","Oviedo Univ., Spain","IEEE Intelligent Systems","20050613","2005","20","3","40","47","We propose a set of (machine learning) ML-based scoring measures for conducting feature selection. We've tested these measures on documents from two well-known corpora, comparing them with other measures previously applied for this purpose. In particular, we've analyzed which measure obtains the best overall classification performance in terms of properties such as precision and recall, emphasizing to what extent some statistical properties of the corpus affects performance. The results show that some of our measures outperform the traditional measures in certain situations.","1541-1672;15411672","","10.1109/MIS.2005.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1439478","feature selection;information retrieval;machine learning;support vector machines;text categorization","Entropy;Frequency estimation;Frequency measurement;Gain measurement;Information retrieval;Information theory;Learning systems;Probability;Statistical distributions;Text categorization","classification;feature extraction;information retrieval;learning (artificial intelligence);text analysis;word processing","ML-based scoring measures;feature selection;information retrieval;machine learning;text categorization","","26","","16","","","May-June 2005","","IEEE","IEEE Journals & Magazines"
"Can threshold networks be trained directly?","Guang-Bin Huang; Qin-Yu Zhu; K. Z. Mao; Chee-Kheong Siew; P. Saratchandran; N. Sundararajan","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore","IEEE Transactions on Circuits and Systems II: Express Briefs","20060313","2006","53","3","187","191","Neural networks with threshold activation functions are highly desirable because of the ease of hardware implementation. However, the popular gradient-based learning algorithms cannot be directly used to train these networks as the threshold functions are nondifferentiable. Methods available in the literature mainly focus on approximating the threshold activation functions by using sigmoid functions. In this paper, we show theoretically that the recently developed extreme learning machine (ELM) algorithm can be used to train the neural networks with threshold functions directly instead of approximating them with sigmoid functions. Experimental results based on real-world benchmark regression problems demonstrate that the generalization performance obtained by ELM is better than other algorithms used in threshold networks. Also, the ELM method does not need control variables (manually tuned parameters) and is much faster.","1549-7747;15497747","","10.1109/TCSII.2005.857540","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1605431","Extreme learning machine (ELM);gradient descent method;threshold neural networks","Analog computers;Computational efficiency;Computer networks;Learning systems;Machine learning;Neural network hardware;Neural networks;Neurons;Process control;System-on-a-chip","gradient methods;learning (artificial intelligence);neural nets;regression analysis;threshold elements","ELM algorithm;extreme learning machine;gradient descent method;neural networks;real-world benchmark regression problems;threshold networks","","117","","13","","","March 2006","","IEEE","IEEE Journals & Magazines"
"Context-aware mobile computing: learning context- dependent personal preferences from a wearable sensor array","A. Krause; A. Smailagic; D. P. Siewiorek","Dept. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA","IEEE Transactions on Mobile Computing","20051227","2006","5","2","113","127","Context-aware computing describes the situation where a wearable/mobile computer is aware of its user's state and surroundings and modifies its behavior based on this information. We designed, implemented, and evaluated a wearable system which can learn context-dependent personal preferences by identifying individual user states and observing how the user interacts with the system in these states. This learning occurs online and does not require external supervision. The system relies on techniques from machine learning and statistical analysis. A case study integrates the approach in a context-aware mobile phone. The results indicate that the method is able to create a meaningful user context model while only requiring data from comfortable wearable sensor devices.","1536-1233;15361233","","10.1109/TMC.2006.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1563997","Index Terms- Location-dependent and sensitive;machine learning;mobile computing;statistical models.;wearable AI;wearable computers","Context awareness;Context modeling;Data analysis;Machine learning;Mobile computing;Mobile handsets;Sensor arrays;Statistical analysis;Wearable computers;Wearable sensors","learning (artificial intelligence);mobile computing;mobile handsets;statistical analysis;wireless sensor networks","context-aware mobile computing;learning context-dependent personal preferences;machine learning;mobile phone;statistical analysis;wearable sensor array","","87","6","23","","","Feb. 2006","","IEEE","IEEE Journals & Magazines"
"Linking molecular function and biological process terms in the ontology for gene expression data analysis","M. DeJongh; P. Van Dort; B. Ramsay","Dept. of Comput. Sci., Hope Coll., Holland, MI, USA","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20050314","2004","2","","2984","2986","The gene ontology (GO) contains three hierarchies that represent gene function based on categories of molecular function, biological process, and cellular component. However, additional knowledge about the mechanisms underlying gene function is buried in the GO term definitions and is not computationally accessible. We describe a process for adding new links to the GO between molecular function terms and the biological process terms that those molecular functions are involved in. These new links enable inference engines to reason about relationships between genes that have disparate molecular functions but participate in the same biological process. In particular, we demonstrate how these new links enable more effective automated analysis of gene expression data.","","POD:0-7803-8439-3","10.1109/IEMBS.2004.1403846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1403846","Gene Expression Analysis;Gene Ontology;Knowledge Representation;Machine Learning","Biochemistry;Biological processes;Computer science;Data analysis;Degradation;Electric breakdown;Gene expression;Joining processes;Ontologies;Radio access networks","biochemistry;biology computing;cellular biophysics;genetics;knowledge representation;learning (artificial intelligence);molecular biophysics","biological process;cellular component;gene expression data analysis;gene ontology;knowledge representation;machine learning;molecular function","","0","","6","","","1-5 Sept. 2004","","IEEE","IEEE Conference Publications"
"Inducing multivariate decision trees with the R<sup>4</sup>-rule","T. Kawatsure; Qiangfu Zhao","Aizu Univ., Japan","2005 IEEE International Conference on Systems, Man and Cybernetics","20060110","2005","4","","3593","3598 Vol. 4","Decision tree (DT) is often considered as a comprehensible learning model. If the data set is large, however, the induced DT may be too large to understand. Currently, we have proposed a non-genetic evolutionary algorithm called R<sup>4</sup>-rule for producing the smallest nearest neighbor classifiers (NNCs). In this paper, we propose two new approaches for inducing DTs with the R<sup>4</sup>-rule. The DTs considered here are multivariate, and there is an NNC with two or more prototypes in each non-terminal node. In the first method, the prototypes are found directly from the training set. In the second method, the prototypes are found from the data assigned to each nonterminal node. Using these methods, we can induce more compact and more comprehensible DTs. The efficiency and efficacy of the methods are verified through experiments with several public databases.","1062-922X;1062922X","POD:0-7803-9298-1","10.1109/ICSMC.2005.1571705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1571705","Machine learning;multivariate decision trees;nearest neighbor classifier;pattern recognition;the R","Classification tree analysis;Databases;Decision trees;Evolutionary computation;Humans;Machine learning;Machine learning algorithms;Nearest neighbor searches;Pattern recognition;Prototypes","decision trees;evolutionary computation;learning (artificial intelligence)","R<sup>4</sup>-rule;learning model;machine learning;multivariate decision trees;nearest neighbor classifiers;nongenetic evolutionary algorithm;nonterminal node;pattern recognition;public database","","0","","13","","","10-12 Oct. 2005","","IEEE","IEEE Conference Publications"
"A probabilistic model for mining labeled ordered trees: capturing patterns in carbohydrate sugar chains","N. Ueda; K. F. Aoki-Kinoshita; A. Yamaguchi; T. Akutsu; H. Mamitsuka","Bioinformatics Center, Kyoto Univ., Goknsho Uji, Japan","IEEE Transactions on Knowledge and Data Engineering","20050627","2005","17","8","1051","1064","Glycans, or carbohydrate sugar chains, which play a number of important roles in the development and functioning of multicellular organisms, can be regarded as labeled ordered trees. A recent increase in the documentation of glycan structures, especially in the form of database curation, has made mining glycans important for the understanding of living cells. We propose a probabilistic model for mining labeled ordered trees, and we further present an efficient learning algorithm for this model, based on an EM algorithm. The time and space complexities of this algorithm are rather favorable, falling within the practical limits set by a variety of existing probabilistic models, including stochastic context-free grammars. Experimental results have shown that, in a supervised problem setting, the proposed method outperformed five other competing methods by a statistically significant factor in all cases. We further applied the proposed method to aligning multiple glycan trees, and we detected biologically significant common subtrees in these alignments where the trees are automatically classified into subtypes already known in glycobiology.","1041-4347;10414347","","10.1109/TKDE.2005.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1458699","Index Terms- Biology and genetics;data mining;machine learning;mining methods and algorithms.","Bioinformatics;Context modeling;Data mining;Documentation;Hidden Markov models;Machine learning;Organisms;Sequences;Stochastic processes;XML","biology computing;computational complexity;context-free grammars;data mining;genetics;learning (artificial intelligence);microorganisms;molecular biophysics;pattern recognition;tree data structures","biologically significant common subtrees;carbohydrate sugar chains;genetics;glycans;glycobiology;labeled ordered tree mining;machine learning;multicellular organisms;probabilistic model;space complexity;stochastic context-free grammars;time complexity","","5","","38","","","Aug. 2005","","IEEE","IEEE Journals & Magazines"
"An empirical comparison of combinations of evolutionary algorithms and neural networks for classification problems","E. Cantu-Paz; C. Kamath","Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20050919","2005","35","5","915","927","There are numerous combinations of neural networks (NNs) and evolutionary algorithms (EAs) used in classification problems. EAs have been used to train the networks, design their architecture, and select feature subsets. However, most of these combinations have been tested on only a few data sets and many comparisons are done inappropriately measuring the performance on training data or without using proper statistical tests to support the conclusions. This paper presents an empirical evaluation of eight combinations of EAs and NNs on 15 public-domain and artificial data sets. Our objective is to identify the methods that consistently produce accurate classifiers that generalize well. In most cases, the combinations of EAs and NNs perform equally well on the data sets we tried and were not more accurate than hand-designed neural networks trained with simple backpropagation.","1083-4419;10834419","","10.1109/TSMCB.2005.847740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1510768","Classification;evolutionary algorithms;feature selection;machine learning;network design;training algorithms","Algorithm design and analysis;Artificial neural networks;Backpropagation algorithms;Biological cells;Encoding;Evolutionary computation;Machine learning;Neural networks;Testing;Training data","evolutionary computation;feature extraction;learning (artificial intelligence);neural net architecture;pattern classification","artificial data set;backpropagation;evolutionary algorithm;feature selection;machine learning;neural network design;neural network training;pattern classification","Algorithms;Cluster Analysis;Evolution;Models, Genetic;Neural Networks (Computer);Pattern Recognition, Automated;Software;Software Validation;Systems Integration","67","","65","","","Oct. 2005","","IEEE","IEEE Journals & Magazines"
"Nearest neighbors by neighborhood counting","Hui Wang","Fac. of Eng., Ulster Univ., Jordanstown, UK","IEEE Transactions on Pattern Analysis and Machine Intelligence","20060424","2006","28","6","942","953","Finding nearest neighbors is a general idea that underlies many artificial intelligence tasks, including machine learning, data mining, natural language understanding, and information retrieval. This idea is explicitly used in the k-nearest neighbors algorithm (kNN), a popular classification method. In this paper, this idea is adopted in the development of a general methodology, neighborhood counting, for devising similarity functions. We turn our focus from neighbors to neighborhoods, a region in the data space covering the data point in question. To measure the similarity between two data points, we consider all neighborhoods that cover both data points. We propose to use the number of such neighborhoods as a measure of similarity. Neighborhood can be defined for different types of data in different ways. Here, we consider one definition of neighborhood for multivariate data and derive a formula for such similarity, called neighborhood counting measure or NCM. NCM was tested experimentally in the framework of kNN. Experiments show that NCM is generally comparable to VDM and its variants, the state-of-the-art distance functions for multivariate data, and, at the same time, is consistently better for relatively large k values. Additionally, NCM consistently outperforms HEOM (a mixture of Euclidean and Hamming distances), the ""standard"" and most widely used distance function for multivariate data. NCM has a computational complexity in the same order as the standard Euclidean distance function and NCM is task independent and works for numerical and categorical data in a conceptually uniform way. The neighborhood counting methodology is proven sound for multivariate data experimentally. We hope it works for other types of data.","0162-8828;01628828","","10.1109/TPAMI.2006.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1624358","Pattern recognition;distance;machine learning;nearest neighbors;neighborhood counting measure.;similarity","Artificial intelligence;Computational complexity;Data mining;Euclidean distance;Information retrieval;Machine learning;Machine learning algorithms;Natural languages;Nearest neighbor searches;Testing","artificial intelligence;pattern classification","Euclidean distances;Hamming distances;artificial intelligence tasks;classification method;computational complexity;data mining;information retrieval;k-nearest neighbors algorithm;machine learning;multivariate data;natural language understanding;neighborhood counting measure;similarity functions;similarity measure;state-of-the-art distance functions","Algorithms;Artificial Intelligence;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated","56","","29","","","June 2006","","IEEE","IEEE Journals & Magazines"
"A support vector machines classifier to assess the severity of idiopathic scoliosis from surface topography","L. Ramirez; N. G. Durdle; V. J. Raso; D. L. Hill","Dept. of Electr. & Comput. Eng., Univ. of Alberta, Edmonton, Alta., Canada","IEEE Transactions on Information Technology in Biomedicine","20060110","2006","10","1","84","91","A support vector machines (SVM) classifier was used to assess the severity of idiopathic scoliosis (IS) based on surface topographic images of human backs. Scoliosis is a condition that involves abnormal lateral curvature and rotation of the spine that usually causes noticeable trunk deformities. Based on the hypothesis that combining surface topography and clinical data using a SVM would produce better assessment results, we conducted a study using a dataset of 111 IS patients. Twelve surface and clinical indicators were obtained for each patient. The result of testing on the dataset showed that the system achieved 69-85% accuracy in testing. It outperformed a linear discriminant function classifier and a decision tree classifier on the dataset","1089-7771;10897771","","10.1109/TITB.2005.855526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1573710","Decision support systems;machine learning;scoliosis assessment;support vector classifiers","Back;Classification tree analysis;Diagnostic radiography;Medical treatment;Orthotics;Support vector machine classification;Support vector machines;Surface topography;Surgery;System testing","biomechanics;biomedical measurement;bone;image classification;medical image processing;support vector machines;surface topography measurement","human backs;idiopathic scoliosis;spine;support vector machines classifier;surface topographic images;trunk deformity","","45","","35","","","Jan. 2006","","IEEE","IEEE Journals & Magazines"
"Functional census of mutation sequence spaces: the example of p53 cancer rescue mutants","S. A. Danziger; S. J. Swamidass; Jue Zeng; L. R. Dearth; Qiang Lu; J. H. Chen; J. Cheng; V. P. Hoang; H. Saigo; R. Luo; P. Baldi; R. K. Brachmann; R. H. Lathrop","California Univ., Irvine, CA, USA","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20060515","2006","3","2","114","125","Many biomedical problems relate to mutant functional properties across a sequence space of interest, e.g., flu, cancer, and HIV. Detailed knowledge of mutant properties and function improves medical treatment and prevention. A functional census of p53 cancer rescue mutants would aid the search for cancer treatments from p53 mutant rescue. We devised a general methodology for conducting a functional census of a mutation sequence space by choosing informative mutants early. The methodology was tested in a double-blind predictive test on the functional rescue property of 71 novel putative p53 cancer rescue mutants iteratively predicted in sets of three (24 iterations). The first double-blind 15-point moving accuracy was 47 percent and the last was 86 percent; r = 0.01 before an epiphanic 16th iteration and r = 0.92 afterward. Useful mutants were chosen early (overall r = 0.80). Code and data are freely available (http://www.igb.uci.edu/research/research.html, corresponding authors: R.H.L. for computation and R.K.B. for biology)","1545-5963;15455963","","10.1109/TCBB.2006.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631993","Biology and genetics;feature extraction or construction;machine learning;medicine and science.","Cancer;DNA;Genetic mutations;Human immunodeficiency virus;Immune system;Influenza;Medical treatment;Neoplasms;Sequences;Testing","cancer;codes;iterative methods;medical computing;molecular biophysics;prediction theory;proteins","HIV;cancer;cancer treatments;code;double-blind predictive test;flu;functional census;iteration;medical prevention;medical treatment;mutation sequence spaces;p53 cancer rescue mutants","Artificial Intelligence;Binding Sites;Computational Biology;Humans;Internet;Models, Molecular;Models, Statistical;Mutation;Mutation, Missense;Neoplasms;Protein Folding;Protein Structure, Tertiary;ROC Curve;Suppression, Genetic;Surface Properties;Tumor Suppressor Protein p53","15","","54","","","April-June 2006","","IEEE","IEEE Journals & Magazines"
"An intelligent system approach to higher-dimensional classification of volume data","F. Y. Tzeng; E. B. Lum; K. L. Ma","Dept. of Comput. Sci., California Univ., Davis, CA, USA","IEEE Transactions on Visualization and Computer Graphics","20050321","2005","11","3","273","284","In volume data visualization, the classification step is used to determine voxel visibility and is usually carried out through the interactive editing of a transfer function that defines a mapping between voxel value and color/opacity. This approach is limited by the difficulties in working effectively in the transfer function space beyond two dimensions. We present a new approach to the volume classification problem which couples machine learning and a painting metaphor to allow more sophisticated classification in an intuitive manner. The user works in the volume data space by directly painting on sample slices of the volume and the painted voxels are used in an iterative training process. The trained system can then classify the entire volume. Both classification and rendering can be hardware accelerated, providing immediate visual feedback as painting progresses. Such an intelligent system approach enables the user to perform classification in a much higher dimensional space without explicitly specifying the mapping for every dimension used. Furthermore, the trained system for one data set may be reused to classify other data sets with similar characteristics.","1077-2626;10772626","","10.1109/TVCG.2005.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407860","Index Terms- User interface design;classification;graphics hardware;machine learning.;transfer functions;visualization;volume rendering","Acceleration;Data visualization;Feedback;Graphics;Hardware;Intelligent systems;Machine learning;Painting;Rendering (computer graphics);Transfer functions","computer graphic equipment;data visualisation;graphical user interfaces;image classification;image colour analysis;learning (artificial intelligence);opacity;rendering (computer graphics)","data classification;graphics hardware;intelligent system;interactive editing;iterative training;machine learning;opacity;painting metaphor;user interface design;visual feedback;volume classification problem;volume data visualization;volume rendering;volume sample slices;voxel visibility","Algorithms;Artificial Intelligence;Cluster Analysis;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface","65","1","28","","","May-June 2005","","IEEE","IEEE Journals & Magazines"
"Recovering intrinsic images from a single image","M. F. Tappen; W. T. Freeman; E. H. Adelson","Comput. Sci. & Artificial Intelligence Lab., MIT, Cambridge, MA, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20050725","2005","27","9","1459","1472","Interpreting real-world images requires the ability distinguish the different characteristics of the scene that lead to its final appearance. Two of the most important of these characteristics are the shading and reflectance of each point in the scene. We present an algorithm that uses multiple cues to recover shading and reflectance intrinsic images from a single image. Using both color information and a classifier trained to recognize gray-scale patterns, given the lighting direction, each image derivative is classified as being caused by shading or a change in the surface's reflectance. The classifiers gather local evidence about the surface's form and color, which is then propagated using the generalized belief propagation algorithm. The propagation step disambiguates areas of the image where the correct classification is not clear from local evidence. We use real-world images to demonstrate results and show how each component of the system affects the results.","0162-8828;01628828","","10.1109/TPAMI.2005.185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471710","Index Terms- Computer vision;belief propagation.;boosting;machine learning;reflectance;shading","Belief propagation;Gray-scale;Humans;Image recognition;Layout;Lighting;Machine learning algorithms;Optical propagation;Pattern recognition;Reflectivity","image classification;image colour analysis;image reconstruction;reflectivity","color information;generalized belief propagation algorithm;gray-scale patterns;image classification;image recovery;real-world images;reflectance intrinsic images;shading;single image","Algorithms;Artificial Intelligence;Colorimetry;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted","152","29","24","","","Sept. 2005","","IEEE","IEEE Journals & Magazines"
"Learning object models from semistructured Web documents","S. Ye; T. S. Chua","Dept. of Comput. Sci., Nat. Univ. of Singapore, Singapore","IEEE Transactions on Knowledge and Data Engineering","20060130","2006","18","3","334","349","This paper presents an automated approach to learning object models by means of useful object data extracted from data-intensive semistructured Web documents such as product descriptions. Modeling intensive data on the Web involves the following three phrases: first, we identify the object region covering the descriptions of object data when irrelevant contents from the Web documents are excluded. Second, we partition the contents of different object data appearing in the object region and construct object data using hierarchical XML outputs. Third, we induce the abstract object model from the analogous object data. This model would match the corresponding object data from a Web site more precisely and comprehensively than the existing handcrafted ontologies. The main contribution of this study is in developing a fully automated approach to extract object data and object model from semistructured Web documents using kernel-based matching and view syntax interpretation. Our system, OnModer, can automatically construct object data and induce object models from complicated Web documents, such as the technical descriptions of personal computers and digital cameras downloaded from manufacturers' and vendors' sites. A comparison with the available hand-crafted ontologies and tests on an open corpus demonstrate that our framework is effective in extracting meaningful and comprehensive models.","1041-4347;10414347","","10.1109/TKDE.2006.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1583583","DOM.;Index Terms- Web mining;computational geometry and object modeling;intelligent web services and Semantic Web;knowledge acquisition;machine learning;ontology design;web text analysis","Computer aided manufacturing;Data mining;Digital cameras;Manufacturing automation;Microcomputers;Ontologies;Semantic Web;Testing;Virtual manufacturing;XML","XML;data mining;learning (artificial intelligence);semantic Web","OnModer;Web site;XML;data-intensive semistructured Web documents;hand-crafted ontologies;kernel-based matching;object models;semantic Web;view syntax interpretation","","15","1","35","","","March 2006","","IEEE","IEEE Journals & Magazines"
"A new fuzzy support vector machine to evaluate credit risk","Yongqiao Wang; Shouyang Wang; K. K. Lai","Inst. of Syst. Sci., Acad. of Math. & Syst. Sci., Beijing, China","IEEE Transactions on Fuzzy Systems","20051212","2005","13","6","820","831","Due to recent financial crises and regulatory concerns, financial intermediaries' credit risk assessment is an area of renewed interest in both the academic world and the business community. In this paper, we propose a new fuzzy support vector machine to discriminate good creditors from bad ones. Because in credit scoring areas we usually cannot label one customer as absolutely good who is sure to repay in time, or absolutely bad who will default certainly, our new fuzzy support vector machine treats every sample as both positive and negative classes, but with different memberships. By this way we expect the new fuzzy support vector machine to have more generalization ability, while preserving the merit of insensitive to outliers, as the fuzzy support vector machine (SVM) proposed in previous papers. We reformulate this kind of two-group classification problem into a quadratic programming problem. Empirical tests on three public datasets show that it can have better discriminatory power than the standard support vector machine and the fuzzy support vector machine if appropriate kernel and membership generation method are chosen.","1063-6706;10636706","","10.1109/TFUZZ.2005.859320","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1556587","Classification;credit scoring;fuzzy theory;machine learning;support vector machine (SVM)","Business;Classification tree analysis;Kernel;Linear programming;Power generation;Quadratic programming;Risk management;Support vector machine classification;Support vector machines;Testing","financial management;fuzzy set theory;learning (artificial intelligence);quadratic programming;support vector machines","credit risk;fuzzy support vector machines;kernel method;machine learning;membership generation method;quadratic programming","","138","","39","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Self-organizing learning array","J. A. Starzyk; Zhen Zhu; Tsun-Ho Liu","Sch. of Electr. Eng. & Comput. Sci., Ohio Univ., Athens, OH, USA","IEEE Transactions on Neural Networks","20050307","2005","16","2","355","363","A new machine learning concept-self-organizing learning array (SOLAR)-is presented. It is a sparsely connected, information theory-based learning machine, with a multilayer structure. It has reconfigurable processing units (neurons) and an evolvable system structure, which makes it an adaptive classification system for a variety of machine learning problems. Its multilayer structure can handle complex problems. Based on the entropy estimation, information theory-based learning is performed locally at each neuron. Neural parameters and connections that correspond to minimum entropy are adaptively set for each neuron. By choosing connections for each neuron, the system sets up its wiring and completes its self-organization. SOLAR classifies input data based on the weighted statistical information from all the neurons. The system classification ability has been simulated and experiments were conducted using test-bench data. Results show a very good performance compared to other classification methods. An important advantage of this structure is its scalability to a large system and ease of hardware implementation on regular arrays of cells.","1045-9227;10459227","","10.1109/TNN.2004.842362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1402496","Information theory-based machine learning;multilayer learning array;self-organizing neurons","Adaptive systems;Entropy;Estimation theory;Hardware;Machine learning;Neurons;Nonhomogeneous media;Scalability;System testing;Wiring","adaptive systems;entropy;learning (artificial intelligence)","adaptive classification system;entropy estimation;evolvable system structure;information theory;machine learning;reconfigurable processing unit;self-organizing learning array","Learning;Neural Networks (Computer);Neurons","21","1","31","","","March 2005","","IEEE","IEEE Journals & Magazines"
"The applicability of recurrent neural networks for biological sequence analysis","J. Hawkins; M. Boden","Sch. of Inf. Technol. & Electr. Eng., Queensland Univ., Brisbane, Qld., Australia","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20050906","2005","2","3","243","253","Selection of machine learning techniques requires a certain sensitivity to the requirements of the problem. In particular, the problem can be made more tractable by deliberately using algorithms that are biased toward solutions of the requisite kind. In this paper, we argue that recurrent neural networks have a natural bias toward a problem domain of which biological sequence analysis tasks are a subset. We use experiments with synthetic data to illustrate this bias. We then demonstrate that this bias can be exploitable using a data set of protein sequences containing several classes of subcellular localization targeting peptides. The results show that, compared with feed forward, recurrent neural networks will generally perform better on sequence analysis tasks. Furthermore, as the patterns within the sequence become more ambiguous, the choice of specific recurrent architecture becomes more critical.","1545-5963;15455963","","10.1109/TCBB.2005.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1504688","Index Terms- Machine learning;bias;biological sequence analysis;classifier design.;motif;neural network architecture;pattern recognition;recurrent neural network;subcellular localization","Feedforward neural networks;Feeds;Hidden Markov models;Machine learning;Machine learning algorithms;Neural networks;Peptides;Proteins;Recurrent neural networks;Sequences","biology computing;cellular biophysics;feedforward neural nets;learning (artificial intelligence);molecular biophysics;molecular configurations;proteins;recurrent neural nets","biological sequence analysis;feed forward recurrent neural networks;machine learning;protein sequences;recurrent neural networks;subcellular localization targeting peptides","Algorithms;Amino Acid Sequence;Gene Expression Profiling;Molecular Sequence Data;Multigene Family;Neural Networks (Computer);Pattern Recognition, Automated;Proteins;Sequence Analysis, Protein;Subcellular Fractions","12","","21","","","July-Sept. 2005","","IEEE","IEEE Journals & Magazines"
"Crossover enhancements in GEFREX","M. Russo","Dept. of Phys. & Astron., Catania Univ., Italy","IEEE Transactions on Neural Networks","20050718","2005","16","4","1000","1002","This letter describes some improvements to the crossover operator in the genetic-neuro-fuzzy algorithm called genetic fuzzy rule extractor (GEFREX). Although, the new crossovers studied are very simple, the performance of GEFREX, in terms of learning time, is decidedly improved.","1045-9227;10459227","","10.1109/TNN.2005.849841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1461444","Crossover;fuzzy logic;genetic algorithms (GAs);machine learning;neural networks","Acceleration;Fuzzy logic;Fuzzy sets;Genetic algorithms;Least squares approximation;Machine learning;Machine learning algorithms;Neural networks;Phase detection;Supervised learning","fuzzy logic;fuzzy neural nets;genetic algorithms;learning (artificial intelligence)","GEFREX;crossover enhancement;genetic fuzzy rule extractor;genetic neuro fuzzy algorithm","Algorithms;Computer Simulation;Fuzzy Logic;Models, Statistical;Neural Networks (Computer);Pattern Recognition, Automated","0","","3","","","July 2005","","IEEE","IEEE Journals & Magazines"
"Toward intelligent music information retrieval","Tao Li; M. Ogihara","","IEEE Transactions on Multimedia","20060515","2006","8","3","564","574","Efficient and intelligent music information retrieval is a very important topic of the 21st century. With the ultimate goal of building personal music information retrieval systems, this paper studies the problem of intelligent music information retrieval. Huron points out that since the preeminent functions of music are social and psychological, the most useful characterization would be based on four types of information: genre, emotion, style,and similarity. This paper introduces Daubechies Wavelet Coefficient Histograms (DWCH)for music feature extraction for music information retrieval. The histograms are computed from the coefficients of the db<sub>8</sub> Daubechies wavelet filter applied to 3 s of music. A comparative study of sound features and classification algorithms on a dataset compiled by Tzanetakis shows that combining DWCH with timbral features (MFCC and FFT), with the use of multiclass extensions of support vector machine,achieves approximately 80% of accuracy, which is a significant improvement over the previously known result on this dataset. On another dataset the combination achieves 75% of accuracy. The paper also studies the issue of detecting emotion in music. Rating of two subjects in the three bipolar adjective pairs are used. The accuracy of around 70% was achieved in predicting emotional labeling in these adjective pairs. The paper also studies the problem of identifying groups of artists based on their lyrics and sound using a semi-supervised classification algorithm. Identification of artist groups based on the Similar Artist lists at All Music Guide is attempted. The semi-supervised learning algorithm resulted in nontrivial increases in the accuracy to more than 70%. Finally, the paper conducts a proof-of-concept experiment on similarity search using the feature set.","1520-9210;15209210","","10.1109/TMM.2006.870730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1632041","Clustering;FFT;machine learning;music information retrieval;wavelet","Classification algorithms;Feature extraction;Filters;Histograms;Intelligent structures;Labeling;Mel frequency cepstral coefficient;Music information retrieval;Psychology;Wavelet coefficients","emotion recognition;feature extraction;information retrieval;information retrieval systems;learning (artificial intelligence);music;support vector machines;wavelet transforms","Daubechies wavelet coefficient histogram;Daubechies wavelet filter;emotion detection;intelligent music information retrieval;music feature extraction;personal music information retrieval system;semisupervised classification algorithm;support vector machine","","55","","38","","","June 2006","","IEEE","IEEE Journals & Magazines"
"Getting Meaning into the Machine","Y. Wilks","University of Sheffield","IEEE Intelligent Systems","20060530","2006","21","3","70","71","The semantic Web is a development of great importance to AI as a whole - even though we still dispute what it means and how it can come into being","1541-1672;15411672","","10.1109/MIS.2006.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1637355","Semantic Web;artificial intelligence;connectionism;information extraction;machine learning;machine translation","Artificial intelligence;Data mining;Humans;Intelligent systems;Machine intelligence;Neutrino sources;Ontologies;Semantic Web;Space technology;World Wide Web","artificial intelligence;semantic Web","AI;artificial intelligence;semantic Web","","0","","","","","Jan.-Feb. 2006","","IEEE","IEEE Journals & Magazines"
"Learning and Education: A Continuing Frontier for AI","O. G. Selfridge","Massachusetts Institute of Technology Media Lab and BBN Technologies","IEEE Intelligent Systems","20060530","2006","21","3","16","23","Learning is the most important part of artificial intelligence. A basic research effort can explore how to build software that can learn and be educated very broadly","1541-1672;15411672","","10.1109/MIS.2006.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1637346","cognition;education;human learning;machine learning;purposes;software design","Artificial intelligence;Cognition;Computer science education;Continuing education;Educational institutions;Educational programs;Educational technology;Humans;Learning systems;Machine learning","learning (artificial intelligence)","AI learning;artificial intelligence","","1","","18","","","Jan.-Feb. 2006","","IEEE","IEEE Journals & Magazines"
"Automated detection of prostatic adenocarcinoma from high-resolution ex vivo MRI","A. Madabhushi; M. D. Feldman; D. N. Metaxas; J. Tomaszeweski; D. Chute","Dept. of Biomed. Eng., State Univ. of New Jersey, Piscataway, NJ, USA","IEEE Transactions on Medical Imaging","20051205","2005","24","12","1611","1625","Prostatic adenocarcinoma is the most commonly occurring cancer among men in the United States, second only to skin cancer. Currently, the only definitive method to ascertain the presence of prostatic cancer is by trans-rectal ultrasound (TRUS) directed biopsy. Owing to the poor image quality of ultrasound, the accuracy of TRUS is only 20%-25%. High-resolution magnetic resonance imaging (MRI) has been shown to have a higher accuracy of prostate cancer detection compared to ultrasound. Consequently, several researchers have been exploring the use of high resolution MRI in performing prostate biopsies. Visual detection of prostate cancer, however, continues to be difficult owing to its apparent lack of shape, and the fact that several malignant and benign structures have overlapping intensity and texture characteristics. In this paper, we present a fully automated computer-aided detection (CAD) system for detecting prostatic adenocarcinoma from 4 Tesla ex vivo magnetic resonance (MR) imagery of the prostate. After the acquired MR images have been corrected for background inhomogeneity and nonstandardness, novel three-dimensional (3-D) texture features are extracted from the 3-D MRI scene. A Bayesian classifier then assigns each image voxel a ""likelihood"" of malignancy for each feature independently. The ""likelihood"" images generated in this fashion are then combined using an optimally weighted feature combination scheme. Quantitative evaluation was performed by comparing the CAD results with the manually ascertained ground truth for the tumor on the MRI. The tumor labels on the MR slices were determined manually by an expert by visually registering the MR slices with the corresponding regions on the histology slices. We evaluated our CAD system on a total of 33 two-dimensional (2-D) MR slices from five different 3-D MR prostate studies. Five slices from two different glands were used for training. Our feature combination scheme was found to outperform the individual te- - xture features, and also other popularly used feature combination methods, including AdaBoost, ensemble averaging, and majority voting. Further, in several instances our CAD system performed better than the experts in terms of accuracy, the expert segmentations being determined solely from visual inspection of the MRI data. In addition, the intrasystem variability (changes in CAD accuracy with changes in values of system parameters) was significantly lower than the corresponding intraobserver and interobserver variability. CAD performance was found to be very similar for different training sets. Future work will focus on extending the methodology to guide high-resolution MRI-assisted in vivo prostate biopsies.","0278-0062;02780062","","10.1109/TMI.2005.859208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1546122","3-D texture;4 tesla;AdaBoost;CAD;MRI;general ensemble method;image analysis;image processing;machine learning;prostate;segmentation","Biopsy;Cancer detection;Image quality;Magnetic resonance;Magnetic resonance imaging;Neoplasms;Prostate cancer;Shape;Skin cancer;Ultrasonic imaging","Bayes methods;biomedical MRI;cancer;image classification;image resolution;image segmentation;image texture;medical image processing;tumours","AdaBoost,;Bayesian classifier;automated prostatic adenocarcinoma detection;benign structures;computer-aided detection;ensemble averaging;high-resolution ex vivo MRI;high-resolution magnetic resonance imaging;image registration;image segmentation;intrasystem variability;malignant structures;prostate cancer detection;texture features;transrectal ultrasound directed biopsy;tumor","Adenocarcinoma;Algorithms;Artificial Intelligence;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Male;Pattern Recognition, Automated;Prostatic Neoplasms;Reproducibility of Results;Sensitivity and Specificity","90","1","52","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Peptide charge state determination for low-resolution tandem mass spectra","A. A. Klammer; C. C. Wu; M. J. MacCoss; W. S. Noble","Dept. of Genome Sci., Seattle, WA, USA","2005 IEEE Computational Systems Bioinformatics Conference (CSB'05)","20050906","2005","","","175","185","Mass spectrometry is a particularly useful technology for the rapid and robust identification of peptides and proteins in complex mixtures. Peptide sequences can be identified by correlating their observed tandem mass spectra (MS/MS) with theoretical spectra of peptides from a sequence database. Unfortunately, to perform this search the charge of the peptide must be known, and current charge-state-determination algorithms only discriminate singly-from multiply-charged spectra: distinguishing +2 from +3, for example, is unreliable. Thus, search software is forced to search multiply-charged spectra multiple times. To minimize this inefficiency, we present a support vector machine (SVM) that quickly and reliably classifies multiply-charged spectra as having either a +2 or +3 precursor peptide ion. By classifying multiply-charged spectra, we obtain a 40% reduction in search time while maintaining an average of 99% of peptide and 99% of protein identifications originally obtained from these spectra.","","POD:0-7695-2344-7","10.1109/CSB.2005.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1498019","charge state;machine learning;mass spectrometry;proteomics;support vector machine","Bioinformatics;Databases;Genomics;Mass spectroscopy;Peptides;Proteins;Search methods;Sequences;Support vector machine classification;Support vector machines","biological techniques;biology computing;genetics;mass spectroscopy;molecular biophysics;pattern classification;proteins;search problems;support vector machines","SVM;charge-state-determination algorithms;machine learning;mass spectrometry;multiply-charged spectra classification;multiply-charged spectra search;peptide charge state determination;peptide sequences;peptides identification;protein identification;proteomics;search software;sequence database;singly-charged spectra;support vector machine;tandem mass spectra;theoretical peptide spectra","","3","","16","","","8-11 Aug. 2005","","IEEE","IEEE Conference Publications"
"Experience-Based Decision Making: A Satisficing Decision Tree Approach","E. Hullermeier","Dept. of Math. & Comput. Sci., Univ. of Marburg, Germany","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20050815","2005","35","5","641","653","This paper introduces a framework of experienced-based decision making as an extension of case-based decision making, a recently proposed alternative to expected utility theory. In experienced-based decision making, an agent faced with a new decision problem acts on the basis of experience gathered from previous problems in the past, either through predicting the utility of potential actions or through establishing a direct relationship between decision problems and appropriate actions. In the paper, a realization of the latter approach in the form of satisficing decision trees is proposed.","1083-4427;10834427","","10.1109/TSMCA.2005.851145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1495607","Bounded rationality;case-based reasoning;compilation;decision making;decision trees;machine learning","Decision making;Decision theory;Decision trees;Helium;Humans;Logic;Machine learning;Problem-solving;Uncertainty;Utility theory","case-based reasoning;decision making;decision trees;utility theory","case based decision making;decision tree;experience based decision making;utility theory","","4","","53","","","Sept. 2005","","IEEE","IEEE Journals & Magazines"
"An empirical comparison of nine pattern classifiers","Q. L. Tran; K. A. Toh; D. Srinivasan; K. L. Wong; Shaun Qiu-Cen Low","Inst. for Infocomm Res., Singapore, Singapore","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20050919","2005","35","5","1079","1091","There are many learning algorithms available in the field of pattern classification and people are still discovering new algorithms that they hope will work better. Any new learning algorithm, beside its theoretical foundation, needs to be justified in many aspects including accuracy and efficiency when applied to real life problems. In this paper, we report the empirical comparison of a recent algorithm RM, its new extensions and three classical classifiers in different aspects including classification accuracy, computational time and storage requirement. The comparison is performed in a standardized way and we believe that this would give a good insight into the algorithm RM and its extension. The experiments also show that nominal attributes do have an impact on the performance of those compared learning algorithms.","1083-4419;10834419","","10.1109/TSMCB.2005.847745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1510781","Hyperbolic functions;machine learning;parameter estimation;pattern classification;polynomials","Character recognition;Humans;Least squares approximation;Machine learning;Machine learning algorithms;Parameter estimation;Pattern classification;Pattern recognition;Polynomials;Support vector machines","learning (artificial intelligence);pattern classification;polynomials","hyperbolic function;machine learning algorithm;parameter estimation;pattern classification;pattern classifier;reduced multivariate polynomial","Algorithms;Artificial Intelligence;Cluster Analysis;Information Storage and Retrieval;Pattern Recognition, Automated;Software;Software Validation","10","","20","","","Oct. 2005","","IEEE","IEEE Journals & Magazines"
"Reliability and validity in comparative studies of software prediction models","I. Myrtveit; E. Stensrud; M. Shepperd","Norwegian Sch. of Manage. BI, Sandvika, Norway","IEEE Transactions on Software Engineering","20050606","2005","31","5","380","391","Empirical studies on software prediction models do not converge with respect to the question ""which prediction model is best?"" The reason for this lack of convergence is poorly understood. In this simulation study, we have examined a frequently used research procedure comprising three main ingredients: a single data sample, an accuracy indicator, and cross validation. Typically, these empirical studies compare a machine learning model with a regression model. In our study, we use simulation and compare a machine learning and a regression model. The results suggest that it is the research procedure itself that is unreliable. This lack of reliability may strongly contribute to the lack of convergence. Our findings thus cast some doubt on the conclusions of any study of competing software prediction models that used this research procedure as a basis of model comparison. Thus, we need to develop more reliable research procedures before we can have confidence in the conclusions of comparative studies of software prediction models.","0098-5589;00985589","","10.1109/TSE.2005.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1438374","Index Terms- Software metrics;accuracy indicators.;arbitrary function approximators;cost estimation;cross-validation;empirical methods;estimation by analogy;machine learning;regression analysis;reliability;simulation;validity","Analytical models;Artificial neural networks;Convergence;Cost function;Machine learning;Mathematical model;Maximum likelihood estimation;Predictive models;Programming;Regression analysis","convergence;function approximation;learning (artificial intelligence);program verification;regression analysis;software cost estimation;software metrics;software reliability","accuracy indicator;analogy estimation;arbitrary function approximators;convergence;cost estimation;cross validation;data sample;empirical method;machine learning model;regression model;simulation;software metrics;software prediction model;software reliability;software validity","","100","","44","","","May 2005","","IEEE","IEEE Journals & Magazines"
"Group decorrelation enhanced subspace method for identifying FIR MIMO channels driven by unknown uncorrelated colored sources","Senjian An; Yingbo Hua; J. H. Manton; Zheng Fang","Dept. of Comput., Curtin Univ. of Technol., WA, Australia","IEEE Transactions on Signal Processing","20051121","2005","53","12","4429","4441","Identification of finite-impulse-response (FIR) and multiple-input multiple-output (MIMO) channels driven by unknown uncorrelated colored sources is a challenging problem. In this paper, a group decorrelation enhanced subspace (GDES) method is presented. The GDES method uses the idea of subspace decomposition and signal decorrelation more effectively than the joint diagonalization enhanced subspace (JDES) method previously reported in the literature. The GDES method has a much better performance than the JDES method. The correctness of the GDES method is proved assuming that 1) the channel matrix is irreducible and column reduced and 2) the source spectral matrix has distinct diagonal functions. However, the GDES method has an inherent ability to trade off between the required condition on the channel matrix and that on the source spectral matrix. Simulations show that the GDES method yields good results even when the channel matrix is not irreducible, which is not possible at all for the JDES method.","1053-587X;1053587X","","10.1109/TSP.2005.859339","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542471","Adaptive signal processing;MIMO channels;blind deconvolution;blind identification;machine learning;sensor array processing;source separation;system identification","Array signal processing;Deconvolution;Decorrelation;Finite impulse response filter;Higher order statistics;MIMO;Machine learning;Matrix decomposition;Sensor arrays;Sensor systems","MIMO systems;adaptive signal processing;array signal processing;deconvolution;learning (artificial intelligence);telecommunication channels","FIR MIMO channel identification;adaptive signal processing;blind deconvolution;channel matrix;finite-impulse-response;group decorrelation enhanced subspace method;joint diagonalization enhanced subspace method;machine learning;multiple-input multiple-output;sensor array processing;signal decorrelation;source separation;source spectral matrix;subspace decomposition;unknown uncorrelated colored source","","15","","15","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Learning-Assisted Multi-Step Planning","K. Hauser; T. Bretl; J. C. Latombe","Stanford University Stanford, CA 94307, USA; khauser@cs.stanford.edu","Proceedings of the 2005 IEEE International Conference on Robotics and Automation","20060110","2005","","","4575","4580","Probabilistic sampling-based motion planners are unable to detect when no feasible path exists. A common heuristic is to declare a query infeasible if a path is not found in a fixed amount of time. In applications where many queries must be processed  for instance, robotic manipulation, multi-limbed locomotion, and contact motion  a critical question arises: what should this time limit be? This paper presents a machine-learning approach to deal with this question. In an off-line learning phase, a classifier is trained to quickly predict the feasibility of a query. Then, an improved multi-step motion planning algorithm uses this classifier to avoid wasting time on infeasible queries. This approach has been successfully demonstrated in simulation on a four-limbed, free-climbing robot.","1050-4729;10504729","POD:0-7803-8914-X","10.1109/ROBOT.2005.1570825","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1570825","Motion planning;climbing robot;machine learning;multi-step planning","Climbing robots;Machine learning;Machine learning algorithms;Motion detection;Motion planning;Orbital robotics;Path planning;Robustness;Sampling methods;Testing","","Motion planning;climbing robot;machine learning;multi-step planning","","4","","18","","","18-22 April 2005","","IEEE","IEEE Conference Publications"
"An Efficient Algorithm for Generating Generalized Decision Forests","Huimin Zhao; A. P. Sinha","Sch. of Bus. Adm., Univ. of Wisconsin-Milwaukee, Milwaukee, WI, USA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20050815","2005","35","5","754","762","A shortcoming of univariate decision tree learners is that they do not learn intermediate concepts and select only one of the input features in the branching decision at each intermediate tree node. It has been empirically demonstrated that cascading other classification methods, which learn intermediate concepts, with decision tree learners can alleviate such representational bias of decision trees and potentially improve classification performance. However, a more complex model that fits training data better may not necessarily perform better on unseen data, commonly referred to as the overfitting problem. To find the most appropriate degree of such cascade generalization, a decision forest (i.e., a set of decision trees with other classification models cascaded to different degrees) needs to be generated, from which the best decision tree can then be identified. In this paper, the authors propose an efficient algorithm for generating such decision forests. The algorithm uses an extended decision tree data structure and constructs any node that is common to multiple decision trees only once. The authors have empirically evaluated the algorithm using 32 data sets for classification problems from the University of California, Irvine (UCI) machine learning repository and report on results demonstrating the efficiency of the algorithm in this paper.","1083-4427;10834427","","10.1109/TSMCA.2005.843392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1495617","Cascade generalization;classification;data mining;decision forest;decision tree;machine learning","Classification tree analysis;Data mining;Decision making;Decision trees;Machine learning;Machine learning algorithms;Predictive models;Supervised learning;Training data;Tree data structures","data mining;data structures;decision trees","cascade generalization;data mining;data structure;generalized decision forest;univariate decision tree learners","","9","","26","","","Sept. 2005","","IEEE","IEEE Journals & Magazines"
"Highly scalable and robust rule learner: performance evaluation and comparison","L. A. Kurgan; K. J. Cios; S. Dick","Dept. of Electr. & Comput. Eng., Univ. of Alberta, Edmonton, Alta., Canada","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20060123","2006","36","1","32","53","Business intelligence and bioinformatics applications increasingly require the mining of datasets consisting of millions of data points, or crafting real-time enterprise-level decision support systems for large corporations and drug companies. In all cases, there needs to be an underlying data mining system, and this mining system must be highly scalable. To this end, we describe a new rule learner called DataSqueezer. The learner belongs to the family of inductive supervised rule extraction algorithms. DataSqueezer is a simple, greedy, rule builder that generates a set of production rules from labeled input data. In spite of its relative simplicity, DataSqueezer is a very effective learner. The rules generated by the algorithm are compact, comprehensible, and have accuracy comparable to rules generated by other state-of-the-art rule extraction algorithms. The main advantages of DataSqueezer are very high efficiency, and missing data resistance. DataSqueezer exhibits log-linear asymptotic complexity with the number of training examples, and it is faster than other state-of-the-art rule learners. The learner is also robust to large quantities of missing data, as verified by extensive experimental comparison with the other learners. DataSqueezer is thus well suited to modern data mining and business intelligence tasks, which commonly involve huge datasets with a large fraction of missing data.","1083-4419;10834419","","10.1109/TSMCB.2005.852983","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580617","Complexity;DataSqueezer;data mining;machine learning;missing data;rule induction;rule learner","Bioinformatics;Companies;Computer science;Data mining;Decision support systems;Decision trees;Drugs;Production;Real time systems;Robustness","competitive intelligence;computational complexity;data mining;decision support systems;greedy algorithms;learning (artificial intelligence);very large databases","DataSqueezer rule learner;bioinformatics;business intelligence;data mining system;dataset mining;greedy rule builder;inductive supervised rule extraction algorithm;log-linear asymptotic complexity;machine learning;real-time enterprise-level decision support system","Algorithms;Artificial Intelligence;Database Management Systems;Databases, Factual;Decision Support Techniques;Information Storage and Retrieval","22","","82","","","Feb. 2006","","IEEE","IEEE Journals & Magazines"
"Essential latent knowledge for protein-protein interactions: analysis by an unsupervised learning approach","H. Mamitsuka","Inst. for Chem. Res., Kyoto Univ., Japan","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20050606","2005","2","2","119","130","Protein-protein interactions play a number of central roles in many cellular functions, including DNA replication, transcription and translation, signal transduction, and metabolic pathways. A recent increase in the number of protein-protein interactions has made predicting unknown protein-protein interactions important for the understanding of living cells. However, the protein-protein interactions experimentally obtained so far are often incomplete and contradictory and, consequently, existing computational prediction methods have integrated evidence (latent knowledge of proteins) from different and more reliable sources. Analyzing the relationships between proteins and the latent knowledge is important to understanding the cellular processes. For this analysis, we propose a new probabilistic model for protein-protein interactions by considering the latent knowledge of proteins. We further present an efficient learning algorithm for this model, based on an EM algorithm. Experimental results have shown that in a supervised test setting, the proposed method outperformed five other competing methods by a statistically significant factor in all cases. Using the probability parameters of a trained model, we have further shown the latent knowledge that is essential to predicting protein-protein interactions. Overall, our experimental results confirm that our proposed model is especially effective for analyzing protein-protein interactions from a viewpoint of the latent knowledge of proteins.","1545-5963;15455963","","10.1109/TCBB.2005.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1438349","Biology and genetics;data mining;machine learning;mining methods and algorithms.","Clustering algorithms;DNA;Data mining;Prediction methods;Predictive models;Protein engineering;Sequences;Signal analysis;Transaction databases;Unsupervised learning","DNA;biology computing;cellular biophysics;molecular biophysics;prediction theory;probability;proteins;unsupervised learning","DNA replication;DNA transcription;DNA translation;cellular functions;computational prediction methods;essential latent knowledge;metabolic pathways;probability parameters;protein-protein interactions;signal transduction;unsupervised learning","Algorithms;Artificial Intelligence;Cluster Analysis;Gene Expression Profiling;Pattern Recognition, Automated;Protein Interaction Mapping;Proteome;Signal Transduction","7","","28","","","April-June 2005","","IEEE","IEEE Journals & Magazines"
"Associative clustering for exploring dependencies between functional genomics data sets","S. Kaski; J. Nikkila; J. Sinkkonen; L. Lahti; J. E. A. Knuuttila; C. Roos","Dept. of Comput. Sci., Helsinki Univ., Finland","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20050906","2005","2","3","203","216","High-throughput genomic measurements, interpreted as cooccurring data samples from multiple sources, open up a fresh problem for machine learning: What is in common in the different data sets, that is, what kind of statistical dependencies are there between the paired samples from the different sets? We introduce a clustering algorithm for exploring the dependencies. Samples within each data set are grouped such that the dependencies between groups of different sets capture as much of pairwise dependencies between the samples as possible. We formalize this problem in a novel probabilistic way, as optimization of a Bayes factor. The method is applied to reveal commonalities and exceptions in gene expression between organisms and to suggest regulatory interactions in the form of dependencies between gene expression profiles and regulator binding patterns.","1545-5963;15455963","","10.1109/TCBB.2005.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1504685","Index Terms- Biology and genetics;clustering;contingency table analysis;machine learning;multivariate statistics.","Bioinformatics;Clustering algorithms;Gene expression;Genetics;Genomics;Machine learning;Machine learning algorithms;Organisms;Regulators;Statistical analysis","Bayes methods;biology computing;genetics;learning (artificial intelligence);molecular biophysics;optimisation;statistical analysis","Bayes factor;associative clustering;clustering algorithm;functional genomics data sets;gene expression;machine learning;optimization;pairwise dependencies;regulator binding patterns;regulatory interactions;statistical dependencies","Algorithms;Artificial Intelligence;Chromosome Mapping;Cluster Analysis;Computer Simulation;Databases, Genetic;Gene Expression Profiling;Information Storage and Retrieval;Models, Genetic;Multigene Family;Oligonucleotide Array Sequence Analysis;Statistics as Topic","5","","46","","","July-Sept. 2005","","IEEE","IEEE Journals & Magazines"
"Evolving ultrafast laser information by a learning genetic algorithm combined with a knowledge base","S. F. Shu","Dept. of Electron. Eng., Ching Yun Univ., Taoyuan, Taiwan","IEEE Photonics Technology Letters","20060103","2006","18","2","379","381","A genetic algorithm (GA) with learning ability has been developed to retrieve the simulated ultrafast laser traces from a second-harmonic generation frequency-resolved optical gating measurement. This learning system handles the trace feature representation, storage, and utilization for helping GA evolution. By properly storing the features in a previously established knowledge base, the system can reuse previous experiences in every new evolution. Its time cost for the same error order is proved to be lower than that for the same GA without learning ability.","1041-1135;10411135","","10.1109/LPT.2005.861953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1564161","Genetic algorithm (GA);machine learning;simulation;ultrafast laser","Frequency measurement;Genetic algorithms;Genetic programming;Laser modes;Laser tuning;Learning systems;Neural networks;Optical harmonic generation;Optical pulses;Ultrafast optics","genetic algorithms;high-speed optical techniques;knowledge based systems;learning (artificial intelligence);optical harmonic generation","frequency-resolved optical gating;genetic algorithm;knowledge base;learning ability;second-harmonic generation;trace feature representation;ultrafast laser","","0","","5","","","Jan. 15, 2006","","IEEE","IEEE Journals & Magazines"
"Ensemble imputation methods for missing software engineering data","B. Twala; M. Cartwright","Brunei Univ., Manchester, UK","11th IEEE International Software Metrics Symposium (METRICS'05)","20051024","2005","","","10 pp.","30","One primary concern of software engineering is prediction accuracy. We use datasets to build and validate prediction systems of software development effort, for example. However it is not uncommon for datasets to contain missing values. When using machine learning techniques to build such prediction systems, handling of incomplete data is an important issue for classifier learning since missing values in either training or test set or in both sets can affect prediction accuracy. Many works in machine learning and statistics have shown that combining (ensemble) individual classifiers is an effective technique for improving accuracy of classification. The ensemble strategy is investigated in the context of incomplete data and software prediction. An ensemble Bayesian multiple imputation and nearest neighbour single imputation method, BAMINNSI, is proposed that constructs ensembles based on two imputation methods. Strong results on two benchmark industrial datasets using decision trees support the method","1530-1435;15301435","POD:0-7695-2371-4","10.1109/METRICS.2005.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509308","Machine learning;decision trees;ensemble;imputation;incomplete data;software prediction","Accuracy;Bayesian methods;Decision trees;Industrial training;Machine learning;Programming;Robustness;Software engineering;Software quality;Statistics","Bayes methods;decision trees;learning (artificial intelligence);software cost estimation;software metrics","classifier learning;data handling;decision trees;ensemble Bayesian multiple imputation method;ensemble imputation methods;machine learning;nearest neighbour single imputation method;prediction systems;software development;software engineering;software prediction","","4","","29","","","1-1 Sept. 2005","","IEEE","IEEE Conference Publications"
"Knowledge-based web-enabled agents and intelligent tutoring systems","S. Piramuthu","Decision & Inf. Sci., Univ. of Florida, Gainesville, FL, USA","IEEE Transactions on Education","20051114","2005","48","4","750","756","Intelligent tutoring systems have been in existence for decades, and their characteristics can be beneficially applied in environments utilizing information and communication technology (ICT). The ""intelligence"" in these systems is seen through the way these systems adapt themselves to the characteristics of the students, such as speed of learning, specific areas in which the student excels as well as falls behind, and rate of learning as more knowledge is learned. In such intelligent learning environments, the agent or set of agents can be modeled to perform pedagogical tasks. This paper considers the necessary characteristics that constitute a good intelligent tutoring system. This paper introduces a framework incorporating an incremental machine-learning approach to capture 1) the dynamics of knowledge creation in the domain of interest and 2) the learned-knowledge content of the student over time. Some of the components of the proposed system are illustrated using examples from an introductory course on database design.","0018-9359;00189359","","10.1109/TE.2005.854574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1532385","Agent-based;intelligent tutoring systems;knowledge-based system;machine learning;virtual learning environments","Communications technology;Computer science education;Databases;Educational technology;Feedback;Intelligent agent;Intelligent systems;Knowledge based systems;Learning systems;Machine learning","Internet;educational courses;intelligent tutoring systems;learning (artificial intelligence)","database design course;incremental machine-learning approach;information and communication technology;intelligent learning environments;intelligent tutoring systems;knowledge-based Web-enabled agents;learned-knowledge content;student learning","","20","","31","","","Nov. 2005","","IEEE","IEEE Journals & Magazines"
"Metric learning for text documents","G. Lebanon","Dept. of Stat., Purdue Univ., West Lafayette, IN, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20060221","2006","28","4","497","508","Many algorithms in machine learning rely on being given a good distance metric over the input space. Rather than using a default metric such as the Euclidean metric, it is desirable to obtain a metric based on the provided data. We consider the problem of learning a Riemannian metric associated with a given differentiable manifold and a set of points. Our approach to the problem involves choosing a metric from a parametric family that is based on maximizing the inverse volume of a given data set of points. From a statistical perspective, it is related to maximum likelihood under a model that assigns probabilities inversely proportional to the Riemannian volume element. We discuss in detail learning a metric on the multinomial simplex where the metric candidates are pull-back metrics of the Fisher information under a Lie group of transformations. When applied to text document classification the resulting geodesic distance resemble, but outperform, the tfidf cosine similarity measure.","0162-8828;01628828","","10.1109/TPAMI.2006.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1597108","Distance learning;machine learning.;text analysis","Euclidean distance;Geometry;Joining processes;Kernel;Level measurement;Machine learning;Machine learning algorithms;Neural networks;Probability;Text analysis","Lie groups;differential geometry;learning (artificial intelligence);statistical analysis;text analysis;transforms","Fisher information;Lie group;Riemannian metric;Riemannian volume element;differentiable manifold;geodesic distance;inverse volume maximization;machine learning;maximum likelihood;metric learning;multinomial simplex;pull-back metrics;text documents;tfidf cosine similarity measure","Algorithms;Artificial Intelligence;Automatic Data Processing;Computer Graphics;Documentation;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted;User-Computer Interface","36","1","13","","","April 2006","","IEEE","IEEE Journals & Magazines"
"Kinematic Redundancy in Robot Grasp Synthesis. An Efficient Tree-based Representation","C. Fernandez; O. Reinoso; A. Vicente; R. Aracil","System Engineering and Automation Division Miguel Hernandez University Av. Universidad s/n, 03202 Elche (Alicante) Spain; c.fernandez@umh.es","Proceedings of the 2005 IEEE International Conference on Robotics and Automation","20060110","2005","","","1184","1189","A redundancy resolution technique devoted to grasp synthesis is presented. Given a set of contact points and a certain robot arm and gripper, the goal is to select both the best assignment of gripper fingers to contact points and the best joint values that allow the fingers to reach such contact points. The system proposed is based on the generation of an inverse kinematics tree where fast searches can be performed in order to find the optimum configuration. Optimality is defined as similarity to previously stored examples over a hierarchical structure of configuration data, which includes finger assignments and robot joints.","1050-4729;10504729","POD:0-7803-8914-X","10.1109/ROBOT.2005.1570276","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1570276","Grasp synthesis;inverse kinematics;machine learning;redundancy resolution","Automatic control;End effectors;Fingers;Grippers;Intelligent robots;Intelligent sensors;Kinematics;Orbital robotics;Robot sensing systems;Robotics and automation","","Grasp synthesis;inverse kinematics;machine learning;redundancy resolution","","0","","12","","","18-22 April 2005","","IEEE","IEEE Conference Publications"
"Probabilistic finite-state machines - part I","E. Vidal; F. Thollard; C. de la Higuera; F. Casacuberta; R. C. Carrasco","Departamento de Sistemas Informaticos y Computacion, Univ. Politecnica de Valencia, Spain","IEEE Transactions on Pattern Analysis and Machine Intelligence","20050523","2005","27","7","1013","1025","Probabilistic finite-state machines are used today in a variety of areas in pattern recognition, or in fields to which pattern recognition is linked: computational linguistics, machine learning, time series analysis, circuit testing, computational biology, speech recognition, and machine translation are some of them. In Part I of this paper, we survey these generative objects and study their definitions and properties. In Part II, we study the relation of probabilistic finite-state automata with other well-known devices that generate strings as hidden Markov models and n-grams and provide theorems, algorithms, and properties that represent a current state of the art of these objects.","0162-8828;01628828","","10.1109/TPAMI.2005.147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1432736","Index Terms- Automata;classes defined by grammars or automata;language acquisition;language models;language parsing and understanding;machine learning;machine translation;speech recognition and synthesis;structural pattern recognition;syntactic pattern recognition.","Circuit analysis;Circuit testing;Computational biology;Computational linguistics;Machine learning;Pattern analysis;Pattern recognition;Speech analysis;Speech recognition;Time series analysis","finite state machines;pattern recognition;probabilistic automata","circuit testing;computational biology;computational linguistics;hidden Markov models;machine learning;machine translation;pattern recognition;probabilistic finite-state automata;probabilistic finite-state machines;speech recognition;time series analysis","Algorithms;Artificial Intelligence;Cluster Analysis;Computer Simulation;Information Storage and Retrieval;Models, Statistical;Natural Language Processing;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Sequence Alignment;Sequence Analysis;Signal Processing, Computer-Assisted","73","","62","","","July 2005","","IEEE","IEEE Journals & Magazines"
"Reducing the cost of protein identifications from mass spectrometry databases","B. Logan; L. Kontothanassis; D. Goddeau; P. J. Moreno; R. Hookway; D. Sarracino","Hewlett-Packard Labs, Cambridge, MA, USA","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20050314","2004","2","","3060","3063","We present two techniques to improve the computational efficiency of protein discovery from mass spectrometry databases: noise filtering and hierarchical searching. Our approaches are orthogonal to existing algorithms and are based on the observation that typical mass spectrometry data contains a large amount of noise that can lead to wasteful computation. Our first improvement uses standard machine learning techniques with novel feature vectors derived from the mass spectra to identify and filter the noisy spectra. We demonstrate this approach results in computational gains of around 38% with less than 10% loss of peptides. Additionally we present a hierarchical searching scheme in which most samples are matched against a small database at low computational cost, leaving only a small number of samples to be searched against larger databases. Combining this scheme with the machine learning filters leads to a further performance improvement of 3%.","","POD:0-7803-8439-3","10.1109/IEMBS.2004.1403865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1403865",": mass spectrometry;machine learning;noise filtering;workflow management","Computational efficiency;Costs;Filtering;Filters;Machine learning;Machine learning algorithms;Mass spectroscopy;Peptides;Proteins;Spatial databases","biochemistry;database management systems;learning (artificial intelligence);mass spectra;mass spectroscopy;medical information systems;medical signal processing;molecular biophysics;proteins;workflow management software","computational efficiency;feature vectors;hierarchical searching;machine learning techniques;mass spectra;mass spectrometry databases;noise filtering;noisy spectra;peptides;protein identification;workflow management","","0","2","5","","","1-5 Sept. 2004","","IEEE","IEEE Conference Publications"
"Supervised image classification by contextual AdaBoost based on posteriors in neighborhoods","R. Nishii; S. Eguchi","Fac. of Math., Kyushu Univ., Fukuoka, Japan","IEEE Transactions on Geoscience and Remote Sensing","20051024","2005","43","11","2547","2554","AdaBoost, a machine learning technique, is employed for supervised classification of land-cover categories of geostatistical data. We introduce contextual classifiers based on neighboring pixels. First, posterior probabilities are calculated at all pixels. Then, averages of the log posteriors are calculated in different neighborhoods and are then used as contextual classification functions. Weights for the classification functions can be determined by minimizing the empirical risk with multiclass. Finally, a convex combination of classification functions is obtained. The classification is performed by a noniterative maximization procedure. The proposed method is applied to artificial multispectral images and benchmark datasets. The performance of the proposed method is excellent and is similar to the Markov-random-field-based classifier, which requires an iterative maximization procedure.","0196-2892;01962892","","10.1109/TGRS.2005.848693","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1522615","Bayes rule;Markov random field (MRF);image segmentation;machine learning;posterior probability","Image classification;Image segmentation;Iterative methods;Machine learning;Markov random fields;Mathematics;Multispectral imaging;Pattern recognition;Probability;Voting","Bayes methods;Markov processes;geophysical signal processing;geophysical techniques;image classification;image segmentation;learning (artificial intelligence);optimisation;remote sensing","Bayes rule;Markov random field;artificial multispectral images;classification functions;contextual AdaBoost;contextual classifiers;image classification;image segmentation;land cover;log posteriors;machine learning technique;noniterative maximization;posterior probability","","20","","17","","","Nov. 2005","","IEEE","IEEE Journals & Magazines"
"Partial discharge pattern classification using the fuzzy decision tree approach","T. K. Abdel-Galil; R. M. Sharkawy; M. M. A. Salama; R. Bartnikas","Dept. of Electr. & Comput. Eng., Univ. of Waterloo, Ont., Canada","IEEE Transactions on Instrumentation and Measurement","20051121","2005","54","6","2258","2263","Partial discharge (PD) measurement is a proven flaw detection technique for finding cavities that are defects in the insulating material. In this paper, a novel approach for the classification of cavity sizes, based on their maximum PD charge transfer-applied voltage (Q-V) characteristics using a fuzzy decision tree system, is proposed. The (Q-V) partial discharge patterns for different cavity sizes are represented by features extracted from their pulse shapes, and the classification rules are directly extracted from the data using the decision tree. The decision rules obtained from the decision tree are then converted to the fuzzy IF-then rules, and the back-propagation algorithm is utilized to tune the parameters of the membership functions employed in the fuzzy classifier. The neuro-fuzzy classification technique is shown to provide successful classification of void sizes in an easily interpretive fashion.","0018-9456;00189456","","10.1109/TIM.2005.858143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542524","Cavity size classification;decision tree;fuzzy logic;machine learning;partial discharges","Classification tree analysis;Data mining;Decision trees;Feature extraction;Fuzzy systems;Insulation;Partial discharge measurement;Partial discharges;Pattern classification;Voltage","decision trees;feature extraction;flaw detection;fuzzy logic;insulating materials;neural nets;partial discharge measurement;pattern classification","back-propagation algorithm;cavity size classification;features extraction;flaw detection;fuzzy decision tree;fuzzy if-then rules;fuzzy logic;insulating material;machine learning;membership functions;neuro-fuzzy classification;partial discharge pattern classification;void size classification","","27","","22","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Data mining for case-based reasoning in high-dimensional biological domains","N. Arshadi; I. Jurisica","Dept. of Comput. Sci., Toronto Univ., Ont., Canada","IEEE Transactions on Knowledge and Data Engineering","20050627","2005","17","8","1127","1137","Case-based reasoning (CBR) is a suitable paradigm for class discovery in molecular biology, where the rules that define the domain knowledge are difficult to obtain and the number and the complexity of the rules affecting the problem are too large for formal knowledge representation. To extend the capabilities of CBR, we propose the mixture of experts for case-based reasoning (MOE4CBR), a method that combines an ensemble of CBR classifiers with spectral clustering and logistic regression. Our approach not only achieves higher prediction accuracy, but also leads to the selection of a subset of features that have meaningful relationships with their class labels. We evaluate MOE4CBR by applying the method to a CBR system called TA3 - a computational framework for CBR systems. For two ovarian mass spectrometry data sets, the prediction accuracy improves from 80 percent to 93 percent and from 90 percent to 98.4 percent, respectively. We also apply the method to leukemia and lung microarray data sets with prediction accuracy improving from 65 percent to 74 percent and from 60 percent to 70 percent, respectively. Finally, we compare our list of discovered biomarkers with the lists of selected biomarkers from other studies for the mass spectrometry data sets.","1041-4347;10414347","","10.1109/TKDE.2005.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1458705","Index Terms- Machine learning;biomarker discovery.;case-based reasoning classifiers;clustering;data mining;feature selection;mass spectrometry data analysis;microarray data analysis","Accuracy;Biomarkers;Cancer;Clinical diagnosis;Data analysis;Data mining;Gene expression;Mass spectroscopy;Medical diagnostic imaging;Proteins","biology computing;case-based reasoning;data mining;knowledge representation;learning (artificial intelligence);molecular biophysics;pattern classification;pattern clustering;regression analysis","biomarker discovery;case-based reasoning;data mining;feature selection;formal knowledge representation;high-dimensional biological domains;leukemia;logistic regression;lung microarray data sets;machine learning;molecular biology;ovarian mass spectrometry data sets;spectral clustering","","38","","41","","","Aug. 2005","","IEEE","IEEE Journals & Magazines"
"A self-learning evolutionary chess program","D. B. Fogel; T. J. Hays; S. L. Hahn; J. Quon","Natural Selection Inc., La Jolla, CA, USA","Proceedings of the IEEE","20050627","2004","92","12","1947","1954","A central challenge of artificial intelligence is to create machines that can learn from their own experience and perform at the level of human experts. Using an evolutionary algorithm, a computer program has learned to play chess by playing games against itself. The program learned to evaluate chessboard configurations by using the positions of pieces, material and positional values, and neural networks to assess specific sections of the chessboard. During evolution, the program improved its play by almost 400 rating points. Testing under simulated tournament conditions against Pocket Fritz 2.0 indicated that the evolved program performs above the master level.","0018-9219;00189219","","10.1109/JPROC.2004.837633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1360168","Chess;computational intelligence;evolutionary computation;machine learning;neural networks","Artificial intelligence;Computational modeling;Evolutionary computation;Feedback;Hardware;Humans;Machine learning;Machine learning algorithms;Neural networks;Testing","computer games;evolutionary computation;neural nets;unsupervised learning","artificial intelligence;chessboard configuration;computer games;evolutionary algorithm;evolutionary chess program;neural networks;pocket Fritz 2.0;self learning","","60","","18","","","Dec 2004","","IEEE","IEEE Journals & Magazines"
"Recovering 3D human pose from monocular images","A. Agarwal; B. Triggs","INRIA Rhone-Alpes, Montbonnot, France","IEEE Transactions on Pattern Analysis and Machine Intelligence","20051121","2006","28","1","44","58","We describe a learning-based method for recovering 3D human body pose from single images and monocular image sequences. Our approach requires neither an explicit body model nor prior labeling of body parts in the image. Instead, it recovers pose by direct nonlinear regression against shape descriptor vectors extracted automatically from image silhouettes. For robustness against local silhouette segmentation errors, silhouette shape is encoded by histogram-of-shape-contexts descriptors. We evaluate several different regression methods: ridge regression, relevance vector machine (RVM) regression, and support vector machine (SVM) regression over both linear and kernel bases. The RVMs provide much sparser regressors without compromising performance, and kernel bases give a small but worthwhile improvement in performance. The loss of depth and limb labeling information often makes the recovery of 3D pose from single silhouettes ambiguous. To handle this, the method is embedded in a novel regressive tracking framework, using dynamics from the previous state estimate together with a learned regression value to disambiguate the pose. We show that the resulting system tracks long sequences stably. For realism and good generalization over a wide range of viewpoints, we train the regressors on images resynthesized from real human motion capture data. The method is demonstrated for several representations of full body pose, both quantitatively on independent but similar test data and qualitatively on real image sequences. Mean angular errors of 4-6 are obtained for a variety of walking motions.","0162-8828;01628828","","10.1109/TPAMI.2006.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542030","Index Terms- Computer vision;human motion estimation;machine learning;multivariate regression.","Biological system modeling;Humans;Image segmentation;Image sequences;Kernel;Labeling;Learning systems;Robustness;Shape;Support vector machines","computer vision;image motion analysis;image sequences;learning (artificial intelligence);regression analysis;support vector machines","3D human pose;histogram-of-shape-contexts descriptors;human motion estimation;image silhouettes;learning-based method;monocular image sequences;nonlinear regression;relevance vector machine regression;ridge regression;shape descriptor vectors;silhouette shape;support vector machine regression","Algorithms;Artificial Intelligence;Humans;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Joints;Pattern Recognition, Automated;Photography;Posture;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique","299","7","32","","","Jan. 2006","","IEEE","IEEE Journals & Magazines"
"Training cost-sensitive neural networks with methods addressing the class imbalance problem","Zhi-Hua Zhou; Xu-Ying Liu","Nat. Lab. for Novel Software Technol., Nanjing Univ., China","IEEE Transactions on Knowledge and Data Engineering","20051205","2006","18","1","63","77","This paper studies empirically the effect of sampling and threshold-moving in training cost-sensitive neural networks. Both oversampling and undersampling are considered. These techniques modify the distribution of the training data such that the costs of the examples are conveyed explicitly by the appearances of the examples. Threshold-moving tries to move the output threshold toward inexpensive classes such that examples with higher costs become harder to be misclassified. Moreover, hard-ensemble and soft-ensemble, i.e., the combination of above techniques via hard or soft voting schemes, are also tested. Twenty-one UCl data sets with three types of cost matrices and a real-world cost-sensitive data set are used in the empirical study. The results suggest that cost-sensitive learning with multiclass tasks is more difficult than with two-class tasks, and a higher degree of class imbalance may increase the difficulty. It also reveals that almost all the techniques are effective on two-class tasks, while most are ineffective and even may cause negative effect on multiclass tasks. Overall, threshold-moving and soft-ensemble are relatively good choices in training cost-sensitive neural networks. The empirical study also suggests that some methods that have been believed to be effective in addressing the class imbalance problem may, in fact, only be effective on learning with imbalanced two-class data sets.","1041-4347;10414347","","10.1109/TKDE.2006.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1549828","Index Terms- Machine learning;class imbalance learning;cost-sensitive learning;data mining;ensemble learning.;neural networks;sampling;threshold-moving","Costs;Data mining;Decision trees;Learning systems;Machine learning;Neural networks;Sampling methods;Testing;Training data;Voting","data mining;learning (artificial intelligence);neural nets;sampling methods","class imbalance learning;cost-sensitive learning;cost-sensitive neural network training;data mining;ensemble learning;machine learning;oversampling technique;threshold-moving;undersampling technique","","286","","39","","","Jan. 2006","","IEEE","IEEE Journals & Magazines"
"Towards Qualitative Positioning for Pervasive Environments","I. Anderson; H. Muller","Member, IEEE, University of Bristol, Department of Computer Science, Merchant Venturers Building, Woodland Road, Bristol, BS8 IUB, U.K. E-mail: anderson@compsci.bris.ac.uk","EUROCON 2005 - The International Conference on "Computer as a Tool"","20060515","2005","1","","724","727","In this paper, we present a strategy and set of algorithms for developing qualitative positioning services that are specifically optimised for the environment where they are to be deployed. We argue that for many context-aware applications, this may be more appropriate than more common quantitative location systems, where the positioning API may make unrealistic demands on the underlying measurement service, and unrealistic promises to the application. We show results for an implementation on a shopping street using cellular networks","","POD:1-4244-0049-X","10.1109/EURCON.2005.1630033","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1630033","Context-Aware Computing;Location Fingerprinting;Machine Learning;Wireless Networks","Calibration;Context modeling;Context-aware services;Fingerprint recognition;Land mobile radio cellular systems;Machine learning;Position measurement;System performance;Ultrasonic variables measurement;Wireless networks","ubiquitous computing","API;context-aware application;location fingerprinting;machine learning;pervasive environment;qualitative positioning service;quantitative location system;wireless network","","1","","14","","","21-24 Nov. 2005","","IEEE","IEEE Conference Publications"
"A comparative study on GA based and BP based induction of neural network trees","H. Hayashi; Qiangfu Zhao","Aizu Univ., Aizuwakamatsu, Japan","2005 IEEE International Conference on Systems, Man and Cybernetics","20060110","2005","1","","822","826 Vol. 1","Neural network tree (NNTree) is a special multivariate decision tree (DT) with each nonterminal node containing an expert neural network (ENN). Generally speaking, NNTrees can outperform standard DTs because the ENNs can extract more complex features. However, induction of multivariate DTs is very difficult. Even if each nonterminal node contains a simple oblique hyperplane, the induction problem can be NP-complete. To solve this problem, we have introduced an evolutionary algorithm that follows the same recursive procedure for inducing a standard DT, and designs an ENN for each nonterminal node using GA (genetic algorithm). This algorithm, however, is very time consuming and cannot be used easily. In this paper, we propose two new methods. One is to evolve the whole tree instead of evolving the ENNs recursively. Another is to define the group labels for the examples assigned to each nonterminal node using a heuristic method, and design the ENNs with the back propagation (BP) algorithm. Experimental results with 10 public databases show that the BP based algorithm is much more efficient than GA based algorithms.","1062-922X;1062922X","POD:0-7803-9298-1","10.1109/ICSMC.2005.1571248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1571248","Machine learning;decision trees;neural network trees;neural networks;pattern recognition","Algorithm design and analysis;Decision trees;Electronic mail;Evolutionary computation;Feature extraction;Genetic algorithms;Machine learning;Machine learning algorithms;Neural networks;Testing","backpropagation;genetic algorithms;heuristic programming;inference mechanisms;neural nets;trees (mathematics)","NP-completeness;back propagation algorithm;complex feature extraction;evolutionary algorithm;expert neural network;genetic algorithm;heuristic method;multivariate decision tree;neural network tree induction;nonterminal node;oblique hyperplane;recursive procedure","","6","","17","","","10-12 Oct. 2005","","IEEE","IEEE Conference Publications"
"Kernel based approach for protein fold prediction from sequence","R. E. Langlois; A. Diec; Y. Dai; H. Lu","Dept. of Bioeng., Illinois Univ., Chicago, IL, USA","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20050314","2004","2","","2885","2888","Due to the relatively large gap of knowledge between gene identification and gene function, the ability to construct a computational model describing gene function from sequence information has become an important area of research. In order to understand the biological role of a specific gene, we will require knowledge of the corresponding protein's structure and function. We present a support vector machines based method for determining a protein's fold from sequence information alone where this sequence has little similarity with sequences with known structures. We have focused on improvement in multiclass classification, parameter tuning, descriptor design, and feature selections. The current implementation showed better performance than previous similar approaches.","","POD:0-7803-8439-3","10.1109/IEMBS.2004.1403821","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1403821","fold recognition;machine learning;proteomics;support vector machines","Hidden Markov models;Humans;Kernel;Machine learning;Neural networks;Proteins;Proteomics;Sequences;Support vector machine classification;Support vector machines","biology computing;feature extraction;genetics;learning (artificial intelligence);macromolecules;molecular biophysics;molecular configurations;pattern classification;proteins;support vector machines","descriptor design;feature selections;gene function;gene identification;kernel based protein fold prediction;machine learning;multiclass classification;parameter tuning;protein function;protein sequence;proteins structure;proteomics;support vector machines","","1","","20","","","1-5 Sept. 2004","","IEEE","IEEE Conference Publications"
"An experimental bias-variance analysis of SVM ensembles based on resampling techniques","G. Valentini","DSI-Dipt. di Sci. dell'Informazione, Univ. degli Studi di Milano, Italy","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20051121","2005","35","6","1252","1271","Recently, bias-variance decomposition of error has been used as a tool to study the behavior of learning algorithms and to develop new ensemble methods well suited to the bias-variance characteristics of base learners. We propose methods and procedures, based on Domingo's unified bias-variance theory, to evaluate and quantitatively measure the bias-variance decomposition of error in ensembles of learning machines. We apply these methods to study and compare the bias-variance characteristics of single support vector machines (SVMs) and ensembles of SVMs based on resampling techniques, and their relationships with the cardinality of the training samples. In particular, we present an experimental bias-variance analysis of bagged and random aggregated ensembles of SVMs in order to verify their theoretical variance reduction properties. The experimental bias-variance analysis quantitatively characterizes the relationships between bagging and random aggregating, and explains the reasons why ensembles built on small subsamples of the data work with large databases. Our analysis also suggests new directions for research to improve on classical bagging.","1083-4419;10834419","","10.1109/TSMCB.2005.850183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542270","Bagging;bias-variance analysis;ensemble of learning machines;support vector machines","Analysis of variance;Bagging;Data analysis;Databases;Decision trees;Kernel;Machine learning;Statistical analysis;Stochastic processes;Support vector machines","covariance analysis;sampling methods;support vector machines","SVM ensembles;bias-variance analysis;large databases;learning algorithm;random aggregating;resampling techniques;support vector machines","Algorithms;Analysis of Variance;Artificial Intelligence;Computer Simulation;Data Interpretation, Statistical;Models, Statistical;Pattern Recognition, Automated;Signal Processing, Computer-Assisted","32","","46","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Learning the topological properties of brain tumors","C. Demir; S. H. Gultekin; B. Yener","Dept. of Comput. Sci., Rensselaer Polytech. Inst., Troy, NY, USA","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20050906","2005","2","3","262","270","This work presents a graph-based representation (a.k.a., cell-graph) of histopathological images for automated cancer diagnosis by probabilistically assigning a link between a pair of cells (or cell clusters). Since the node set of a cell-graph can include a cluster of cells as well as individual ones, it enables working with low-cost, low-magnification photomicrographs. The contributions of this work are twofold. First, it is shown that without establishing a pairwise spatial relation between the cells (i.e., the edges of a cell-graph), neither the spatial distribution of the cells nor the texture analysis of the images yields accurate results for tissue level diagnosis of brain cancer called malignant glioma. Second, this work defines a set of global metrics by processing the entire cell-graph to capture tissue level information coded into the histopathological images. In this work, the results are obtained on the photomicrographs of 646 archival brain biopsy samples of 60 different patients. It is shown that the global metrics of cell-graphs distinguish cancerous tissues from noncancerous ones with high accuracy (at least 99 percent accuracy for healthy tissues with lower cellular density level, and at least 92 percent accuracy for benign tissues with similar high cellular density level such as nonneoplastic reactive/inflammatory conditions).","1545-5963;15455963","","10.1109/TCBB.2005.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1504690","Index Terms- Image representation;graph theory;machine learning;medical information systems.;model development","Biopsy;Cancer;Fractals;Graph theory;Image analysis;Image texture analysis;Logistics;Machine learning;Neoplasms;Pixel","brain;cancer;cellular biophysics;graphs;image representation;medical image processing;tumours","automated cancer diagnosis;benign tissues;brain cancer;brain tumor topology;cancerous tissues;cell clusters;cell graph;cellular density;global metrics;graph-based representation;histopathological images;malignant glioma;nonneoplastic reactive/inflammatory conditions;photomicrographs;tissue level diagnosis","Algorithms;Artificial Intelligence;Brain Neoplasms;Cluster Analysis;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","26","1","27","","","July-Sept. 2005","","IEEE","IEEE Journals & Magazines"
"A self-organizing computing network for decision-making in data sets with a diversity of data types","Q. X. Wu; M. McGinnity; D. A. Bell; Girijesh Prasad","Sch. of Comput. Sci., Queen's Univ., Belfast, UK","IEEE Transactions on Knowledge and Data Engineering","20060530","2006","18","7","941","953","A self-organizing computing network based on concepts of fuzzy conditions, beliefs, probabilities, and neural networks is proposed for decision-making in intelligent systems which are required to handle data sets with a diversity of data types. A sense-function with a sense-range and fuzzy edges is defined as a transfer function for connections from the input layer to the hidden layer in the network. By generating hidden cells and adjusting the parameters of the sense-functions, the network self-organizes and adapts to a training set. Computing cells in the input layer are designed as data converters so that the network can deal with both symbolic data and numeric data. Hidden computing cells in the network can be explained via fuzzy rules in a similar manner to those in fuzzy neural networks. The values in the output layer can be explained as a belief distribution over a decision space. The final decision is made by means of the winner-take-all rule. The approach was applied to a series of the benchmark data sets with a diversity of data types and comparative results obtained. Based on these results, the suitability of a range of data types for processing by different intelligent techniques was analyzed, and the results show that the proposed approach is better than other approaches for decision-making in information systems with mixed data types.","1041-4347;10414347","","10.1109/TKDE.2006.103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1637420","Information technology and systems;decision support;fuzzy sets.;machine learning","Computer networks;Decision making;Fuzzy neural networks;Fuzzy sets;Fuzzy systems;Information analysis;Intelligent networks;Intelligent systems;Neural networks;Transfer functions","belief networks;decision making;decision support systems;fuzzy set theory;learning (artificial intelligence);neural nets;transfer functions","belief distribution;data converters;decision making;fuzzy neural networks;fuzzy rules;hidden computing cell;information systems;intelligent system;numeric data;self-organizing computing network;sense-functions;symbolic data","","5","","15","","","July 2006","","IEEE","IEEE Journals & Magazines"
"Subsurface characterization with support vector machines","B. Wohlberg; D. M. Tartakovsky; A. Guadagnini","Theor. Div., Los Alamos Nat. Lab., NM, USA","IEEE Transactions on Geoscience and Remote Sensing","20051227","2006","44","1","47","57","A typical subsurface environment is heterogeneous, consists of multiple materials (geologic facies), and is often insufficiently characterized by data. The ability to delineate geologic facies and to estimate their properties from sparse data is essential for modeling physical and biochemical processes occurring in the subsurface. We demonstrate that the support vector machine is a viable and efficient tool for lithofacies delineation, and we compare it with a geostatistical approach. To illustrate our approach, and to demonstrate its advantages, we construct a synthetic porous medium consisting of two heterogeneous materials and then estimate boundaries between these materials from a few selected data points. Our analysis shows that the error in facies delineation by means of support vector machines decreases logarithmically with increasing sampling density. We also introduce and analyze the use of regression support vector machines to estimate the parameter values between points where the parameter is sampled.","0196-2892;01962892","","10.1109/TGRS.2005.859953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1564394","Data analysis;geologic facies;geostatistics;machine learning;support vector machine (SVM)","Biological materials;Geology;Laboratories;Machine learning;Machine learning algorithms;Neural networks;Sampling methods;Statistics;Support vector machine classification;Support vector machines","data acquisition;data analysis;geology;geophysical signal processing;geophysical techniques;rocks;support vector machines","data analysis;geologic facies delineation;geostatistical approach;lithofacies delineation;machine learning;regression support vector machine;sampling density;subsurface characterization;synthetic porous medium","","31","","25","","","Jan. 2006","","IEEE","IEEE Journals & Magazines"
"Multivariate interdependent discretization for continuous attribute","Sam Chao; Yiping Li","Fac. of Sci. & Technol., Macau Univ., China","Third International Conference on Information Technology and Applications (ICITA'05)","20050801","2005","1","","167","172 vol.1","Decision tree is one of the most widely used and practical methods in the data mining and machine learning discipline. However, many discretization algorithms developed in this field focus on univariate only, which is inadequate to handle the critical problems especially owned by medical domain. In this paper, we propose a new multivariate discretization method called multivariate interdependent discretization for continuous attributes - MIDCA. Our novel algorithm can minimize the uncertainty between the interdependent attribute and the continuous-valued attribute, and at the same time to maximize their correlation. The empirical results demonstrate a comparison of performance of various decision tree algorithms on twelve real-life datasets from UCI repository.","","POD:0-7695-2316-1","10.1109/ICITA.2005.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1488790","Correlated Attribute;Data Mining;Interdependent;Machine Learning;Multivariate Discretization","Aging;Bayesian methods;Blood pressure;Chaos;Data mining;Decision trees;Hypertension;Inference algorithms;Machine learning;Machine learning algorithms","data mining;decision trees;learning (artificial intelligence)","UCI repository;continuous-valued attribute;data mining;decision tree algorithms;interdependent attribute;machine learning;multivariate interdependent discretization","","4","","20","","","4-7 July 2005","","IEEE","IEEE Conference Publications"
"Kernel adaptive subspace detector for hyperspectral imagery","Heesung Kwon; N. M. Nasrabadi","US Army Res. Lab., Adelphi, MD, USA","IEEE Geoscience and Remote Sensing Letters","20060418","2006","3","2","271","275","In this letter, we present a kernel-based nonlinear version of the adaptive subspace detector (ASD) that implicitly detects signals of interest in a high-dimensional (possibly infinite) feature space associated with a particular nonlinear mapping. In order to address the high dimensionality of the feature space, ASD is first implicitly formulated in the feature space, which is then converted into an expression in terms of kernel functions via the kernel trick property of the Mercer kernels. Experimental results based on simulated data and real hyperspectral imagery show that the proposed kernel-based ASD outperforms the conventional ASD and a nonlinear anomaly detector so called the kernel RX-algorithm.","1545-598X;1545598X","","10.1109/LGRS.2006.869985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1621094","Kernel-based machine learning;kernel subspace;subspace detectors;subspace matched filters;target detection","Adaptive signal detection;Detectors;Hyperspectral imaging;Kernel;Matched filters;Maximum likelihood estimation;Object detection;Signal detection;Signal processing;Variable speed drives","adaptive signal detection;matched filters;optical filters;remote sensing","Mercer kernels;high dimensional feature space;hyperspectral imagery;kernel RX algorithm;kernel adaptive subspace detector;kernel based machine learning;kernel subspace;kernel trick property;nonlinear anomaly detector;nonlinear mapping;subspace matched filters;target detection","","4","1","20","","","April 2006","","IEEE","IEEE Journals & Magazines"
"A Wholesale Power Trading Simulator With Learning Capabilities","T. Sueyoshi; G. R. Tadiparthi","Dept. of Manage., New Mexico Inst. of Min. & Technol., Socorro, NM, USA","IEEE Transactions on Power Systems","20050801","2005","20","3","1330","1340","The U.S. wholesale power market comprises a large commodity market. The growth in power trading is due to the ongoing deregulation policy of the electric power industry. Most deregulation scenarios indicate a further separation of power production from transmission and retailing. The power production is opened to more competition. Unfortunately, the power trading mechanism is not clearly investigated in the level that we can predict a price change in the U.S. wholesale power market. Such a price change in the U.S. wholesale power market is explored from a simulation system with learning capabilities. Using the new intelligence system, we investigate the bidding strategies of traders in the wholesale power market and examine how the price change occurs under different economic and engineering environments.","0885-8950;08858950","","10.1109/TPWRS.2005.851948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1490584","Electricity competition;machine learning;market model;strategic pricing;wholesale power trading","Computational modeling;Electricity supply industry deregulation;Electronic mail;Intelligent systems;Learning systems;Power engineering and energy;Power markets;Power system economics;Pricing;Production","power markets;power system economics;retailing","US wholesale power market;electric power industry deregulation policy;intelligence system;learning capability;power production;power trading simulator","","28","","33","","","Aug. 2005","","IEEE","IEEE Journals & Magazines"
"Fast SVM training algorithm with decomposition on very large data sets","Jian-xiong Dong; A. Krzyzak; C. Y. Suen","Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, Que., Canada","IEEE Transactions on Pattern Analysis and Machine Intelligence","20050307","2005","27","4","603","618","Training a support vector machine on a data set of huge size with thousands of classes is a challenging problem. This paper proposes an efficient algorithm to solve this problem. The key idea is to introduce a parallel optimization step to quickly remove most of the nonsupport vectors, where block diagonal matrices are used to approximate the original kernel matrix so that the original problem can be split into hundreds of subproblems which can be solved more efficiently. In addition, some effective strategies such as kernel caching and efficient computation of kernel matrix are integrated to speed up the training process. Our analysis of the proposed algorithm shows that its time complexity grows linearly with the number of classes and size of the data set. In the experiments, many appealing properties of the proposed algorithm have been investigated and the results show that the proposed algorithm has a much better scaling capability than Libsvm, SVM<sup>light</sup>, and SVMTorch. Moreover, the good generalization performances on several large databases have also been achieved.","0162-8828;01628828","","10.1109/TPAMI.2005.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1401912","Index Terms- Support vector machines (SVMs);algorithm design and analysis;algorithm efficiency;handwritten character recognition.;machine learning","Algorithm design and analysis;Character recognition;Databases;Handwriting recognition;Kernel;Large-scale systems;Machine learning algorithms;Optimization methods;Support vector machine classification;Support vector machines","computational complexity;learning (artificial intelligence);optimisation;support vector machines;very large databases","SVM training algorithm;block diagonal matrices;handwritten character recognition;parallel optimization;support vector machine;time complexity;very large data sets","Algorithms;Artificial Intelligence;Automatic Data Processing;Computer Simulation;Database Management Systems;Databases, Factual;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted","105","","42","","","April 2005","","IEEE","IEEE Journals & Magazines"
"Predictive controller for heterogeneous sensor network operation in dynamic environments","A. Talukder; S. Muhammad Ali; A. Panangadan; L. Chandramouli","CHLA, Southern California Univ., USA","2005 IEEE/RSJ International Conference on Intelligent Robots and Systems","20051205","2005","","","1710","1716","We discuss a novel control methodology for power management in heterogeneous distributed sensor networks. Many algorithms for resource management in sensor networks require complete knowledge of the external environment and the sensor network system, are rule-based and cannot handle rapidly changing environments; this restricts their use in real-world environments. We present an event based control optimization formulation of the resource management problem and discuss a method to adaptively change desired system performance of the sensor network in response to events. This functionality is critical in field-deployable sensor networks where the available energy is extremely limited. This limitation disallows continuous operation as a very expensive option and necessitates system adaptation as a means to extend operational lifetime in the face of dynamic external events. We show results on synthetic sensor networks where only partially accurate information about the external world and the sensing system is available and illustrate the efficacy of the control algorithm in handling dynamic events with guaranteed minimum system lifespan via efficient usage of energy resources. We show that the control algorithm makes effective control decisions about the use of energy resources with varying sensor reliabilities.","2153-0858;21530858","POD:0-7803-8912-3","10.1109/IROS.2005.1545132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545132","Evolutionary algorithm;control;distributed sensing;machine learning;mathematical optimization;pattern recognition;resource management;sensor networks;wireless communication","Biomedical monitoring;Biosensors;Communication system control;Energy management;Event detection;Intelligent networks;Machine learning algorithms;Resource management;Sensor systems;Signal processing algorithms","distributed sensors;optimisation;predictive control","energy resources;event based control optimization;evolutionary algorithm;heterogeneous distributed sensor network;machine learning;mathematical optimization;pattern recognition;power management;predictive controller;resource management;synthetic sensor network;wireless communication","","0","","12","","","2-6 Aug. 2005","","IEEE","IEEE Conference Publications"
"Auto-correlation wavelet support vector machine and its applications to regression","Guangyi Chen; G. Dudek","Center for Intelligence Machines, McGill Univ., Montreal, Que., Canada","The 2nd Canadian Conference on Computer and Robot Vision (CRV'05)","20050620","2005","","","246","252","A support vector machine (SVM) with the autocorrelation of compactly supported wavelet as kernel is proposed in this paper. It is proved that this kernel is an admissible support vector kernel. The main advantage of the auto-correlation of a compactly supported wavelet is that it satisfies the translation invariant property, which is very important for signal processing. Also, we can choose a better wavelet from different choices of wavelet families for our auto-correlation wavelet kernel. Experiments on signal regression show that this method is better than the existing SVM function regression with the scalar wavelet kernel, the Gaussian kernel, and the exponential radial basis function kernel It can be easily extended to other applications such as pattern recognition by using this newly developed auto-correlation wavelet SVM.","","POD:0-7695-2319-6","10.1109/CRV.2005.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1443136","Wavelets;function regression;machine learning;support vector machine","Application software;Autocorrelation;Computer vision;Robot vision systems;Support vector machines","correlation methods;regression analysis;signal processing;support vector machines","Gaussian kernel;auto-correlation wavelet SVM;auto-correlation wavelet kernel;exponential radial basis function kernel;function regression;machine learning;pattern recognition;scalar wavelet kernel;signal processing;signal regression;support vector kernel;support vector machine","","6","","24","","","9-11 May 2005","","IEEE","IEEE Conference Publications"
"An Innovative Spam Filtering Model Based on Support Vector Machine","M. R. Islam; M. U. Chowdhury; Wanlei Zhou","Deakin University, Melbourne, Australia","International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)","20060522","2005","2","","348","353","Spam is commonly defined as unsolicited email messages and the goal of spam categorization is to distinguish between spam and legitimate email messages. Many researchers have been trying to separate spam from legitimate emails using machine learning algorithms based on statistical learning methods. In this paper, an innovative and intelligent spam filtering model has been proposed based on support vector machine (SVM). This model combines both linear and nonlinear SVM techniques where linear SVM performs better for text based spam classification that share similar characteristics. The proposed model considers both text and image based email messages for classification by selecting an appropriate kernel function for information transformation","","POD:0-7695-2504-0","10.1109/CIMCA.2005.1631493","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631493","Machine learning;SVM;kernel.;spam","Electronic mail;Filtering;Internet;Kernel;Learning systems;Machine learning;Support vector machine classification;Support vector machines;Text categorization;Unsolicited electronic mail","classification;information filtering;learning (artificial intelligence);statistical analysis;support vector machines;text analysis;unsolicited e-mail","image based email message;information transformation;innovative spam filtering model;kernel function;machine learning algorithm;spam categorization;statistical learning method;support vector machine;text based spam classification;unsolicited email message","","9","","15","","","28-30 Nov. 2005","","IEEE","IEEE Conference Publications"
"Kinematic Redundancy in Robot Grasp Synthesis. An Efficient Tree-based Representation","C. Fernandez; O. Reinoso; A. Vicente; R. Aracil","System Engineering and Automation Division Miguel Hernandez University Av. Universidad s/n, 03202 Elche (Alicante) Spain; c.fernandez@umh.es","Proceedings of the 2005 IEEE International Conference on Robotics and Automation","20060110","2005","","","1203","1209","A redundancy resolution technique devoted to grasp synthesis is presented. Given a set of contact points and a certain robot arm and gripper, the goal is to select both the best assignment of gripper fingers to contact points and the best joint values that allow the fingers to reach such contact points. The system proposed is based on the generation of an inverse kinematics tree where fast searches can be performed in order to find the optimum configuration. Optimality is defined as similarity to previously stored examples over a hierarchical structure of configuration data, which includes finger assignments and robot joints.","1050-4729;10504729","POD:0-7803-8914-X","10.1109/ROBOT.2005.1570279","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1570279","Grasp synthesis;inverse kinematics;machine learning;redundancy resolution","Automatic control;End effectors;Fingers;Grippers;Intelligent robots;Intelligent sensors;Kinematics;Orbital robotics;Robot sensing systems;Robotics and automation","","Grasp synthesis;inverse kinematics;machine learning;redundancy resolution","","0","","12","","","18-22 April 2005","","IEEE","IEEE Conference Publications"
"Learning users' interests by quality classification in market-based recommender systems","Y. Z. Wei; L. Moreau; N. R. Jennings","British Telecommun., Ipswich, UK","IEEE Transactions on Knowledge and Data Engineering","20051031","2005","17","12","1678","1688","Recommender systems are widely used to cope with the problem of information overload and, to date, many recommendation methods have been developed. However, no one technique is best for all users in all situations. To combat this, we have previously developed a market-based recommender system that allows multiple agents (each representing a different recommendation method or system) to compete with one another to present their best recommendations to the user. In our system, the marketplace encourages good recommendations by rewarding the corresponding agents who supplied them according to the users' ratings of their suggestions. Moreover, we have theoretically shown how our system incites the agents to bid in a manner that ensures only the best recommendations are presented. To do this effectively in practice, however, each agent needs to be able to classify its recommendations into different internal quality levels, learn the users' interests for these different levels, and then adapt its bidding behavior for the various levels accordingly. To this end, in this paper, we develop a reinforcement learning and Boltzmann exploration strategy that the recommending agents can exploit for these tasks. We then demonstrate that this strategy does indeed help the agents to effectively obtain information about the users' interests which, in turn, speeds up the market convergence and enables the system to rapidly highlight the best recommendations.","1041-4347;10414347","","10.1109/TKDE.2005.200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1524967","Index Terms- Information filtering;machine learning;markets.;recommender systems","Collaboration;Convergence;Information filtering;Information filters;Machine learning;Recommender systems","information filters;learning (artificial intelligence);multi-agent systems;pattern classification;user modelling","Boltzmann exploration strategy;bidding behavior;internal quality levels;market-based recommender systems;quality classification;reinforcement learning;user interest learning;user ratings","","12","2","25","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Intelligent Patient and Nurse Scheduling in Ambulatory Health Care Centers","G. Stiglic; P. Kokol","Laboratory for System Design, FERI, University of Maribor, Slovenia","2005 IEEE Engineering in Medicine and Biology 27th Annual Conference","20060410","2005","","","5475","5478","Ambulatory health care centers are the major arena for delivery of primary health care to patients. In contrast to hospital or urgent care scheduling systems, ambulatory health care centers offer different challenge for scheduling optimization. The aim is similar, i.e. to reduce the average waiting time and maintain high resource utilization, but the concept is different. In this paper we present a multi-agent based system for long-term scheduling, where agents use their time-series forecasting and pattern recognition abilities to predict possible patient flow peaks and inform the main scheduling agent of these events. To ease such peaks, we use adaptive nurse scheduling by adapting the nurse schedules each week-end. Our multi-agent system helps the personnel managers and other staff in health centers to adapt the nurse and patient scheduling in dependence of the current patient flow","1094-687X;1094687X","POD:0-7803-8741-4","10.1109/IEMBS.2005.1615722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1615722","healthcare information systems;machine learning;multi-agent systems;scheduling","Biological system modeling;Biomedical engineering;Electrocardiography;Laboratories;Medical services;Medical simulation;Medical treatment;Multiagent systems;System testing;Ultrasonic imaging","adaptive scheduling;health care;medical information systems;multi-agent systems;pattern recognition;time series","adaptive nurse scheduling;ambulatory health care centers;intelligent patient scheduling;multi-agent based system;patient flow peaks;pattern recognition;primary health care;time-series forecasting","","1","2","16","","","17-18 Jan. 2006","","IEEE","IEEE Conference Publications"
"Learning yeast gene functions from heterogeneous sources of data using hybrid weighted Bayesian networks","X. Deng; H. Geng; H. Ali","Dept of Comput. Sci., Nebraska Univ., Omaha, NE, USA","2005 IEEE Computational Systems Bioinformatics Conference (CSB'05)","20050906","2005","","","25","34","We developed a machine learning system for determining gene functions from heterogeneous sources of data sets using a Weighted Naive Bayesian Network (WNB). The knowledge of gene functions is crucial for understanding many fundamental biological mechanisms such as regulatory pathways, cell cycles and diseases. Our major goal is to accurately infer functions of putative genes or ORFs (Open Reading Frames) from existing databases using computational methods. However, this task is intrinsically difficult since the underlying biological processes represent complex interactions of multiple entities. Therefore many functional links would be missing when only one or two source of data is used in the prediction. Our hypothesis is that integrating evidence from multiple and complementary sources could significantly improve the prediction accuracy. In this paper, our experimental results not only suggest that the above hypothesis is valid, but also provide guidelines for using the WNB system for data collection, training and predictions. The combined training data sets contain information from gene annotations, gene expressions, clustering outputs, keyword annotations and sequence homology from public databases. The current system is trained and tested on the genes of budding yeast Saccharomyces cerevisiae. Our WNB model can also be used to analyze the contribution of each source of information toward the prediction performance through the weight training process. The contribution analysis could potentially lead to significant scientific discovery by facilitating the interpretation and understanding of the complex relationships between biological entities.","","POD:0-7695-2344-7","10.1109/CSB.2005.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1498003","Bayesian network;gene function prediction;machine learning;yeast","Accuracy;Bayesian methods;Biological processes;Biology computing;Cells (biology);Databases;Diseases;Fungi;Guidelines;Learning systems","belief networks;biology computing;cellular biophysics;diseases;genetics;learning (artificial intelligence);microorganisms;pattern clustering","Open Reading Frames;Saccharomyces cerevisiae;Weighted Naive Bayesian Network;biological mechanism;budding yeast;cell cycles;clustering outputs;computational method;data collection;data sets;diseases;gene annotation;gene expression;gene functions;keyword annotation;machine learning system;public databases;regulatory pathways;sequence homology","","0","","20","","","8-11 Aug. 2005","","IEEE","IEEE Conference Publications"
"Ordering and finding the best of K > 2 supervised learning algorithms","O. T. Yildiz; E. Alpaydin","Dept. of Comput. Eng., Bogazici Univ., Istanbul, Turkey","IEEE Transactions on Pattern Analysis and Machine Intelligence","20060123","2006","28","3","392","402","Given a data set and a number of supervised learning algorithms, we would like to find the algorithm with the smallest expected error. Existing pairwise tests allow a comparison of two algorithms only; range tests and ANOVA check whether multiple algorithms have the same expected error and cannot be used for finding the smallest. We propose a methodology, the multitest algorithm, whereby we order supervised learning algorithms taking into account 1) the result of pairwise statistical tests on expected error (what the data tells us), and 2) our prior preferences, e.g., due to complexity. We define the problem in graph-theoretic terms and propose an algorithm to find the ""best"" learning algorithm in terms of these two criteria, or in the more general case, order learning algorithms in terms of their ""goodness."" Simulation results using five classification algorithms on 30 data sets indicate the utility of the method. Our proposed method can be generalized to regression and other loss functions by using a suitable pairwise test.","0162-8828;01628828","","10.1109/TPAMI.2006.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580484","Index Terms- Machine learning;classifier design and evaluation;experimental design.","Analysis of variance;Classification algorithms;Design for experiments;Error analysis;Iterative algorithms;Machine learning;Machine learning algorithms;Probability;Supervised learning;Testing","graph theory;learning (artificial intelligence);statistical testing","ANOVA check;K > 2 supervised learning algorithms;classification algorithms;graph theory;multitest algorithm;pairwise statistical tests;smallest expected error","Algorithms;Artificial Intelligence;Computer Simulation;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Software","14","1","23","","","March 2006","","IEEE","IEEE Journals & Magazines"
"A statistical self-organizing learning system for remote sensing classification","Hoi-Ming Chi; O. K. Ersoy","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","IEEE Transactions on Geoscience and Remote Sensing","20050725","2005","43","8","1890","1900","A new learning system called a statistical self-organizing learning system (SSOLS), combining functional-link neural networks, statistical hypothesis testing, and self-organization of a number of enhancement nodes, is introduced for remote sensing applications. Its structure consists of two stages, a mapping stage and a learning stage. The input training vectors are initially mapped to the enhancement vectors in the mapping stage by multiplying with a random matrix, followed by pointwise nonlinear transformations. Starting with only one enhancement node, the enhancement layer incrementally adds an extra node in each iteration. The optimum dimension of the enhancement layer is determined by using an efficient leave-one-out cross-validation method. In this way, the number of enhancement nodes is also learned automatically. A t-test algorithm can also be applied to the mapping stage to mitigate the effect of overfitting and to further reduce the number of enhancement nodes required, resulting in a more compact network. In the learning stage, both the input vectors and the enhancement vectors are fed into a least squares learning module to obtain the estimated output vectors. This is made possible by choosing the output layer linear. In addition, several SSOLSs can be trained independently in parallel to form a consensual SSOLS, whose final output is a linear combination of the outputs of each SSOLS module. The SSOLS is simple, fast to compute, and suitable for remote sensing applications, especially with hyperspectral image data of high dimensionality.","0196-2892;01962892","","10.1109/TGRS.2005.851188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1487646","Artificial neural networks;hyperspectral image classification;machine learning;overfitting;support vector machine (SMV);t-test","Automatic testing;Buildings;Hyperspectral imaging;Hyperspectral sensors;Learning systems;Least squares methods;Neural networks;Remote sensing;System testing;Vectors","geophysical techniques;image classification;learning (artificial intelligence);neural nets;remote sensing;self-adjusting systems;support vector machines","enhancement node;enhancement vectors;hyperspectral image data;image classification;leave-one-out cross-validation method;machine learning;neural networks;overfitting;remote sensing;statistical hypothesis testing;statistical self-organizing learning system;support vector machine;t-test algorithm","","9","","24","","","Aug. 2005","","IEEE","IEEE Journals & Magazines"
"Effective spam classification based on meta-heuristics","Chi-Yuan Yeh; Chili-Hung Wu; Shine-Hwang Doong","Dept. of Inf. Manage., Shu-Te Univ., Kaohsiung, Taiwan","2005 IEEE International Conference on Systems, Man and Cybernetics","20060110","2005","4","","3872","3877 Vol. 4","Using machine learning techniques such as naive Bayes, decision trees and support vector machines to automatically filter out spam e-mails has drawn many researchers' attention. Previous methods use keywords contained in e-mails to extract binary features from the corpus. However, since keywords of e-mails change from time to time, the performance of keyword-based solution is not stable. In this study, we use behaviors of spammers as the features for classifying e-mails. Such behaviors are first described by meta-heuristics and used as features of e-mails for classification. A total of 113 new features are extracted from the given meta-heuristics. Using existing machine learning techniques, the filtering performance is much better than that using keyword-based filtering. In addition, the training time is substantially reduced because of the low dimensional feature space and sparse feature vectors.","1062-922X;1062922X","POD:0-7803-9298-1","10.1109/ICSMC.2005.1571750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1571750","Nave Bayesian;classification;decision trees;machine learning;meta-heuristics;spam;support vector machines","Bayesian methods;Decision trees;Electronic mail;Feature extraction;Genetic programming;Information filtering;Information filters;Machine learning;Support vector machines;Unsolicited electronic mail","belief networks;decision trees;learning (artificial intelligence);support vector machines;unsolicited e-mail","binary feature extraction;decision trees;keyword-based filtering;low dimensional feature space;machine learning;meta-heuristics;naive Bayes;spam classification;spam e-mail;sparse feature vector;support vector machine","","5","1","18","","","10-12 Oct. 2005","","IEEE","IEEE Conference Publications"
"Nested Monte Carlo EM algorithm for switching state-space models","C. A. Popescu; Y. S. Wong","Grant MacEwan Coll., Edmonton, Alta., Canada","IEEE Transactions on Knowledge and Data Engineering","20051031","2005","17","12","1653","1663","Switching state-space models have been widely used in many applications arising from science, engineering, economic, and medical research. In this paper, we present a Monte Carlo Expectation Maximization (MCEM) algorithm for learning the parameters and classifying the states of a state-space model with a Markov switching. A stochastic implementation based on the Gibbs sampler is introduced in the expectation step of the MCEM algorithm. We study the asymptotic properties of the proposed algorithm, and we also describe how a nesting approach and the Rao-Blackwellized forms can be employed to accelerate the rate of convergence of the MCEM algorithm. Finally, the performance and the effectiveness of the proposed method are demonstrated by applications to simulated and physiological experimental data.","1041-4347;10414347","","10.1109/TKDE.2005.202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1524965","Index Terms- Time series analysis;Kalman filtering;Markov processes;Monte Carlo simulation.;machine learning;parameter learning;probabilistic algorithms","Acceleration;Biomedical engineering;Brain modeling;Convergence;Econometrics;Machine learning;Machine learning algorithms;Medical diagnostic imaging;Monte Carlo methods;Stochastic processes","Markov processes;Monte Carlo methods;data mining;learning (artificial intelligence);optimisation;pattern classification;state-space methods;temporal databases","Gibbs sampler;Markov switching;Monte Carlo Expectation Maximization algorithm;Rao-Blackwellized form;asymptotic algorithm properties;physiological experimental data;state-space models","","5","","32","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Probabilistic finite-state machines - part II","E. Vidal; F. Thollard; C. de la Higuera; F. Casacuberta; R. C. Carrasco","Departamento de Sistemas Informaticos y Computacion, Univ. Politecnica de Valencia, Spain","IEEE Transactions on Pattern Analysis and Machine Intelligence","20050523","2005","27","7","1026","1039","Probabilistic finite-state machines are used today in a variety of areas in pattern recognition or in fields to which pattern recognition is linked. In part I of this paper, we surveyed these objects and studied their properties. In this part, we study the relations between probabilistic finite-state automata and other well-known devices that generate strings like hidden Markov models and n-grams and provide theorems, algorithms, and properties that represent a current state of the art of these objects.","0162-8828;01628828","","10.1109/TPAMI.2005.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1432737","Index Terms- Automata;classes defined by grammars or automata;language acquisition;language models;language parsing and understanding;machine learning;machine translation;speech recognition and synthesis;structural pattern recognition;syntactic pattern recognition.","Computer Society;Hidden Markov models;Learning automata;Machine learning;Machine learning algorithms;Natural languages;Pattern recognition;Probability distribution;Speech recognition;Stochastic processes","finite state machines;hidden Markov models;pattern recognition;probabilistic automata","hidden Markov models;n-grams;pattern recognition;probabilistic finite-state automata;probabilistic finite-state machines","Algorithms;Artificial Intelligence;Cluster Analysis;Computer Simulation;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted","11","","106","","","July 2005","","IEEE","IEEE Journals & Magazines"
"Semisupervised learning for molecular profiling","C. Furlanello; M. Serafini; S. Merler; G. Jurman","ITC-irst, Trento, Italy","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20050606","2005","2","2","110","118","Class prediction and feature selection are two learning tasks that are strictly paired in the search of molecular profiles from microarray data. Researchers have become aware how easy it is to incur a selection bias effect, and complex validation setups are required to avoid overly optimistic estimates of the predictive accuracy of the models and incorrect gene selections. This paper describes a semisupervised pattern discovery approach that uses the by-products of complete validation studies on experimental setups for gene profiling. In particular, we introduce the study of the patterns of single sample responses (sample-tracking profiles) to the gene selection process induced by typical supervised learning tasks in microarray studies. We originate sample-tracking profiles as the aggregated off-training evaluation of SVM models of increasing gene panel sizes. Genes are ranked by E-RFE, an entropy-based variant of the recursive feature elimination for support vector machines (RFE-SVM). A dynamic time warping (DTW) algorithm is then applied to define a metric between sample-tracking profiles. An unsupervised clustering based on the DTW metric allows automating the discovery of outliers and of subtypes of different molecular profiles. Applications are described on synthetic data and in two gene expression studies.","1545-5963;15455963","","10.1109/TCBB.2005.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1438348","Machine learning;bioinformatics databases.;biology and genetics;classifier design and evaluation;clustering;data mining;feature evaluation and selection;pattern analysis;similarity measures","Accuracy;Bioinformatics;Clustering algorithms;Costs;Gene expression;Predictive models;Semisupervised learning;Supervised learning;Support vector machine classification;Support vector machines","biology computing;entropy;genetics;learning (artificial intelligence);molecular biophysics;support vector machines","class prediction;dynamic time warping;entropy;feature selection;gene expression;gene profiling;gene selections;learning tasks;microarray data;molecular profiling;recursive feature elimination;sample-tracking profiles;semisupervised learning;semisupervised pattern discovery approach;support vector machines;unsupervised clustering","Algorithms;Artificial Intelligence;Cluster Analysis;Gene Expression;Gene Expression Profiling;Oligonucleotide Array Sequence Analysis;Pattern Recognition, Automated","12","","26","","","April-June 2005","","IEEE","IEEE Journals & Magazines"
"Learning nonlinear image manifolds by global alignment of local linear models","J. Verbeek","GRAVIR-INRIA, Montbonnot, France","IEEE Transactions on Pattern Analysis and Machine Intelligence","20060619","2006","28","8","1236","1250","Appearance-based methods, based on statistical models of the pixel values in an image (region) rather than geometrical object models, are increasingly popular in computer vision. In many applications, the number of degrees of freedom (DOF) in the image generating process is much lower than the number of pixels in the image. If there is a smooth function that maps the DOF to the pixel values, then the images are confined to a low-dimensional manifold embedded in the image space. We propose a method based on probabilistic mixtures of factor analyzers to 1) model the density of images sampled from such manifolds and 2) recover global parameterizations of the manifold. A globally nonlinear probabilistic two-way mapping between coordinates on the manifold and images is obtained by combining several, locally valid, linear mappings. We propose a parameter estimation scheme that improves upon an existing scheme and experimentally compare the presented approach to self-organizing maps, generative topographic mapping, and mixtures of factor analyzers. In addition, we show that the approach also applies to finding mappings between different embeddings of the same manifold","0162-8828;01628828","","10.1109/TPAMI.2006.166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1642659","Feature extraction or construction;machine learning;statistical image representation.","Application software;Computer vision;Image analysis;Image generation;Manifolds;Parameter estimation;Pixel;Principal component analysis;Self organizing feature maps;Solid modeling","computer vision;image resolution;learning (artificial intelligence);parameter estimation;sampling methods;smoothing methods","appearance-based methods;computer vision;factor analyzers;generative topographic mapping;geometrical object models;global alignment;global parameterizations;globally nonlinear probabilistic two-way mapping;image generating process;image pixel values;image sampling density;local linear models;low-dimensional manifold;nonlinear image manifold learning;parameter estimation scheme;probabilistic mixtures;self-organizing maps;smooth function;statistical models","Algorithms;Artificial Intelligence;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Linear Models;Nonlinear Dynamics;Pattern Recognition, Automated","42","","54","","","Aug. 2006","","IEEE","IEEE Journals & Magazines"
"Toward intelligent assistance for a data mining process: an ontology-based approach for cost-sensitive classification","A. Bernstein; F. Provost; S. Hill","Dept. of Informatics, Zurich Univ., Switzerland","IEEE Transactions on Knowledge and Data Engineering","20050307","2005","17","4","503","518","A data mining (DM) process involves multiple stages. A simple, but typical, process might include preprocessing data, applying a data mining algorithm, and postprocessing the mining results. There are many possible choices for each stage, and only some combinations are valid. Because of the large space and nontrivial interactions, both novices and data mining specialists need assistance in composing and selecting DM processes. Extending notions developed for statistical expert systems we present a prototype intelligent discovery assistant (IDA), which provides users with 1) systematic enumerations of valid DM processes, in order that important, potentially fruitful options are not overlooked, and 2) effective rankings of these valid processes by different criteria, to facilitate the choice of DM processes to execute. We use the prototype to show that an IDA can indeed provide useful enumerations and effective rankings in the context of simple classification processes. We discuss how an IDA could be an important tool for knowledge sharing among a team of data miners. Finally, we illustrate the claims with a demonstration of cost-sensitive classification using a more complicated process and data from the 1998 KDDCUP competition.","1041-4347;10414347","","10.1109/TKDE.2005.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1401890","Index Terms- Cost-sensitive learning;data mining;data mining process;intelligent assistants;knowledge discovery;knowledge discovery process;machine learning;metalearning.","Bayesian methods;Data mining;Delta modulation;Expert systems;Learning systems;Machine learning;Machine learning algorithms;Ontologies;Prototypes;Space exploration","data mining;expert systems;learning (artificial intelligence);meta data;ontologies (artificial intelligence);very large databases","cost-sensitive classification;cost-sensitive learning;data mining;data mining process;intelligent discovery assistant;knowledge discovery;knowledge sharing;machine learning;metalearning;ontology;statistical expert systems","","66","2","61","","","April 2005","","IEEE","IEEE Journals & Magazines"
"Active learning: theory and applications to automatic speech recognition","G. Riccardi; D. Hakkani-Tur","AT&T Labs.-Res., USA","IEEE Transactions on Speech and Audio Processing","20050620","2005","13","4","504","511","We are interested in the problem of adaptive learning in the context of automatic speech recognition (ASR). In this paper, we propose an active learning algorithm for ASR. Automatic speech recognition systems are trained using human supervision to provide transcriptions of speech utterances. The goal of Active Learning is to minimize the human supervision for training acoustic and language models and to maximize the performance given the transcribed and untranscribed data. Active learning aims at reducing the number of training examples to be labeled by automatically processing the unlabeled examples, and then selecting the most informative ones with respect to a given cost function for a human to label. In this paper we describe how to estimate the confidence score for each utterance through an on-line algorithm using the lattice output of a speech recognizer. The utterance scores are filtered through the informativeness function and an optimal subset of training samples is selected. The active learning algorithm has been applied to both batch and on-line learning scheme and we have experimented with different selective sampling algorithms. Our experiments show that by using active learning the amount of labeled data needed for a given word accuracy can be reduced by more than 60% with respect to random sampling.","1063-6676;10636676","","10.1109/TSA.2005.848882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1453593","Acoustic modeling;active learning;language modeling;large vocabulary continuous speech recognition;machine learning","Automatic speech recognition;Cost function;Humans;Machine learning;Machine learning algorithms;Sampling methods;Speech recognition;Statistics;Stochastic processes;Vocabulary","learning (artificial intelligence);signal sampling;speech recognition","active learning algorithm;adaptive learning;automatic speech recognition;language modeling;lattice output;vocabulary continuous speech recognition","","43","5","34","","","July 2005","","IEEE","IEEE Journals & Magazines"
"A field model for human detection and tracking","Ying Wu; Ting Yu","Dept. of Electr. & Comput. Eng., Northwestern Univ., Evanston, IL, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20060320","2006","28","5","753","765","The large shape variability and partial occlusions challenge most object detection and tracking methods for nonrigid targets such as pedestrians. This paper presents a new approach based on a two-layer statistical field model that characterizes the prior of the complex shape variations as a Boltzmann distribution and embeds this prior and the complex image likelihood into a Markov field. A probabilistic variational analysis of this model reveals a set of fixed-point equations characterizing the equilibrium of the field. It leads to computationally efficient methods for calculating the image likelihood and for training the model. Based on that, effective algorithms for detecting nonrigid objects are developed. This new approach has several advantages. First, it is intrinsically suitable for capturing local nonrigidity. In addition, due to the distributed likelihood, this approach is robust to partial occlusions. Moreover, the two-layer structure provides large flexibility of modeling the image observations, which makes the new method robust to clutters. Extensive experiments demonstrate its effectiveness.","0162-8828;01628828","","10.1109/TPAMI.2006.87","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608038","Markov random fields;Object detection;image models;machine learning;probabilistic algorithms.;shape;statistical computing","Boltzmann distribution;Face detection;Humans;Motion analysis;Object detection;Robustness;Shape;Target tracking;Uncertainty;Video surveillance","Boltzmann equation;Markov processes;image motion analysis;image resolution;object detection;tracking","Boltzmann distribution;Markov field;human detection;human tracking;large shape variability;nonrigid targets;object detection;object tracking method;partial occlusions;pedestrians;probabilistic variational analysis;statistical field model","Algorithms;Artificial Intelligence;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Joints;Models, Anatomic;Models, Biological;Movement;Pattern Recognition, Automated","42","","40","","","May 2006","","IEEE","IEEE Journals & Magazines"
"Tri-training: exploiting unlabeled data using three classifiers","Zhi-Hua Zhou; Ming Li","Novel Software Technol., Nanjing Univ., China","IEEE Transactions on Knowledge and Data Engineering","20050926","2005","17","11","1529","1541","In many practical data mining applications, such as Web page classification, unlabeled training examples are readily available, but labeled ones are fairly expensive to obtain. Therefore, semi-supervised learning algorithms such as co-training have attracted much attention. In this paper, a new co-training style semi-supervised learning algorithm, named tri-training, is proposed. This algorithm generates three classifiers from the original labeled example set. These classifiers are then refined using unlabeled examples in the tri-training process. In detail, in each round of tri-training, an unlabeled example is labeled for a classifier if the other two classifiers agree on the labeling, under certain conditions. Since tri-training neither requires the instance space to be described with sufficient and redundant views nor does it put any constraints on the supervised learning algorithm, its applicability is broader than that of previous co-training style algorithms. Experiments on UCI data sets and application to the Web page classification task indicate that tri-training can effectively exploit unlabeled data to enhance the learning performance.","1041-4347;10414347","","10.1109/TKDE.2005.186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512038","Index Terms- Data mining;Web page classification.;co-training;learning from unlabeled data;machine learning;semi-supervised learning;tri-training","Data mining;Humans;Labeling;Machine learning;Machine learning algorithms;Parameter estimation;Partitioning algorithms;Semisupervised learning;Supervised learning;Web pages","Internet;data mining;learning (artificial intelligence);pattern classification","Web page classification;co-training style algorithm;data mining;machine learning;semisupervised learning algorithm;tri-training process;unlabeled data","","227","1","29","","","Nov. 2005","","IEEE","IEEE Journals & Magazines"
"Learning the relationship between patient geometry and beam intensity in breast intensity-modulated radiotherapy","Renzhi Lu; R. J. Radke; L. Hong; Chen-Shou Chui; Jianping Xiong; E. Yorke; A. Jackson","Electr., Comput., & Syst. Eng. Dept., Rensselaer Polytech. Inst., Troy, NY, USA","IEEE Transactions on Biomedical Engineering","20060418","2006","53","5","908","920","Intensity modulated radiotherapy (IMRT) has become an effective tool for cancer treatment with radiation. However, even expert radiation planners still need to spend a substantial amount of time adjusting IMRT optimization parameters in order to get a clinically acceptable plan. We demonstrate that the relationship between patient geometry and radiation intensity distributions can be automatically inferred using a variety of machine learning techniques in the case of two-field breast IMRT. Our experiments show that given a small number of human-expert-generated clinically acceptable plans, the machine learning predictions produce equally acceptable plans in a matter of seconds. The machine learning approach has the potential for greater benefits in sites where the IMRT planning process is more challenging or tedious","0018-9294;00189294","","10.1109/TBME.2005.863987","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1621142","IMRT;intensity-modulated radiotherapy;machine learning","Biomedical engineering;Biomedical imaging;Breast;Cancer;Geometry;Machine learning;Medical treatment;Physics;Shape;Systems engineering and theory","biological organs;gynaecology;learning (artificial intelligence);medical computing;radiation therapy","beam intensity;breast intensity-modulated radiotherapy;cancer treatment;human-expert-generated clinically acceptable plans;machine learning;patient geometry;radiation intensity distributions","Artificial Intelligence;Body Burden;Breast Neoplasms;Decision Support Systems, Clinical;Decision Support Techniques;Humans;Radiometry;Radiotherapy Dosage;Radiotherapy Planning, Computer-Assisted;Radiotherapy, Conformal;Relative Biological Effectiveness;Therapy, Computer-Assisted","3","","36","","","May 2006","","IEEE","IEEE Journals & Magazines"
"AuToCrawler: an integrated system for automatic topical crawler","Jyh-Jong Tsay; Chen-Yang Shih; Bo-Liang Wu","Dept. of Comput. Sci. & Inf. Eng., National Chung Cheng Univ., Chiayi, Taiwan","Fourth Annual ACIS International Conference on Computer and Information Science (ICIS'05)","20060418","2005","","","462","467","A topical (or focused) crawler is a Web crawler aiming to search and retrieve Web pages from the World Wide Web, which are related to a specific topic. Rather than downloading all accessible Web pages, a topical crawler analyzes the frontier of the crawled region to visit only the portion of the Web that contains relevant Web pages, and at the same time, try to skip irrelevant regions. This leads to significant savings in both computation and communication resources. In this paper, we present an integrated topical crawler: AuToCrawler. The main features of AuToCrawler consist of a user interest specification module that mediates between users and search engines to identify target examples and keywords that together specify the topic of their interest, and a URL ordering strategy that combines features of several previous approaches and achieves significant improvement. It also provides a graphic user interface such that users can evaluate and visualize the crawling results that can be used as feedback to reconfigure the crawler.","","POD:0-7695-2296-3","10.1109/ICIS.2005.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1515448","Focused Crawler;Information Retrieval;Machine Learning;Search Engines;Topical Crawler","Computer science;Crawlers;Graphics;Information retrieval;Search engines;Uniform resource locators;User interfaces;Visualization;Web pages;Web sites","data visualisation;graphical user interfaces;information retrieval;learning (artificial intelligence);search engines","AuToCrawler;URL ordering;Web crawler;Web page retrieval;Web page searching;World Wide Web;automatic topical crawler;crawler reconfiguration;feedback;focused crawler;graphic user interface;information retrieval;keywords;machine learning;search engines;user interest specification module","","3","","12","","","2005","","IEEE","IEEE Conference Publications"
"A multi-agent learning model based on dynamic fuzzy logic","Li-ping Xie; Fan-zhang Li","Comput. Sci. & Technol. Sch., Soochow Univ., Suzhou, China","2005 IEEE International Conference on Granular Computing","20051205","2005","1","","310","313 Vol. 1","Machine learning is one of the key problems of artificial intelligence, and the agent learning has become an important branch of machine learning. One of the main characters of intelligence agent is that it can adapt to the unknown environment. The ability to learn is the key property of agent. Because the learning act of agent is dynamic and fuzzy, this paper uses the conception of dynamic fuzzy logic. First, it gives the conception of agent learning based on DFL. Then, it supplies a multi-agent learning model based on DFL, namely a multi-agent learning model planned on a whole. Furthermore, the paper validates that the model is an useful model by an example.","","POD:0-7803-9017-2","10.1109/GRC.2005.1547292","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1547292","Agent Learning;Dynamic Fuzzy Logic;Machine Learning","Artificial intelligence;Computer science;Computer science education;Fuzzy logic;Fuzzy systems;Intelligent agent;Learning systems;Machine learning","fuzzy logic;learning (artificial intelligence);multi-agent systems","artificial intelligence;dynamic fuzzy logic;intelligence agent;machine learning;multiagent learning","","1","","6","","","25-27 July 2005","","IEEE","IEEE Conference Publications"
"Trainable post-processing method to reduce false alarms in the detection of small blotches of archive films","A. Licsar; L. Czuni; T. Sziranyi","Dept. of Image Process. & Neurocomput., Veszprem Univ., Hungary","IEEE International Conference on Image Processing 2005","20051114","2005","2","","II","562-5","We have developed a new semi-automatic neural network based method to detect blotches with low false alarm rate on archive films. Blotches can be modeled as temporal intensity discontinuities, hence false detection results originate from object motion (e.g. occlusion), non-rigid objects or erroneous motion estimation. In practice, usually, after the automatic detection step the false alarms are removed manually by an operator, significantly decreasing the efficiency of the restoration process. Our post-processing method classifies each detected blotch by its image features to minimize false results and the necessity of human intervention. The proposed method is tested on real archive sequences.","1522-4880;15224880","POD:0-7803-9134-9","10.1109/ICIP.2005.1530117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1530117","blotch detection;digital film restoration;machine learning","Costs;Degradation;Humans;Image motion analysis;Image restoration;Motion detection;Motion estimation;Neural networks;Object detection;Optical films","image restoration;image sequences;motion estimation;neural nets","archive sequences;false detection;human intervention;motion estimation;object motion;post-processing method;restoration process;semiautomatic neural network;temporal intensity discontinuities;trainable post-processing method","","0","","14","","","11-14 Sept. 2005","","IEEE","IEEE Conference Publications"
"Patient-specific seizure onset detection","A. Shoeb; H. Edwards; J. Connolly; B. Bourgeois; T. Treves; J. Guttag","Dept. of Electr. Eng. & Comput. Sci., MIT, Cambridge, MA, USA","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20050314","2004","1","","419","422","This work presents an automated, patient-specific method for the detection of epileptic seizure onsets from noninvasive EEG. We adopt a patient-specific approach to exploit the consistency of an individual patient's seizure and non-seizure EEG. Our method uses a wavelet decomposition to construct a feature vector that captures the morphology and spatial distribution of an EEG epoch, and then determines whether that vector is representative of a patient's seizure or non-seizure EEG using the support-vector machine classification algorithm. Our completely automated method was tested on non-invasive EEG from thirty-six pediatric subjects suffering from a variety of seizure types. It detected 131 of 139 seizure events within 8.03.2 seconds following electrographic onset, and declared 15 false-detections in 60 hours of clinical EEG. Our patient-specific method can be used to initiate delay-sensitive clinical procedures following seizure onset; for example, the injection of an imaging radiopharmaceutical or stimulation of the vagus nerve.","","POD:0-7803-8439-3","10.1109/IEMBS.2004.1403183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1403183","Epilepsy;Machine Learning;Seizure Detection","Delay;Detectors;Electroencephalography;Epilepsy;Event detection;Focusing;Hospitals;Lifting equipment;Morphology;Pediatrics","electroencephalography;medical signal detection;medical signal processing;signal classification;support vector machines;wavelet transforms","4.8 to 11.2 sec;60 hour;delay-sensitive clinical procedures;imaging radiopharmaceutical;noninvasive EEG;patient-specific seizure onset detection;pediatric subjects;support-vector machine classification algorithm;vagus nerve stimulation;wavelet decomposition","","6","","10","","","1-5 Sept. 2004","","IEEE","IEEE Conference Publications"
"Ensembling local learners ThroughMultimodal perturbation","Zhi-Hua Zhou; Yang Yu","Nat. Lab. for Novel Software Technol., Nanjing Univ., China","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20050718","2005","35","4","725","735","Ensemble learning algorithms train multiple component learners and then combine their predictions. In order to generate a strong ensemble, the component learners should be with high accuracy as well as high diversity. A popularly used scheme in generating accurate but diverse component learners is to perturb the training data with resampling methods, such as the bootstrap sampling used in bagging. However, such a scheme is not very effective on local learners such as nearest-neighbor classifiers because a slight change in training data can hardly result in local learners with big differences. In this paper, a new ensemble algorithm named Filtered Attribute Subspace based Bagging with Injected Randomness (FASBIR) is proposed for building ensembles of local learners, which utilizes multimodal perturbation to help generate accurate but diverse component learners. In detail, FASBIR employs the perturbation on the training data with bootstrap sampling, the perturbation on the input attributes with attribute filtering and attribute subspace selection, and the perturbation on the learning parameters with randomly configured distance metrics. A large empirical study shows that FASBIR is effective in building ensembles of nearest-neighbor classifiers, whose performance is better than that of many other ensemble algorithms.","1083-4419;10834419","","10.1109/TSMCB.2005.845396","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1468246","Data mining;ensemble learning;local learner;machine learning;multimodal perturbation;nearest-neighbor classifier;stable base learner","Bagging;Decision trees;Diversity reception;Educational programs;Filtering;Machine learning;Machine learning algorithms;Neural networks;Sampling methods;Training data","data mining;learning (artificial intelligence);sampling methods","bootstrap sampling;data mining;ensemble learning algorithm;filtered attribute subspace;machine learning;multimodal perturbation;multiple component learner;nearest-neighbor classifier;resampling method;stable base learner","Algorithms;Artificial Intelligence;Cluster Analysis;Computer Simulation;Information Storage and Retrieval;Models, Statistical;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated","50","","30","","","Aug. 2005","","IEEE","IEEE Journals & Magazines"
"""Missing is useful"": missing values in cost-sensitive decision trees","Shichao Zhang; Z. Qin; C. X. Ling; S. Sheng","Dept. of Autom. Control, Beijing Univ. of Aeronaut. & Astronaut., China","IEEE Transactions on Knowledge and Data Engineering","20051031","2005","17","12","1689","1693","Many real-world data sets for machine learning and data mining contain missing values and much previous research regards it as a problem and attempts to impute missing values before training and testing. In this paper, we study this issue in cost-sensitive learning that considers both test costs and misclassification costs. If some attributes (tests) are too expensive in obtaining their values, it would be more cost-effective to miss out their values, similar to skipping expensive and risky tests (missing values) in patient diagnosis (classification). That is, ""missing is useful"" as missing values actually reduces the total cost of tests and misclassifications and, therefore, it is not meaningful to impute their values. We discuss and compare several strategies that utilize only known values and that ""missing is useful"" for cost reduction in cost-sensitive decision tree learning.","1041-4347;10414347","","10.1109/TKDE.2005.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1524968","Index Terms- Induction;knowledge acquisition;machine learning.","Costs;Data mining;Decision trees;Knowledge acquisition;Learning systems;Life testing;Machine learning;Medical diagnosis;Medical tests;Predictive models","cost reduction;data mining;decision trees;learning (artificial intelligence);pattern classification","cost reduction;cost-sensitive decision tree learning;data mining;machine learning;misclassification costs;missing values;patient diagnosis;real-world data sets;test costs","","51","","24","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"A new image representation algorithm inspired by image submodality models, redundancy reduction, and learning in biological vision","N. Balakrishnan; K. Hariharakrishnan; D. Schonfeld","Dept. of Bioeng., Illinois Univ., Chicago, IL, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20050725","2005","27","9","1367","1378","We develop a new biologically motivated algorithm for representing natural images using successive projections into complementary subspaces. An image is first projected into an edge subspace spanned using an ICA basis adapted to natural images which captures the sharp features of an image like edges and curves. The residual image obtained after extraction of the sharp image features is approximated using a mixture of probabilistic principal component analyzers (MPPCA) model. The model is consistent with cellular, functional, information theoretic, and learning paradigms in visual pathway modeling. We demonstrate the efficiency of our model for representing different attributes of natural images like color and luminance. We compare the performance of our model in terms of quality of representation against commonly used basis, like the discrete cosine transform (DCT), independent component analysts (ICA), and principal components analysis (PCA), based on their entropies. Chrominance and luminance components of images are represented using codes having lower entropy than DCT, ICA, or PCA for similar visual quality. The model attains considerable simplification for learning from images by using a sparse independent code for representing edges and explicitly evaluating probabilities in the residual subspace.","0162-8828;01628828","","10.1109/TPAMI.2005.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471704","Index Terms- Computer vision;clustering algorithms;color.;feature representation;machine learning;statistical models","Biological information theory;Biological system modeling;Data mining;Discrete cosine transforms;Entropy;Image analysis;Image representation;Independent component analysis;Performance analysis;Principal component analysis","discrete cosine transforms;edge detection;feature extraction;image representation;independent component analysis;learning (artificial intelligence);principal component analysis","biological vision;discrete cosine transform;edge subspace;feature extraction;image redundancy reduction;image representation algorithm;image submodality model;independent component analysts;learning paradigm;natural images;probabilistic principal component analyzers;visual pathway modeling","Algorithms;Animals;Artificial Intelligence;Biomimetics;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Biological;Models, Statistical;Pattern Recognition, Automated;Visual Perception","8","","25","","","Sept. 2005","","IEEE","IEEE Journals & Magazines"
"Architecture for an intelligent distributed database","A. C. Munoz; J. L. Aguilar","Dpto. de Tecnologia, Inst. Universitario Tecnologico de Ejido IUTE, Ejido Merida, Venezuela","13th Euromicro Conference on Parallel, Distributed and Network-Based Processing","20050314","2005","","","322","328","In this paper we present an architecture for an intelligent distributed database. It integrates different kinds of database, such as relational, object-oriented, temporal, knowledge, deductive and multimedia databases, among others. In our approach we are using concepts from federate databases, fuzzy classified systems; and a database integration methodology. The architecture is based on a bridge as a mediator and uses learning machines to manage events, data and knowledge.","1066-6192;10666192","POD:0-7695-2280-7","10.1109/EMPDP.2005.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1386075","Federated Database;Intelligent Distributed Databases;Learning Machines;Mediator","Bridges;Computer architecture;Database systems;Deductive databases;Distributed databases;Information processing;Machine learning;Multimedia databases;Object oriented databases;Relational databases","data mining;distributed databases;learning (artificial intelligence)","database integration methodology;federate database;fuzzy classified system;intelligent distributed database;learning machines;mediator","","1","","11","","","9-11 Feb. 2005","","IEEE","IEEE Conference Publications"
"Recognition of facial expressions and measurement of levels of interest from video","M. Yeasin; B. Bullot; R. Sharma","","IEEE Transactions on Multimedia","20060515","2006","8","3","500","508","This paper presents a spatio-temporal approach in recognizing six universal facial expressions from visual data and using them to compute levels of interest. The classification approach relies on a two-step strategy on the top of projected facial motion vectors obtained from video sequences of facial expressions. First a linear classification bank was applied on projected optical flow vectors and decisions made by the linear classifiers were coalesced to produce a characteristic signature for each universal facial expression. The signatures thus computed from the training data set were used to train discrete hidden Markov models (HMMs) to learn the underlying model for each facial expression. The performances of the proposed facial expressions recognition were computed using five fold cross-validation on Cohn-Kanade facial expressions database consisting of 488 video sequences that includes 97 subjects. The proposed approach achieved an average recognition rate of 90.9% on Cohn-Kanade facial expressions database. Recognized facial expressions were mapped to levels of interest using the affect space and the intensity of motion around apex frame. Computed level of interest was subjectively analyzed and was found to be consistent with ""ground truth"" information in most of the cases. To further illustrate the efficacy of the proposed approach, and also to better understand the effects of a number of factors that are detrimental to the facial expression recognition, a number of experiments were conducted. The first empirical analysis was conducted on a database consisting of 108 facial expressions collected from TV broadcasts and labeled by human coders for subsequent analysis. The second experiment (emotion elicitation) was conducted on facial expressions obtained from 21 subjects by showing the subjects six different movies clips chosen in a manner to arouse spontaneous emotional reactions that would produce natural facial expressions.","1520-9210;15209210","","10.1109/TMM.2006.870737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1632035","Emotions;face detection;hidden Markov models (HMMs);levels of interest;machine learning;universal facial expressions","Databases;Face recognition;Hidden Markov models;Humans;Image motion analysis;Information analysis;TV broadcasting;Training data;Vectors;Video sequences","emotion recognition;face recognition;hidden Markov models;image motion analysis;image sequences;learning (artificial intelligence);pattern classification;visual databases","Cohn-Kanade facial expressions database;HMM;discrete hidden Markov model training;empirical analysis;facial motion vector projection;levels of interest measurement;linear classification bank;optical flow vector projection;spatio-temporal approach;universal facial expression recognition;video sequences","","92","3","64","","","June 2006","","IEEE","IEEE Journals & Magazines"
"Cost-constrained data acquisition for intelligent data preparation","X. Zhu; X. Wu","Dept. of Comput. Sci., Vermont Univ., Burlington, VT, USA","IEEE Transactions on Knowledge and Data Engineering","20050926","2005","17","11","1542","1556","Real-world data is noisy and can often suffer from corruptions or incomplete values that may impact the models created from the data. To build accurate predictive models, data acquisition is usually adopted to prepare the data and complete missing values. However, due to the significant cost of doing so and the inherent correlations in the data set, acquiring correct information for all instances is prohibitive and unnecessary. An interesting and important problem that arises here is to select what kinds of instances to complete so the model built from the processed data can receive the ""maximum"" performance improvement. This problem is complicated by the reality that the costs associated with the attributes are different, and fixing the missing values of some attributes is inherently more expensive than others. Therefore, the problem becomes that given a fixed budget, what kinds of instances should be selected for preparation, so that the learner built from the processed data set can maximize its performance? In this paper, we propose a solution for this problem, and the essential idea is to combine attribute costs and the relevance of each attribute to the target concept, so that the data acquisition can pay more attention to those attributes that are cheap in price but informative for classification. To this end, we will first introduce a unique economical factor (EF) that seamlessly integrates the cost and the importance (in terms of classification) of each attribute. Then, we will propose a cost-constrained data acquisition model, where active learning, missing value prediction, and impact-sensitive instance ranking are combined for effective data acquisition. Experimental results and comparative studies from real-world data sets demonstrate the effectiveness of our method.","1041-4347;10414347","","10.1109/TKDE.2005.176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512039","Index Terms- Data mining;cost-sensitive;data acquisition;instance ranking.;intelligent data preparation;machine learning","Classification tree analysis;Context modeling;Costs;Data acquisition;Data mining;Decision trees;Economic forecasting;Hospitals;Learning systems;Predictive models","data acquisition;data mining;learning (artificial intelligence);pattern classification","cost-constrained data acquisition;data mining;instance ranking;intelligent data preparation;machine learning;unique economical factor","","15","","38","","","Nov. 2005","","IEEE","IEEE Journals & Magazines"
"Reinforcement Learning in Quasi-Continuous Time","P. Wawrzynski; A. Pacut","Warsaw University of Technology, Poland","International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)","20060522","2005","2","","1031","1036","Reinforcement learning (RL) is used here as a tool for control systems optimization. State and action spaces are assumed to be continuous. Time is assumed to be discrete, yet the discretization may be arbitrarily fine. Within the proposed algorithm, a piece of information that leads to a policy improvement, is inferred from an experiment that lasts for several consecutive steps, rather than from a single step, as in more traditional RL methods. Simulations reveal that the algorithm is able to optimize the control policies for plants for which it is very difficult to apply the traditional methods","","POD:0-7695-2504-0","10.1109/CIMCA.2005.1631605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631605","Adaptive Control.;Machine Learning;Reinforcement Learning","Adaptive control;Control engineering computing;Control systems;Information resources;Intelligent agent;Machine learning;Machine learning algorithms;Optimization methods;Process control;Space technology","adaptive control;continuous time systems;control system analysis;learning (artificial intelligence);learning systems;optimal control","control policy optimization;control systems optimization;quasicontinuous time system;reinforcement learning","","0","","13","","","28-30 Nov. 2005","","IEEE","IEEE Conference Publications"
"Efficiently mining gene expression data via a novel parameterless clustering method","V. S. Tseng; Ching-Pin Kao","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20051121","2005","2","4","355","365","Clustering analysis has been an important research topic in the machine learning field due to the wide applications. In recent years, it has even become a valuable and useful tool for in-silico analysis of microarray or gene expression data. Although a number of clustering methods have been proposed, they are confronted with difficulties in meeting the requirements of automation, high quality, and high efficiency at the same time. In this paper, we propose a novel, parameterless and efficient clustering algorithm, namely, correlation search technique (CST), which fits for analysis of gene expression data. The unique feature of CST is it incorporates the validation techniques into the clustering process so that high quality clustering results can be produced on the fly. Through experimental evaluation, CST is shown to outperform other clustering methods greatly in terms of clustering quality, efficiency, and automation on both of synthetic and real data sets.","1545-5963;15455963","","10.1109/TCBB.2005.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1541987","Machine learning;clustering;data mining;mining methods and algorithms.","Algorithm design and analysis;Automation;Clustering algorithms;Clustering methods;Data mining;Fungi;Gene expression;Machine learning;Partitioning algorithms;Psychology","biology computing;data mining;genetics;learning (artificial intelligence);molecular biophysics;statistical analysis","correlation search technique;data mining;gene expression;machine learning;parameterless clustering method","Algorithms;Cell Cycle;Cluster Analysis;Computational Biology;Gene Expression Profiling;Models, Genetic;Models, Statistical;Oligonucleotide Array Sequence Analysis;ROC Curve;Sequence Analysis, DNA;Software;Yeasts","74","","21","","","Oct.-Dec. 2005","","IEEE","IEEE Journals & Magazines"
"A support vectors classifier approach to predicting the risk of progression of adolescent idiopathic scoliosis","P. O. Ajemba; L. Ramirez; N. G. Durdle; D. L. Hill; V. J. Raso","Dept. of Electr. & Comput. Eng., Univ. of Alberta, Edmonton, Alta., Canada","IEEE Transactions on Information Technology in Biomedicine","20050613","2005","9","2","276","282","A support vector classifier (SVC) approach was employed in predicting the risk of progression of adolescent idiopathic scoliosis (AIS), a condition that causes visible trunk asymmetries. As the aetiology of AIS is unknown, its risk of progression can only be predicted from measured indicators. Previous studies suggest that individual indicators of AIS do not reliably predict its risk of progression. Complex indicators with better predictive values have been developed but are unsuitable for clinical use as obtaining their values is often onerous, involving much skill and repeated measurements taken over time. Based on the hypothesis that combining common indicators of AIS using an SVC approach would produce better prediction results more quickly, we conducted a study using three datasets comprising a total of 44 moderate AIS patients (30 observed, 14 treated with brace). Of the 44 patients, 13 progressed less than 5 and 31 progressed more than 5. One dataset comprised all the patients. A second dataset comprised all the observed patients and a third comprised all the brace-treated patients. Twenty-one radiographic and clinical indicators were obtained for each patient. The result of testing on the three datasets showed that the system achieved 100% accuracy in training and 65%-80% accuracy in testing. It outperformed a ""statistically equivalent"" logistic regression model and a stepwise linear regression model on the said datasets. It took less than 20 min per patient to measure the indicators, input their values into the system, and produce the needed results, making the system viable for use in a clinical environment.","1089-7771;10897771","","10.1109/TITB.2005.847169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1435425","Decision support systems;Lenke indicators;machine learning (ML);scoliosis progression;support vector classifiers (SVCs)","Diagnostic radiography;Linear regression;Logistics;Machine learning;Medical treatment;Spine;Static VAr compensators;Surgery;System testing;Time measurement","decision support systems;diseases;learning (artificial intelligence);medical computing;medical information systems;radiography;regression analysis;support vector machines","Lenke indicator;adolescent idiopathic scoliosis;aetiology;brace-treated patient;clinical indicator;decision support system;hypothesis;logistic regression model;machine learning;radiographic indicator;scoliosis progression risk;stepwise linear regression model;support vectors classifier;visible trunk asymmetry","Adolescent;Decision Support Systems, Clinical;Disease Progression;Female;Humans;Male;Retrospective Studies;Scoliosis","12","2","20","","","June 2005","","IEEE","IEEE Journals & Magazines"
"Introducing a family of linear measures for feature selection in text categorization","E. F. Combarro; E. Montanes; I. Diaz; J. Ranilla; R. Mones","Artificial Intelligence Center, Oviedo Univ., Gijon, Spain","IEEE Transactions on Knowledge and Data Engineering","20050801","2005","17","9","1223","1232","Text categorization, which consists of automatically assigning documents to a set of categories, usually involves the management of a huge number of features. Most of them are irrelevant and others introduce noise which could mislead the classifiers. Thus, feature reduction is often performed in order to increase the efficiency and effectiveness of the classification. In this paper, we propose to select relevant features by means of a family of linear filtering measures which are simpler than the usual measures applied for this purpose. We carry out experiments over two different corpora and find that the proposed measures perform better than the existing ones.","1041-4347;10414347","","10.1109/TKDE.2005.149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1490529","Index Terms- Text categorization;feature selection;filtering measures;machine learning.","Availability;Filtering;Frequency;Humans;Machine learning;Maximum likelihood detection;Nonlinear filters;Performance evaluation;Text categorization;Wrapping","classification;feature extraction;information filtering;learning (artificial intelligence);pattern classification;text analysis","document classification;feature reduction;feature selection;linear filtering measures;machine learning;text categorization","","29","","18","","","Sept. 2005","","IEEE","IEEE Journals & Magazines"
"Selecting feature subsets for inducing classifiers using a committee of heterogeneous methods","D. M. Santoro; E. R. Hruschska; M. do Carmo Nicoletti","DC, UFSCar, Sao Carlos, Brazil","2005 IEEE International Conference on Systems, Man and Cybernetics","20060110","2005","1","","375","380 Vol. 1","As a previous step to machine learning (ML) induced classifiers, attribute subset selection methods have become an efficient alternative for reducing the dimensionality of the search space, with obvious benefits to the learning techniques used. This paper investigates the problem of feature subset selection using a committee of filter, wrapper and embedded methods. The wrappers were implemented using two different search mechanisms, a genetic algorithm and a best-first procedure as well as three different machine learning paradigms: instance-based (nearest neighbor - NN), neural network (DistAl) and symbolic (C4.5). The two filter methods used are based on consistency and correlation measures. The goals of the experiments were to be able to identify the most suitable attribute subsets to be further used for inducing a classifier as well as investigate if the combination of different results given by the committee's members can outperform any machine learning method using the original training set.","1062-922X;1062922X","POD:0-7803-9298-1","10.1109/ICSMC.2005.1571175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1571175","DistAl;feature subset selection;filter;machine learning;wrapper","Data mining;Filters;Gain measurement;Genetic algorithms;Learning systems;Machine learning;Machine learning algorithms;Nearest neighbor searches;Neural networks;Time measurement","learning (artificial intelligence);neural nets","DistAl;dimensionality reduction;embedded method;feature subset selection;filter method;genetic algorithm;machine learning;nearest neighbor;neural network;pattern classification;search space;wrapper method","","1","","14","","","10-12 Oct. 2005","","IEEE","IEEE Conference Publications"
"Fast discovery and the generalization of strong jumping emerging patterns for building compact and accurate classifiers","H. Fan; Kotagiri Ramamohanarao","Dept. of Comput. Sci. & Software Eng., Melbourne Univ., Vic., Australia","IEEE Transactions on Knowledge and Data Engineering","20060501","2006","18","6","721","737","Classification of large data sets is an important data mining problem that has wide applications. Jumping emerging patterns (JEPs) are those itemsets whose supports increase abruptly from zero in one data set to nonzero in another data set. In this paper, we propose a fast, accurate, and less complex classifier based on a subset of JEPs, called strong jumping emerging patterns (SJEPs). The support constraint of SJEP removes potentially less useful JEPs while retaining those with high discriminating power. Previous algorithms based on the manipulation of border as well as consEPMiner cannot directly mine SJEPs. In this paper, we present a new tree-based algorithm for their efficient discovery. Experimental results show that: 1) the training of our classifier is typically 10 times faster than earlier approaches, 2) our classifier uses much fewer patterns than the JEP-classifier to achieve a similar (and, often, improved) accuracy, and 3) in many cases, it is superior to other state-of-the-art classification systems such as naive Bayes, CBA, C4.5, and bagged and boosted versions of C4.5. We argue that SJEPs are high-quality patterns which possess the most differentiating power. As a consequence, they represent sufficient information for the construction of accurate classifiers. In addition, we generalize these patterns by introducing noise-tolerant emerging patterns (NEPs) and generalized noise-tolerant emerging patterns (GNEPs). Our tree-based algorithms can be adopted to easily discover these variations. We experimentally demonstrate that SJEPs, NEPs, and GNEPs are extremely useful for building effective classifiers that can deal well with noise","1041-4347;10414347","","10.1109/TKDE.2006.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1626228","Data mining;classification;emerging patterns;frequent patterns;machine learning;mining methods and algorithms.","Buildings;Data mining;Databases;Expert systems;Itemsets;Machine learning;Machine learning algorithms;Neural networks;Statistics;Supervised learning","data mining;learning (artificial intelligence);pattern classification;tree data structures;very large databases","SJEP;consEPMiner;data mining;generalized noise-tolerant emerging patterns;pattern classification system;strong jumping emerging patterns;support constraint;tree-based algorithm","","39","","39","","","June 2006","","IEEE","IEEE Journals & Magazines"
"Hybridization of fuzzy GBML approaches for pattern classification problems","H. Ishibuchi; T. Yamamoto; T. Nakashima","Dept. of Ind. Eng., Osaka Prefecture Univ., Japan","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20050321","2005","35","2","359","365","We propose a hybrid algorithm of two fuzzy genetics-based machine learning approaches (i.e., Michigan and Pittsburgh) for designing fuzzy rule-based classification systems. First, we examine the search ability of each approach to efficiently find fuzzy rule-based systems with high classification accuracy. It is clearly demonstrated that each approach has its own advantages and disadvantages. Next, we combine these two approaches into a single hybrid algorithm. Our hybrid algorithm is based on the Pittsburgh approach where a set of fuzzy rules is handled as an individual. Genetic operations for generating new fuzzy rules in the Michigan approach are utilized as a kind of heuristic mutation for partially modifying each rule set. Then, we compare our hybrid algorithm with the Michigan and Pittsburgh approaches. Experimental results show that our hybrid algorithm has higher search ability. The necessity of a heuristic specification method of antecedent fuzzy sets is also demonstrated by computational experiments on high-dimensional problems. Finally, we examine the generalization ability of fuzzy rule-based classification systems designed by our hybrid algorithm.","1083-4419;10834419","","10.1109/TSMCB.2004.842257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1408064","Fuzzy rules;genetic algorithms;machine learning;pattern classification","Algorithm design and analysis;Fuzzy sets;Fuzzy systems;Genetic algorithms;Genetic mutations;Industrial engineering;Knowledge based systems;Machine learning;Machine learning algorithms;Pattern classification","fuzzy set theory;genetic algorithms;knowledge based systems;learning (artificial intelligence);pattern classification","Michigan approach;Pittsburgh approach;fuzzy GBML approach;fuzzy genetics-based machine learning approach;fuzzy rule-based classification system;genetic algorithm;pattern classification problem","Algorithms;Artificial Intelligence;Cluster Analysis;Fuzzy Logic;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","131","","21","","","April 2005","","IEEE","IEEE Journals & Magazines"
"Inducing NNC-trees with the R<sup>4</sup>-rule","Qiangfu Zhao","Univ. of Aizu, Fukushima, Japan","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20060605","2005","36","3","520","533","An NNC-Tree is a decision tree (DT) with each nonterminal node containing a nearest neighbor classifier (NNC). Compared with the conventional axis-parallel DTs (APDTs), the NNC-Trees can be more efficient, because the decision boundary made by an NNC is more complex than an axis-parallel hyperplane. Compared with single-layer NNCs, the NNC-Trees can classify given data in a hierarchical structure that is often useful for many applications. This paper proposes an algorithm for inducing NNC-Trees based on the R<sup>4</sup>-rule, which was proposed by the author for finding the smallest nearest neighbor based multilayer perceptrons (NN-MLPs). There are mainly two contributions here. 1) A heuristic but effective method is given to define the teacher signals (group labels) for the data assigned to each nonterminal node. 2) The R<sup>4</sup>-rule is modified so that an NNC with proper size can be designed automatically in each nonterminal node. Experiments with several public databases show that the proposed algorithm can produce NNC-Trees effectively and efficiently.","1083-4419;10834419","","10.1109/TSMCB.2005.861868","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634646","Decision trees;NNC-Trees;machine learning and understanding;nearest neighbor classifier;neural networks","Classification tree analysis;Databases;Decision trees;Machine learning;Machine learning algorithms;Multilayer perceptrons;Nearest neighbor searches;Neural networks;Signal design;Testing","decision trees;learning (artificial intelligence);multilayer perceptrons;pattern classification","NNC-Trees;R/sup 4/-rule;data classification;decision tree;multilayer perceptrons;nearest neighbor classifier","Algorithms;Artificial Intelligence;Decision Support Techniques;Pattern Recognition, Automated","6","","38","","","June 2005","","IEEE","IEEE Journals & Magazines"
"System Based on Computational Intelligence for Ophthalmology Image Understanding","A. V. Netto","","IEEE Latin America Transactions","20060619","2005","3","5","14","22","In this project a computational system of images analysis was developed based on machine learning techniques to aid the diagnosis in the optometry `area`, particularly, an objective and automatic system of ocular refraction errors measurement (astigmatism, hypermetropia and short-sightedness). The results of the work suggest a way to improve the images interpretation from the acquisition technique called Hartmann-Shack (HS) to allow that, later, other ocular problems are detected and measured. The work was realized in an image understanding `area` using Support Vector Machines (SVM). The motivation to investigate images learning techniques for the recognition and analysis of the images in this project was the search for a measurement system capable to interpret the content of the images as a whole, instead of measuring for the comparison of extracted discreet data of the image with extracted data of a reference image.","1548-0992;15480992","","10.1109/TLA.2005.1642434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1642434","Image understanding;Intelligent systems;Machine Learning;Support Vector Machine (SVM);ophthalmology images;refractive errors","Computational intelligence;Single event transient;Support vector machines;Testing","","Image understanding;Intelligent systems;Machine Learning;Support Vector Machine (SVM);ophthalmology images;refractive errors","","0","","34","","","Dec. 2005","","IEEE","IEEE Journals & Magazines"
"Learning Activity-Based Ground Models from a Moving Helicopter Platform","A. Lookingbill; D. Lieb; D. Stavens; S. Thrun","Stanford AI Lab Stanford University Stanford, CA 94305; apml@stanford.edu","Proceedings of the 2005 IEEE International Conference on Robotics and Automation","20060110","2005","","","3948","3953","We present a method for learning activity-based ground models based on a multiple particle filter approach to motion tracking in video acquired from a moving aerial platform. Such models offer a number of potential benefits. In this paper we demonstrate the ability of activity-based models to improve the performance of an object motion tracker as well as their applicability to global registration of video sequences.","1050-4729;10504729","POD:0-7803-8914-X","10.1109/ROBOT.2005.1570724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1570724","Activity Maps;Computer Vision;Machine Learning;Object Tracking;Particle Filters","Artificial intelligence;Cameras;Helicopters;Histograms;Layout;Mobile robots;Particle filters;Particle tracking;Probability distribution;Roads","","Activity Maps;Computer Vision;Machine Learning;Object Tracking;Particle Filters","","6","","14","","","18-22 April 2005","","IEEE","IEEE Conference Publications"
"Evolving the structure of hidden Markov models","Kyoung-Jae Won; A. Prugel-Bennett; A. Krogh","Sch. of Electron. & Comput. Sci., Univ. of Southampton, UK","IEEE Transactions on Evolutionary Computation","20060130","2006","10","1","39","49","A genetic algorithm (GA) is proposed for finding the structure of hidden Markov Models (HMMs) used for biological sequence analysis. The GA is designed to preserve biologically meaningful building blocks. The search through the space of HMM structures is combined with optimization of the emission and transition probabilities using the classic Baum-Welch algorithm. The system is tested on the problem of finding the promoter and coding region of C. jejuni. The resulting HMM has a superior discrimination ability to a handcrafted model that has been published in the literature.","1089-778X;1089778X","","10.1109/TEVC.2005.851271","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1583626","Biological sequence analysis;genetic algorithm (GA);hidden Markov model (HMM);hybrid algorithm;machine learning","Algorithm design and analysis;Approximation error;Bioinformatics;Biological system modeling;Estimation error;Genetic algorithms;Hidden Markov models;Machine learning;Machine learning algorithms;System testing","biology;genetic algorithms;hidden Markov models;probability","Baum-Welch algorithm;C. jejuni;biological sequence analysis;coding region;emission probability;genetic algorithm;hidden Markov models;promoter region;transition probability","","8","","25","","","Feb. 2006","","IEEE","IEEE Journals & Magazines"
"Improving Prediction of Residue Solvent Accessibility with SVR and Multiple Sequence Alignment Profile","Ao Li; Xian Wang; Zhaohui Jiang; Huanqing Feng","Department of Electronic Science and Technology University of Science and Technology of China, Hefei, Anhui 230026, China","2005 IEEE Engineering in Medicine and Biology 27th Annual Conference","20060410","2005","","","2595","2598","A new method based on support vector regression (SVR) has been introduced to predict the relative solvent accessibility (RSA) of residues from protein primary sequences, which uses the local information of protein primary sequences as input. Different to most previous methods which are designed to predict the exposure state (exposed/buried, exposed/intermediate/buried, etc) of a particular residue according to its relative solvent accessibility, this method predicts the real value of RSA, by which more information about residue location in protein 3D structure can be retained than state assignment. Measurements for prediction performance, i.e. the mean absolute error (MAE) and correlation coefficient (CC), were compared with a former RVP-Net method, which was based on a multilayer feed-forward neural network. With 3-fold cross validation test, the MAE and CC of the SVR method for all data sets were consistently better than those obtained by the RVP-Net. In addition, we used the profile of multiple sequence alignment as input and achieved a significant improvement in prediction performance comparing with using only single sequence information. The final prediction result on the CB-513 data set by our method was 16.8% for MAE and 0.562 for CC. The results demonstrate that SVR is a useful tool for protein sequence analyses","1094-687X;1094687X","POD:0-7803-8741-4","10.1109/IEMBS.2005.1617000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1617000","Bioinformatics;Machine learning;Protein structure prediction;Relative solvent accessibility;Support vector regression","Bioinformatics;Design methodology;Feedforward neural networks;Feedforward systems;Machine learning;Multi-layer neural network;Neural networks;Protein sequence;Solvents;Testing","biology computing;feedforward neural nets;molecular biophysics;molecular configurations;proteins;regression analysis;support vector machines","RVP-Net method;SVR;correlation coefficient;mean absolute error;multilayer feedforward neural network;multiple sequence alignment profile;protein 3D structure;protein primary sequences;protein sequence analyses;residue location;residue solvent accessibility prediction;support vector regression","","0","","6","","","17-18 Jan. 2006","","IEEE","IEEE Conference Publications"
"Using multiagent system for gene expression classification","G. Stiglic; P. Kokol","Lab. for Syst. Design, Maribor Univ., Slovenia","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20050314","2004","2","","2952","2955","Recent advances in microarray technology offer the ability to measure expression levels of thousands of genes simultaneously. Analysis of such data can help us identifying different clinical outcomes using only expressions of a few predictive genes. This paper presents an application of multiagent system to the analysis of gene expression data. Our goal is to find significant classification genes using simple classifiers that can be used by agents when exploring the gene expression database. We present our results on two well-known publicly available gene expression problems where we try to achieve the highest possible accuracy of classification using the smallest possible set of genes.","","POD:0-7803-8439-3","10.1109/IEMBS.2004.1403838","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1403838","case based reasoning;machine learning;microarray classification;multi-agent systems","Clustering methods;Data analysis;Databases;Gene expression;Learning systems;Machine learning;Multiagent systems;Multidimensional systems;Neoplasms;Space exploration","biology computing;case-based reasoning;cellular biophysics;genetics;learning (artificial intelligence);molecular biophysics;pattern classification","case based reasoning;gene expression classification;gene expression database;machine learning;microarray technology;multiagent system;predictive genes","","1","","11","","","1-5 Sept. 2004","","IEEE","IEEE Conference Publications"
"Ensemble-based discriminant learning with boosting for face recognition","J. Lu; K. N. Plataniotis; A. N. Venetsanopoulos; S. Z. Li","Edward S. Rogers Sr. Dept. of Electr. & Comput. Eng., Univ. of Toronto, Ont., Canada","IEEE Transactions on Neural Networks","20060213","2006","17","1","166","178","In this paper, we propose a novel ensemble-based approach to boost performance of traditional Linear Discriminant Analysis (LDA)-based methods used in face recognition. The ensemble-based approach is based on the recently emerged technique known as ""boosting"". However, it is generally believed that boosting-like learning rules are not suited to a strong and stable learner such as LDA. To break the limitation, a novel weakness analysis theory is developed here. The theory attempts to boost a strong learner by increasing the diversity between the classifiers created by the learner, at the expense of decreasing their margins, so as to achieve a tradeoff suggested by recent boosting studies for a low generalization error. In addition, a novel distribution accounting for the pairwise class discriminant information is introduced for effective interaction between the booster and the LDA-based learner. The integration of all these methodologies proposed here leads to the novel ensemble-based discriminant learning approach, capable of taking advantage of both the boosting and LDA techniques. Promising experimental results obtained on various difficult face recognition scenarios demonstrate the effectiveness of the proposed approach. We believe that this work is especially beneficial in extending the boosting framework to accommodate general (strong/weak) learners.","1045-9227;10459227","","10.1109/TNN.2005.860853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1593701","Boosting;face recognition (FR);linear discriminant analysis;machine learning;mixture of linear models;small-sample-size (SSS) problem;strong learner","Authentication;Biometrics;Boosting;Engines;Face detection;Face recognition;Indexing;Linear discriminant analysis;Machine learning;Monitoring","face recognition;learning (artificial intelligence)","boosting;ensemble-based discriminant learning;face recognition;linear discriminant analysis;machine learning","Algorithms;Artificial Intelligence;Databases, Factual;Face;Pattern Recognition, Automated","105","","59","","","Jan. 2006","","IEEE","IEEE Journals & Magazines"
"Philosophy and methodology for knowledge discovery in autonomic computing systems","J. Strassner; B. J. Menich","Motorola Labs., Schaumburg, IL, USA","16th International Workshop on Database and Expert Systems Applications (DEXA'05)","20050919","2005","","","738","743","Autonomic computing has been advanced as a solution to the currently problematic control of voice and data communications networks. Autonomic systems adapt both to their environment and to the demands placed upon them as a consequence of the use of the system(s) within their purview. Data and voice networks function in a changing environment with varying use cases; hence, autonomic systems must be deployed with both a significant a priori knowledge base and the capability to continuously upgrade that knowledge base. The system must engage in some amount of unsupervised learning and hypothesize as to nature of its functioning. Maintenance of hypotheses and theories is intrinsic to the system, especially in evolutionary scenarios. This paper explores how knowledge maintenance is done for voice and data communications networks applications that use autonomic system approaches.","1529-4188;15294188","POD:0-7695-2424-9","10.1109/DEXA.2005.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1508361","Autonomic Computing;Causal Determinacy;Causal and Developmental Morphology;Information Model;Machine Learning;Ontology;Superficial Causality","Communication system control;Computer networks;Data communication;Environmental management;Information management;Intelligent networks;Knowledge management;Ontologies;Transfer functions;Unsupervised learning","computer network management;data mining;integrated voice/data communication;telecommunication computing;unsupervised learning","autonomic computing;data communications networks;knowledge discovery;knowledge maintenance;unsupervised learning;voice networks","","5","1","19","","","22-26 Aug. 2005","","IEEE","IEEE Conference Publications"
