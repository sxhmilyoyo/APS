"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7371260,7371361,7314905,7368772,7367738,7368776,7369242,7367064,7363241,7364114,7363953,7364034,7363073,7363774,7364098,7363164,7364001,7363395,7363448,7363905,7359450,7355313,7298436,7359282,7358791,7358416,7353577,7354457,7357081,7354435,7354004,7317747,7353037,7358813,7353475,7328752,7360021,7350932,7349719,7350874,7350839,7351042,7351837,7349950,7351836,7351206,7351271,7351466,7351247,7351708,7351742,7351656,7346197,7348310,7344817,7344814,7344858,7344554,7344637,7344643,7344778,7344545,7344808,7346646,7344144,7346165,7348375,7347684,7163639,7343074,7343919,7340498,7345495,7340862,7341398,7340859,7345645,7340820,7345493,7345005,7340807,7340789,7334812,7336035,7337843,7336086,7337926,7337999,7337903,7334841,7339147,7336089,7337853,7336249,7337944,7001634,7084661,7334166,7329752,7334080",2017/05/05 22:37:53
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Regularizing deep learning architecture for face recognition with weight variations","S. Nagpal; M. Singh; M. Vatsa; R. Singh","IIIT-Delhi, New Delhi, India","2015 IEEE 7th International Conference on Biometrics Theory, Applications and Systems (BTAS)","20151217","2015","","","1","6","Several mathematical models have been proposed for recognizing face images with age variations. However, effect of change in body-weight is also an interesting covariate that has not been much explored. This paper presents a novel approach to incorporate the weight variations during feature learning process. In a deep learning architecture, we propose incorporating the body-weight in terms of a regularization function which helps in learning the latent variables representative of different weight categories. The formulation has been proposed for both Autoencoder and Deep Boltzmann Machine. On extended WIT database of 200 subjects, the comparison with a commercial system and an existing algorithm show that the proposed algorithm outperforms them by more than 9% at rank-10 identification accuracy.","","Electronic:978-1-4799-8776-4; POD:978-1-4799-8777-1","10.1109/BTAS.2015.7358791","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358791","","Databases;Decoding;Encoding;Face;Face recognition;Machine learning;Training","Boltzmann machines;face recognition;learning (artificial intelligence)","age variations;autoencoder;deep Boltzmann machine;face image recognition;face recognition;feature learning process;mathematical models;regularization function;regularizing deep learning architecture;weight variations","","1","","14","","","8-11 Sept. 2015","","IEEE","IEEE Conference Publications"
"Adapting sentiment analysis to face-to-face human-agent interactions: From the detection to the evaluation issues","C. Langlet; C. Clavel","Institut Mines-T&#233;l&#233;com, T&#233;l&#233;com ParisTech, CNRS LTCI, 46 Rue Barrault, 75013 Paris, France","2015 International Conference on Affective Computing and Intelligent Interaction (ACII)","20151207","2015","","","14","20","This paper introduces a sentiment analysis method suitable to the human-agent and face-to-face interactions. We present the positioning of our system and its evaluation protocol according to the existing sentiment analysis literature and detail how the proposed system integrates the human-agent interaction issues. Finally, we provide an in-depth analysis of the results obtained by the evaluation, opening the discussion on the different difficulties and the remaining challenges of sentiment analysis in human-agent interactions.","","Electronic:978-1-4799-9953-8; POD:978-1-4799-9954-5; USB:978-1-4799-9952-1","10.1109/ACII.2015.7344545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344545","alignment;embodied conversational agent;emotional stance;engagement;other-repetition","Adaptation models;Context;Machine learning algorithms;Pragmatics;Protocols;Semantics;Sentiment analysis","human computer interaction;multi-agent systems;protocols;text analysis","ECA;embodied conversational agent;evaluation protocol;face-to-face human-agent interaction;sentiment analysis","","","","40","","","21-24 Sept. 2015","","IEEE","IEEE Conference Publications"
"Tutorial 1: NVIDIA's platform for Deep Neural Networks","G. Röth","Solution Architect @ NVIDIA","2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20151207","2015","","","XXXVII","XXXIX","Summary form only given. In that session, we will present the NVIDIA's platform for Deep Neural Networks (DNN). NVIDIA designs and produces GPUs and processors that are at the origin of breakthroughs in Deep Learning. NVIDIA also develops CuDNN, a library of primitives for Deep Learning which is integrated in leading frameworks like Theano, Torch and Caffe and DIGITS, an interactive Deep Learning GPU Training System. During that session, you will learn more about those different components to help you make your DNN more powerful.","","Electronic:978-1-4673-8273-1; POD:978-1-4673-8274-8","10.1109/DSAA.2015.7344778","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344778","","Biological system modeling;Computer science;Machine learning;Machine learning algorithms;Neural networks;Training;Tutorials","graphics processing units;neural nets","Caffe;CuDNN;DIGITS;GPUs;NVIDIA;Theano;Torch;deep neural networks;interactive deep learning GPU training system","","","","","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"A hybrid Deep belief network approach for Financial distress prediction","Z. Lanbouri; S. Achchab","National School for Computer Science and Systems analysis, Mohammed V University of Rabat, Morocco","2015 10th International Conference on Intelligent Systems: Theories and Applications (SITA)","20151217","2015","","","1","6","After the subprime crisis in 2008, an efficient Financial Distress Prediction (FDP) model has become necessary. Many research works have attempted to provide a model using statistical or intelligent methods. In this respect, this paper adopts a two-stage hybrid model that integrates Deep Learning and Support Vector Machine as a FDP modeling method. Local receptive fields is a technique used in order to select the nodes for each layer of our deep network. Then, stacked Restricted Boltzmann Machine is applied to form a Deep Belief Network as pre-training. Subsequently, Support Vector Machine follows for classification. An experiment over a sample of French firms offers accuracy details about this method. The proposed model actually provides a result of 76,8% instances that are correctly classified. Henceforth, the new technique could prevent Financial distress before it happens. As such, investors, managers, banks, decision makers and others could benefit from its significant impact.","","Electronic:978-1-5090-0220-7; POD:978-1-5090-0221-4","10.1109/SITA.2015.7358416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358416","","Artificial neural networks;Business;Correlation;Machine learning;Measurement;Support vector machines;Training","","","","","","19","","","20-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Classifier with hierarchical topographical maps as internal representation","T. Trappenberg; P. Hollensen; P. Hartono","Faculty of Computer Science, Dalhousie University, Halifax, Canada","2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES)","20151123","2015","","","341","345","In this study we want to connect our previously proposed context-relevant topographical maps with the deep learning community. Our architecture is a classifier with hidden layers that are hierarchical two-dimensional topographical maps. These maps differ from the conventional self-organizing maps in that their organizations are influenced by the context of the data labels in a top-down manner. In this way bottom-up and top-down learning are combined in a biologically relevant representational learning setting. Compared to our previous work, we are here specifically elaborating the model in a more challenging setting compared to our previous experiments and to advance more hidden representation layers to bring our discussions into the context of deep representational learning.","","Electronic:978-1-4673-7939-7; POD:978-1-4673-7940-3; USB:978-1-4673-7938-0","10.1109/INES.2015.7329752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7329752","","Animals;Context;Databases;Machine learning;Neurons;Organizations;Radial basis function networks","learning (artificial intelligence);pattern classification;self-organising feature maps","bottom-up learning;context-relevant topographical maps;deep learning community;deep representational learning;hierarchical topographical maps;hierarchical two-dimensional topographical maps;internal representation;self-organizing maps;top-down learning","","","","9","","","3-5 Sept. 2015","","IEEE","IEEE Conference Publications"
"A scalable solution for group feature selection","P. Govindan; R. Chen; K. Scheinberg; S. Srinivasan","Rutgers University","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2846","2848","In many applications, we may want to build a classifier with high confidence, while reducing the number of features. We consider the case where features are assigned to predefined groups and cannot be removed individually. An additional and important constraint is that the datasets may be very large and may not fit in memory. We use logistic regression with group penalty, which results in sparse solutions at the group level. In our implementation, we apply L-BFGS to approximate the quadratic loss function of logistic regression and use Block Co-ordinate Descent to solve for each group. Our contributions can be summarized as follows: (1) we discuss different scalable approaches, depending on characteristics of the dataset, such as, large number of data points or large number of features or large number of groups; (2) for datasets with large number of data points and few groups of features, we identify the bottlenecks for scalability; (3) we present Spark solutions in Python and discuss the advantages of our solution over alternate solutions; (4) we present the experiments and results on synthetic data and real data from manufacturing applications.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364098","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364098","","Approximation methods;Big data;Logistics;Machine learning algorithms;Runtime;Sparks;Sparse matrices","feature selection;pattern classification;regression analysis","L-BFGS;Python;Spark;block coordinate descent;group feature selection;logistic regression","","","","5","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Acquisition by robots of danger-avoidance behaviors using probability-based reinforcement learning","D. Takeyama; M. Kanoh; T. Matsui; T. Nakamura","Graduate School of Computer Science, Chukyo University, 101-2 Yagoto Honmachi, Showa-ku, Nagoya, Aichi 466-8666, Japan","2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20151130","2015","","","1","4","Robots are being used more and more in dangerous environments such as space and disaster areas. However, when robots are at risk in dangerous environments, the time during which robot operators can issue risk avoidance instructions is limited. Therefore, robots should be able to acquire behaviors that enable them to autonomously avoid danger. In this paper, we present a probability-based reinforcement learning (PrRL) method and apply it to robot behavior acquisition.","","Electronic:978-1-4673-7428-6; POD:978-1-4673-7429-3","10.1109/FUZZ-IEEE.2015.7337999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337999","","Compounds;Computer science;Learning (artificial intelligence);Machine learning algorithms;Mathematical model;Presses;Robots","intelligent robots;learning (artificial intelligence);probability","PrRL method;danger-avoidance behaviors;dangerous environments;probability-based reinforcement learning;risk avoidance instructions;robot behavior acquisition;robot operators","","","","7","","","2-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Analog inference circuits for deep learning","J. Holleman; I. Arel; S. Young; J. Lu","Department of Electrical Engineering & Computer Science, University of Tennessee, Knoxville, Knoxville, TN, USA","2015 IEEE Biomedical Circuits and Systems Conference (BioCAS)","20151207","2015","","","1","4","Deep Machine Learning (DML) algorithms have proven to be highly successful at challenging, high-dimensional learning problems, but their widespread deployment is limited by their heavy computational requirements and the associated power consumption. Analog computational circuits offer the potential for large improvements in power efficiency, but noise, mismatch, and other effects cause deviations from ideal computations. In this paper we describe circuits useful for DML algorithms, including a tunable-width bump circuit and a configurable distance calculator. We also discuss the impacts of computational errors on learning performance. Finally we will describe a complete deep learning engine implemented using current-mode analog circuits and compare its performance to digital equivalents.","","Electronic:978-1-4799-7234-0; POD:978-1-4799-7235-7; USB:978-1-4799-7233-3","10.1109/BioCAS.2015.7348310","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7348310","analog CMOS;deep learning;error modeling;neuromorphic computing","Clustering algorithms;Computational efficiency;Computational modeling;Feature extraction;Integrated circuit modeling;Machine learning algorithms;Training","CMOS analogue integrated circuits;biomedical electronics;learning (artificial intelligence);medical computing","DML algorithms;analog computational circuits;analog inference circuits;computational errors;configurable distance calculator;current-mode analog circuits;deep learning engine;deep machine learning algorithms;digital equivalents;heavy computational requirements;high-dimensional learning problems;noise;power consumption;tunable-width bump circuit","","1","","8","","","22-24 Oct. 2015","","IEEE","IEEE Conference Publications"
"Interpolation aided fuzzy image classification","Yongfeng Zhang; C. Shang; Q. Shen","Department of Computer Science, Institute of Mathematics, Physics and Computer Science, Aberystwyth University, UK","2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20151130","2015","","","1","7","This paper presents a novel application of interpolation in supporting fuzzy image classification. The recently introduced Deep Spatio-Temporal Inference Network (DeSTIN) is employed to carry out limited original feature extraction. A simple but effective linear interpolation is then used to artificially increase the dimensionality of the extracted feature sets for accurate classification, without incurring heavy computational cost. In particular, Fuzzy-Rough Nearest Neighbour (FRNN) and Fuzzy Ownership Nearest Neighbour (FRNN-O) are each utilised for image classification. The work is tested against the popular MNIST dataset of handwritten digits [1]. Experimental results indicate that the proposed approach is highly promising.","","Electronic:978-1-4673-7428-6; POD:978-1-4673-7429-3","10.1109/FUZZ-IEEE.2015.7337903","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337903","","Computer architecture;Computer science;Feature extraction;Interpolation;Machine learning;Time complexity;Tin","feature extraction;fuzzy set theory;image classification;interpolation;rough set theory","DeSTIN;FRNN-O;MNIST;deep spatio-temporal inference network;feature extraction;fuzzy ownership nearest neighbour;fuzzy-rough nearest neighbour;handwritten digits;linear interpolation aided fuzzy image classification","","","","18","","","2-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Generalization of optimal motion trajectories for bipedal walking","A. Werner; D. Trautmann; D. Lee; R. Lampariello","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany","2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","20151217","2015","","","1571","1577","Control of robot locomotion profits from the use of pre-planned trajectories. This paper presents a way to generalize globally optimal and dynamically consistent trajectories for cyclic bipedal walking. A small task-space consisting of stride-length and step time is mapped to spline parameters which fully define the optimal joint space motion. The paper presents the impact of different machine learning algorithms for velocity and torque optimal trajectories with respect to optimality and feasibility. To demonstrate the usefulness of the trajectories, a control approach is presented that allows general walking including transitions between points in the task-space.","","Electronic:978-1-4799-9994-1; POD:978-1-4799-9995-8; USB:978-1-4799-9993-4","10.1109/IROS.2015.7353577","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7353577","","Cost function;Legged locomotion;Machine learning algorithms;Splines (mathematics);Trajectory","learning (artificial intelligence);legged locomotion","cyclic bipedal walking;dynamically consistent trajectories;general walking;generalization;machine learning algorithms;optimal joint space motion;optimal motion trajectories;preplanned trajectories;robot locomotion;small task space;spline parameters;step time;stride length;torque optimal trajectories","","1","","15","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Recommend My Dish: A multi-sensory food recommender","H. Abdool; A. Pooransingh; Y. Li","The University of the West Indies, St. Augustine, Trinidad","2015 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM)","20151130","2015","","","240","245","In this paper, the model for a multi-sensory food recommender is presented, which takes into account both taste and aesthetic attributes of food. The recommender was designed using a case-based reasoning (CBR) approach, and built with the myCBR framework. The recommender was later integrated into an Android application prototype, via which potential user feedback was obtained. We conducted a preliminary user study in which all participants rated their satisfaction with the recommendations above 5 on a scale of 0 to 10. Furthermore, 72% of participants felt that by considering their aesthetic preferences in the recommendation process, the system produced better recommendations than if they were not considered.","","Electronic:978-1-4673-7788-1; POD:978-1-4673-7789-8; USB:978-1-4673-7787-4","10.1109/PACRIM.2015.7334841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334841","Case-based reasoning;image processing;knowledge-based systems;myCBR;recommender systems","Cognition;Collaboration;Image color analysis;Machine learning algorithms;Recommender systems","Android (operating system);advertising data processing;case-based reasoning;customer services;food products;image processing;mobile computing;recommender systems","Android application prototype;CBR;aesthetic attributes;case-based reasoning;multisensory food recommender;recommend my dish;taste attributes","","","","20","","","24-26 Aug. 2015","","IEEE","IEEE Conference Publications"
"A hybrid approach to sentiment analysis of news comments","A. Mukwazvure; K. P. Supreethi","Department of Computer Science and Engineering, JNTU College of Engineering Hyderabad, Kukatpally, 500 085, Telangana, India","2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions)","20151217","2015","","","1","6","Today, the web hosts quite a voluminous amount of information. Among such information is user generated content which plays an important role in analyzing different business aspects. Sentiment analysis therefore becomes an effective way of understanding public opinions. Businesses, particularly in ecommerce, stock market, social networks and also political entities can use sentiment analysis for decision making. Traditional methods of opinion gathering involved the use of questioners and interviews which solely depend on the good will of the people to be interviewed. Most research on sentiment analysis focused on social networks, product reviews and also on the stock market. Less research has been covered on analysis of news comments. This research embarks on a hybrid approach to sentiment analysis of news comments which involves using sentiment lexicon for polarity detection (polarity will be classified as positive, negative and neutral). The results from the lexicon based method are then used to train machine learning algorithms. Two algorithms employed in this research are the Support Vector Machine (SVM) and K-Nearest Neighbour (kNN). Experimental results show that SVM performs better than kNN on news comments.","","Electronic:978-1-4673-7231-2; POD:978-1-4673-7232-9","10.1109/ICRITO.2015.7359282","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359282","SVM;User generated content;kNN;polarity;sentiment analysis;sentiment lexicon","Classification algorithms;Dictionaries;Machine learning algorithms;Market research;Sentiment analysis;Support vector machines","data mining;decision making;electronic publishing;learning (artificial intelligence);pattern classification;sentiment analysis;social networking (online);support vector machines","SVM;Web hosts;business aspects;decision making;k-nearest neighbour;kNN;lexicon based method;machine learning algorithms;news comment sentiment analysis;opinion gathering;polarity classification;polarity detection;product reviews;public opinions;sentiment lexicon;social networks;stock market;support vector machine","","","","21","","","2-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"Brushstroke based sparse hybrid convolutional neural networks for author classification of Chinese ink-wash paintings","M. Sun; D. Zhang; J. Ren; Z. Wang; J. S. Jin","School of Computer Science and Technology, Tianjin University, Tianjin, China","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","626","630","A novel stroke based sparse hybrid convolutional neural networks (CNNs) method is proposed for author classification of Chinese ink-wash paintings (IWPs). As Chinese IWPs usually have many authors in several art styles, this differs from real images or western paintings and has led to a big challenge. In our work, we classify Chinese IWPs of different artists by analyzing a set of automatically extracted brushstrokes. A sparse hybrid CNNs in a deep-learning framework is then proposed to extract brushstroke features to replace the commonly used handcrafted ones such as edge, color, intensity and texture. Using 120 IWPs from six famous artists, promising results have been shown in successfully classifying authors in comparison to two other state-of-the-art approaches.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7350874","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350874","Brushstroke analysis;Chinese ink-wash painting;convolutional neural networks;image classification;sparse coding","Art;Convolution;Feature extraction;Image edge detection;Machine learning;Neural networks;Painting","image classification;neural nets","Chinese IWP;Chinese ink-wash paintings;author classification;brushstroke based sparse hybrid convolutional neural networks;brushstroke features;deep-learning framework;sparse hybrid CNN method;western paintings","","1","","24","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Deep learning classifier for fall detection based on IR distance sensor data","S. Jankowski; Z. Szymański; U. Dziomin; P. Mazurek; J. Wagner","Warsaw University of Technology, Nowowiejska 15/19, 00-665 Warszawa, Poland","2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)","20151203","2015","2","","723","727","The goal of research is the fall detection in elderly residents based on infra red depth sensor measurements. Our attention is focused on statistical properties as generalization. The effectiveness of discriminative statistical classifiers (multilayer perceptron) is improved by addition of feature selection block by Gram-Schmidt orthogonalization, which determines the ranking of the features, and NPCA block, which transforms the raw data into a nonlinear manifold and reduces the dimensionality of the data. Performance of our system measured in terms of sensitivity is 92% and precision is 93%, which means it can be used for real life applications.","","CD-ROM:978-1-4673-8358-5; Electronic:978-1-4673-8361-5; POD:978-1-4673-8362-2","10.1109/IDAACS.2015.7341398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7341398","Gramm-Schmidt orthogonalization;NPCA;fall detection;feature selection;infra red distance sensor","Acceleration;Machine learning;Manifolds;Neural networks;Principal component analysis;Sensitivity;Training","assisted living;feature selection;geriatrics;infrared detectors;learning (artificial intelligence);multilayer perceptrons;object detection;signal classification;spatial variables measurement;statistical analysis","Gram-Schmidt orthogonalization;IR distance sensor data;NPCA block;data dimensionality reduction;deep learning classifier;discriminative statistical classifiers;elderly residents;fall detection;feature ranking;feature selection block;infrared depth sensor measurements;multilayer perceptron;nonlinear manifold;statistical properties","","1","","19","","","24-26 Sept. 2015","","IEEE","IEEE Conference Publications"
"Deep-plant: Plant identification with convolutional neural networks","S. H. Lee; C. S. Chan; P. Wilkin; P. Remagnino","Centre of Image & Signal Processing, Fac. Comp. Sci. & Info. Tech., University of Malaya, Malaysia","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","452","456","This paper studies convolutional neural networks (CNN) to learn unsupervised feature representations for 44 different plant species, collected at the Royal Botanic Gardens, Kew, England. To gain intuition on the chosen features from the CNN model (opposed to a `black box' solution), a visualisation technique based on the deconvolutional networks (DN) is utilized. It is found that venations of different order have been chosen to uniquely represent each of the plant species. Experimental results using these CNN features with different classifiers show consistency and superiority compared to the state-of-the art solutions which rely on hand-crafted features.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7350839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350839","deep learning;feature visualisation;plant classification","Failure analysis;Machine learning;Shape;Support vector machines;Training;Visualization;Yttrium","biology computing;botany;data visualisation;feature extraction;image classification;image representation;learning (artificial intelligence)","CNN model;England;Kew;Royal Botanic Garden;convolutional neural network;deconvolutional networks;deep learning;plant identification;plant species;unsupervised feature representation;visualisation technique","","1","","22","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Combining deep learning and unsupervised clustering to improve scene recognition performance","A. Kappeler; R. D. Morris; A. R. Kamat; N. Rasiwasia; G. Aggarval","Northwestern University, 633 Clark Street, Evanston, IL 60208, USA","2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)","20151203","2015","","","1","6","Deep Neural Networks (DNN) are now the state-of-the-art for many image and object recognition tasks, as illustrated by their performance on standard benchmarks. The success of DNNs is attributed to their ability to learn rich mid-level image representations, as opposed to hand-designed low-level features used in other image analysis methods. Typically a large dataset of unlabeled images is used for unsupervised feature learning, and then standard classifiers are trained on the features extracted from the images in a labeled set. In this paper, we show that clustering the images using the features from the DNN allows more accurate per-cluster classifiers to be learned, which improves the overall classification accuracy. We demonstrate the effectiveness of our approach on a scene recognition task.","","Electronic:978-1-4673-7478-1; POD:978-1-4673-7479-8","10.1109/MMSP.2015.7340859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7340859","","Feature extraction;Image representation;Machine learning;Neural networks;Sun;Support vector machines;Training","neural nets;object recognition;unsupervised learning","DNN;deep learning;deep neural networks;mid-level image representations;object recognition;scene recognition performance;unsupervised clustering;unsupervised feature learning","","","","18","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Sentiment expression via emoticons on social media","H. Wang; J. A. Castanon","Silicon Valley Laboratory, IBM San Jose, USA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2404","2408","Emoticons (e.g., :) and :( ) have been widely used in sentiment analysis and other NLP tasks as features to machine learning algorithms or as entries of sentiment lexicons. In this paper, we argue that while emoticons are strong and common signals of sentiment expression on social media the relationship between emoticons and sentiment polarity are not always clear. Thus, any algorithm that deals with sentiment polarity should take emoticons into account but extreme caution should be exercised in which emoticons to depend on. First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large recent Twitter data set. Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used. The first analysis surveyed a group of participants for their perceived sentiment polarity of the most frequent emoticons. The second analysis examined clustering of words and emoticons to better understand the meaning conveyed by the emoticons. The third analysis compared the sentiment polarity of microblog posts before and after emoticons were removed from the text. The last analysis tested the hypothesis that removing emoticons from text hurts sentiment classification by training two models with and without emoticons in the text, respectively. The results confirms the arguments that: 1) a few emoticons are strong and reliable signals of sentiment polarity and one should take advantage of them in any sentiment analysis; 2) a large group of the emoticons conveys complicated sentiment hence they should be treated with extreme caution.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364034","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364034","Twitter;emoticon;polarity;sentiment;social media","Big data;Context;Machine learning algorithms;Media;Reliability;Sentiment analysis;Twitter","pattern classification;pattern clustering;sentiment analysis;social networking (online)","NLP tasks;Twitter data set;emoticons;machine learning algorithms;microblog posts;sentiment analysis;sentiment classification;sentiment expression;sentiment lexicons;sentiment polarity;social media;words clustering","","","","20","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Fuzzy Rough Set Prototype Selection for Regression","S. Vluymans; Y. Saeys; C. Cornelis; A. Teredesai; M. De Cock","Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Gent, Belgium","2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20151130","2015","","","1","8","Instance selection methods are a class of preprocessing techniques that have been widely studied in machine learning to remove redundant or noisy instances from a training set. The main focus of such prior efforts has been on the selection of suitable training instances to perform a classification task for crisp class labels. In this paper, we propose a novel instance selection technique termed Fuzzy Rough Set Prototype Selection for Regression (FRPS-R) for solving regression problems, where the outcome is continuous. We use concepts from fuzzy rough set theory and extend the currently well-known fuzzy rough set prototype selection technique to model the quality of all available elements and then use a wrapper approach to select an optimal subset of high-quality instances; thereby generalizing the idea. Our experimental evaluation shows that the application of our proposed instance selection technique can significantly improve the predictive performance of the weighted k-nearest neighbor regression algorithm, in particular when noise is present in the original training set.","","Electronic:978-1-4673-7428-6; POD:978-1-4673-7429-3","10.1109/FUZZ-IEEE.2015.7337926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337926","","Additives;Electronic mail;Machine learning algorithms;Prediction algorithms;Prototypes;Set theory;Training","fuzzy set theory;regression analysis;rough set theory","FRPS-R;fuzzy rough set prototype selection;fuzzy rough set theory;instance selection method;weighted k-nearest neighbor regression algorithm;wrapper approach","","","","14","","","2-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Noise correction of image labeling in crowdsourcing","B. Nicholson; V. S. Sheng; J. Zhang","Department of Computer Science, University of Central Arkansas","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","1458","1462","We investigate the methods of improving data quality, in terms of label accuracy, in the context of image labeling in crowdsourcing. First, we look at three consensus methods for inferring a ground-truth label from the multiple noisy labels obtained from crowdsourcing, i.e., Majority Voting (MV), Dawid Skene (DS), and KOS. We then apply three noise correction methods to correct labels inferred by these consensus methods, i.e., Polishing Labels (PL), Self-Training Correction (STC), and Cluster Correction (CC). Our experimental results show that the noise correction methods improve the labeling quality significantly.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351042","","Clustering algorithms;Crowdsourcing;Feature extraction;Labeling;Machine learning algorithms;Noise measurement;Yttrium","image denoising","Dawid skene;KOS;STC;cluster correction;consensus methods;crowdsourcing;data quality;ground-truth label;image labeling;label accuracy;labeling quality;majority voting;noise correction methods;noisy labels;polishing labels;self-training correction","","","","16","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Hashing for Statistics over K-Partitions","S. Dahlgaard; M. B. T. Knudsen; E. Rotenberg; M. Thorup","Dept. of Comput. Sci., Univ. of Copenhagen, Copenhagen, UK","2015 IEEE 56th Annual Symposium on Foundations of Computer Science","20151217","2015","","","1292","1310","In this paper we analyze a hash function for k-partitioning a set into bins, obtaining strong concentration bounds for standard algorithms combining statistics from each bin. This generic method was originally introduced by Flajolet and Martin [FOCS'83] in order to save a factor Ω(k) of time per element over k independent samples when estimating the number of distinct elements in a data stream. It was also used in the widely used HyperLogLog algorithm of Flajolet et al. [AOFA'97] and in large-scale machine learning by Li et al. [NIPS'12] for minwise estimation of set similarity. The main issue of k-partition, is that the contents of different bins may be highly correlated when using popular hash functions. This means that methods of analyzing the marginal distribution for a single bin do not apply. Here we show that a tabulation based hash function, mixed tabulation, does yield strong concentration bounds on the most popular applications of k-partitioning similar to those we would get using a truly random hash function. The analysis is very involved and implies several new results of independent interest for both simple and double tabulation, e.g. a simple and efficient construction for invertible bloom filters and uniform hashing on a given set.","0272-5428;02725428","Electronic:978-1-4673-8191-8","10.1109/FOCS.2015.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354457","Hashing;concentration bounds;constant moments;invertible bloom filters;joint distributions;k-partition;peelability;tabulation hashing;uniform hashing","Computer science;Correlation;Estimation;Frequency estimation;Machine learning algorithms;Polynomials;Yttrium","data structures;estimation theory;learning (artificial intelligence);statistics","HyperLogLog algorithm;hash function;invertible Bloom filters;k-partitioning;large-scale machine learning;minwise estimation;statistics","","1","","42","","","17-20 Oct. 2015","","IEEE","IEEE Conference Publications"
"An Intention-Topic Model Based on Verbs Clustering and Short Texts Topic Mining","T. Lu; S. Hou; Z. Chen; L. Cui; L. Zhang","Sch. of Inf. Sci. & Eng., Univ. of Jinan, Jinan, China","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","837","842","Microblog, Twitter, status messages, the classified information website and so on are experiencing explosive growth with the development of web2.0, people prefer to use short texts to express their intentions and activities. Yet, when people submit some requirements through short texts, they hope to get a feedback which can help them to solve their problems rather than relevant content. Sometimes people need corresponding intention rather than similar content. However, current researches cannot solve the problem well. In this paper, we propose an intentiontopic model: Verb-Biterm Topic Model(V-BTM), which aims at corresponding intention matching. Intention is expressed by verbs and topic is expressed by BTM. Intention is the action of people want to express and topic is the goal of the intention. The key of the model is that people tend to express their intention with verbs and tend to express the topic with non-verb. In this model, firstly, we distinguish intentions with the verb clustering with the help of word2vec which is a deep learning tool. Secondly, we mine the topic using Biterm Topic Model(BTM) on the data without verbs. We carry out experiments on real-world short text collections. The results demonstrate that our approach can get better verb clustering and mine more coherent topics. Furthermore, the new model can be the base of our future researches.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363164","","Algorithm design and analysis;Clustering algorithms;Data mining;Data models;Machine learning;Probability distribution;Semantics","data mining;learning (artificial intelligence);pattern clustering;pattern matching;text analysis","Twitter;V-BTM;Verb-Biterm topic model;Web 2.0;classified information Web site;deep learning tool;intention matching;intention-topic model;microblog;real-world short text collections;short text topic mining;status messages;verb clustering;word2vec","","","","27","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Classification with a reject option under Concept Drift: The Droplets algorithm","P. X. Loeffel; C. Marsala; M. Detyniecki","Sorbonne Universit&#233;s, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, 4 place Jussieu 75005 Paris","2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20151207","2015","","","1","9","In this paper a new on-line algorithm is proposed (the Droplets algorithm) for dealing with concept drifts and to produce reliable predictions. The two main characteristics of this algorithm are that it is able to adapt to different types of drifts without making any assumptions regarding their type or when they occur, and can provide reliable predictions in a non-stationary environment without using a fixed confidence threshold. Experimental results on five datasets based on Random RBF and Rotating Hyperplane generators as well as a new semi-synthetic dataset based weather temperatures show that, by discarding difficult observations, the Droplets algorithm manages to obtain the best average accuracy against ten classifiers. The results also indicate that the algorithm manages to provide reliable prediction by accurately distinguishing which observations are easily classifiable.","","Electronic:978-1-4673-8273-1; POD:978-1-4673-8274-8","10.1109/DSAA.2015.7344808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344808","","Algorithm design and analysis;Bagging;Classification algorithms;Indexes;Machine learning algorithms;Prediction algorithms;Reliability","pattern classification;statistical distributions","Droplets algorithm;concept drift;data classification;reject option","","","","25","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Prediction Models for Performance, Power, and Energy Efficiency of Software Executed on Heterogeneous Hardware","D. Bán; R. Ferenc; I. Siket; Á. Kiss","Dept. of Software Eng., Univ. of Szeged, Szeged, Hungary","2015 IEEE Trustcom/BigDataSE/ISPA","20151203","2015","3","","178","183","Heterogeneous environments are becoming commonplace so it is increasingly important to understand how and where we could execute a given algorithm the most efficiently. In this paper we propose a methodology that uses both static source code metrics and dynamic execution time, power and energy measurements to build configuration prediction models. These models are trained on special benchmarks that have both sequential and parallel implementations and can be executed on various computing elements, e.g., on CPUs or GPUs. After they are built, however, they can be applied to a new system using only the system's static metrics which are much more easily computable than any dynamic measurement. We found that we could predict the optimal execution configuration fairly accurately using static information alone.","","Electronic:978-1-4673-7952-6; POD:978-1-4673-7953-3","10.1109/Trustcom.2015.629","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345645","Green computing;configuration selection;heterogeneous architecture;performance optimization;power-aware execution","Algorithm design and analysis;Benchmark testing;Computational modeling;Machine learning algorithms;Measurement;Prediction algorithms;Predictive models","graphics processing units;parallel programming;prediction theory;sequential estimation;software metrics;source code (software)","CPU;GPU;dynamic execution time;energy efficiency;energy measurement;heterogeneous hardware;optimal execution configuration;parallel implementation;power measurement;prediction model;sequential implementation;software execution;static source code metrics","","","","16","","","20-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"A Decision Making Method Based on Society of Mind Theory in Multi-player Imperfect Information Games","M. Wakatsuki; M. Fujimura; T. Nishino","Grad. Sch. of Inf. & Eng., Univ. of Electro-Commun., Chofu, Japan","2015 3rd International Conference on Applied Computing and Information Technology/2nd International Conference on Computational Science and Intelligence","20151130","2015","","","67","72","We are concerned with a card game called Daihinmin, which is a multi-player imperfect information game. Using Marvin Minsky's ""Society of Mind"" theory, we attempt to model the workings of the minds of game players. The UEC Computer Daihinmin Championship is held at The University of Electro-Communications every year, to bring together competitive client programs that correspond to players of Daihinmin, and contest their strengths. In this paper, we extract the behavior of client programs from actual competition records of the computer Daihinmin, and propose a method of building a system that determines the parameters of Daihinmin agencies by machine learning.","","Electronic:978-1-4673-9642-4; POD:978-1-4673-9643-1","10.1109/ACIT-CSI.2015.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336035","Daihinmin;Society of Mind;deep learning;multiplayer imperfect information game","Buildings;Computers;Games;Informatics;Machine learning;Neural networks;Tuning","computer games;decision making;learning (artificial intelligence)","Daihinmin agency;Society-of-Mind theory;UEC Computer Daihinmin Championship;University of Electro-Communications;card game;decision making method;machine learning;multiplayer imperfect information game","","","","7","","","12-16 July 2015","","IEEE","IEEE Conference Publications"
"Learning hyperparameter optimization initializations","M. Wistuba; N. Schilling; L. Schmidt-Thieme","Information Systems and Machine Learning Lab University of Hildesheim, Hildesheim, Germany","2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20151207","2015","","","1","10","Hyperparameter optimization is often done manually or by using a grid search. However, recent research has shown that automatic optimization techniques are able to accelerate this optimization process and find hyperparameter configurations that lead to better models. Currently, transferring knowledge from previous experiments to a new experiment is of particular interest because it has been shown that it allows to further improve the hyperparameter optimization. We propose to transfer knowledge by means of an initialization strategy for hyperparameter optimization. In contrast to the current state of the art initialization strategies, our strategy is neither limited to hyperparameter configurations that have been evaluated on previous experiments nor does it need meta-features. The initial hyperparameter configurations are derived by optimizing for a meta-loss formally defined in this paper. This loss depends on the hyperparameter response function of the data sets that were investigated in past experiments. Since this function is unknown and only few observations are given, the meta-loss is not differentiable. We propose to approximate the response function by a differentiable plug-in estimator. Then, we are able to learn the initial hyperparameter configuration sequence by applying gradient-based optimization techniques. Extensive experiments are conducted on two meta-data sets. Our initialization strategy is compared to the state of the art for initialization strategies and further methods that are able to transfer knowledge between data sets. We give empirical evidence that our work provides an improvement over the state of the art.","","Electronic:978-1-4673-8273-1; POD:978-1-4673-8274-8","10.1109/DSAA.2015.7344817","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344817","","Data models;Gaussian processes;Information systems;Kernel;Machine learning algorithms;Optimization;Predictive models","data mining;learning (artificial intelligence);meta data;optimisation","automatic optimization technique;data mining domain;differentiable plug-in estimator;gradient-based optimization technique;grid search;hyperparameter configuration;hyperparameter optimization;hyperparameter response function;knowledge transfer;meta-data set","","4","","26","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Natural Language Processing for Sentiment Analysis: An Exploratory Analysis on Tweets","W. Y. Chong; B. Selvaretnam; L. K. Soon","Fac. of Comput. & Inf., Multimedia Univ., Cyberjaya, Malaysia","2014 4th International Conference on Artificial Intelligence with Applications in Engineering and Technology","20151210","2014","","","212","217","In this paper, we present our preliminary experiments on tweets sentiment analysis. This experiment is designed to extract sentiment based on subjects that exist in tweets. It detects the sentiment that refers to the specific subject using Natural Language Processing techniques. To classify sentiment, our experiment consists of three main steps, which are subjectivity classification, semantic association, and polarity classification. The experiment utilizes sentiment lexicons by defining the grammatical relationship between sentiment lexicons and subject. Experimental results show that the proposed system is working better than current text sentiment analysis tools, as the structure of tweets is not same as regular text.","","CD-ROM:978-1-4799-7909-7; Electronic:978-1-4799-7910-3; POD:978-1-4799-7911-0","10.1109/ICAIET.2014.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351837","Sentiment Analysis; Natural Language Processing; Tweets","Feature extraction;Machine learning algorithms;Semantics;Sentiment analysis;Tagging;Twitter","data mining;emotion recognition;natural language processing;pattern classification;social networking (online);text analysis","grammatical relationship;natural language processing techniques;polarity classification;semantic association;sentiment classification;sentiment lexicons;subject based sentiment extraction;text sentiment analysis tools;tweet sentiment analysis","","1","","14","","","3-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Denoising AutoEncoder in Neural Networks with Modified Elliott Activation Function and Sparsity-Favoring Cost Function","H. Burhani; W. Feng; G. Hu","Depts. of Comput. & Inf. Syst. & Math., Trent Univ., Peterborough, ON, Canada","2015 3rd International Conference on Applied Computing and Information Technology/2nd International Conference on Computational Science and Intelligence","20151130","2015","","","343","348","Neural networks (NN) are architectures and algorithms for machine learning. They are quite powerful for tasks like classification, clustering, and pattern recognition. Large neural networks can be considered a universal function that can approximate any function, and hence are effective at learning from the training data, not only the useful information but also the noise in the training data. However, as the number of neurons and the number of hidden layers grow, the number of connections in the network increases exponentially, and the over fitting problem becomes more severe biased towards noise. Various methods have been proposed to address this problem such as AutoEncoder, Dropout, DropConnect, and Factored Mean training. In this paper, we propose a denoising autoencoder approach using a modified Elliott activation function and a cost function that favors sparsity in the input data. Preliminary experiments using the modified algorithm on several real data sets showed that the proposed approach performed well.","","Electronic:978-1-4673-9642-4; POD:978-1-4673-9643-1","10.1109/ACIT-CSI.2015.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336086","Deep neural networks;activation function;cost function;denoising autoencoder","Biological neural networks;Cost function;Machine learning algorithms;Neurons;Noise reduction;Training","neural nets;transfer functions","denoising autoencoder;input data sparsity;modified Elliott activation function;neural networks;sparsity-favoring cost function","","","","18","","","12-16 July 2015","","IEEE","IEEE Conference Publications"
"Human Detection and Activity Classification Based on Micro-Doppler Signatures Using Deep Convolutional Neural Networks","Y. Kim; T. Moon","Dept. of Electr. & Comput. Eng., California State Univ., Fresno, CA, USA","IEEE Geoscience and Remote Sensing Letters","20160106","2016","13","1","8","12","We propose the use of deep convolutional neural networks (DCNNs) for human detection and activity classification based on Doppler radar. Previously, proposed schemes for these problems remained in the conventional supervised learning paradigm that relies on the design of handcrafted features. Whereas these schemes attained high accuracy, the requirement for domain knowledge of each problem limits the scalability of the proposed schemes. In this letter, we present an alternative deep learning approach. We apply the DCNN, one of the most successful deep learning algorithms, directly to a raw micro-Doppler spectrogram for both human detection and activity classification problem. The DCNN can jointly learn the necessary features and classification boundaries using the measured data without employing any explicit features on the micro-Doppler signals. We show that the DCNN can achieve accuracy results of 97.6% for human detection and 90.9% for human activity classification.","1545-598X;1545598X","","10.1109/LGRS.2015.2491329","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314905","Convolutional neural network;deep learning;human activity classification;human detection;micro-Doppler","Accuracy;Convolution;Doppler radar;Feature extraction;Machine learning;Spectrogram","Doppler radar;geophysical techniques;neural nets","DCNN;Doppler radar;activity classification problem;classification boundaries;conventional supervised learning paradigm;deep convolutional neural networks;deep learning algorithms;human detection;microDoppler signatures;microDoppler spectrogram","","5","","23","","20151102","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Generating multi-fingered robotic grasps via deep learning","J. Varley; J. Weisz; J. Weiss; P. Allen","","2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","20151217","2015","","","4415","4420","This paper presents a deep learning architecture for detecting the palm and fingertip positions of stable grasps directly from partial object views. The architecture is trained using RGBD image patches of fingertip and palm positions from grasps computed on complete object models using a grasping simulator. At runtime, the architecture is able to estimate grasp quality metrics without the need to explicitly calculate the given metric. This ability is useful as the exact calculation of these quality functions is impossible from an incomplete view of a novel object without any tactile feedback. This architecture for grasp quality prediction provides a framework for generalizing grasp experience from known to novel objects.","","Electronic:978-1-4799-9994-1; POD:978-1-4799-9995-8; USB:978-1-4799-9993-4","10.1109/IROS.2015.7354004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354004","","Computer architecture;Grasping;Heating;Image segmentation;Machine learning;Training;Training data","grippers;haptic interfaces;image colour analysis","RGBD image patches;deep learning architecture;fingertip positions;grasp quality metrics;grasp quality prediction;grasping simulator;multifingered robotic grasps;object models;palm positions;quality functions;tactile feedback","","2","","19","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Posed and spontaneous facial expression differentiation using deep Boltzmann machines","Q. Gan; C. Wu; S. Wang; Q. Ji","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China","2015 International Conference on Affective Computing and Intelligent Interaction (ACII)","20151207","2015","","","643","648","Current works on differentiating between posed and spontaneous facial expressions usually use features that are handcrafted for expression category recognition. Till now, no features have been specifically designed for differentiating between posed and spontaneous facial expressions. Recently, deep learning models have been proven to be efficient for many challenging computer vision tasks, and therefore in this paper we propose using the deep Boltzmann machine to learn representations of facial images and to differentiate between posed and spontaneous facial expressions. First, faces are located from images. Then, a two-layer deep Boltzmann machine is trained to distinguish posed and spon-tanous expressions. Experimental results on two benchmark datasets, i.e. the SPOS and USTC-NVIE datasets, demonstrate that the deep Boltzmann machine performs well on posed and spontaneous expression differentiation tasks. Comparison results on both datasets show that our method has an advantage over the other methods.","","Electronic:978-1-4799-9953-8; POD:978-1-4799-9954-5; USB:978-1-4799-9952-1","10.1109/ACII.2015.7344637","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344637","deep boltzmann machines;expression differentiation;feature learning;posed and spontaneous expressions","Electronic mail;Face recognition;Machine learning;Neural networks;Nonhomogeneous media;Standards;Training","Boltzmann machines;emotion recognition;face recognition;feature extraction;learning (artificial intelligence)","SPOS dataset;USTC-NVIE dataset;deep learning model;facial image;posed facial expression differentiation;spontaneous facial expression differentiation;two-layer deep Boltzmann machine","","1","","18","","","21-24 Sept. 2015","","IEEE","IEEE Conference Publications"
"Review Sentiment Analysis Based on Deep Learning","Z. Hu; J. Hu; W. Ding; X. Zheng","Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2015 IEEE 12th International Conference on e-Business Engineering","20151210","2015","","","87","94","With rapid development of E-commerce platforms, automated review sentiment analysis for commodities becomes a research focus, with main purpose to extract potential information within reviews for decision making of consumers. Traditional methods have made some progress on document level sentiment analysis, but with tremendous increasing of data scale, how to process high dimension of data fast and effectively becomes the largest limitation. In this paper, we import deep neural network which is appropriate for high dimension data analysis, and propose a framework of sentiment analysis based on deep learning. Experiments on different data scale and different domains show that the proposed method can solve high dimensional problem with good performance.","","Electronic:978-1-4673-8002-7; POD:978-1-4673-8003-4","10.1109/ICEBE.2015.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349950","deep learning;deep nerual network;sentiment analysis","Algorithm design and analysis;Context;Feature extraction;Machine learning;Neural networks;Semantics;Sentiment analysis","consumer behaviour;data analysis;decision making;electronic commerce;feature extraction;learning (artificial intelligence);neural nets;text analysis","consumer decision making;data analysis;deep learning;deep neural network;e-commerce platform;information extraction;review sentiment analysis","","","","20","","","23-25 Oct. 2015","","IEEE","IEEE Conference Publications"
"Convolutional neural network for 3D object recognition based on RGB-D dataset","J. Wang; J. Lu; W. Chen; X. Wu","School of Automation Science and Electrical Engineering, Beihang University, Beijing 100191, China","2015 IEEE 10th Conference on Industrial Electronics and Applications (ICIEA)","20151123","2015","","","34","39","Object recognition is fundamental to some high-level computer vision tasks such as image segmentation, object tracking and behavior analysis. The main objective of object recognition is to answer whether a specified object exists in a given image, so extracting representative features from images and training a right classifier become the key techniques in this area. In this paper, we use convolutional neural network model to learn features from RGB-D dataset which are then given to a linear SVM classifier to classify objects. As the number of images in RGB-D dataset is not big enough to retrain a deep neural network with high feature extraction accuracy, we fine-tune the caffe model which was trained on approximately 1.2 million RGB images from ImageNet database. While the framework of depth image is intrinsically different form RGB image, we transform the depth image into three channels and use the same method with the RGB image to extract features. We can achieve a classification accuracy of 91.35% which is much better than the state of the art.","","Electronic:978-1-4799-8389-6; POD:978-1-4799-8467-1; USB:978-1-4673-7317-3","10.1109/ICIEA.2015.7334080","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334080","Convolutional Neural Networks;RGB-D object dataset;SVM;fine-tuning;three-channel","Accuracy;Feature extraction;Kernel;Machine learning;Neural networks;Object recognition;Training","computer vision;feature extraction;image classification;image colour analysis;image segmentation;learning (artificial intelligence);neural nets;object recognition;object tracking;support vector machines","3D object recognition;ImageNet database;RGB images;RGB-D dataset;behavior analysis;caffe model fine-tuning;classifier training;convolutional neural network model;deep neural network;depth image;feature learning;high-level computer vision;image segmentation;linear SVM classifier;object classification;object tracking;representative feature extraction","","3","","19","","","15-17 June 2015","","IEEE","IEEE Conference Publications"
"Modeling recurrent distributions in streams using possible worlds","M. Geilke; A. Karwath; S. Kramer","Johannes Gutenberg-Universit&#228;t Mainz, Staudingerweg 9, 55128 Mainz, Germany","2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20151207","2015","","","1","9","Discovering changes in the data distribution of streams and discovering recurrent data distributions are challenging problems in data mining and machine learning. Both have received a lot of attention in the context of classification. With the ever increasing growth of data, however, there is a high demand of compact and universal representations of data streams that enable the user to analyze current as well as historic data without having access to the raw data. To make a first step towards this direction, we propose a condensed representation that captures the various - possibly recurrent - data distributions of the stream by extending the notion of possible worlds. The representation enables queries concerning the whole stream and can, hence, serve as a tool for supporting decision-making processes or serve as a basis for implementing data mining and machine learning algorithms on top of it. We evaluate this condensed representation on synthetic and real-world data.","","Electronic:978-1-4673-8273-1; POD:978-1-4673-8274-8","10.1109/DSAA.2015.7344814","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344814","","Clocks;Context;Data mining;Data models;Itemsets;Machine learning algorithms;Shape","data mining;data structures;decision making;learning (artificial intelligence)","data mining;data representation;data streams;decision making process;machine learning;possible worlds;recurrent data distributions discovery;universal representations","","","","35","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Sociolinguistics and programming","F. Naz; J. E. Rice","Department of Math and Computer Science, University of Lethbridge, Alberta, Canada","2015 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM)","20151130","2015","","","74","79","This paper focuses on the use of machine learning techniques for the analysis of computer programs in order to acquire information about an author's gender. There are few existing studies that address the relationship between linguistics and programming; however, in many areas where language is analyzed it is possible to mine important information about the users of that language associated with set of attribute or coding style. In this work we use open source implementations of machine learning algorithms, specifically, nearest neighbor (K*), decision tree (J48), and Bayes classifier (Naïve Bayes). These algorithms were applied to C++ programs which were associated with sociolinguistic information about the program authors. Our goal was to classify the programs according to the gender of the author. As indicated by our initial results we have been able to achieve precision of 72.3%, recall of 72%, and f-measure of 71.9% which demonstrates that we can predict the gender of the authors of C++ programs.","","Electronic:978-1-4673-7788-1; POD:978-1-4673-7789-8; USB:978-1-4673-7787-4","10.1109/PACRIM.2015.7334812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334812","","Computers;Machine learning algorithms;Measurement;Pragmatics;Software;Software algorithms;Supervised learning","C++ language;decision trees;learning (artificial intelligence);pattern classification","Bayes classifier;C++ programs;computer programs;decision tree;machine learning techniques;nearest neighbor;open source implementations;sociolinguistic information","","","","24","","","24-26 Aug. 2015","","IEEE","IEEE Conference Publications"
"Gray scale image watermarking using fuzzy entropy and Lagrangian twin SVR in DCT domain","Ashok Kumar Yadav; R. Mehta; R. Kumar","Department of Computer Science and Engineering, UIET, Maharishi Dayanand University, Rohtak, India","2015 Eighth International Conference on Contemporary Computing (IC3)","20151207","2015","","","19","24","In this paper, the effect of low, middle and high frequency DCT coefficients are investigated onto gray scale image watermarking in terms of imperceptibility and robustness. The performance of Lagrangian twin support vector regression (LTSVR), which was successfully applied on synthetic datasets obtained from UCI repository for various kinds of regression problems by Balasundaram et al. [9], onto image watermarking problem, is validated by embedding and extracting the watermark on different standard and real world images. Also the good learning capability of image characteristics provides the good imperceptibility of the watermark and robustness against several kinds of image processing attacks verifies the high generalization performance of LTSVR. Through the experimental results, it is observed that significant amount of imperceptibility and robustness is achieved using low frequency (LF) DCT coefficients as compared to middle frequency (MF) and high frequency (HF) DCT coefficients as well as state-of-art technique.","","CD-ROM:978-1-4673-7946-5; Electronic:978-1-4673-7948-9; POD:978-1-4673-7949-6","10.1109/IC3.2015.7346646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346646","Discrete Cosine Transform;Imperceptibility;Lagragian twin support vector regression;Robustness","Discrete cosine transforms;Entropy;Frequency-domain analysis;Machine learning algorithms;Robustness;Support vector machines;Watermarking","discrete cosine transforms;image colour analysis;image watermarking;realistic images;regression analysis;support vector machines","DCT domain;HF DCT coefficient;LF DCT coefficient;LTSVR;Lagrangian twin SVR;Lagrangian twin support vector regression;MF DCT coefficient;UCI repository;fuzzy entropy;generalization performance;gray scale image watermarking;high frequency DCT coefficient;image characteristics;image processing attack;imperceptibility;learning capability;low frequency DCT coefficient;middle frequency DCT coefficient;real world image;regression problem;robustness;synthetic dataset","","1","","18","","","20-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"Opportunities for Moodle data and learning intelligence in Virtual Environments","B. M. Corsatea; S. Walker","School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom","2015 IEEE International Conference on Evolving and Adaptive Intelligent Systems (EAIS)","20160104","2015","","","1","6","Virtual Learning Environments (VLEs) have increased immensely in their popularity worldwide. In the UK, every higher educational institution is using one or more VLEs to assist teaching. Because of the growing number of online interactions with these environments, students are leaving trails of information regarding their online activities. This data is descriptive of students' behavior and has the potential of becoming a goldmine of educational data.","","Electronic:978-1-4673-6698-4; POD:978-1-4673-6699-1; USB:978-1-4673-6697-7","10.1109/EAIS.2015.7368776","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368776","Moodle;VLE;clustering;learning intelligence;student performance","Clustering algorithms;Computer science;Data mining;Databases;Electronic learning;Machine learning algorithms","computer aided instruction;data mining;educational institutions;further education;learning (artificial intelligence);teaching","Moodle data;School of Computer Science and Electronic Engineering;UK;University of Essex;VLE;e-learning data mining process;educational data;higher educational institution;information exchange;information sharing;learning intelligence;machine learning algorithms;online activities;online interactions;student behavior;teaching;virtual learning environments","","","","15","","","1-3 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Word Sense Disambiguation Technique for Sinhala","J. Arukgoda; V. Bandara; S. Bashani; V. Gamage; D. Wimalasuriya","Dept. of Comput. Sci. & Eng., Univ. of Moratuwa, Moratuwa, Sri Lanka","2014 4th International Conference on Artificial Intelligence with Applications in Engineering and Technology","20151210","2014","","","207","211","Word sense disambiguation is the task of identifying the implied sense of a polysemous word in a given context. There have been many efforts on word sense disambiguation for English, but the amount of efforts for Sinhala is very little. This paper presents ongoing efforts on developing a rule based word sense disambiguation algorithm using the Sinhala WordNet developed at University of Moratuwa as a basis. This is the first attempt on building such an algorithm for Sinhala. For this task we have implemented the Simplified Lesk algorithm with our own modifications under the two assumptions 'one sense per collocation' and 'one sense per discourse'. We define a window size around the target polysemous word and calculate the number of words in that window that overlap with each sense of the target polysemous word. Since there has not been many significant initiatives on natural language processing applications for Sinhala, critical resources such as functioning morphological analysis tools are not available, making accurate word sense disambiguation an even harder task. Using web articles as the data source, this system has attempted to disambiguate 10 instances of polysemous words and has been evaluated to achieve a precision of 63% and an F score 0.63.","","CD-ROM:978-1-4799-7909-7; Electronic:978-1-4799-7910-3; POD:978-1-4799-7911-0","10.1109/ICAIET.2014.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351836","Lesk; Sinhala; word sense disambiguation; WordNet","Computational linguistics;Computers;Context;Knowledge based systems;Machine learning algorithms;Natural language processing;Semantics","Internet;knowledge based systems;natural language processing;word processing","English;Sinhala WordNet;University of Moratuwa;Web articles;data source;functioning morphological analysis tools;natural language processing applications;one sense per collocation;one sense per discourse;polysemous word sense;rule based word sense disambiguation algorithm;simplified Lesk algorithm;window size","","","","14","","","3-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Clustering-based revision debug in regression verification","D. Maksimovic; A. Veneris; Z. Poulos","Department of Electrical and Computer Engineering, University of Toronto, Toronto, Ontario, Canada","2015 33rd IEEE International Conference on Computer Design (ICCD)","20151217","2015","","","32","37","Modern digital systems are growing in size and complexity, introducing significant organizational and verification challenges in the design cycle. Verification today takes as much as 70% of the design time with debugging being responsible for half of this effort. Automation has mitigated part of the resource-intensive nature of rectifying erroneous designs. Nevertheless, most tools target failures in isolation. Since regression verification can discover myriads of failures in one run, automation is also required to guide an engineer to rank them and expedite debugging. To address this growing regression pain, this paper presents a framework that utilizes traditional machine learning techniques along with historical data in version control systems and the results of functional debugging. Its aim is to rank revisions based on their likelihood of being responsible for a particular failure. Ranking prioritizes revisions that ought to be targeted first, and therefore it speeds-up the localization of the error source. This effectively reduces the number of debug iterations. Experiments on industrial designs demonstrate a 68% improvement in the ranking of actual erroneous revisions versus the ranking obtained through existing industrial methodologies. This benefit arrives with negligible run-time overhead.","","Electronic:978-1-4673-7166-7; POD:978-1-4673-7167-4","10.1109/ICCD.2015.7357081","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7357081","","Algorithm design and analysis;Clustering algorithms;Control systems;Debugging;Force;Hardware design languages;Machine learning algorithms","configuration management;learning (artificial intelligence);pattern clustering;program debugging;program verification","clustering-based revision debugging;debug iterations;erroneous revisions;error source localization;functional debugging;machine learning techniques;modern digital systems;regression verification;revision ranking;version control systems","","1","","11","","","18-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Deep kinship verification","M. Wang; Zechao Li; Xiangbo Shu; Jingdong; J. Tang","School of Computer Science and Engineering, Nanjing University of Science and Technology, China","2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)","20151203","2015","","","1","6","To improve the performance of kinship verification, we propose a novel deep kinship verification (DKV) model by integrating excellent deep learning architecture into metric learning. Unlike most existing shallow models based on metric learning for kinship verification, we employ a deep learning model followed by a metric learning formulation to select nonlinear features, which can find the appropriate project space to ensure the margin of negative sample pairs (i.e. parent and child without kinship relation) as large as possible and the margin of positive sample pairs (i.e. parent and child with kinship relation) as small as possible. Experimental results show that our method achieves satisfactory performance on two widely-used benchmarks, i.e. KFW-I and KFW-II.","","Electronic:978-1-4673-7478-1; POD:978-1-4673-7479-8","10.1109/MMSP.2015.7340820","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7340820","","Decoding;Face;Feature extraction;Image color analysis;Machine learning;Measurement;Training","computer vision;learning (artificial intelligence)","DKV model;computer vision;deep kinship verification;deep learning architecture;metric learning","","","","31","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Improving deep convolutional neural networks with unsupervised feature learning","K. Nguyen; C. Fookes; S. Sridharan","Image and Video lab, SAIVT Research Program, Queensland University of Technology, Brisbane, Australia","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","2270","2274","The latest generation of Deep Convolutional Neural Networks (DCNN) have dramatically advanced challenging computer vision tasks, especially in object detection and object classification, achieving state-of-the-art performance in several computer vision tasks including text recognition, sign recognition, face recognition and scene understanding. The depth of these supervised networks has enabled learning deeper and hierarchical representation of features. In parallel, unsupervised deep learning such as Convolutional Deep Belief Network (CDBN) has also achieved state-of-the-art in many computer vision tasks. However, there is very limited research on jointly exploiting the strength of these two approaches. In this paper, we investigate the learning capability of both methods. We compare the output of individual layers and show that many learnt filters and outputs of the corresponding level layer are almost similar for both approaches. Stacking the DCNN on top of unsupervised layers or replacing layers in the DCNN with the corresponding learnt layers in the CDBN can improve the recognition/classification accuracy and training computational expense. We demonstrate the validity of the proposal on ImageNet dataset.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351206","Convolutional Neural Network;Deep Convolutional Belief Network;Deep learning;Supervised deep learning;Unsupervised deep learning","Computer architecture;Convolutional codes;Machine learning;Neural networks;Supervised learning;Training;Unsupervised learning","computer vision;feature extraction;image classification;image representation;learning (artificial intelligence);neural nets;object detection","DCNN;ImageNet dataset;computer vision;deep convolutional neural network;face recognition;hierarchical feature representation;object classification;object detection;scene understanding;sign recognition;text recognition;unsupervised feature learning","","","","21","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Image classification using RBM to encode local descriptors with group sparse learning","J. Wang; W. Wang; R. Wang; W. Gao","School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","912","916","This paper proposes to employ deep learning model to encode local descriptors for image classification. Previous works using deep architectures to obtain higher representations are often operated from pixel level, which lack the power to be generalized to large-size and complex images due to computational burdens and internal essence capture. Our method slips the leash of this limitation by starting from local descriptors to leverage more semantical inputs. We investigate to use two layers of Restricted Boltzmann Machines (RBMs) to encode different local descriptors with a novel group sparse learning (GSL) inspired by the recent success of sparse coding. Besides, unlike the most existing pure unsupervised feature coding strategies, we use another RBM corresponding to semantic labels to perform supervised fine-tuning which makes our model more suitable for classification task. Experimental results on Caltech-256 and Indoor-67 datasets demonstrate the effectiveness of our method.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7350932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350932","Feature Coding;Group Sparse Learning (GSL);Image Classification;Restricted Boltzmann Machine (RBM)","Computational modeling;Computer architecture;Encoding;Machine learning;Training;Training data;Visualization","Boltzmann machines;image classification;image coding;learning (artificial intelligence)","Caltech-256 datasets;GSL;Indoor-67 datasets;RBMs;classification task;deep learning model;group sparse learning;image classification;local descriptor encoding;local descriptors;restricted Boltzmann machines;semantic labels;sparse coding;supervised fine-tuning","","1","","34","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Using fuzzy undersampling and fuzzy PCA to improve imbalanced classification through Rotation Forest algorithm","M. Hosseinzadeh; M. Eftekhari","Department of Computer Engineering, Shahid Bahonar University of Kerman, Iran","2015 International Symposium on Computer Science and Software Engineering (CSSE)","20160104","2015","","","1","7","This paper proposed a novel undersampling method to reduce the imbalance ratio of a dataset using fuzzy memberships degrees as well as utilizing a new fuzzy principal components analysis (F-PCA) for the classification through Rotation Forest algorithm. In the undersampling phase, first two membership functions are defined on each feature (dimension); one indicates the minority concept and the other shows majority concept. After that, each data sample receives a score based on its membership degrees in each dimension of the feature space. Majority samples with the highest scores are the best candidates of removal. Then during the Rotation Forest algorithm's train phase, a fuzzy Principal Component Analysis (F-PCA) is applied on the fuzzified values of samples which are produced in the undersampling phase. Moreover, these values are used to build the base classifiers of the ensemble. The obtained results illustrate the efficiency and noteworthy high performance of our proposed method comparing to the other state-of-the-art algorithms for class imbalance problem.","","Electronic:978-1-4673-9181-8; POD:978-1-4673-9182-5","10.1109/CSICSSE.2015.7369242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7369242","Imbalanced Classification;otation Forest Algorithm;uzzy PCA;uzzy Undersampling","Algorithm design and analysis;Fuzzy logic;Machine learning algorithms;Principal component analysis;Radio frequency;Standards;Training","fuzzy set theory;pattern classification;principal component analysis;sampling methods","F-PCA;class imbalance problem;fuzzy PCA;fuzzy memberships degrees;fuzzy undersampling;imbalanced classification;membership function;principal components analysis;rotation forest algorithm","","","","19","","","18-19 Aug. 2015","","IEEE","IEEE Conference Publications"
"Learning classifiers from remote RDF data stores augmented with RDFS subclass hierarchies","H. T. Lin; N. Bui; V. Honavar","Department of Computer Science, Iowa State University, Ames, IA 50011, USA","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1807","1813","Rapid growth of RDF data in the Linked Open Data (LOD) cloud offers unprecedented opportunities for analyzing such data using machine learning algorithms. The massive size and distributed nature of LOD cloud present a challenging machine learning problem where the data can only be accessed remotely, i.e. through a query interface such as the SPARQL end-point of the data store. Existing approaches to learning classifiers from RDF data in such a setting fail to take advantage of RDF schema (RDFS) associated with the data store that asserts subclass hierarchies which provide information that can potentially be exploited by the learner. Against this background, we present a general approach that augments an existing directed graphical model with hidden variables that encode subclass hierarchies via probabilistic constraints. We also present an algorithm ProbAVT that adopts the variational Bayesian expectation maximization approach to efficiently learn parameters in such settings. Our experiments with several synthetic and real world datasets show that: (i) ProbAVT matches or outperforms its counterpart that does not incorporate background knowledge in the form of subclass hierarchies; (ii) ProbAVT remains competitive compared to other state-of-art models that incorporate subclass hierarchies, and is able to scale up to large hierarchies consisting of over tens of thousands of nodes.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363953","","Bayes methods;Big data;Data models;Graphical models;Machine learning algorithms;Predictive models;Resource description framework","Bayes methods;cloud computing;expectation-maximisation algorithm;learning (artificial intelligence);pattern classification;query processing","LOD cloud;ProbAVT;RDFS subclass hierarchies;SPARQL;directed graphical model;learning classifiers;linked open data;machine learning algorithms;query interface;remote RDF data;variational Bayesian expectation maximization","","","","30","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"To Combat Multi-Class Imbalanced Problems by Means of Over-Sampling Techniques","L. Abdi; S. Hashemi","Department of Computer Science and Engineering, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran","IEEE Transactions on Knowledge and Data Engineering","20151204","2016","28","1","238","251","Class imbalance problem is quite pervasive in our nowadays human practice. This problem basically refers to the skewness in the data underlying distribution which, in turn, imposes many difficulties on typical machine learning algorithms. To deal with the emerging issues arising from multi-class skewed distributions, existing efforts are mainly divided into two categories: model-oriented solutions and data-oriented techniques. Focusing on the latter, this paper presents a new over-sampling technique which is inspired by Mahalanobis distance. The presented over-sampling technique, called MDO (Mahalanobis Distance-based Over-sampling technique), generates synthetic samples which have the same Mahalanobis distance from the considered class mean as other minority class examples. By preserving the covariance structure of the minority class instances and intelligently generating synthetic samples along the probability contours, new minority class instances are modelled better for learning algorithms. Moreover, MDO can reduce the risk of overlapping between different class regions which are considered as a serious challenge in multi-class problems. Our theoretical analyses and empirical observations across wide spectrum multi-class imbalanced benchmarks indicate that MDO is the method of choice by offering statistical superior MAUC and precision compared to the popular over-sampling techniques.","1041-4347;10414347","","10.1109/TKDE.2015.2458858","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163639","Mahalanobis distance;Multi-class imbalance problems;over-sampling techniques","Accuracy;Algorithm design and analysis;Benchmark testing;Eigenvalues and eigenfunctions;Machine learning algorithms;Mathematical model;Training","covariance analysis;learning (artificial intelligence);modelling;pattern classification;sampling methods;statistical distributions","MDO;Mahalanobis distance-based oversampling technique;covariance structure;data skewness;data-oriented technique;machine learning algorithm;minority class instance modelling;model-oriented solution;multiclass imbalanced problem;probability contour","","3","","57","","20150721","Jan. 1 2016","","IEEE","IEEE Journals & Magazines"
"Feature Ranking Based on Information Gain for Large Classification Problems with MapReduce","E. Zdravevski; P. Lameski; A. Kulakov; B. Jakimovski; S. Filiposka; D. Trajanov","Fac. of Comput. Sci. & Eng., Ss.Cyril & Methodius Univ., Skopje, Macedonia","2015 IEEE Trustcom/BigDataSE/ISPA","20151203","2015","2","","186","191","In classification problems the large number of features can pose a significant challenge from many aspects. This is particularly the case in the context of Big Data. In order to address this issue we propose a distributed and parallel computation of information gain based on MapReduce. The proposed implementation on Hadoop can be used for ranking features of large datasets and furthermore for feature selection. The data-parallelism is achieved by uniformly distributing it using HBase tables with proper row keys. Performance evaluations are made by estimation of the speed-up of multi-node clusters against a one-node cluster. The framework was deployed on a on-premises Hadoop cluster. The results show that by parallelization and distribution of the computations on a cluster significant speedup can be achieved. The main contribution of this paper is that we have demonstrated how the higher level scripting language Pig Latin can be used for writing MapReduce jobs instead of directly writing a separate map and reduce function. Additionally, we have proposed the use of manually pre-splitted HBase tables instead of HDFS files for data fragmentation in order to set the degree of parallelism on a higher level.","","Electronic:978-1-4673-7952-6; POD:978-1-4673-7953-3","10.1109/Trustcom.2015.580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345493","HBase;Hadoop;MapReduce;feature ranking;information gain;parallelization","Context;Entropy;Machine learning algorithms;Mathematical model;Measurement;Servers;Writing","Big Data;feature selection;parallel processing;pattern classification;pattern clustering","Big Data;HBase tables;HDFS files;Hadoop cluster;MapReduce jobs;Pig Latin;classification problems;data fragmentation;data-parallelism;distributed computation;feature ranking;feature selection;higher level scripting language;information gain;large datasets;multinode clusters;one-node cluster;parallel computation;parallelization","","2","","31","","","20-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"A Map-Reduce Method for Training Autoencoders on Xeon Phi","Q. Yao; X. Liao; H. Jin","Services Comput. Technol. & Syst. Lab., Huazhong Univ. of Sci. & Technol., Wuhan, China","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","1330","1337","The stacked autoencoder is a deep learning model that consists of multiple autoencoders. This model has been widely applied in numerous machine learning applications. A significant amount of effort has been made to increase the size of the deep learning model with respect to the size of the training dataset and the parameter of the model to improve performance. However, training a large deep learning model is highly time consuming. Recent studies have applied the CPU cluster with thousands of machines as well as the single GPU or the GPU cluster, to train large scale deep learning models. As a high-performance coprocessor like GPU, the Xeon Phi can be an alternative tool for training large scale deep learning models on a single machine. The Xeon Phi can be recognized as a small cluster which features about 60 cores, and each core supports four hardware threads. Massive parallelism offsets the low computing capacity of every core, but challenges an efficient parallel autoencoders design. In this paper, we analyze the training algorithm of autoen-coders based on the matrix operation and point out the thread oversubscription problem, which results in performance degradation. Based on the observation, we propose our map-reduce implementation of autoencoders on the Xeon Phi coprocessor. Our basic idea is to parallelize multiple autoencoder model replicas with bulk synchronous parallel (BSP) communication model where the parameters are updated after the computations of all replicas are completed. Each thread is responsible for one model replica, and all replicas work together on the same mini-batch. This data parallelism method is suitable for training autoencoders on the Xeon Phi, and can extend to asynchronous parallel training method without thread oversubscription. In our experiment the speedup is four times higher than that of sequential implementation. Enlarging the size of the autoencoder model, our method still gets stable speedup.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363241","Autoencoder;BSP;Deep Learning;Map-reduce;Xeon Phi","Computational modeling;Coprocessors;Graphics processing units;Instruction sets;Machine learning;Parallel processing;Training","coprocessors;data handling;learning (artificial intelligence);matrix algebra;parallel processing;pattern clustering","BSP communication model;CPU cluster;GPU cluster;Mapreduce method;Xeon Phi coprocessor;asynchronous parallel training method;autoencoder MapReduce implementation;autoencoder training;bulk synchronous parallel communication model;data parallelism method;hardware threads;high-performance coprocessor;large scale deep learning models;machine learning applications;matrix operation;stacked autoencoder;thread oversubscription;thread oversubscription problem","","","","24","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Using Word2Vec to process big text data","L. Ma; Y. Zhang","Computer Science Department, Georgia State University, Atlanta, Georgia","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2895","2897","Big data is a broad data set that has been used in many fields. To process huge data set is a time consuming work, not only due to its big volume of data size, but also because data type and structure can be different and complex. Currently, many data mining and machine learning technique are being applied to deal with big data problem; some of them can construct a good learning algorithm in terms of lots of training example. However, considering the data dimension, it will be more efficient if learning algorithm is capable of selecting useful features or decreasing the feature dimension. Word2Vec, proposed and supported by Google, is not an individual algorithm, but it consists of two learning models, Continuous Bag of Words (CBOW) and Skip-gram. By feeding text data into one of learning models, Word2Vec outputs word vectors that can be represented as a large piece of text or even the entire article. In our work, we first training the data via Word2Vec model and evaluated the word similarity. In addition, we clustering the similar words together and use the generated clusters to fit into a new data dimension so that the data dimension is decreased.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364114","Word2Vec;big data;clustering;feature reduction","Algorithm design and analysis;Big data;Clustering algorithms;Data models;Machine learning algorithms;Training;Training data","Big Data;data mining;learning (artificial intelligence);text analysis","CBOW;Word2Vec model;big text data processing;continuous bag-of-words;data dimension;data mining;data structure;data type;machine learning technique;skip-gram","","","","12","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"A parallel cross-language retrieval system for patent documents","X. Shen; H. Huang; L. Li; Y. Huang","Beijing Engineering Research Center of High Volume Language Information Processing & Cloud Computing Application, Beijing Institute of Technology, Beijing, 100081 China","2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20151130","2015","","","672","676","In order to help people obtain useful information from patent documents in different languages. This paper proposes a cross-language retrieval system to search Chinese and English patent documents simultaneously. This system consists of query translation module, document retrieval module and user interaction module. Query translation module is used to translate query based on bilingual dictionaries. Document retrieval module consists of monolingual retrieval system using standard vector space model. In order to retrieve in highly parallel, we use the MapReduce model to calculate the similarity. User interaction module provides users with interactive mechanism used to improve the retrieval accuracy in the system. It contains two parts: the second translation and relevance feedback. The experimental results show that our system has good performance.","2327-0586;23270586","CD-ROM:978-1-4799-8351-3; Electronic:978-1-4799-8353-7; POD:978-1-4799-8354-4","10.1109/ICSESS.2015.7339147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339147","Hadoop;Patent document;cross-language information retrieval;parallel retrieval","Accuracy;Context;Data processing;Dictionaries;Machine learning algorithms;Patents","dictionaries;natural language processing;parallel processing;patents;query processing;relevance feedback","Chinese patent documents;English patent documents;MapReduce model;bilingual dictionaries;document retrieval module;interactive mechanism;monolingual retrieval system;parallel cross-language retrieval system;patent documents;query translation;query translation module;relevance feedback;user interaction module;vector space model","","","","12","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Sensor event mining with hybrid ensemble learning and evolutionary feature subset selection model","N. Mehdiyev; J. Krumeich; D. Werth; P. Loos","Institute for Information System (IWi) German Research Center for Artificial Intelligence (DFKI) Saarbr&#252;cken, Germany","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","2159","2168","Recent advancements in sensor technology offer opportunities to manage business processes in a proactive manner. To enable an effective and real-time monitoring, sensor data have to be treated and processed in an event processing manner. Complex Event Processing is an efficient technology that detects useful complex events by matching primitive sensor events using event patterns. Event patterns can be represented as templates that combine primitive events by temporal, logical, spatial and sequential correlations to detect more complex events. Identifying event patterns out of streaming data with a high data volume and velocity is a challenging task. In this paper, we propose an Ensemble Model consisting of a crisp and fuzzy rule based classifiers in order to derive decision rules as event patterns. Before implementing the ensemble classifier directly to the streaming data, we select the most influential feature subset using a multi-objective evolutionary algorithm. The performance of the proposed model was evaluated using real data obtained from accelerometer sensors. Promising results with high accuracy and appropriate level of computational complexity were obtained and discussed.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7364001","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364001","complex event processing;ensemble learning;feature subset selection;multi-objective evolutionary algorithm;rule induction","Classification algorithms;Data mining;Evolutionary computation;Filtering algorithms;Genetic algorithms;Machine learning algorithms;Optimization","data mining;evolutionary computation;feature selection;learning (artificial intelligence);pattern classification","accelerometer sensors;business process management;complex event processing;evolutionary feature subset selection model;fuzzy rule based classifier;hybrid ensemble learning;logical correlation;multiobjective evolutionary algorithm;sensor event mining;sequential correlation;spatial correlation;temporal correlation","","1","","42","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Exact Recovery in the Stochastic Block Model","E. Abbe; A. S. Bandeira; G. Hall","Department of Electrical EngineeringProgram in Applied and Computational Mathematics, Princeton University, Princeton, NJ, USA","IEEE Transactions on Information Theory","20151218","2016","62","1","471","487","The stochastic block model with two communities, or equivalently the planted bisection model, is a popular model of random graph exhibiting a cluster behavior. In the symmetric case, the graph has two equally sized clusters and vertices connect with probability p within clusters and q across clusters. In the past two decades, a large body of literature in statistics and computer science has focused on providing lower bounds on the scaling of | p - q| to ensure exact recovery. In this paper, we identify a sharp threshold phenomenon for exact recovery: if α = pn/log(n) and β = qn/ log(n) are constant (with α > β), recovering the communities with high probability is possible if (α + β/2) - √(αβ) > 1 and is impossible if (α + β/2) - √(αβ) <; 1. In particular, this improves the existing bounds. This also sets a new line of sight for efficient clustering algorithms. While maximum likelihood (ML) achieves the optimal threshold (by definition), it is in the worst case NP-hard. This paper proposes an efficient algorithm based on a semidefinite programming relaxation of ML, which is proved to succeed in recovering the communities close to the threshold, while numerical experiments suggest that it may achieve the threshold. An efficient algorithm that succeeds all the way down to the threshold is also obtained using a partial recovery algorithm combined with a local improvement procedure.","0018-9448;00189448","","10.1109/TIT.2015.2490670","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298436","Communities;clustering algorithms;detection algorithms;network theory (graphs);statistical learning","Clustering algorithms;Computational modeling;Computer science;Machine learning algorithms;Maximum likelihood decoding;Maximum likelihood estimation;Stochastic processes","mathematical programming;maximum likelihood estimation;network theory (graphs);probability","clustering algorithm;computer science;maximum likelihood;partial recovery algorithm;probability;semidefinite programming relaxation;stochastic block model","","14","","40","","20151014","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Tendencies towards DEEP or SURFACE learning for participants taking a large massive open online course (MOOC)","A. Kemppainen; J. Sticklen; B. Oakley; D. Chung","Department of Engineering Fundamentals, Michigan Technological University, Houghton, MI USA","2015 IEEE Frontiers in Education Conference (FIE)","20151207","2015","","","1","4","In this report we will describe our first steps in understanding the characteristics of individuals enrolling and completing MOOCs. The learner characteristic we focus on is the deep versus shallow learning dimension. We will use the revised two-factor study process questionnaire of Biggs in our study [1]. To our knowledge, there is no comparable research either reported in the literature or currently under way. Our focus is on Learning How to Learn (LHTL), currently the most heavily subscribed course on the Coursera platform. The last offering of LHTL, completed in January, 2015, attracted just under a quarter million learners. In the fourth and final week of the course, the R-SPQ-2F survey instrument was made available to all students on the LHTL site. Approximately 1,600 students completed the survey. We believe our research to be of interest widely because of the confluence in our research of (a) MOOCs, (b) the deep versus surface learning dimension, and (c) a methodology that can lead to better understanding of MOOCs.","","Paper:978-1-4799-8454-1","10.1109/FIE.2015.7344144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344144","MOOC;deep learning;online learning;surface learning","Correlation;Instruments;Machine learning;Planning;Sociology;Videos","computer aided instruction;educational courses","Coursera platform;DEEP learning;LHTL site;MOOC;R-SPQ-2F survey instrument;SURFACE learning;learner characteristic;learning how to learn;massive open online course;surface learning dimension","","1","","7","","","21-24 Oct. 2015","","IEEE","IEEE Conference Publications"
"Bridge deep learning to the physical world: An efficient method to quantize network","P. H. Hung; C. H. Lee; S. W. Yang; V. S. Somayazulu; Y. K. Chen; S. Y. Chien","Media IC and System Lab, Graduate Institute of Electronics Engineering and Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan","2015 IEEE Workshop on Signal Processing Systems (SiPS)","20151203","2015","","","1","6","As better performance is achieved by deep convolutional network with more and more layers, the increasing number of weighting and bias parameters makes it only possible to be implemented on servers in cyber space but infeasible to be deployed in physical-world embedded systems because of huge storage and memory bandwidth requirements. In this paper, we proposed an efficient method to quantize the model parameters. Instead of taking the quantization process as a negative effect on precision, we regarded it as a regularize problem to prevent overfitting, and a two-stage quantization technique including soft- and hard-quantization is developed. With the help of our quantization method, not only 93.75% of the parameter memory size can be reduced by replacing the word length from 32-bit to 2-bit, but the testing accuracy after quantization is also better than previous approaches in some dataset, and the additional training overhead is only 3% of the ordinary one.","","Electronic:978-1-4673-9604-2; POD:978-1-4673-9605-9; USB:978-1-4673-9603-5","10.1109/SiPS.2015.7345005","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345005","Convolutional Network;Deep Learning;Deep Neural Network;Quantize;Regularize","Computational modeling;Graphics processing units;Machine learning;Memory management;Neural networks;Quantization (signal);Training","convolution;embedded systems;image classification;learning (artificial intelligence);quantisation (signal)","deep convolutional network;deep learning;image classification;network quantization;physical world embedded system","","1","","27","","","14-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"Deep feature synthesis: Towards automating data science endeavors","J. M. Kanter; K. Veeramachaneni","CSAIL, MIT, Cambridge, MA - 02139","2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","20151207","2015","","","1","10","In this paper, we develop the Data Science Machine, which is able to derive predictive models from raw data automatically. To achieve this automation, we first propose and develop the Deep Feature Synthesis algorithm for automatically generating features for relational datasets. The algorithm follows relationships in the data to a base field, and then sequentially applies mathematical functions along that path to create the final feature. Second, we implement a generalizable machine learning pipeline and tune it using a novel Gaussian Copula process based approach. We entered the Data Science Machine in 3 data science competitions that featured 906 other data science teams. Our approach beats 615 teams in these data science competitions. In 2 of the 3 competitions we beat a majority of competitors, and in the third, we achieved 94% of the best competitor's score. In the best case, with an ongoing competition, we beat 85.6% of the teams and achieved 95.7% of the top submissions score.","","Electronic:978-1-4673-8273-1; POD:978-1-4673-8274-8","10.1109/DSAA.2015.7344858","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344858","","Algorithm design and analysis;Data mining;Data models;Feature extraction;Machine learning algorithms;Prediction algorithms;Predictive models","Gaussian processes;data analysis;learning (artificial intelligence)","Gaussian copula process;data science endeavor automation;data science machine;deep feature synthesis;feature generation;generalizable machine learning pipeline;mathematical functions;relational datasets","","3","","17","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Hyperspectral classification via learnt features","Y. Liu; G. Cao; Q. Sun; M. Siegel","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","2591","2595","This paper presents a new hyperspectral image (HSI) classification method which is capable of automatic feature learning while achieving high classification accuracy. The method contains two major modules: the spectral classification module and the spatial constraint module. Spectral classification module uses a deep network named stacked denoising autoencoders (SdA) to learn feature representation of the data. Through SdA, the data are projected nonlinearly from its original hyperspectral space to some higher dimensional space where more compact distribution is obtained. An interesting aspect of this method is that it does not need a feature design/extraction process guided by human prior. The suitable feature for the classification is learned by the deep network itself. Superpixel is utilized to generate the spatial constraints to refine the spectral classification results. By exploiting the spatial consistency of neighborhood pixels, the accuracy of classification is further improved by a big margin. Experiments on the public datasets reveal the superior performance of the proposed method.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351271","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351271","Deep learning;hyperspectral image classification;remote sensing;stacked denoising autoencoders (SdA);superpixel","Hyperspectral imaging;Image segmentation;Machine learning;Noise reduction;Spatial resolution;Training","feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence)","HSI classification method;SdA;automatic feature learning;deep network;higher dimensional space;hyperspectral image classification method;hyperspectral space;neighborhood pixel spatial consistency;spatial constraint module;spectral classification module;stacked denoising autoencoder;superpixel","","","","21","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Face Recognition Despite Wearing Glasses","A. Liang; C. S. N. Pathirage; C. Wang; W. Liu; L. Li; J. Duan","Dept. of Comput., Curtin Univ., Perth, WA, Australia","2015 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20160107","2015","","","1","8","In this paper we address the challenge of performing face recognition on human faces that are wearing glasses. This is a common problem for face recognition and automatic identity checking at airports, as passengers frequently forget to remove their glasses when passing through customs. In order to solve this problem, we first propose an automatic glasses presence detection model based on the tree-pictorial-structured face detection model and such model can detect the presence of glasses and further assign landmarks on the rim, hinge, and bridge of the glasses on frontal faces. Experimental results show that the glasses detection rate is highly satisfactory for various face databases. Secondly, based on the landmarks on glasses, we apply the non-local colour total variation (CTV) inpainting approach in an attempt to remove the glasses; also, we apply the deep learning technique to further remove the traces of glasses and light reflection on lenses by regarding them as noises. Finally, experiments for face recognition after glasses removal are conducted by using some typical approaches and the results show that our glasses removal framework can improve face recognition accuracy significantly.","","Electronic:978-1-4673-6795-0; POD:978-1-4673-6796-7","10.1109/DICTA.2015.7371260","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371260","","Databases;Face;Face recognition;Glass;Machine learning;Shape;Training","face recognition;feature extraction;image colour analysis;image restoration;iterative methods;optimisation;trees (mathematics)","CTV inpainting approach;automatic glass presence detection model;automatic identity checking;colour total variation;face recognition;iterative optimization;tree-pictorial-structured face detection model","","","","35","","","23-25 Nov. 2015","","IEEE","IEEE Conference Publications"
"Sentiment Analysis Using Convolutional Neural Network","X. Ouyang; P. Zhou; C. H. Li; L. Liu","Sch. of Electron. Inf. & Commun., Huazhong Univ. of Sci. & Technol., Wuhan, China","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","2359","2364","Sentiment analysis of text content is important for many natural language processing tasks. Especially, as the development of the social media, there is a big need in dig meaningful information from the big data on Internet through the sentiment analysis. Inspired by the successes of deep learning, we are interested in handling the sentiment analysis task using deep learning models. In this paper, we propose a framework called Word2vec + Convolutional Neural Network (CNN). Firstly, we use the word2vec proposed by Google to compute vector representations of words, which will be the input for the CNN. The purpose of using word2vec is to gain the vector representation of word and reflect the distance of words. That will lead to initialize the parameters at a good point of CNN, which can efficiently improve the performance of the nets in this problem. Secondly, we design a suitable CNN architecture for the sentiment analysis task. We use 3 pairs of convolutional layers and pooling layers in this architecture. To the best of our knowledge, this is the first time that a 7-layers architecture model is applied using word2vec and CNN to analyze sentences' sentiment. We also use the Parametric Rectified Linear Unit (PReLU), Normalization and Dropout technology to improve the accuracy and generalizability of our model. We test our framework in a public dataset which is the corpus of movie review excerpts that includes fives labels: negative, somewhat negative, neural, somewhat positive and positive. Our network achieves test accuracy of 45.4% in this dataset, which is a better performance than some other neural network model like Recursive Neural Network (RNN) and Matrix-Vector Recursive Neural Network (MV-RNN).","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.349","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363395","deep learning;sentiment analysis;word2vec","Analytical models;Computational modeling;Google;Machine learning;Media;Neural networks;Sentiment analysis","learning (artificial intelligence);neural net architecture;sentiment analysis","7-layers architecture model;Big Data;CNN architecture;Internet;MV-RNN;PReLU;RNN;Word2vec framework;convolutional layers;convolutional neural network;deep learning models;matrix-vector recursive neural network;natural language processing tasks;normalization and dropout technology;parametric rectified linear unit;pooling layers;recursive neural network;sentence sentiment analysis;social media;text content sentiment analysis;word vector representation","","","","21","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Learning from depth sensor data using inductive logic programming","M. Drole; P. Vračar; A. Panjkota; I. Stančić; J. Music; I. Kononenko; M. Kukar","Faculty of Computer and Information Science, University of Ljubljana, Ve&#269;na pot 113, Ljubljana, Slovenia","2015 XXV International Conference on Information, Communication and Automation Technologies (ICAT)","20151203","2015","","","1","6","The problem of detecting objects and their movements in sensor data is of crucial importance in providing safe navigation through both indoor and outdoor environments for the visually impaired. In our setting we use depth-sensor data obtained from a simulator and use inductive logic programming (ILP), a subfield of machine learning that deals with learning concept descriptions, to learn how to detect borders, find the border that is nearest to some point of interest, and border correspondence through time. We demonstrate how ILP can be used to tackle this problem in an incremental manner by using previously learned predicates to construct more complex ones. The learned concept descriptions show high (> 90%) accuracy and their natural language interpretation closely matches an intuitive understanding of their meaning.","","CD-ROM:978-1-4673-8145-1; Electronic:978-1-4673-8146-8; POD:978-1-4673-8147-5","10.1109/ICAT.2015.7340498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7340498","assistive devices;context awareness;knowlegde discovery;supervised learning","Cameras;Global Positioning System;Logic programming;Machine learning algorithms;Robot sensing systems;Safety","computerised instrumentation;inductive logic programming;sensors;spatial variables measurement","depth sensor data;indoor environments;inductive logic programming;machine learning;natural language interpretation;object detection;outdoor environments","","","","31","","","29-31 Oct. 2015","","IEEE","IEEE Conference Publications"
"Achieving ""synergy"" in cognitive behavior of humanoids via deep learning of dynamic visuo-motor-attentional coordination","J. Hwang; M. Jung; N. Madapana; J. Kim; M. Choi; J. Tani","","2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids)","20151228","2015","","","817","824","The current study examines how adequate coordination among different cognitive processes including visual recognition, attention switching, action preparation and generation can be developed via learning of robots by introducing a novel model, the Visuo-Motor Deep Dynamic Neural Network (VMDNN). The proposed model is built on coupling of a dynamic vision network, a motor generation network, and a higher level network allocated on top of these two. The simulation experiments using the iCub simulator were conducted for cognitive tasks including visual object manipulation responding to human gestures. The results showed that ""synergetic"" coordination can be developed via iterative learning through the whole network when spatio-temporal hierarchy and temporal one can be self-organized in the visual pathway and in the motor pathway, respectively, such that the higher level can manipulate them with abstraction.","","Electronic:978-1-4799-6885-5; POD:978-1-4799-6886-2; USB:978-1-4799-6884-8","10.1109/HUMANOIDS.2015.7363448","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363448","","Hidden Markov models;Machine learning;Neural networks;Robot kinematics;Training;Visualization","cognitive systems;control engineering computing;humanoid robots;learning (artificial intelligence);neural nets;object recognition;robot programming;robot vision","VMDNN;action preparation;attention switching;cognitive behavior;dynamic vision network;humanoid robot;iCub simulator;iterative learning;motor generation network;robot learning;synergy;visual object manipulation;visual recognition;visuo-motor deep dynamic neural network","","","","29","","","3-5 Nov. 2015","","IEEE","IEEE Conference Publications"
"A big-data processing framework for uncertainties in transportation data","Jie Yang; Jun Ma","SMART Infrastructure Facility, Faculty of Engineering and Information Sciences, University of Wollongong, Northfields Avenue, New South Wales 2522, Australia","2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20151130","2015","","","1","6","Transportation infrastructure takes a primary role in urban development planning. To better facilitate or understand the infrastructure status and demands, a huge amount of transportation data such as traffic flow counts has been collected from numerous transportation monitoring systems. Making full use of harvested data samples to discover important patterns has become an increasingly appealing research topic, in which a sophisticated and uncertainty-processing framework is required. In this paper, a big-data processing framework is introduced to analyse the transportation data, particularly taking the classification problem of the parking occupation status as an illustrative example. Three modules are implemented to crawl the raw records, generate high-level features, and apply the machine learning algorithm for classification. In addition, the fuzzification algorithm is also introduced to quantify the key attributes of the data, which helps in removing the data redundancy and inconsistency. The proposed framework then is evaluated using a real-world dataset collected from twelve car parks in a university. Simulation results show that the proposed framework performs well with a convincing classification accuracy.","","Electronic:978-1-4673-7428-6; POD:978-1-4673-7429-3","10.1109/FUZZ-IEEE.2015.7337843","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337843","","Biological system modeling;Crawlers;Feature extraction;Machine learning algorithms;Real-time systems;Support vector machines;Transportation","Big Data;fuzzy set theory;intelligent transportation systems;learning (artificial intelligence);pattern classification","big-data processing framework;classification accuracy;classification problem;data inconsistency;data redundancy;fuzzification algorithm;infrastructure status;machine learning algorithm;parking occupation status;traffic flow count;transportation data;transportation infrastructure;transportation monitoring system;uncertainty-processing framework;urban development planning","","","","14","","","2-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Generating Multi-modality Virtual Samples with Soft DBSCAN for Small Data Set Learning","L. S. Lin; D. C. Li; W. H. Yu; Y. M. Hsueh","Dept. of Ind. & Inf. Manage., Nat. Cheng Kung Univ., Tainan, Taiwan","2015 3rd International Conference on Applied Computing and Information Technology/2nd International Conference on Computational Science and Intelligence","20151130","2015","","","363","368","Owing to the factors of cost and time limit, the number of samples is usually small in the early stages of manufacturing systems. When the number of available data is small, traditional statistic techniques have difficulty to obtain robust analyses. Therefore, based on a uni-modality distribution assumption, many researchers have proposed virtual sample generation methods to expand the training sample size to enhance the performance of small data set learning. In practice, small data may be following a multi-modality distribution. Therefore, in order to solve multi-modal small data sets, this study proposes a new approach to create multi-modality Weibull virtual samples, where we use the maximal p-value to estimate parameters of the Weibull distribution. In addition, the soft DBSCAN method is used to identify a suitable number of modalities. One data set is employed to check the performance of the proposed method, and comparisons are made by the prediction on root mean square error. The results using a paired t-test show that the proposed method has a superior prediction performance than that of the mega-trend-diffusion method using a uni-modality triangular membership function.","","Electronic:978-1-4673-9642-4; POD:978-1-4673-9643-1","10.1109/ACIT-CSI.2015.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336089","maximal p-value;multi-modality distribution;small data set;soft DBSCAN","Clustering algorithms;Distributed databases;Machine learning algorithms;Shape;Sociology;Statistics;Weibull distribution","Weibull distribution;data analysis;learning (artificial intelligence);manufacturing systems","manufacturing system;mega-trend-diffusion method;multimodality Weibull virtual sample;multimodality distribution;multimodality virtual sample;paired t-test;robust analysis;root mean square error;small data set learning;soft DBSCAN method;statistic technique;unimodality triangular membership function","","","","12","","","12-16 July 2015","","IEEE","IEEE Conference Publications"
"A Deep Learning Neural Network for Number Cognition: A bi-cultural study with the iCub","A. Di Nuovo; V. M. De La Cruz; A. Cangelosi","Centre for Robotics and Neural Systems, Plymouth University, UK","2015 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)","20151207","2015","","","320","325","The novel deep learning paradigm offers a highly biologically plausible way to train neural network architectures with many layers, inspired by the hierarchical organization of the human brain. Indeed, deep learning gives a new dimension to research modeling human cognitive behaviors, and provides new opportunities for applications in cognitive robotics. In this paper, we present a novel deep neural network architecture for number cognition by means of finger counting and number words. The architecture is composed of 5 layers and is designed in a way that allows it to learn numbers from one to ten by associating the sensory inputs (motor and auditory) coming from the iCub humanoid robotic platform. The architecture performance is validated and tested in two developmental experiments. In the first experiment, standard backpropagation is compared with a deep learning approach, in which weights and biases are pre-trained by means of a greedy algorithm and then refined with backpropagation. In the second experiment, six bi-cultural number learning conditions are compared to explore the impact of different languages (for number words) and finger counting strategies. The developmental experiments confirm the validity of the model and the increase in efficiency given by the deep learning approach. Results of the bi-cultural study are presented and discussed with respect to the neuro-psychological literature and implications of the results for learning situations are briefly outlined.","","Electronic:978-1-4673-9320-1; POD:978-1-4673-9321-8","10.1109/DEVLRN.2015.7346165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346165","Bi-Cultural learning;Cognitive Developmental Robotics;Deep Learning;Embodiment;Number Cognition","Cognition;Computer architecture;Machine learning;Robot sensing systems;Thumb","artificial intelligence;backpropagation;brain;dexterous manipulators;humanoid robots;intelligent robots;neural nets","backpropagation;bi-cultural number learning condition;cognitive robotics;deep learning neural network;human brain;human cognitive behavior;iCub humanoid robotic platform;neural network architecture;number cognition","","1","","26","","","13-16 Aug. 2015","","IEEE","IEEE Conference Publications"
"Audio event recognition based on DBN features from multiple filter-bank representations","Feng Guo; Xiaoou Chen; Deshun Yang","Inst. of Comput. Sci. & Technol., Peking Univ., Beijing, China","2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)","20151203","2015","","","1","6","In the audio event classification or detection research field, the representation of the audio itself is important. Many researchers tried to apply Deep Belief Network (DBN) to learn new representations of the audio. The mel filter-bank feature, which is obtained based on mel scale, is commonly used as the low level representation of the audio in the pre-processing procedure of DBN. However, the mel bands used in mel filter-bank feature may not be sufficient for the comprehensive representation of the diverse audio events in the real world and then it will make it difficult for DBN to learn good audio features. In this paper, two steps are taken to explore and tackle the problem. In the first step, we conduct a comparison of the effects among different arrangements of frequency bands to DBN feature learning in the audio event recognition. Here the arrangements of frequency bands include mel bands, bark bands, linear bands and pyramid bands. In the second step, in order to utilize the different classification capabilities of the DBN features on different audio events, we adopt the Adaboost algorithm to fuse them. We conduct the experiments on real datasets collected from findsound website, and the results verifies that our proposed audio event classification system, which uses diverse features selected by Adaboost from all sets of DBN features, outperforms the one using only one kind of DBN feature set.","","Electronic:978-1-4673-7478-1; POD:978-1-4673-7479-8","10.1109/MMSP.2015.7340807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7340807","","Event detection;Feature extraction;Fuses;Machine learning;Multimedia communication;Streaming media;Training","audio signal processing;belief networks;learning (artificial intelligence);signal classification","Adaboost algorithm;DBN features;audio event classification;audio event classification system;audio event recognition;bark bands;deep belief network;linear bands;mel bands;mel filter-bank feature;multiple filter-bank representations;pyramid bands","","","","","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Mine the fine: Fine-grained fragment discovery","M. H. Kiapour; W. Di; V. Jagadeesh; R. Piramuthu","University of North Carolina at Chapel Hill Chapel Hill, NC, USA","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","3555","3559","While discriminative visual element mining has been introduced before, in this paper we present an approach that requires minimal annotation in both training and test time. Given only a bounding box localization of the foreground objects, our approach automatically transforms the input images into a roughly-aligned pose space and discovers the most discriminative visual fragments for each category. These fragments are then used to learn robust classifiers that discriminate between very similar categories under challenging conditions such as large variations in pose or habitats. The minimal required input, is a critical characteristic that enables our approach to generalize over visual domains where expert knowledge is not readily available. Moreover, our approach takes advantage of deep networks that are targeted towards fine-grained classification. It learns mid-level representations that are specific to a category and generalize well across the category instances at the same time. Our evaluations demonstrate that the automatically learned representation based on discriminative fragments, significantly outperforms globally extracted deep features in classification accuracy.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351466","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351466","Fine-grained;classification;deep learning;mid-level representation","Birds;Feature extraction;Machine learning;Robustness;Training;Visualization;Yttrium","data mining;feature extraction;image classification;image representation;learning (artificial intelligence);neural nets","bounding box localization;classification accuracy;deep networks;discriminative visual element mining;discriminative visual fragments;feature extraction;fine-grained classification;fine-grained fragment discovery;foreground objects;mid-level representations;robust classifiers;roughly-aligned pose space;visual domains","","","","25","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Weakly Semi-Supervised Deep Learning for Multi-Label Image Annotation","F. Wu; Z. Wang; Z. Zhang; Y. Yang; J. Luo; W. Zhu; Y. Zhuang","College of Computer Science, Zhejiang University, Hangzhou, China","IEEE Transactions on Big Data","20151217","2015","1","3","109","122","In this paper, we study leveraging both weakly labeled images and unlabeled images for multi-label image annotation. Motivated by the recent advance in deep learning, we propose an approach called weakly semi-supervised deep learning for multi-label image annotation (WeSed). In WeSed, a novel weakly weighted pairwise ranking loss is effectively utilized to handle weakly labeled images, while a triplet similarity loss is employed to harness unlabeled images. WeSed enables us to train deep convolutional neural network (CNN) with images from social networks where images are either only weakly labeled with several labels or unlabeled. We also design an efficient algorithm to sample high-quality image triplets from large image datasets to fine-tune the CNN. WeSed is evaluated on benchmark datasets for multi-label annotation. The experiments demonstrate the effectiveness of our proposed approach and show that the leverage of the weakly labeled images and unlabeled images leads to a significantly better performance.","2332-7790;23327790","","10.1109/TBDATA.2015.2497270","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7317747","Weakly labeled image;deep learning;ranking loss;unlabeled image","Big data;Machine learning;Neural networks;Semantics;Social network services;Training;Visualization","image retrieval;image sampling;learning (artificial intelligence);neural nets;visual databases","CNN training;WeSed;benchmark datasets;deep-convolutional neural network training;high-quality image triplet sampling;large image datasets;multilabel image annotation;social network images;triplet similarity loss;unlabeled image leveraging;weakly-labeled image leveraging;weakly-semisupervised deep-learning;weakly-weighted pairwise ranking loss","","4","","35","","20151104","Sept. 1 2015","","IEEE","IEEE Journals & Magazines"
"Fuzzy clustering based on α-divergence for spherical data and for categorical multivariate data","Y. Kanzawa","School of Communication Engineering, Shibaura Institute of Technology, Toyosu, Tokyo 135-8548, Japan","2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20151130","2015","","","1","8","This paper presents two clustering algorithms based on α-divergence between memberships and variables that control cluster sizes: one is for spherical data and the other for categorical multivariate data. First, this paper shows that a conventional method for vectorial data can be interpreted as the regularization of another conventional method with α-divergence. Second, with this interpretation, a spherical clustering algorithm based on α-divergence is derived from an optimization problem built by regularizing a conventional method with α-divergence. Third, this paper connects the facts that the α-divergence is a generalization of Kullback-Leibler (KL)-divergence, and that three conventional co-clustering methods are based on KL-divergence. Based on these facts, a co-clustering algorithm based on α-divergence is derived from an optimization problem built by extending the KL-divergence in conventional methods to α-divergence. This paper also demonstrates some numerical examples for the proposed methods.","","Electronic:978-1-4673-7428-6; POD:978-1-4673-7429-3","10.1109/FUZZ-IEEE.2015.7337853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337853","","Atmospheric measurements;Clustering algorithms;Clustering methods;Entropy;Machine learning algorithms;Optimization;Particle measurements","fuzzy set theory;optimisation;pattern clustering;statistical distributions","α-divergence;KL-divergence;Kullback-Leibler divergence;categorical multivariate data;cluster size;fuzzy clustering;optimization problem;spherical data","","","","26","","","2-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Artificial Intelligence for Detecting Preterm Uterine Activity in Gynecology and Obstetric Care","I. O. Idowu; P. Fergus; A. Hussain; C. Dobbins; M. Khalaf; R. V. C. Eslava; R. Keight","Sch. of Comput. & Math. Sci., Liverpool John Moores Univ., Liverpool, UK","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","20151228","2015","","","215","220","Preterm birth brings considerable emotional and economic costs to families and society. However, despite extensive research into understanding the risk factors, the prediction of patient mechanisms and improvements to obstetrical practice, the UK National Health Service still annually spends more than £2.95 billion on this issue. Diagnosis of labour in normal pregnancies is important for minimizing unnecessary hospitalisations, interventions and expenses. Moreover, accurate identification of spontaneous preterm labour would also allow clinicians to start necessary treatments early in women with true labour and avert unnecessary treatment and hospitalisation for women who are simply having preterm contractions, but who are not in true labour. In this research, the Electrohysterography signals have been used to detect preterm births, because Electrohysterography signals provide a strong basis for objective prediction and diagnosis of preterm birth. This has been achieved using an open dataset, which contains 262 records for women who delivered at term and 38 who delivered prematurely. Three different machine learning algorithm were used to identify these records. The results illustrate that the Random Forest performed the best of sensitivity 97%, specificity of 85%, Area under the Receiver Operator curve (AUROC) of 94% and mean square error rate of 14%.","","CD:978-1-5090-0153-8; Electronic:978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363073","AUROC and Features extraction;Classification;Electrohysterography(EHG);Fourier Transform (FT);Leave-one-out Cross-va;Power Spectral Density (PSD);Preterm Delivery;Preterm Labour ( PTL);Random Forest;Rule-Base;Term Delivery;Wavelet Transform (WT)","Classification algorithms;Databases;Feature extraction;Machine learning algorithms;Pediatrics;Pregnancy;Vegetation","data analysis;gynaecology;learning (artificial intelligence);mean square error methods;medical signal processing","AUROC;MSE;UK national health service;area under the receiver operator curve;artificial intelligence;economic costs;electrohysterography signals;emotional costs;gynecology;machine learning algorithm;mean square error rate;objective prediction;obstetric care;obstetrical practice;open dataset;patient mechanisms;preterm birth;preterm contractions;preterm uterine activity detection;random forest;risk factors","","","","36","","","26-28 Oct. 2015","","IEEE","IEEE Conference Publications"
"Selective and compressive sensing for energy-efficient implantable neural decoding","A. Wang; C. Song; X. Xu; F. Lin; Z. Jin; W. Xu","CSE Dept., SUNY at Buffalo, NY, USA","2015 IEEE Biomedical Circuits and Systems Conference (BioCAS)","20151207","2015","","","1","4","The spike classification is a critical step in implantable neural decoding. The energy efficiency issue in the sensor node is a big challenge in the entire system. Compressive sensing (CS) provides a potential way to tackle this problem. However, the overhead of signal reconstruction constrains the compression in sensor node and analysis in remote server. In this paper, we design a new selective CS architecture for wireless implantable neural decoding. We implement all the signal analysis on the compressed domain. To achieve better energy efficiency, we propose a two-stage classification procedure, including a coarse-grained screening module with softmax regression and a fine-grained analysis module based on deep learning. The screening module completes the low-effort classification task in the front-end and transmits the compressed data of high-effort task to remote server for fine-grained analysis. Experimental results indicate that our selective CS architecture can gain more than 50% energy savings, yet keeping the high accuracy as state-of-the-art CS architectures.","","Electronic:978-1-4799-7234-0; POD:978-1-4799-7235-7; USB:978-1-4799-7233-3","10.1109/BioCAS.2015.7348375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7348375","","Compressed sensing;Decoding;Machine learning;Quantization (signal);Servers;Wireless communication;Wireless sensor networks","compressed sensing;electroencephalography;learning (artificial intelligence);medical signal processing;neurophysiology;regression analysis;signal classification;signal reconstruction;wireless sensor networks","classification task;coarse-grained screening module;compressed domain;compressive sensing;deep learning;energy efficiency;energy-efficient implantable neural decoding;fine-grained analysis module;high-effort task;remote server;selective CS architecture;sensor node;signal analysis;signal reconstruction;softmax regression;spike classification;two-stage classification procedure;wireless implantable neural decoding","","","","10","","","22-24 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Parallel Computing Hybrid Approach for Feature Selection","J. Silva; A. Aguiar; F. Silva","Inst. de Telecomun., Univ. of Porto, Porto, Portugal","2015 IEEE 18th International Conference on Computational Science and Engineering","20160107","2015","","","97","104","The ultimate goal of feature selection is to select the smallest subset of features that yields minimum generalization error from an original set of features. This effectively reduces the feature space, and thus the complexity of classifiers. Though several algorithms have been proposed, no single one outperforms all the other in all scenarios, and the problem is still an actively researched field. This paper proposes a new hybrid parallel approach to perform feature selection. The idea is to use a filter metric to reduce feature space, and then use an innovative wrapper method to search extensively for the best solution. The proposed strategy is implemented on a shared memory parallel environment to speedup the process. We evaluated its parallel performance using up to 32 cores and our results show 30 times gain in speed. To test the performance of feature selection we used five datasets from the well known NIPS challenge and were able to obtain an average score of 95.90% for all solutions.","","Electronic:978-1-4673-8297-7; POD:978-1-4673-8298-4","10.1109/CSE.2015.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371361","Feature Selection;Hybrid Approach;Parallel Computing;Wrapper Search","Computational efficiency;Electronic mail;Machine learning algorithms;Measurement;Parallel processing;Prediction algorithms;Support vector machines","feature selection;parallel processing;pattern classification;shared memory systems","classifier complexity;feature selection;feature space reduction;filter metric;parallel computing hybrid approach;shared memory parallel environment;wrapper method","","","","20","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Implementing Randomized Matrix Algorithms in Parallel and Distributed Environments","J. Yang; X. Meng; M. W. Mahoney","Inst. for Comput. & Math. Eng., Stanford Univ., Stanford, CA, USA","Proceedings of the IEEE","20151218","2016","104","1","58","92","In this era of large-scale data, distributed systems built on top of clusters of commodity hardware provide cheap and reliable storage and scalable processing of massive data. With cheap storage, instead of storing only currently relevant data, it is common to store as much data as possible, hoping that its value can be extracted later. In this way, exabytes (1018 bytes) of data are being created on a daily basis. Extracting value from these data, however, requires scalable implementations of advanced analytical algorithms beyond simple data processing, e.g., statistical regression methods, linear algebra, and optimization algorithms. Most such traditional methods are designed to minimize floating-point operations, which is the dominant cost of in-memory computation on a single machine. In parallel and distributed environments, however, load balancing and communication, including disk and network input/output (I/O), can easily dominate computation. These factors greatly increase the complexity of algorithm design and challenge traditional ways of thinking about the design of parallel and distributed algorithms. Here, we review recent work on developing and implementing randomized matrix algorithms in large-scale parallel and distributed environments. Randomized algorithms for matrix problems have received a great deal of attention in recent years, thus far typically either in theory or in machine learning applications or with implementations on a single machine.","0018-9219;00189219","","10.1109/JPROC.2015.2494219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7355313","Big data;distributed matrix algorithms;least absolute deviation;least squares;preconditioning;randomized linear algebra;subspace embedding","Algorithm design and analysis;Approximation algorithms;Approximation methods;Big data;Distributed databases;Machine learning algorithms;Matrix decomposition","iterative methods;matrix algebra;parallel algorithms;randomised algorithms;regression analysis","analytical algorithms;commodity hardware clusters;communication;data extraction value;data processing;data storage;distributed environment;floating-point operation minimization;in-memory computation;input-sparsity time;iterative algorithms;l<sub>1</sub>-regression problem;l<sub>2</sub>-regression problem;large-scale data;linear algebra;load balancing;machine learning;network I/O;network input/output;optimization algorithms;over-constrained problems;parallel environment;preconditioned problem;probability;random projection algorithms;random sampling algorithms;randomized matrix algorithm;relative-error approximate solutions;statistical regression methods","","1","","71","","20151217","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Vehicle Speed Prediction Using Deep Learning","J. Lemieux; Y. Ma","Dept. of Electr. & Comput. Eng., Univ. of Michigan, Dearborn, MI, USA","2015 IEEE Vehicle Power and Propulsion Conference (VPPC)","20151217","2015","","","1","5","Global optimization of the energy consumption of dual power source vehicles such as hybrid electric vehicles, plug-in hybrid electric vehicles, and plug in fuel cell electric vehicles requires knowledge of the complete route characteristics at the beginning of the trip. One of the main characteristics is the vehicle speed profile across the route. The profile will translate directly into energy requirements for a given vehicle. However, the vehicle speed that a given driver chooses will vary from driver to driver and from time to time, and may be slower, equal to, or faster than the average traffic flow. If the specific driver speed profile can be predicted, the energy usage can be optimized across the route chosen. The purpose of this paper is to research the application of Deep Learning techniques to this problem to identify at the beginning of a drive cycle the driver specific vehicle speed profile for an individual driver repeated drive cycle, which can be used in an optimization algorithm to minimize the amount of fossil fuel energy used during the trip.","","Electronic:978-1-4673-7637-2; POD:978-1-4673-7638-9","10.1109/VPPC.2015.7353037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7353037","","Data mining;Machine learning;Neural networks;Roads;Standards;Traffic control;Vehicles","energy consumption;fossil fuels;fuel cell vehicles;hybrid electric vehicles","deep learning;dual power source vehicles;energy consumption;energy usage;fossil fuel energy;plug in fuel cell electric vehicles;plug-in hybrid electric vehicles;vehicle speed prediction","","1","","6","","","19-22 Oct. 2015","","IEEE","IEEE Conference Publications"
"SWAP-NODE: A regularization approach for deep convolutional neural networks","T. Yamashita; M. Tanaka; Y. Yamauchi; H. Fujiyoshi","Chubu University 1200 Matsumoto-cho, Kasugai, Aichi, Japan","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","2475","2479","The regularization is important for training of a deep network. One of breakthrough approach is dropout. It randomly deletes a certain number of activations in each layer in the feed-forward step of the training process. The dropout significantly reduces an effect of over-fitting and improves test performance. We introduce a new regularization approach for deep learning, called the swap-node. The swap-node, which is applied to a fully connected layer, swaps the activation values of two nodes randomly selected with a certain probability. Empirical evaluation shows that the network using the swap-node performs the best on MNIST, CIFAR-10, and SVHN. We also demonstrate superior performance of a combination of the swap-node and dropout on these datasets.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351247","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351247","deep learning;dropout;regularization;swap-node","Computer vision;Convolution;Error analysis;Machine learning;Neural networks;Training;Training data","learning (artificial intelligence);neural nets","CIFAR-10;MNIST;SVHN;SWAP-NODE;activation values;deep convolutional neural networks;deep learning;feed-forward step;regularization approach;swap-node;training","","","","12","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Temporal Pattern and Association Discovery of Diagnosis Codes Using Deep Learning","S. Mehrabi; S. Sohn; D. Li; J. J. Pankratz; T. Therneau; J. L. S. Sauver; H. Liu; M. Palakal","Dept. of Health Sci. Res., Mayo Clinic, Rochester, MN, USA","2015 International Conference on Healthcare Informatics","20151210","2015","","","408","416","Longitudinal health records contain data on patients' visits, condition, treatment, and test results representing progression of their health status over time. In poorly understood patient populations, such data are particularly helpful in characterizing disease progression and early detection. In this work we developed a deep learning algorithm for temporal pattern discovery over Rochester Epidemiology Project data. We modeled each patient's records as a matrix of temporal clinical events with ICD9 and HCUP CSS diagnosis codes as rows and years of diagnosis as columns. Patients aged 18 or younger at the time of diagnosis were selected. A deep Boltzmann machine network with three hidden layers was constructed with each patient's diagnosis matrix values as visible nodes. The final weights of the network model were analyzed as the common features among patients' records.","","Electronic:978-1-4673-9548-9; POD:978-1-4673-9549-6","10.1109/ICHI.2015.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7349719","Deep Learning;Rochester Epidemiology Project;Temporal Pattern Discovery","Cascading style sheets;Diseases;Machine learning;Medical diagnostic imaging;Sociology;Statistics","Boltzmann machines;data mining;electronic health records;learning (artificial intelligence);matrix algebra;patient diagnosis","HCUP CSS diagnosis;ICD9 diagnosis code;Rochester Epidemiology Project data;deep Boltzmann machine network;deep learning;deep learning algorithm;disease progression;longitudinal health record;patient diagnosis matrix value;temporal association discovery;temporal pattern discovery","","4","","45","","","21-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Automated Detection of Urban Road Manhole Covers Using Mobile Laser Scanning Data","Y. Yu; H. Guan; Z. Ji","Key Lab. of Sensing & Comput. for Smart Cities, Xiamen Univ., Xiamen, China","IEEE Transactions on Intelligent Transportation Systems","20151124","2015","16","6","3258","3269","This paper proposes a novel framework for automated detection of urban road manhole covers using mobile laser scanning (MLS) data. First, to narrow searching regions and reduce the computational complexity, road surface points are segmented from a raw point cloud via a curb-based road surface segmentation approach and rasterized into a georeferenced intensity image through inverse distance weighted interpolation. Then, a supervised deep learning model is developed to construct a multilayer feature generation model for depicting high-order features of local image patches. Next, a random forest model is trained to learn mappings from high-order patch features to the probabilities of the existence of urban road manhole covers centered at specific locations. Finally, urban road manhole covers are detected from georeferenced intensity images based on the multilayer feature generation model and random forest model. Quantitative evaluations show that the proposed algorithm achieves an average completeness, correctness, quality, and F<sub>1</sub>-measure of 0.955, 0.959, 0.917, and 0.957, respectively, in detecting urban road manhole covers from georeferenced intensity images. Comparative studies demonstrate the advantageous performance of the proposed algorithm over other existing methods for rapid and automated detection of urban road manhole covers using MLS data.","1524-9050;15249050","","10.1109/TITS.2015.2413812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7084661","Deep learning;manhole cover;mobile laser scanning (MLS);random forest;road distress;road safety","Algorithm design and analysis;Feature extraction;Image segmentation;Machine learning;Road safety;Training","feature extraction;geophysical image processing;image segmentation;intelligent transportation systems;interpolation;learning (artificial intelligence);object detection;random processes;road safety","F1-measure;MLS data;automated detection;computational complexity;curb-based road surface segmentation approach;georeferenced intensity image;high-order patch features;intelligent transportation system;inverse distance weighted interpolation;local image patches;mappings learning;mobile laser scanning data;multilayer feature generation model;random forest model;raw point cloud;road safety;road surface points segmentation;supervised deep learning model;urban road manhole covers detection","","4","","28","","20150413","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"Multistep Fuzzy Bridged Refinement Domain Adaptation Algorithm and Its Application to Bank Failure Prediction","V. Behbood; J. Lu; G. Zhang; W. Pedrycz","School of Software, Center for Quantum Computation and Intelligent System, Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, N.S.W., Australia","IEEE Transactions on Fuzzy Systems","20151125","2015","23","6","1917","1935","Machine learning plays an important role in data classification and data-based prediction. In some real-world applications, however, the training data (coming from the source domain) and test data (from the target domain) come from different domains or time periods, and this may result in the different distributions of some features. Moreover, the values of the features and/or labels of the datasets might be nonnumeric and involve vague values. Traditional learning-based prediction and classification methods cannot handle these two issues. In this study, we propose a multistep fuzzy bridged refinement domain adaptation algorithm, which offers an effective way to deal with both issues. It utilizes a concept of similarity to modify the labels of the target instances that were initially predicted by a shift-unaware model. It then refines the labels using instances that are most similar to a given target instance. These instances are extracted from mixture domains composed of source and target domains. The proposed algorithm is built on a basis of some data and refines the labels, thus performing completely independently of the shift-unaware prediction model. The algorithm uses a fuzzy set-based approach to deal with the vague values of the features and labels. Four different datasets are used in the experiments to validate the proposed algorithm. The results, which are compared with those generated by the existing domain adaptation methods, demonstrate a significant improvement in prediction accuracy in both the above-mentioned datasets.","1063-6706;10636706","","10.1109/TFUZZ.2014.2387872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001634","Classification;Domain Adaptation;Fuzzy set-based Approach;Fuzzy similarity;Transfer Learning;domain adaptation;fuzzy set-based approach;fuzzy similarity;transfer learning","Adaptation models;Classification algorithms;Data models;Learning systems;Machine learning algorithms;Prediction algorithms;Predictive models","bank data processing;fuzzy set theory;iterative methods;learning (artificial intelligence);pattern classification","bank failure prediction;data classification;data-based prediction;machine learning;multistep fuzzy bridged refinement domain adaptation algorithm;shift-unaware prediction model","","2","","37","","20150106","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"Time complexity and architecture of a cloud based prognostics system for a multi-client condition monitoring activity","A. K. T. Natarajan; S. Kamarthi","Dept. of Mechanical and Industrial Engineering, Northeastern University, Boston, MA 02115","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","1446","1450","Condition and cloud based prognostics offers the opportunities to reduce loss due to machine failures and delay in planning for maintenance activities and spare parts. The time complexity of the prognostics algorithms used for predicting imminent component failures or the remaining useful life of critical components plays a vital role in determining the accuracy and feasibility of prognostics systems. We discuss the infrastructure needs of cloud based prognostics and compare time complexity of different prognostics methods used to predict machine failures.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363905","Cloud-enabled prognostics;condition-based prognostic;prediction algorithms;spare parts management","Machine learning algorithms;Machine tools;Manufacturing;Monitoring;Real-time systems;Time complexity","cloud computing;computational complexity;condition monitoring;machine tools;machinery production industries;maintenance engineering;production engineering computing;remaining life assessment","cloud based prognostics system;critical component remaining useful life;machine failure prediction;maintenance activities;multiclient condition monitoring activity;spare parts;time complexity","","1","","28","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Deep learning vs. kernel methods: Performance for emotion prediction in videos","Y. Baveye; E. Dellandréa; C. Chamaret; L. Chen","Technicolor 975, avenue des Champs Blancs, 35576 Cesson S&#233;vign&#233;, France","2015 International Conference on Affective Computing and Intelligent Interaction (ACII)","20151207","2015","","","77","83","Recently, mainly due to the advances of deep learning, the performances in scene and object recognition have been progressing intensively. On the other hand, more subjective recognition tasks, such as emotion prediction, stagnate at moderate levels. In such context, is it possible to make affective computational models benefit from the breakthroughs in deep learning? This paper proposes to introduce the strength of deep learning in the context of emotion prediction in videos. The two main contributions are as follow: (i) a new dataset, composed of 30 movies under Creative Commons licenses, continuously annotated along the induced valence and arousal axes (publicly available) is introduced, for which (ii) the performance of the Convolutional Neural Networks (CNN) through supervised fine-tuning, the Support Vector Machines for Regression (SVR) and the combination of both (Transfer Learning) are computed and discussed. To the best of our knowledge, it is the first approach in the literature using CNNs to predict dimensional affective scores from videos. The experimental results show that the limited size of the dataset prevents the learning or finetuning of CNN-based frameworks but that transfer learning is a promising solution to improve the performance of affective movie content analysis frameworks as long as very large datasets annotated along affective dimensions are not available.","","Electronic:978-1-4799-9953-8; POD:978-1-4799-9954-5; USB:978-1-4799-9952-1","10.1109/ACII.2015.7344554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344554","affective computing;benchmarking;continuous emotion prediction;deep learning","Computational modeling;Correlation;Hidden Markov models;Kernel;Machine learning;Motion pictures;Videos","emotion recognition;learning (artificial intelligence);object recognition;regression analysis;support vector machines;video signal processing","CNN-based frameworks;SVR;affective movie content analysis frameworks;computational models;convolutional neural networks;creative common licenses;deep learning;dimensional affective scores;kernel methods;object recognition;supervised fine-tuning;support vector machines for regression;transfer learning;video emotion prediction","","1","","27","","","21-24 Sept. 2015","","IEEE","IEEE Conference Publications"
"Development of a UAV-type jellyfish monitoring system using deep learning","H. Kim; D. Kim; Sungwook Jung; Jungmo Koo; J. U. Shin; H. Myung","Urban Robotics Laboratory (URL), Civil & Environmental Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro (373-1 Guseong-dong), Yuseong-gu, Daejeon 34141, Korea","2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","20151217","2015","","","495","497","At present, unmanned aerial vehicles (UAVs) are the primary platforms widely used for environmental monitoring. The advantage of the UAV-type surveillance system is its low-cost with high observation performance. Using this system, we can extend the workable area of the jellyfish removal system. The proposed system observes jellyfish on the surface of the sea while flying, and can recognize a herd of jellyfish using deep learning. The preliminary results of the proposed system show that the proposed system improves the jellyfish removal system for efficient operation.","","Electronic:978-1-4673-7971-7; POD:978-1-4673-7972-4","10.1109/URAI.2015.7358813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358813","Jellyfish removal;monitoring system;unmanned aerial vehicle","Clustering algorithms;Global Positioning System;Machine learning;Robots;Sea surface;Surveillance","autonomous aerial vehicles;environmental management;intelligent robots;learning (artificial intelligence)","UAV-type jellyfish monitoring system;UAV-type surveillance system;deep learning;environmental monitoring;jellyfish removal system;unmanned aerial vehicles","","","","8","","","28-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"The Potential of the Intel (R) Xeon Phi for Supervised Deep Learning","A. Viebke; S. Pllana","Dept. of Comput. Sci., Linnaeus Univ., Vaxjo, Sweden","2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems","20151130","2015","","","758","765","Supervised learning of Convolutional Neural Networks (CNNs), also known as supervised Deep Learning, is a computationally demanding process. To find the most suitable parameters of a network for a given application, numerous training sessions are required. Therefore, reducing the training time per session is essential to fully utilize CNNs in practice. While numerous research groups have addressed the training of CNNs using GPUs, so far not much attention has been paid to the Intel Xeon Phi coprocessor. In this paper we investigate empirically and theoretically the potential of the Intel Xeon Phi for supervised learning of CNNs. We design and implement a parallelization scheme named CHAOS that exploits both the thread-and SIMD-parallelism of the coprocessor. Our approach is evaluated on the Intel Xeon Phi 7120P using the MNIST dataset of handwritten digits for various thread counts and CNN architectures. Results show a 103.5x speed up when training our large network for 15 epochs using 244 threads, compared to one thread on the coprocessor. Moreover, we develop a performance model and use it to assess our implementation and answer what-if questions.","","Electronic:978-1-4799-8937-9; POD:978-1-4799-8938-6","10.1109/HPCC-CSS-ICESS.2015.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336249","Convolutional Neural Networks;Intel Xeon Phi;Many-core;Parallel Computing;Supervised Deep Learning","Biological neural networks;Chaos;Coprocessors;Instruction sets;Machine learning;Neurons;Training","graphics processing units;learning (artificial intelligence);neural nets;parallel processing","CHAOS;CNN;GPU;Intel Xeon Phi 7120P;Intel Xeon Phi coprocessor;SIMD-parallelism;convolutional neural network;parallelization scheme;supervised deep learning;thread-parallelism","","4","","33","","","24-26 Aug. 2015","","IEEE","IEEE Conference Publications"
"Haptic handwritten signatures: the effect of deconcentrated dissimilarities on manifold extraction","J. J. Valdes; F. A. Alsulaiman; A. E. Saddik","National Research Council Canada Emerging Technologies Division Information and Communications Technologies Portfolio Ottawa, Ontario, Canada","2015 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE)","20151221","2015","","","1","6","The use of a haptic-based handwritten signatures has an intrinsic biometric nature and an important potential in user identification/authentication because it incorporates tactile information. However, in order to exploit this potential for constructing decision systems, it is necessary to gain an appropriate understanding of the internal structure of the data, which in relational representations tend to be very highly dimensional. Most machine learning techniques i) are affected by the curse of dimensionality, ii) use algorithms involving distances (usually Euclidean), but in high dimensional spaces they suffer from the concentration phenomenon. This paper explores the behavior of different strategies for distance deconcentration of haptic data when used for nonlinear unsupervised mappings into low dimensional spaces. An aposteriori use of class information shows that deconcentration transformations improve class cohesion and separation, which can improve the performance of machine learning algorithms.","","Electronic:978-1-4673-9175-7; POD:978-1-4673-9176-4","10.1109/HAVE.2015.7359450","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359450","","Data mining;Electronic mail;Euclidean distance;Extraterrestrial phenomena;Haptic interfaces;Machine learning algorithms;Manifolds","digital signatures;handwritten character recognition;haptic interfaces;unsupervised learning","decision systems;deconcentrated dissimilarities;deconcentration transformations;dimensional spaces;distance deconcentration phenomenon;haptic data;haptic-based handwritten signatures;intrinsic biometric nature;low dimensional spaces;machine learning algorithms;machine learning techniques;nonlinear unsupervised mappings;relational representations;tactile information","","1","","23","","","11-11 Oct. 2015","","IEEE","IEEE Conference Publications"
"Optimal transport using Helmholtz-Hodge decomposition and first-order primal-dual algorithms","M. Henry; E. Maitre; V. Perrier","University of Grenoble-Alpes, Laboratoire Jean Kuntzmann, St Martin d'H&#x00E8;res, France","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","4748","4752","This work deals with the resolution of the optimal transport problem between 2D images in the fluid mechanics framework of Benamou and Brenier formulation [1], which numerical resolution is still challenging even for medium-sized images. We develop a method using the Helmholtz-Hodge decomposition [2] in order to enforce the divergence-free constraint throughout the iterations. We then show how to use a first order primal-dual algorithm for convex problems of Chambolle and Pock [3] to solve the obtained problem, leading to a new algorithm easy to implement. Besides, numerical experiments demonstrate that this algorithm is faster than state of the art methods and efficient with real-sized images.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351708","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351708","Convex optimization;Helmholtz-Hodge decomposition;image processing;optimal transport;proximal splitting","Boundary conditions;Image resolution;Machine learning algorithms;Poisson equations;Ports (Computers);Transforms","Helmholtz equations;computational fluid dynamics;convex programming;image resolution","2D images;Benamou and Brenier formulation;Helmholtz-Hodge decomposition;convex problems;divergence-free constraint;first-order primal-dual algorithms;fluid mechanics framework;medium-sized images;optimal transport problem","","","","20","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Leveraging appearance priors in non-rigid registration, with application to manipulation of deformable objects","S. H. Huang; J. Pan; G. Mulcaire; P. Abbeel","Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, USA","2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","20151217","2015","","","878","885","Manipulation of deformable objects is a widely applicable but challenging task in robotics. One promising nonparametric approach for this problem is trajectory transfer, in which a non-rigid registration is computed between the starting scene of the demonstration and the scene at test time. This registration is extrapolated to find a function from ℝ<sup>3</sup> to ℝ<sup>3</sup>, which is then used to warp the demonstrated robot trajectory to generate a proposed trajectory to execute in the test scene. In prior work [1] [2], only depth information from the scenes has been used to compute this warp function. This approach ignores appearance information, but there are situations in which using both shape and appearance information is necessary for finding high quality non-rigid warp functions. In this paper, we describe an approach to learn relevant appearance information about deformable objects using deep learning, and use this additional information to improve the quality of non-rigid registration between demonstration and test scenes. Our method better registers areas of interest on deformable objects that are crucial for manipulation, such as rope crossings and towel corners and edges. We experimentally validate our approach in both simulation and in the real world, and show that the utilization of appearance information leads to a significant improvement in both selecting the best matching demonstration scene for a given test scene, and finding a high quality non-rigid registration between those two scenes.","","Electronic:978-1-4799-9994-1; POD:978-1-4799-9995-8; USB:978-1-4799-9993-4","10.1109/IROS.2015.7353475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7353475","","Context;Machine learning;Neural networks;Robots;Shape;Three-dimensional displays;Trajectory","extrapolation;image registration;robot vision;trajectory control","appearance prior;deep learning;deformable object manipulation;nonparametric approach;nonrigid registration;robotics;trajectory transfer;warp function","","2","","38","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"An application of black hole algorithm and decision tree for medical problem","E. Pashaei; M. Ozen; N. Aydin","Department of Computer Engineering, Yildiz Technical University, Istanbul, Turkey","2015 IEEE 15th International Conference on Bioinformatics and Bioengineering (BIBE)","20160104","2015","","","1","6","In this study, we propose a novel method for medical data classification, it is the integration of new heuristic algorithm that get inspired the black hole phenomenon called as Black Hole Algorithm (BHA) and decision tree (C4.5). To evaluate the effectiveness of our proposed method, it is implemented on 2 microarray dataset and 5 different medical data sets obtained from UCI machine learning databases. The results of BHA + C4.5 implementation are compared to seven well-known benchmark classification methods (support vector machine under the kernel of Radial Basis Function, Classification And Regression Tree (CART), C4.5 decision tree, C5.0 decision tree, Linear Discriminant Analysis (LDA), Self-Organizing Map and Naive Bayes). Repeated five-fold cross-validation method is used to justify the performance of classifiers. Two criteria are used for model evaluation. They are Matthews' Correlation Coefficient (MCC) and Accuracy. Experimental results show that our proposed method outperforms the other classification methods in MCC index and have higher accuracy after SVM and LDA classifiers.","","Electronic:978-1-4673-7983-0; POD:978-1-4673-7984-7","10.1109/BIBE.2015.7367738","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367738","","Classification algorithms;Correlation coefficient;Data mining;Decision trees;Machine learning algorithms;Optimization;Space exploration","classification;data mining;decision trees;heuristic programming;learning (artificial intelligence);medical computing;radial basis function networks;regression analysis;self-organising feature maps;support vector machines","BHA;C4.5 decision tree;C5.0 decision tree;CART;Classification And Regression Tree;LDA classifier;Linear Discriminant Analysis;MCC index;Matthews' Correlation Coefficient and Accuracy;Radial Basis Function;SVM classifier;Self-Organizing Map and Naive Bayes;UCI machine learning databases;benchmark classification method;black hole algorithm;five-fold cross-validation method;heuristic algorithm;medical data classification;medical data sets;microarray dataset;support vector machine","","2","","17","","","2-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"Deep learning in acoustic modeling for Automatic Speech Recognition and Understanding - an overview -","I. Gavat; D. Militaru","Department of Electronics, Telecommunications and Information Technology, University POLITEHNICA, Bucharest, Romania","2015 International Conference on Speech Technology and Human-Computer Dialogue (SpeD)","20151203","2015","","","1","8","This paper will discuss the progress made in Automatic Speech Recognition and Understanding (ASRU) by applying Deep Learning (DL) in the frame of acoustic modeling. After explaining the concept of DL, specific algorithms like Restricted Bolzmann Machine (RBM), Convolutional Neural Network (CNN), Autoencoder (AE), Deep Belief Network (DBN), will be presented and evaluated. Experiments in the academic research but also in the industry with DL structures concerning Phone Recognition and Large Vocabulary Continuous Speech Recognition (LVCSR) will be highlighted, confirming the usefulness of the DL framework in ASRU. Some considerations about the future of this new and effective machine learning paradigm will conclude the paper.","","DVD:978-1-4673-7559-7; Electronic:978-1-4673-7560-3; POD:978-1-4673-7561-0","10.1109/SPED.2015.7343074","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7343074","ASRU;LVCSR;autoencoder;continuous speech recognition;convolutional neural network;deep belief network;deep learning;restricted Bolzmann machine","Acoustics;Feature extraction;Hidden Markov models;Machine learning;Neural networks;Speech;Speech recognition","Boltzmann machines;acoustic signal processing;belief networks;learning (artificial intelligence);neural nets;speech recognition","AE;ASRU;CNN;DBN;DL;LVCSR;RBM;acoustic modeling;autoencoder;automatic speech recognition and understanding;convolutional neural network;deep belief network;deep learning;large vocabulary continuous speech recognition;machine learning paradigm;phone recognition;restricted Boltzmann machine","","","","33","","","14-17 Oct. 2015","","IEEE","IEEE Conference Publications"
"Incremental One-Class Bagging for Streaming and Evolving Big Data","B. Krawczyk; M. Wozniak","Dept. of Syst. & Comput. Networks, Wroclaw Univ. of Technol., Wroclaw, Poland","2015 IEEE Trustcom/BigDataSE/ISPA","20151203","2015","2","","193","198","Modern machine learning systems need to be able to efficiently process big data. Extracting useful patterns from massive collection of objects requires not only accurate, but also fast algorithms with limited computational complexity. However, one should remember that the problem with massive datasets lies not only in their volume. There is a number of difficulties embedded in the nature of data, that must be properly addressed in order to design an efficient learning system. In this paper we address multiple problems related to big data analytics. We assume the streaming nature of our data. Additionally, we work in non-stationary environment where nature of data may constantly change. Finally, we consider a situation where not object from one class are only available what leads us to the one-class classification task. We propose a novel incremental ensemble of weighted one-class classifiers, based on boosting. Our learners adapt to evolving nature of data stream by changing weights assigned to objects and forgetting outdated examples. The proposed bagging scheme allows for diversifying the pool of individual classifiers which can run in a distributed computing environment. We propose to maintain the diversity of the ensemble by updating each classifier with a bootstrap sample from incoming stream. Experimental study proves the usefulness of our approach in scenarios, where we need to process massive and evolving data streams without the access to counterexamples.","","Electronic:978-1-4673-7952-6; POD:978-1-4673-7953-3","10.1109/Trustcom.2015.582","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7345495","big data;classifier ensemble;concept drift;data streams;incremental learning;one-class classification","Bagging;Big data;Data mining;Learning systems;Machine learning algorithms;Support vector machines;Training","Big Data;data analysis;distributed processing;learning (artificial intelligence);pattern classification","Big Data analytics;Big Data streaming;distributed computing environment;machine learning system;one-class classification task","","","","21","","","20-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"A dual block coordinate proximal algorithm with application to deconvolution of interlaced video sequences","F. Abboud; E. Chouzenoux; J. C. Pesquet; J. H. Chenot; L. Laborelli","LIGM, Univ. Paris-Est, Champs-sur-Marne, France","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","4917","4921","Inverse problems encountered in video processing often require to minimize criteria involving a high number of variables. Among available optimization techniques, proximal methods have shown their efficiency in solving large-scale possibly nonsmooth problems. When some of the proximity operators involved in these methods do not have closed form expressions, they may constitute a bottleneck in terms of computational complexity and memory requirements. In this paper, we address this problem and propose accelerated techniques for solving it. A new dual block-coordinate forward-backward algorithm computing the proximity operator of a sum of convex functions composed with linear operators is proposed and theoretically analyzed. The numerical performance of the approach is assessed through an application to deconvolution and super-resolution of interlaced video sequences.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351742","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351742","Proximity operator;block-coordinate approach;convex optimization;deconvolution;deinterlacing;duality;forward-backward;super-resolution;video processing","Convergence;Convex functions;Deconvolution;Machine learning algorithms;Measurement;Optimization;Video sequences","convex programming;deconvolution;image resolution;image sequences;video signal processing","convex functions;deconvolution;dual block coordinate proximal algorithm;dual block-coordinate forward-backward algorithm;interlaced video sequences;optimization techniques;proximal methods;video processing;video super-resolution","","1","","","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"Deep belief networks for predicting corporate defaults","S. H. Yeh; C. J. Wang; M. F. Tsai","Department of Computer Science, University of Taipei, Taipei, Taiwan","2015 24th Wireless and Optical Communication Conference (WOCC)","20151207","2015","","","159","163","This paper provides a new perspective on the default prediction problem using deep learning algorithms. Via the advantages of deep learning, the representable factors of input data will no longer need to be explicitly extracted, but can be implicitly learned by the deep learning algorithms. We consider the stock returns of both default and solvent companies as input signals and adopt one of the deep learning architecture, Deep Belief Networks (DBN), to train the prediction models. The preliminary results show that the proposed approach outperforms traditional machine learning algorithms.","2379-1268;23791268","Electronic:978-1-4799-8854-9; POD:978-1-4799-8849-5","10.1109/WOCC.2015.7346197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346197","","Companies;Feature extraction;Machine learning;Prediction algorithms;Predictive models;Time series analysis;Training","belief networks;business data processing;financial data processing;learning (artificial intelligence);prediction theory;stock markets","DBN;corporate default prediction;deep belief network;deep learning algorithm;machine learning algorithm;prediction model;stock return","","","","27","","","23-24 Oct. 2015","","IEEE","IEEE Conference Publications"
"Tight Bounds on Low-Degree Spectral Concentration of Submodular and XOS Functions","V. Feldman; J. Vondrák","IBM Almaden Res. Center, San Jose, CA, USA","2015 IEEE 56th Annual Symposium on Foundations of Computer Science","20151217","2015","","","923","942","Submodular and fractionally subadditive (or equivalently XOS) functions play a fundamental role in combinatorial optimization, algorithmic game theory and machine learning. Motivated by learnability of these classes of functions from random examples, we consider the question of how well such functions can be approximated by low-degree polynomials in ℓ<sub>2</sub> norm over the uniform distribution. This question is equivalent to understanding the concentration of Fourier weight on low-degree coefficients, a central concept in Fourier analysis. Denoting the smallest degree sufficient to approximate f in ℓ<sub>2</sub> norm within ∈ by deg<sub>∈</sub>(ℓ<sub>2</sub>)(f), we show that : For any submodular function f : {0, 1}<sup>n</sup> → [0, 1], deg<sub>∈</sub>(ℓ<sub>2</sub>)(f) = O(log(1/∈)/∈<sup>4/5</sup>) and there is a submodular function that requires degree Ω(1/∈<sup>4/5</sup>). : For any XOS function f : {0, 1} → [0, 1], deg<sub>∈</sub>(ℓ<sub>2</sub>) (f) = O(1/∈) and there exists an XOS function that requires degree Ω(1/∈). This improves on previous approaches that all showed an upper bound of O(1/∈<sup>2</sup>) for submodular [CKKL12], [FKV13], [FV13] and XOS [FV13] functions. The best previous lower bound was Ω(1/∈<sup>2/3</sup>) for monotone submodular functions [FKV13]. Our techniques reveal new structural properties of submodular and XOS functions and the upper bounds lead to nearly optimal PAC learning algorithms for these classes of functions.","0272-5428;02725428","Electronic:978-1-4673-8191-8","10.1109/FOCS.2015.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354435","XOS function;spectral concentration;submodular function","Algorithm design and analysis;Approximation algorithms;Approximation methods;Game theory;Machine learning algorithms;Polynomials;Upper bound","computational complexity;function approximation;learning (artificial intelligence);polynomial approximation","CKKL12 function;FKV13 function;FV13 function;Fourier analysis;Fourier weight;XOS functions;fractionally subadditive functions;function approximation;function class learnability;l<sub>2</sub> norm;low-degree coefficients;low-degree polynomials;low-degree spectral concentration;lower bound;monotone submodular functions;nearly-optimal PAC learning algorithms;tight bounds;uniform distribution;upper bound","","1","","60","","","17-20 Oct. 2015","","IEEE","IEEE Conference Publications"
"k-Nearest Neighbors algorithm based on weak bit implementation on Enhanced Vote Count circuit","H. Shu; W. Jiang; R. Yu","Institute for Infocomm Research, A*STAR, Singapore 138632","2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)","20151203","2015","","","1","6","k-Nearest Neighbors (kNN) algorithm is a method to find the closest points in a dataset to a query point. The result of kNN can be used for classification and regression, both of which are commonly used in data mining and machine learning. In this paper, Enhanced Vote Count (EVC) circuit, which uses hardware to compare the quantized projected values of query and training/reference vectors instead of the vectors themselves, is considered to approximate the kNN search to provide a low complexity search solution. To improve the performance of EVC with limited projection number because projection number is directly related to implementation cost of EVC circuit, the concept of weak bit is considered and only reliable binary pattern matching is evaluated. The implementation of weak bit based on EVC circuit is also described. Simulation results show that, the performance of EVC can be significantly improved with weak bit implementation under limited projection number.","","Electronic:978-1-4673-7478-1; POD:978-1-4673-7479-8","10.1109/MMSP.2015.7340862","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7340862","Enhanced Vote Count;k-Nearest Neighbors algorithm;weak bit","Complexity theory;Hamming distance;Machine learning algorithms;Pattern matching;Quantization (signal);Radiation detectors;Reliability","approximation theory;data mining;image classification;learning (artificial intelligence);regression analysis","binary pattern matching;complexity search solution;data mining;enhanced vote count circuit;k-nearest neighbors algorithm;kNN search;machine learning","","","","17","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"A scalable implementation of information theoretic feature selection for high dimensional data","A. Kleerekoper; M. Pappas; A. Pocock; G. Brown; M. Lujan","School of Computing, Mathematics and Digital Technologies, Manchester Metropolitan University, UK","2015 IEEE International Conference on Big Data (Big Data)","20151228","2015","","","339","346","With the growth of high dimensional data, feature selection is a vital component of machine learning as well as an important stand alone data analytics tool. Without it, the computation cost of big data analytics can become unmanageable and spurious correlations and noise can reduce the accuracy of any results. Feature selection removes irrelevant and redundant information leading to faster, more reliable data analysis. Feature selection techniques based on information theory are among the fastest known and the Manchester AnalyticS Toolkit (MAST) provides an efficient, parallel and scalable implementation of these methods. This paper considers a number of data structures for storing the frequency counters that underpin MAST. We show that preprocessing the data to reduce the number of zero-valued counters in an array structure results in an order of magnitude reduction in both memory usage and execution time compared to state of the art structures that use explicit mappings to avoid zero-valued counters. We also describe a number of parallel processing techniques that enable MAST to scale linearly with the number of processors even on NUMA architectures. MAST targets scale-up servers rather than scale-out clusters and we show that it performs orders of magnitude faster than existing tools. Moreover, we show that MAST is 3.5 times faster than a scale-out solution built for Spark running on the same server. As an example of the performance of MAST, we were able to process a dataset of 100 million examples and 100,000 features in under 10 minutes on a four socket server which each socket containing an 8-core Intel Xeon E5-4620 processor.","","Electronic:978-1-4799-9926-2; POD:978-1-4799-9927-9","10.1109/BigData.2015.7363774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363774","Big Data;Data Analytics;Data Structures;Feature Selection;Information Theory;Mutual Information;Parallel Processing","Arrays;Big data;Machine learning algorithms;Mutual information;Radiation detectors;Servers","Big Data;data analysis;data structures;feature selection;information theory;parallel processing","8-core Intel Xeon E5-4620 processor;Big Data analytics;MAST;Manchester analytics toolkit;NUMA architectures;Spark;data analytics tool;data preprocessing;data structures;frequency counters;high dimensional data;information theoretic feature selection;machine learning;magnitude reduction;memory execution time;memory usage;noise reduction;parallel processing techniques;scale-out clusters;socket server;zero-valued counters","","","","22","","","Oct. 29 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"Sequencing of categorical time series","C. Richter; M. Luboschik; M. Röhlig; H. Schumann","University of Rostock, Germany","2015 IEEE Conference on Visual Analytics Science and Technology (VAST)","20151207","2015","","","213","214","Exploring and comparing categorical time series and finding temporal patterns are complex tasks in the field of time series data mining. Although different analysis approaches exist, these tasks remain challenging, especially when numerous time series are considered at once. We propose a visual analysis approach that supports exploring such data by ordering time series in meaningful ways. We provide interaction techniques to steer the automated arrangement and to allow users to investigate patterns in detail.","","Electronic:978-1-4673-9783-4; POD:978-1-4673-9784-1","10.1109/VAST.2015.7347684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347684","H.5.2 [Information Interfaces and Presentation]: User Interfaces-Graphical user interfaces (GUI);I.5.3 [Clustering ]: Algorithm-Similarity measures","Algorithm design and analysis;Clustering algorithms;Machine learning algorithms;Measurement;Sequential analysis;Time series analysis;Visualization","data analysis;data mining;data visualisation;time series","automated arrangement;categorical time series sequencing;interaction techniques;temporal patterns;time series data mining;time series ordering;visual analysis approach","","","","5","","","25-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"Deep Aging Face Verification With Large Gaps","L. Liu; C. Xiong; H. Zhang; Z. Niu; M. Wang; S. Yan","National University of Singapore, Singapore","IEEE Transactions on Multimedia","20151217","2016","18","1","64","75","Along with the long-time evolution of popular social networks, e.g. Facebook, social media analysis research inevitably arrived at the era of considering face/user recognition with large age gaps. However, related research with adequate subjects and large age gaps is surprisingly rare. In this work, we first collect a so-called cross-age face (CAFE) dataset, ranging from child, to young, to adult, to old groups. Then, we propose a novel framework, called deep aging face verification (DAFV), for this challenging task. DAFV includes two modules: aging pattern synthesis and aging face verification. The aging pattern synthesis module synthesizes the faces of all age groups for the input face of an arbitrary age, and the core structure is a deep aging-aware denoising auto-encoder ( a<sup>2</sup>-DAE) with multiple outputs. The aging face verification module then takes the synthesized aging patterns of a face pair as the input, and each pair of synthesized images of the same age group is fed into a parallel CNN; finally, all parallel CNN outputs are fused to provide similar/dissimilar prediction. For DAFV, the training of the aging face verification module easily suffers from the overfitting results from the aging pattern synthesis module, and we propose to use the cross- validation strategy to produce error-aware outputs for the synthesis module. Extensive experiments on the CAFE dataset well demonstrate the superiority of the proposed DAFV framework over other solutions for aging face verification.","1520-9210;15209210","","10.1109/TMM.2015.2500730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328752","Cross-age;deep learning;face verification","Aging;Face;Face recognition;Image reconstruction;Machine learning;Testing;Training","face recognition;image denoising;neural nets","CAFE dataset;DAFV;aging pattern synthesis module;cross-age face dataset;cross-validation strategy;deep aging face verification;deep aging-aware denoising auto-encoder;face recognition;parallel CNN;social networks;user recognition","","2","","38","","20151113","Jan. 2016","","IEEE","IEEE Journals & Magazines"
"Perception of intensity incongruence in synthesized multimodal expressions of laughter","R. Niewiadomski; Y. Ding; M. Mancini; C. Pelachaud; G. Volpe; A. Camurri","Casa Paganini-InfoMus, DIBRIS University of Genoa, Genoa, Italy","2015 International Conference on Affective Computing and Intelligent Interaction (ACII)","20151207","2015","","","684","690","In this paper, we study perception of intensity in-congruence between auditory and visual modalities of synthesized expressions of laughter. In particular, we investigate whether incongruent expressions are perceived as 1) regulated, and 2) unsuccessful in terms of animation synthesis. For this purpose, we conducted a perceptive study with the use of a virtual agent. Congruent and incongruent multimodal expressions of laughter were synthesized from natural audiovisual laughter episodes, using machine learning algorithms. Next, the intensity of facial expressions and body movements were systematically manipulated to check whether the resulting incongruent expressions are perceived differently compared to the corresponding congruent expressions. Results show that 1) intensity incongruence lowers the perception of believability and plausibility, and 2) the in-congruent laughter expressions displaying high intensity in the audio modality and low intensity in the body movement and facial expression are perceived as more fake than the corresponding congruent expressions. Such results have implications for both animation synthesis as well as expression regulation research.","","Electronic:978-1-4799-9953-8; POD:978-1-4799-9954-5; USB:978-1-4799-9952-1","10.1109/ACII.2015.7344643","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344643","incongruence;laughter;multimodal expressions;virtual agents","Animation;Context;Electronic mail;Face;Machine learning algorithms;Torso;Visualization","computer animation;emotion recognition;face recognition;learning (artificial intelligence);multi-agent systems;psychology;visual perception","animation synthesis;auditory modality;body movement;expression regulation;facial expression;intensity incongruence perception;laughter multimodal expression;machine learning algorithm;virtual agent;visual modality","","","","25","","","21-24 Sept. 2015","","IEEE","IEEE Conference Publications"
"On discerning strings with finite automata","A. Yakaryilmaz; J. A. Montoya","National Laboratory for Scientific Computing, Petr&#243;polis, RJ, 25651-075, Brazil","2015 Latin American Computing Conference (CLEI)","20151217","2015","","","1","5","We study the problem of discerning strings with deterministic finite state automata (DFAs, for short). We begin with a survey on the historical and algorithmic roots of this problem. Then, we focus on the maximun number of states that are necessary to separate two strings of a given length. We survey the most important results concerning this issue and we study the problem from the point of view of some alternative models of automata. The preliminary results concerning the last issue motivate us to formulate a conjecture stating that DFAs can separate any pair of strings by using a logarithmic number of states. We give some evidence supporting our conjecture.","","Electronic:978-1-4673-9143-6; POD:978-1-4673-9144-3","10.1109/CLEI.2015.7360021","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360021","","Algorithm design and analysis;Automata;Computational modeling;Electronic mail;Learning automata;Machine learning algorithms;Probabilistic logic","deterministic automata;finite state machines","DFA;deterministic finite state automata;discerning string;logarithmic number","","","","","","","19-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Differently implicational hierarchical inference algorithm under interval-valued fuzzy environment","Y. Tang","Anhui Province Key Laboratory of Affective Computing and Advanced Intelligent Machine, School of Computer and Information, Hefei University of Technology, 230009, China","2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20151130","2015","","","1","8","Under interval-valued fuzzy environment, based on the differently implicational idea and hierarchical inference mechanism, the interval-valued universal triple I algorithm is put forward. To begin with, the interval-valued fuzzy implications and related residual pairs are researched. Furthermore, the interval-valued universal triple I principles are proposed, and the optimal solutions of the interval-valued universal triple I algorithm are achieved from the viewpoints of residual pairs together with the R-implications, and the corresponding hierarchical inference mode is established, meanwhile the reversible properties of the interval-valued universal triple I algorithm are proved. Finally, it is verified by examples that the interval-valued universal triple I algorithm performs better than the interval-valued triple I algorithm.","","Electronic:978-1-4673-7428-6; POD:978-1-4673-7429-3","10.1109/FUZZ-IEEE.2015.7337944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337944","","Algorithm design and analysis;Fuzzy logic;Fuzzy sets;Fuzzy systems;Inference algorithms;Inference mechanisms;Machine learning algorithms","fuzzy reasoning","R-implications;differently implicational hierarchical inference algorithm;interval-valued fuzzy environment;interval-valued universal triple I algorithm;residual pairs","","","","46","","","2-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Keynote speaker 2: Real time data mining","J. Gama","University of Porto, Portugal","2015 IEEE International Conference on Evolving and Adaptive Intelligent Systems (EAIS)","20160104","2015","","","1","1","Nowadays, there are applications in which the data are modelled best not as persistent tables, but rather as transient data streams. In this keynote, we discuss the limitations of current machine learning and data mining algorithms. We discuss the fundamental issues in learning in dynamic environments like learning decision models that evolve over time, learning and forgetting, concept drift and change detection. Data streams are characterized by huge amounts of data that introduce new constraints in the design of learning algorithms: limited computational resources in terms of memory, processing time and CPU power. In this talk, we present some illustrative algorithms designed to taking these constrains into account. We identify the main issues and current challenges that emerge in learning from data streams, and present open research lines for further developments.","","Electronic:978-1-4673-6698-4; POD:978-1-4673-6699-1; USB:978-1-4673-6697-7","10.1109/EAIS.2015.7368772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368772","","Adaptive systems;Algorithm design and analysis;Change detection algorithms;Conferences;Data mining;Heuristic algorithms;Machine learning algorithms","data mining;learning (artificial intelligence)","CPU power;change detection;computational resources;dynamic environments;keynote speaker;learning algorithms;learning decision models;machine learning;open research lines;real time data mining algorithms;transient data streams","","","","","","","1-3 Dec. 2015","","IEEE","IEEE Conference Publications"
"Learning deep features for image emotion classification","M. Chen; L. Zhang; J. P. Allebach","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN 47906, USA","2015 IEEE International Conference on Image Processing (ICIP)","20151210","2015","","","4491","4495","Images can both express and affect people's emotions. It is intriguing and important to understand what emotions are conveyed and how they are implied by the visual content of images. Inspired by the recent success of deep convolutional neural networks (CNN) in visual recognition, we explore two simple, yet effective deep learning-based methods for image emotion analysis. The first method uses off-the-shelf CNN features directly for classification. For the second method, we fine-tune a CNN that is pre-trained on a large dataset, i.e. ImageNet, on our target dataset first. Then we extract features using the fine-tuned CNN at different location at multiple levels to capture both the global and local information. The features at different location are aggregated using the Fisher Vector for each level and concatenated to form a compact representation. From our experimental results, both the deep learning-based methods outperforms traditional methods based on generic image descriptors and hand-crafted features.","","Electronic:978-1-4799-8339-1; POD:978-1-4799-8340-7","10.1109/ICIP.2015.7351656","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351656","Image emotion;convolutional neural network;deep learning;image classification","Feature extraction;Image recognition;Machine learning;Neural networks;Support vector machines;Training;Visualization","emotion recognition;feature extraction;image classification;image representation;learning (artificial intelligence);neural nets;vectors","Fisher vector;compact representation;deep convolutional neural networks;deep feature learning;feature extraction;image emotion classification;off-the-shelf CNN features;visual recognition","","1","","18","","","27-30 Sept. 2015","","IEEE","IEEE Conference Publications"
"VRank: Voting system on Ranking model for human age estimation","T. Lim; K. L. Hua; H. C. Wang; K. W. Zhao; M. C. Hu; W. H. Cheng","Research Center for Information Technology Innovation (CITI), Academia Sinica, Taipei, 115 Taiwan","2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)","20151203","2015","","","1","6","Ranking algorithms have proven the potential for human age estimation. Currently, a common paradigm is to compare the input face with reference faces of known age to generate a ranking relation whereby the first-rank reference is exploited for labeling the input face. In this paper, we proposed a framework to improve upon the typical ranking model, called Voting system on Ranking model (VRank), by leveraging relational information (comparative relations, i.e. if the input face is younger or older than each of the references) to make a more robust estimation. Our approach has several advantages: firstly, comparative relations can be explicitly involved to benefit the estimation task; secondly, few incorrect comparisons will not influence much the accuracy of the result, making this approach more robust than the conventional approach; finally, we propose to incorporate the deep learning architecture for training, which extracts robust facial features for increasing the effectiveness of classification. In comparison to the best results from the state-of-the-art methods, the VRank showed a significant outperformance on all the benchmarks, with a relative improvement of 5.74% ~ 69.45% (FG-NET), 19.09% ~ 68.71% (MORPH), and 0.55% ~ 17.73% (IoG).","","Electronic:978-1-4673-7478-1; POD:978-1-4673-7479-8","10.1109/MMSP.2015.7340789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7340789","","Bismuth;Estimation;Face;Feature extraction;Machine learning;Robustness;Support vector machines","estimation theory;feature extraction","VRank;deep learning architecture;estimation task;first-rank reference;human age estimation;ranking model;relational information;robust estimation;robust facial features;voting system","","","","30","","","19-21 Oct. 2015","","IEEE","IEEE Conference Publications"
"Towards reliable data feature retrieval and decision engine in host-based anomaly detection systems","W. Haider; J. Hu; M. Xie","School of Engineering and Information Technology, University of New South Wales at the Australian Defence Force Academy, Canberra, Australia","2015 IEEE 10th Conference on Industrial Electronics and Applications (ICIEA)","20151123","2015","","","513","517","Host-based anomaly detection systems (HADS) serves as the second line of defense after cyber attacks have penetrated the network level defense. The major components of reliable HADS includes enriched data source (DS), computational efficient data feature retrieval (DFR), accurate and fast decision engine (DE). ADFA-LD is a recently published data set which reflects the invisible threat environment of modern computer system. The existing HADS utilizing ADFA-LD as DS, exhibits high computational DFR and inferior performance of the DE at real-time. The major drawback is inability to acquire representative features from host activities. Confronting this drawback in this paper, at DFR a character data zero watermark inspired statistical based strategy is developed for integer data to extract hidden reliable or representative features from system calls of the trace. At DE, three supervised machine learning classifiers such as support vector machine (SVM) with linear and radial bases function (RBF) kernels and k-nearest neighbor (KNN) are evaluated across detection rate (DR), false alarm rate (FAR) and computational time. The numerical trials validates that the suggested statistical feature extraction strategy at DFR and KNN at DE can attain acceptable performance at real-time.","","Electronic:978-1-4799-8389-6; POD:978-1-4799-8467-1; USB:978-1-4673-7317-3","10.1109/ICIEA.2015.7334166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334166","Host based intrusion detection systems (HIDS);Low foot print attacks;System calls;Zero-day attacks","Feature extraction;Kernel;Machine learning algorithms;Reliability;Support vector machines;Training;Watermarking","computer network security;feature extraction;learning (artificial intelligence);mechanical engineering computing;pattern classification;statistical analysis","DFR;HADS;KNN;computer system;cyber attack;data feature retrieval;data source;decision engine;host-based anomaly detection system;statistical based strategy;statistical feature extraction strategy;supervised machine learning classifier","","","","32","","","15-17 June 2015","","IEEE","IEEE Conference Publications"
"Reinforcement learning demonstrator for opportunistic spectrum access on real radio signals","C. Moy; A. Nafkha; M. Naoues","CentraleSupelec/IETR, Rennes campus, Cesson-S&#233;vign&#233;, France","2015 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN)","20151203","2015","","","283","284","This demonstration presents a proof-of-concept for opportunistic spectrum access. It particularly focuses on reinforcement learning algorithm called UCB (Upper Confidence Bound) designed by the machine learning community to solve the MAB problem (Multi-Armed Bandit). The demonstrator shows the first worldwide implementation of reinforcement learning algorithms for OSA (opportunistic spectrum access) on real radio environment using USRP N210 platforms.","","Electronic:978-1-4799-7452-8; POD:978-1-4799-7453-5","10.1109/DySPAN.2015.7343919","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7343919","","Algorithm design and analysis;Detectors;Dynamic spectrum access;Heuristic algorithms;Learning (artificial intelligence);Machine learning algorithms","cognitive radio;learning (artificial intelligence);telecommunication computing","MAB problem;OSA;UCB;USRP N210 platforms;cognitive radio;machine learning community;multiarmed bandit;opportunistic spectrum access;real radio signals;reinforcement learning demonstrator;upper confidence bound","","1","","8","","","Sept. 29 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Perceived impact of activities and resources on higher order learning skills in an online course","D. Morin; J. D. E. Thomas; D. Kira","Concordia University, Montreal, Quebec, Canada","2015 World Congress on Information Technology and Computer Applications (WCITCA)","20160104","2015","","","1","6","This paper examines students' perceptions of their acquisition of various higher order thinking skills as developed through the use of various activities and resources in an entirely online Undergraduate Introductory Statistics course. The results indicate that certain activities and resources contribute more to the perception of the development of certain skills than others, which have implications for the design of course content delivered in a virtual or distance environment.","","Electronic:978-1-4673-6636-6; POD:978-1-4673-6637-3","10.1109/WCITCA.2015.7367064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367064","Distance Learning;Higher order Learning;Online learning;Virtual Learning","Cognition;Computer aided instruction;Context;Machine learning;Problem-solving;Tutorials","computer aided instruction;distance learning;educational courses;further education;human factors;statistics","course content design;distance environment;higher order learning skills;higher order thinking skills acquisition;online Undergraduate Introductory Statistics course;student perception;virtual environment","","","","13","","","11-13 June 2015","","IEEE","IEEE Conference Publications"
