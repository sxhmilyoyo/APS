"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6726818,6727216,6726457,6728198,6726447,6727234,6728108,6726198,6727304,6727199,6726493,6728171,6726201,6720779,6722313,6724343,6724163,6724281,6721645,6724370,6722347,6722566,6723841,6722000,6720619,6721666,6722414,6723073,6722634,6724269,6720677,6722128,6720601,6716664,6719012,6719312,6717305,6719307,6718884,6716628,6717260,6719105,6719259,6718280,6716758,6716355,6712400,6710573,6710495,6665155,6709847,6710030,6709997,6710015,6702977,6702809,6704522,6702744,6701495,6701700,6702822,6703770,6707519,6701507,6701564,6701679,6701731,6703181,6705722,6707550,6707768,6705250,6707042,6702910,6704136,6707984,6707728,6704146,6707733,6707795,6679093,6703381,6707000,6701582,6703006,6707786,6694049,6693501,6694278,6693512,6693500,6698888,6693323,6694501,6693407,6693350,6693525,6693561,6693969,6694008",2017/05/04 22:20:11
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Sentiment analysis in twitter using machine learning techniques","M. S. Neethu; R. Rajasree","Dept. of Comput. Sci. & Eng., Coll. of Eng., Trivandrum, India","2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT)","20140130","2013","","","1","5","Sentiment analysis deals with identifying and classifying opinions or sentiments expressed in source text. Social media is generating a vast amount of sentiment rich data in the form of tweets, status updates, blog posts etc. Sentiment analysis of this user generated data is very useful in knowing the opinion of the crowd. Twitter sentiment analysis is difficult compared to general sentiment analysis due to the presence of slang words and misspellings. The maximum limit of characters that are allowed in Twitter is 140. Knowledge base approach and Machine learning approach are the two strategies used for analyzing sentiments from the text. In this paper, we try to analyze the twitter posts about electronic products like mobiles, laptops etc using Machine Learning approach. By doing sentiment analysis in a specific domain, it is possible to identify the effect of domain information in sentiment classification. We present a new feature vector for classifying the tweets as positive, negative and extract peoples' opinion about products.","","Electronic:978-1-4799-3926-8; POD:978-1-4799-3927-5","10.1109/ICCCNT.2013.6726818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726818","Machine Learning Techniques;Sentiment Analysis;Twitter","Entropy;Feature extraction;Speech;Support vector machines;Training;Twitter;Vectors","information retrieval;knowledge based systems;learning (artificial intelligence);natural language processing;pattern classification;social networking (online);text analysis","Twitter sentiment analysis;crowd opinion extraction;domain information;electronic products;feature vector;knowledge base approach;machine learning techniques;opinion classification;opinion identification;sentiment analysis;sentiment classification;sentiment identification;sentiment rich data;social media;source text","","15","1","17","","","4-6 July 2013","","IEEE","IEEE Conference Publications"
"Improving Gloss Vector Semantic Relatedness Measure by Integrating Pointwise Mutual Information: Optimizing Second-Order Co-occurrence Vectors Computed from Biomedical Corpus and UMLS","A. Pesaranghader; S. Muthaiyah; A. Pesaranghader","Fac. of Creative Multimedia, MMU, Cyberjaya, Malaysia","2013 International Conference on Informatics and Creative Multimedia","20140109","2013","","","196","201","Methods of semantic relatedness are essential for wide range of tasks such as information retrieval and text mining. This paper, concerned with these automated methods, attempts to improve Gloss Vector semantic relatedness measure for more reliable estimation of relatedness between two input concepts. Generally, this measure by considering frequency cut-off for big rams tries to remove low and high frequency words which usually do not end up being significant features. However, this naive cutting approach can lead to loss of valuable information. By employing point wise mutual information (PMI) as a measure of association between features, we will try to enforce the foregoing elimination step in a statistical fashion. Applying both approaches to the biomedical domain, using MEDLINE as corpus, MeSH as thesaurus, and available reference standard of 311 concept pairs manually rated for semantic relatedness, we will show that PMI for removing insignificant features is more effective approach than frequency cut-off.","","Electronic:978-0-7695-5133-3; POD:978-1-4799-3702-8","10.1109/ICICM.2013.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702809","Bioinformatics;Biomedical Text Mining;Computational Linguistics;Semantic Relatedness;UMLS","Biomedical measurement;Cutoff frequency;Frequency measurement;Semantics;Taxonomy;Unified modeling language;Vectors","data mining;information retrieval;medical computing;text analysis","MEDLINE;MeSH;PMI;UMLS;biomedical corpus;gloss vector semantic relatedness measure;information retrieval;naive cutting approach;point wise mutual information;pointwise mutual information;second-order co-occurrence vectors;text mining;unified medical language system","","1","","17","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Music classification using extreme learning machines","S. Scardapane; D. Comminiello; M. Scarpiniti; A. Uncini","Dept. of Inf. Eng., Electron. & Telecommun. (DIET), &#x201C;Sapienza&#x201D; Univ. of Rome, Rome, Italy","2013 8th International Symposium on Image and Signal Processing and Analysis (ISPA)","20140109","2013","","","377","381","Over the last years, automatic music classification has become a standard benchmark problem in the machine learning community. This is partly due to its inherent difficulty, and also to the impact that a fully automated classification system can have in a commercial application. In this paper we test the efficiency of a relatively new learning tool, Extreme Learning Machines (ELM), for several classification tasks on publicly available song datasets. ELM is gaining increasing attention, due to its versatility and speed in adapting its internal parameters. Since both of these attributes are fundamental in music classification, ELM provides a good alternative to standard learning models. Our results support this claim, showing a sustained gain of ELM over a feedforward neural network architecture. In particular, ELM provides a great decrease in computational training time, and has always higher or comparable results in terms of efficiency.","1845-5921;18455921","Electronic:978-953-184-194-8; POD:978-1-4799-3125-5; USB:978-953-184-187-0","10.1109/ISPA.2013.6703770","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703770","","Feature extraction;Multiple signal classification;Neural networks;Signal processing;Speech;Standards;Training","audio signal processing;feedforward neural nets;information retrieval;learning (artificial intelligence);music;signal classification","ELM;automated classification system;automatic music classification;automatic music retrieval;extreme learning machines;feedforward neural network architecture;learning tool","","6","","14","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Document Summarization Using Semantic Clouds","A. M. Rinaldi","DIETI - Dipt. di Ing. Elettr. e delle Tecnol. dell'Inf., Univ. di Napoli Federico II, Naples, Italy","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","100","103","Document summarization and visualization techniques take into account important aspects of information retrieval process. They have a great impact on several dimensions of user information perception and relevant information recognition. In this paper we propose a novel summarization strategy to add terms semantically related to the keywords extracted from a single document using a semantic content analysis approach, ontologies, metrics for semantic similarity measure and information visualization. These additional information are extracted from a general knowledge base. The obtained keywords are visualized by means of a bag of words called Semantic Cloud. We evaluate the efficiency of our strategy using a standard test set document collection and we present some user centered experimental results together with a document summarization example.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693501","Document summarization;keyword extraction;ontologies;semantic document analysis;tag clouds","Context;Data mining;Measurement;Pragmatics;Semantics;Tag clouds;Visualization","cloud computing;data visualisation;document handling;information analysis;information retrieval;knowledge based systems;ontologies (artificial intelligence);semantic networks","bag of words;document summarization;document visualization techniques;information retrieval process;information visualization;knowledge base;ontology;relevant information recognition;semantic clouds;semantic content analysis approach;semantic similarity measure metrics;standard test set document collection;summarization strategy;user information perception","","0","","20","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Prioritizing students' mobile centric information access needs: A case of postgraduate students","B. Chipangura; J. A. van Biljon; A. Botha","Sch. of Comput., Univ. of South Africa, Pretoria, South Africa","2013 International Conference on Adaptive Science and Technology","20140109","2013","","","1","7","Students enrolled at Open and Distance Learning (ODL) institutions tend to combine study and work and to succeed they have to optimize free time for studying. Therefore, many ODL students access and interact with information in a mobile context, which implies that interaction takes place in dynamic and changing environments. This presents students with a number of overlapping contextual challenges that need to be managed when accessing and interacting with information. Higher Educational Institutions (HEIs) are also confronted by these challenges as they strive to provide access through technologies that are accessible, usable, scalable and sustainable to students. Against this background, it is important to have an understanding of the categories of information that students would want to access and interact with through the devices that they privately own, of which mobile phones are the most common. This study investigated the categories of information that students would want to access through mobile cellular phones. The data capturing involved both qualitative and quantitative data. In order to get a comprehensive and representative set of information access needs it was necessary to start with open-ended questions. Based on the analysis of the 50 responses to the open-ended questions, fixed-response questions were formulated. The 84 responses to the fixed-response questions were then analyzed to determine the importance of the information access needs as well as the access frequency. The contribution of this paper is a set of prioritized information needs that provide some insight into the mobile centric information needs of students at the University of South Africa (UNISA) as an example of an ODL institution.","2326-9413;23269413","Electronic:978-1-4799-3067-8; POD:978-1-4799-3068-5","10.1109/ICASTech.2013.6707519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707519","information access needs;mobile phone;mobile phone acces","Computer aided instruction;Discussion forums;Educational institutions;Libraries;Materials;Mobile communication;Mobile handsets","cellular radio;computer aided instruction;distance learning;information retrieval;mobile computing","HEI;ODL students access;UNISA;University of South Africa;higher educational institution;mobile cellular phone;mobile centric information access needs;open-and-distance learning;postgraduate student","","0","","33","","","25-27 Nov. 2013","","IEEE","IEEE Conference Publications"
"Identification of Most Contributing Features for Audio Classification","N. P. Patel; M. S. Patwardhan","Dept. of Comput. Eng., VIT, Pune, India","2013 International Conference on Cloud & Ubiquitous Computing & Emerging Technologies","20140109","2013","","","219","223","Audio classification is very essential for faster retrieval of audio files. Extracting best set of features and deciding best analysis method is very important for getting best results of audio classification. In this paper, we have used distinct feature selection methods to identify the most relevant and non-redundant feature set for audio classification into four classes: pure speech, pure music, silence and noise. With these set of features and Support Vector Machine (SVM) as a classifier we have got the precision of 99.8% and recall of 99.9%, which is more promising than the previous approaches.","","Electronic:978-1-4799-2235-2; POD:978-1-4799-2236-9","10.1109/CUBE.2013.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701507","Audio Feature extraction;Audio Feature selection;Audio Signal Processing;SVM","Accuracy;Feature extraction;Mel frequency cepstral coefficient;Method of moments;Noise;Speech;Support vector machines","audio signal processing;feature extraction;information retrieval;music;signal classification;speech processing;support vector machines","SVM classifier;audio classification;audio files retrieval;best analysis method;distinct feature selection methods;features extraction;noise;pure music;pure speech;silence;support vector machine","","1","","10","","","15-16 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Synergistic Framework for Geographic Question Answering","W. Chen; E. Fosler-Lussier; N. Xiao; S. Raje; R. Ramnath; D. Sui","Dept. of Comput. Sci. & Eng., Ohio State Univ. Columbus, Columbus, OH, USA","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","94","99","QA (question answering) systems designated for answering in-depth geographic questions are highly demanded but not quite available. Previous research has visited various individual aspects of a QA system but few synergistic frameworks have been proposed. This paper investigates the nature of geographic question formation and observes their unique linguistic structures that can be semantically translated into a spatial query. We create a new task of solving non-trivial questions using GIS (Geographic Information System) and test it with an associated corpus. A dynamic programming algorithm is developed for classification and voting algorithm for verification. Two types of ontologies are integrated for disambiguating and discriminating spatial terms. PostGIS serves as the GIS backend to provide domain expertise for spatial reasoning. Results show that exact answers can be returned quickly and correctly by our system. Contrast classification results in improved accuracy compared with the baseline which proves the effectiveness of proposed methods.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693500","dynamic programming;gis;machine learning;nlp;ontology;question answering;spatial SQL;voting algorithm","Accuracy;Cities and towns;Classification algorithms;Feature extraction;Geographic information systems;Knowledge discovery;Ontologies","computational linguistics;dynamic programming;geographic information systems;ontologies (artificial intelligence);pattern classification;question answering (information retrieval);spatial reasoning","PostGIS;QA system;associated corpus;contrast classification;dynamic programming algorithm;geographic information system;geographic question answering;geographic question formation;linguistic structures;nontrivial questions;ontologies;question answering system;spatial query;spatial reasoning;spatial terms;synergistic framework;voting algorithm","","2","","27","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Med-Tree: A user knowledge graph framework for medical applications","M. S. Desarkar; S. Bhaumik; S. K. Sathish; S. Singh; R. V. Narayanan","Advanced Web group at SRI-B","13th IEEE International Conference on BioInformatics and BioEngineering","20140109","2013","","","1","4","The field of context and intelligence, as a topic of pervasive computing, has been gaining considerable momentum. Typically, context-aware intelligence is applied to understand the situation of the users and their behavior with the objective of providing adaptive services that are closely associated with that context. In this work, we have taken an orthogonal approach wherein we attempt to aggregate knowledge and cognition, of the user, on a given topic to build models out of them. The model thus created is analyzed to derive inferences about the user, where the analysis is performed on a graph model comprising topics based information obtained by mining domain specific personal data sources and from certain facts on which the user has expressed fair level of belief. We have explored the possibility of deriving beneficial information by provisioning an appropriate representation of knowledge as belief-graph with specific orientation in healthcare and call this model as Med-Tree. Subject to privacy conditions, we open up the belief-graph model to establish objective based social connections that gets contextually bound. As a next step, such contextually bound ad-hoc networks are subjected to advanced querying process resulting in useful information extraction and inferences. Leveraging on user's knowledge or the belief-graph, the proposed Med-Tree could help derive benefits towards better personal healthcare and disease management.","","Electronic:978-1-4799-3163-7; POD:978-1-4799-3164-4","10.1109/BIBE.2013.6701564","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701564","","Breast cancer;Context;Data models;Diseases;Electronic mail;Medical diagnostic imaging","data mining;graph theory;health care;inference mechanisms;information retrieval;medical computing;ubiquitous computing","Med-Tree;belief-graph model;context-aware intelligence;disease management;healthcare;information extraction;information inferences;knowledge representation;medical applications;personal data sources;pervasive computing;user knowledge graph framework","","0","","15","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"LightWAVE: Waveform and annotation viewing and editing in aWeb browser","G. B. Moody","Massachusetts Inst. of Technol., Cambridge, MA, USA","Computing in Cardiology 2013","20140116","2013","","","17","20","This paper describes LightWAVE, recently-developed open-source software for viewing ECGs and other physiologic waveforms and associated annotations (event markers). It supports efficient interactive creation and modification of annotations, capabilities that are essential for building new collections of physiologic signals and time series for research. LightWAVE is constructed of components that interact in simple ways, making it straightforward to enhance or replace any of them. The back end (server) is a common gateway interface (CGI) application written in C for speed and efficiency. It retrieves data from its data repository (PhysioNet's open-access PhysioBank archives by default, or any set of files or web pages structured as in PhysioBank) and delivers them in response to requests generated by the front end. The front end (client) is a web application written in JavaScript. It runs within any modern web browser and does not require installation on the user's computer, tablet, or phone. Finally, LightWAVE's scribe is a tiny CGI application written in Perl, which records the user's edits in annotation files. LightWAVE's data repository, back end, and front end can be located on the same computer or on separate computers. The data repository may be split across multiple computers. For compatibility with the standard browser security model, the front end and the scribe must be loaded from the same domain.","0276-6574;02766574","Electronic:978-1-4799-0886-8; POD:978-1-4799-0885-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6712400","","Browsers;Computers;Libraries;Standards;Web servers","Java;electrocardiography;information retrieval;medical computing;online front-ends;public domain software;time series","ECG;JavaScript;Perl;PhysioBank;Web application;annotation viewer;common gateway interface application;data repository;interactive creation;lightWAVE;modern Web browser;open-source software;physiologic waveforms;standard browser security model;time series;tiny CGI application;waveform and annotation viewing and editing","","0","","9","","","22-25 Sept. 2013","","IEEE","IEEE Conference Publications"
"HiCrawl: A Hidden Web Crawler for Medical Domain","S. Gupta; K. K. Bhatia","Dept. of Comput. Eng., YMCA Univ. of Sci. & Technol., Faridabad, India","2013 International Symposium on Computational and Business Intelligence","20140127","2013","","","152","157","The Hidden Web refers to a huge portion of the WWW that holds numerous freely accessible Web databases, hidden behind search form interfaces which can only be accessed through dynamic web pages that are generated in response to the user queries issued at the search form interface. Thus, the core challenge to implement any crawler for the Hidden Web is to routinely surpass these search form interfaces by automatically generating & issuing queries that help discover these dynamic Web pages. The paper provides a novel approach to guide the crawler in choosing the right query term to be submitted to any search form interface that has been designed to accept keywords or terms as input to it. The system is based on the use of classification hierarchies that might have either been manually or automatically constructed. And for the purposes of illustration, we have considered the search form interfaces in the 'Medical' domain, it being one of the most popular domains used by the researchers and the use of a manually generated top-down classification hierarchy in the same domain.","","Electronic:978-0-7695-5066-4; POD:978-1-4799-0998-8","10.1109/ISCBI.2013.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724343","Content Retrieval;Hidden Web;Surface Web;WWW;automatic form filling;crawlers;form processing","Crawlers;Databases;Larynx;Lungs;Nose;Web pages","Internet;information retrieval;medical information systems;search engines","HiCrawl;Web database;World Wide Web;classification hierarchy;dynamic Web pages;hidden Web crawler;medical domain","","0","","17","","","24-26 Aug. 2013","","IEEE","IEEE Conference Publications"
"Domain knowledge enriched framework for restricted domain question answering system","N. Malik; A. Sharan; P. Biswas","Sch. of Comput. & Syst. Sci., Jawahar Lal Nehru Univ., New Delhi, India","2013 IEEE International Conference on Computational Intelligence and Computing Research","20140127","2013","","","1","7","The field of question answering is a very fertile area of research. Till now most of the work that has been done in this area is either in open or closed domain. Restricted domain question answering is emerging as more appropriate and challenging area of research. This paper presents a generic architecture for development of a restricted domain question answering system with a focus on domain knowledge. The paper emphasizes on intelligently combining the domain knowledge and NLP resources in different stages of development of the system.","","Electronic:978-1-4799-1597-2; POD:978-1-4799-1596-5","10.1109/ICCIC.2013.6724163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724163","answer processing;ontology;question Answering;question processing;restricted domain question answering","Computers;Knowledge based systems;Knowledge discovery;Natural languages;Ontologies;Search engines","natural language processing;question answering (information retrieval)","NLP resources;domain knowledge enriched framework;generic architecture;restricted domain question answering system;restricted domain question answering system development","","0","","14","","","26-28 Dec. 2013","","IEEE","IEEE Conference Publications"
"An eigenvalues analysis with entropy-per-chroma feature","A. Manzo-Mart√≠nez; A. Camarena-Ibarrola","Inst. Tecnol. de Morelia, Morelia, Mexico","2013 IEEE International Autumn Meeting on Power Electronics and Computing (ROPEC)","20140109","2013","","","1","6","A variety of audio features have been proposed for describing the music in the last decades. These features are used in various ways, for instance as inputs to different music information retrieval systems. Most, if not all, aim for capturing the essential perceptive characteristics of the audio-signal that are not present in its temporal representation. In this work we analyze entropy-per-chroma feature on a basis of eigenvalues decomposition. This feature has been successfully applied on audio-fingerprinting-based audio recognition systems. We show that involving eigenvalues decomposition contributes for an even more robust audio feature which may be used in audio matching task. In the experiments we used a set of performances of polyphonic music. We equated two versions of a same performance in order to prove that both performances yield almost the same set of features despite being performance by another musician and/or different instruments.","","Electronic:978-1-4799-2370-0; POD:978-1-4799-3924-4","10.1109/ROPEC.2013.6702744","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702744","Audio Features;Chroma;Eigenvalues;Entropy","Eigenvalues and eigenfunctions;Entropy;Feature extraction;Histograms;Robustness;Time series analysis;Vectors","audio signal processing;eigenvalues and eigenfunctions;information retrieval systems;music","audio features;audio matching task;audio-fingerprinting-based audio recognition systems;audio-signal;eigenvalues analysis;eigenvalues decomposition;entropy-per-chroma feature;music information retrieval systems;polyphonic music;robust audio feature;temporal representation","","0","","20","","","13-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Method of Automatic Semantic Annotation of 3D Model Based on Content Feature","Z. Liu; L. Li","Fac. of Comput. Eng., Huaiyin Inst. of Technol., Huai'an, China","2013 International Conference on Information Technology and Applications","20140111","2013","","","324","327","In response to the existing problem of 3D model semantic retrieval, a method of automatic semantic annotation of 3D model based on content feature is proposed on the basis of Word Net. According to the similarity of content features, this method selects the annotation vocabularies to construct a vocabulary set. Then, some appropriate vocabularies can be selected from the vocabulary set to annotate the 3D models by the similarity between the 3D model to be annotated and the vocabularies in the vocabulary set. In the experiments, three relative parameters are optimized to improve the performance and efficiency. Proved by the experiments, this method proposed in this paper can solve the semantic gap problem. The performance and efficiency of the method is pretty good.","","Electronic:978-1-4799-2877-4; POD:978-1-4799-2878-1","10.1109/ITA.2013.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6709997","3D Model;Content Feature;Semantic Annotation;Similarity","Computational modeling;Equations;Mathematical model;Semantics;Solid modeling;Three-dimensional displays;Vocabulary","information retrieval;natural language processing;vocabulary","3D model semantic retrieval;Word Net;annotation vocabularies;automatic semantic annotation method;content feature;semantic gap problem","","0","","8","","","16-17 Nov. 2013","","IEEE","IEEE Conference Publications"
"OnTheFly 2.0: A tool for automatic annotation of files and biological information extraction","E. Pafilis; G. A. Pavlopoulos; V. P. Satagopam; N. Papanikolaou; H. Horn; C. Arvanitidis; L. J. Jensen; R. Schneider; I. Iliopoulos","Inst. of Marine Biol., Biotechnol. & Aquacultures (IMBBC), Hellenic Center for Marine Res. (HCMR), Heraklion, Greece","13th IEEE International Conference on BioInformatics and BioEngineering","20140109","2013","","","1","4","Retrieving all of the necessary information from databases about bioentities mentioned in an article is not a trivial or an easy task. Following the daily literature about a specific biological topic and collecting all the necessary information about the bioentities mentioned in the literature manually is tedious and time consuming. OnTheFly 2.0 is a web application mainly designed for non-computer experts which aims to automate data collection and knowledge extraction from biological literature in a user friendly and efficient way. OnTheFly 2.0 is able to extract bioentities from individual articles such as text, Microsoft Word, Excel and PDF files. With a simple drag-and-drop motion, the text of a document is extensively parsed for bioentities such as protein/gene names and chemical compound names. Utilizing high quality data integration platforms, OnTheFly allows the generation of informative summaries, interaction networks and at-a-glance popup windows containing knowledge related to the bioentities found in documents. OnTheFly 2.0 provides a concise application to automate the extraction of bioentities hidden in various documents and is offered as a web based application. It can be found at: http://onthefly.embl.de, http://onthefly.med.uoc.gr or http://onthefly.hcmr.gr.","","Electronic:978-1-4799-3163-7; POD:978-1-4799-3164-4","10.1109/BIBE.2013.6701679","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701679","","Bioinformatics;Databases;Electronic mail;Organisms;Protein engineering;Proteins","Internet;biology computing;data integration;genetics;information retrieval;knowledge acquisition;text analysis","Microsoft Excel files;Microsoft Word files;OnTheFly 2.0;PDF files;Web application;at-a-glance popup window generation;automatic file annotation;bioentity extraction;biological information extraction;biological topic;chemical compound names;data collection automation;data integration platforms;drag-and-drop motion;gene names;informative summary generation;interaction network generation;knowledge extraction automation;protein names","","0","","18","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"Finding test data with specific properties via metaheuristic search","R. Feldt; S. Poulding","Dept. of Comput. Sci. & Eng., Chalmers Univ. of Technol., Goteborg, Sweden","2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE)","20140102","2013","","","350","359","For software testing to be effective the test data should cover a large and diverse range of the possible input domain. Boltzmann samplers were recently introduced as a systematic method to randomly generate data with a range of sizes from combinatorial classes, and there are a number of automated testing frameworks that serve a similar purpose. However, size is only one of many possible properties that data generated for software testing should exhibit. For the testing of realistic software systems we also need to trade off between multiple different properties or search for specific instances of data that combine several properties. In this paper we propose a general search-based framework for finding test data with specific properties. In particular, we use a metaheuristic, differential evolution, to search for stochastic models for the data generator. Evaluation of the framework demonstrates that it is more general and flexible than existing solutions based on random sampling.","1071-9458;10719458","Electronic:978-1-4799-2366-3; POD:978-1-5090-4462-7","10.1109/ISSRE.2013.6698888","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698888","","Adaptation models;Arrays;Data models;Generators;Grammar;Testing","data structures;evolutionary computation;information retrieval;program testing","Boltzmann samplers;automated testing frameworks;combinatorial classes;data generator;data structures;differential evolution;general search-based framework;metaheuristic search;random sampling;realistic software systems;software testing;test data","","7","","19","","","4-7 Nov. 2013","","IEEE","IEEE Conference Publications"
"A searchable encryption of CP-ABE scheme in cloud storage","A. P. Xiong; Q. X. Gan; X. X. He; Q. Zhao","Sch. of Comput. Sci. & Technol., Chongqing Univ. of Posts & Telecommun., Chongqing, China","2013 10th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20140123","2013","","","345","349","Cloud storage is an important service of cloud computing, which offers services for data owners to host their data in the cloud. But cloud computing also brings new and challenging security threats to the outsourced data. In order to regain security assurances and access control in the cloud storage, we analyzes the access control algorithm of Ciphertext-policy attribute-based encryption. In this paper, we combining a security homomorphic encryption algorithm with the traditional CP-ABE algorithm, we constructed a Searchable Encryption CP-ABE (SE-CP-ABE) access control scheme, and give the security analysis and experimental analysis for the scheme. The experimental results show that SE-CP-ABE scheme is not only ensures the security of CP-ABE, but also implements ciphertext retrieval and reduces the retrieval time.","","CD-ROM:978-1-4799-2444-8; Electronic:978-1-4799-2446-2; POD:978-1-4799-2447-9","10.1109/ICCWAMTIP.2013.6716664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716664","Access Control;CP-ABE;Ciphertext Retrieval;Cloud Storage;Homomorphic Encryption","Access control;Algorithm design and analysis;Cloud computing;Encryption;Games","access control;cloud computing;cryptography;information retrieval;storage management","SE-CP-ABE access control scheme;ciphertext retrieval;ciphertext-policy attribute-based encryption;cloud computing;cloud storage;outsourced data;searchable encryption;security threats","","0","","11","","","17-19 Dec. 2013","","IEEE","IEEE Conference Publications"
"Digital Archive and Exhibiting Methods of a Buddhist Ceremonial Procession","A. Soga; Y. Niwa; M. Shiba; Y. Okada","Fac. of Sci. & Technol., Ryukoku Univ., Otsu, Japan","2013 International Conference on Signal-Image Technology & Internet-Based Systems","20140130","2013","","","372","377","Our research group has been archiving a Buddhist ceremonial procession called Nerikuyo. Nerikuyo has special features in its walking movements and actions. It is difficult to display these features using traditional panels in a museum. Our purpose is to create videos and interactive content that vividly describe this ceremony. We have archived the ceremony with super-high-detail videos and then created video contents for a special exhibition on Nerikuyo. We have also proposed a virtual fitting system that recognizes poses or gestures of users and then displays the corresponding images and sounds over the captured images of the users. All of the gestures are related to the poses or motions of Nerikuyo, and they are assigned to masks and tools. The created videos were shown at a special exhibition of the Ryukoku Museum, and the proposed system was demonstrated for three days as one of the related events of the special exhibition.","","Electronic:978-1-4799-3211-5; POD:978-1-4799-3212-2","10.1109/SITIS.2013.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727216","4K;Nerikuyo;digital archive;interactive system;museum","Bridges;Cameras;Fitting;Head;Image recognition;Three-dimensional displays;Videos","cultural aspects;feature extraction;gesture recognition;image capture;image motion analysis;information retrieval systems;interactive video;museums;pose estimation","Buddhist ceremonial procession;Nerikuyo;Ryukoku Museum;digital archive methods;digital exhibiting methods;image capture;interactive content;super-high-detail videos;user gesture recognition;user pose recognition;video contents;virtual fitting system;walking actions;walking movements","","0","","5","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Multi-tweet Summarization of Real-Time Events","M. A. H. Khan; D. Bollegala; G. Liu; K. Sezaki","Grad. Sch. of Inf. Sci. & Technol., Univ. of Tokyo, Tokyo, Japan","2013 International Conference on Social Computing","20140102","2013","","","128","133","Popular real-time public events often cause upsurge of traffic in Twitter while the event is taking place. These posts range from real-time update of the event's occurrences highlights of important moments thus far, personal comments and so on. A large user group has evolved who seeks these live updates to get a brief summary of the important moments of the event so far. However, major social search engines including Twitter still present the tweets satisfying the Boolean query in reverse chronological order, resulting in thousands of low quality matches agglomerated in a prosaic manner. To get an overview of the happenings of the event, a user is forced to read scores of uninformative tweets causing frustration. In this paper, we propose a method for multi-tweet summarization of an event. It allows the search users to quickly get an overview about the important moments of the event. We have proposed a graph-based retrieval algorithm that identifies tweets with popular discussion points among the set of tweets returned by Twitter search engine in response to a query comprising the event related keywords. To ensure maximum coverage of topical diversity, we perform topical clustering of the tweets before applying the retrieval algorithm. Evaluation performed by summarizing the important moments of a real-world event revealed that the proposed method could summarize the proceeding of different segments of the event with up to 81.6% precision and up to 80% recall.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693323","Social network analysis;Text mining;Tweet summarization;Twitter search","Clustering algorithms;Hidden Markov models;Linear programming;Real-time systems;Search engines;Twitter;Vectors","Boolean algebra;graph theory;information retrieval;search engines;social networking (online);text analysis","Boolean query;Twitter search engine;graph-based retrieval algorithm;multitweet summarization;real-time public event;social search engine;topical clustering;topical diversity","","2","","22","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"A novel distributed algorithm for redundant reader elimination in RFID networks","Meng Ma; Ping Wang; Chao-Hsien Chu","Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China","2013 IEEE International Conference on RFID-Technologies and Applications (RFID-TA)","20140102","2013","","","1","6","Redundant reader is a typical problem which consumes additional power and algorithm overhead for Radio Frequency Identification (RFID) systems development. Therefore, eliminating redundant readers is of great importance to prolong the lifetime of RFID systems. In this paper, we propose a distributed algorithm for redundant reader elimination based on neighboring coverage density (NCD). We also elaborate an optimization scheme leveraging partially movement detection (MD) in RFID systems, called NCDMD. The NCDMD algorithm achieves significant optimization in tag-write operation over NCD. Our experiments show that NCD and NCDMD algorithm are effective and of low overheads as compared to other distributed algorithms. In the performance simulation, we analyze the multi-phase scheme principle and its effect. NCD and NCDMD algorithm can further improve the performance of multi-phase approach in redundant reader elimination.","","Electronic:978-1-4799-2114-0; POD:978-1-4799-2116-4","10.1109/RFID-TA.2013.6694501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694501","RFID networks;neighboring coverage density;reader redundancy;redundant reader elimination","Chaotic communication;Complexity theory;Educational institutions;Low earth orbit satellites;Optimization;Topology","distributed algorithms;information retrieval;optimisation;radiofrequency identification;telecommunication computing","NCDMD algorithm;RFID networks;movement detection;multiphase scheme principle;neighboring coverage density;novel distributed algorithm;optimization scheme;radio frequency identification systems;redundant reader elimination;tag-write operation","","0","","20","","","4-5 Sept. 2013","","IEEE","IEEE Conference Publications"
"Innovative ICT public awareness campaign strategy to communicate environmental sustainability in Africa","W. Okaka; J. Apil","Fac. of Educ., Kyambogo Univ., Kampala, Uganda","2013 IST-Africa Conference & Exhibition","20140109","2013","","","1","9","This paper uses lessons learned from a recent study done in Uganda (East Africa) to show case the urgent need to mainstream the ICTs in environmental policy awareness communication strategy. A recent multimedia public communications campaigns evaluation study conducted in Uganda has indicated that electronic media was the most accessible channels in delivering environmental policy messages countrywide. The problem was based on the assumptions that the campaigns strategy for the national wetlands policy awareness in Uganda has for along time been less successful because it did not focus on the right media strategy with respect to the target audience participation and audience demographic characteristics. There was no gender barrier to information uptake. Low income and education levels were barriers to community access to wetlands information. The study found that the socio-economic backgrounds of the audiences were identical in their access to public information and the types of media used in the campaigns. A combined use of ICTs with human interactions enhances audience exposure to environment messages.","","Electronic:978-1-905824-38-0; POD:978-1-4673-5664-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701731","ICTs policy;awareness;communication;environmental sustainability","Africa;Communities;Education;Entertainment industry;Media;Meteorology;Technological innovation","environmental legislation;environmental science computing;information retrieval;innovation management;multimedia systems;socio-economic effects;sustainable development;wetlands","East Africa;Uganda;audience demographic characteristics;audience participation;electronic media;environmental policy awareness communication strategy;environmental policy messages;environmental sustainability;human interactions;innovative ICT public awareness campaign strategy;low education levels;low income levels;multimedia public communication campaign evaluation study;national wetlands policy awareness;public information;socio-economic backgrounds;wetlands information access","","0","","14","","","29-31 May 2013","","IEEE","IEEE Conference Publications"
"Information inquiry for research institutions: A semantic web based approach","Y. Li; X. Wei","Dongguan Cleaner Production Center, Dongguan Univ. of Technol., Dongguan, China","2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering","20140109","2013","1","","476","479","Conventionally, when the administration needs to learn the work of its research institutions, the most popular form is handing out various survey reports. Due to the difference in the platforms and vocabularies used by research institutions and their administrations, it is hard to completely automate this task and thus it takes a lot of time for the institutions to manually fill out these reports. To fill this gap, this paper employs the semantic web technologies to develop an information inquiry system for research institutions. First, we extract and preprocess the entity information from the institutions. Then we use the ontology language to describe the logical relations between entities like organizations, people and projects. Thus an institution-oriented functional ontology is constructed, which is capable of logical reasoning. Next, with self-defined rules, we also incorporate the generic rule engine to realize the functionality of information retrieval. Finally, by treating this system as the service provider in the architecture of the semantic web services, we fulfill the separation of query content from query format and enable the interoperable machine-to-machine interaction over a network. Therefore, both the administrations and the institutions can use their own language to pose or process the query. Such a system not only demonstrates the power of semantic web, but also provides a portal for the exchange and sharing of information between research institutions and their administrations.","2155-1456;21551456","Electronic:978-1-4799-0245-3; POD:978-1-4799-0243-9","10.1109/ICIII.2013.6702977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702977","information inquiry;ontology modeling;semantic web;web service","Cognition;Databases;Engines;Ontologies;Semantic Web;Semantics;Web services","information retrieval;research initiatives;semantic Web","entity information;generic rule engine;information inquiry;information retrieval;institution oriented functional ontology;interoperable machine-to-machine interaction;logical reasoning;logical relations;ontology language;query content;query format;research institutions;self-defined rules;semantic Web services;semantic Web technologies","","0","","15","","","23-24 Nov. 2013","","IEEE","IEEE Conference Publications"
"Searching and Establishment of S-P-O Relationships for Linked RDF Graphs: An Adaptive Approach","A. Chakraborty; S. Munshi; D. Mukhopadhyay","Dept. of Comput. Sci. Eng., Techno India Coll. of Technol., Kolkata, India","2013 International Conference on Cloud & Ubiquitous Computing & Emerging Technologies","20140109","2013","","","156","160","In the coming era of semantic web linked data analysis is a very burning issue for efficient searching and retrieval of information. One way of establishing this link is to implement subject-predicate-object relationship through Set Theory approach which is already done in our previous work. For analyzing inter-relationship between two RDF Graphs, RDFSchema(RDFS) should also be taken care of. In the present paper, an adaptive combination rule based framework has been proposed for establishment of S-P-O (Subject-Predicate-Object)relationship and RDF Graph searching is reported. Hence the identification of criteria for inter-relationship of RDF Graphs opens up new road in semantic search.","","Electronic:978-1-4799-2235-2; POD:978-1-4799-2236-9","10.1109/CUBE.2013.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701495","Blank Node;Dampster Shafer Rule;Pattern analyzer;RDF Graph;RDF Graph Relation;RDFSet;Subject-Predicate-Object;Triple;URISequence;adaptiveness","Data models;Green products;Resource description framework;Search problems;Semantics","data analysis;graph theory;information retrieval;knowledge based systems;semantic Web;set theory","RDF graph searching;RDFSchema(RDFS);S-P-O relationships;adaptive approach;adaptive combination rule based framework;information retrieval;information searching;interrelationship analysis;linked RDF graphs;linked data analysis;semantic Web;semantic search;set theory approach;subject-predicate-object relationship","","1","","16","","","15-16 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Dynamic Replication Mechanism to Reduce Response-Time of I/O Operations in High Performance Computing Clusters","E. M. Khaneghah; S. L. Mirtaheri; L. Grandinetti; A. S. Memaripour; M. Sharifi","Center of High Performance Comput. for Parallel & Distrib. Process., Univ. of Calabria, Rende, Italy","2013 International Conference on Social Computing","20140102","2013","","","738","743","Extraordinary large datasets of high performance computing applications require improvement in existing storage and retrieval mechanisms. Moreover, enlargement of the gap between data processing and I/O operations' throughput will bound the system performance to storage and retrieval operations and remarkably reduce the overall performance of high performance computing clusters. File replication is a way to improve the performance of I/O operations and increase network utilization by storing several copies of every file. Furthermore, this will lead to a more reliable and fault-tolerant storage cluster. In order to improve the response time of I/O operations, we have proposed a mechanism that estimates the required number of replicas for each file based on its popularity. Besides that, the remaining space of storage cluster is considered in the evaluation of replication factors and the number of replicas is adapted to the storage state. We have implemented the proposed mechanism using HDFS and evaluated it using MapReduce framework. Evaluation results prove its capability to improve the response time of read operations and increase network utilization. Consequently, this mechanism reduces the overall response time of read operations by considering files' popularity in replication process and adapts the replication factor to the cluster state.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693407","Adaptive Storage;Dynamic Replication;File Replication;File Systems","Bandwidth;High performance computing;History;Reliability;System performance;Throughput;Time factors","distributed databases;information retrieval systems;input-output programs;parallel processing","HDFS;IO operation response-time;MapReduce framework;cluster state;dynamic replication mechanism;file popularity;high performance computing applications;high performance computing clusters;large datasets;network utilization;read operations;replication process;retrieval mechanisms;storage mechanisms","","0","","21","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"A Multi-objective Solution for Retrieving Class Diagrams","W. K. G. Assun√ß√£o; S. R. Vergilio","DINF, Fed. Univ. of Parana (UFPR), Curitiba, Brazil","2013 Brazilian Conference on Intelligent Systems","20140130","2013","","","249","255","A problem related to software reuse is to locate and retrieve, from a repository, the most suitable model, such as the UML class diagram. The search space is generally huge, and several characteristics (objectives) need to be considered. Similar software engineering problems, which are dependent on different measures, have been efficiently solved by using multi-objective algorithms. Considering this fact, the goal of this paper is to introduce a multi-objective solution for retrieving class diagrams. This solution considers as objectives structural and semantic characteristics of models in a repository. Preliminary results with NSGA-II show that the solutions obtained by the multi-objective algorithm constitute better options to the developer than that ones based on simple GAs.","","Electronic:978-0-7695-5092-3; POD:978-1-4799-1271-1","10.1109/BRACIS.2013.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726457","Software reuse;UML;evolutionary algorithms","Genetic algorithms;Object oriented modeling;Semantics;Sociology;Software;Statistics;Unified modeling language","Unified Modeling Language;genetic algorithms;information retrieval;software reusability","NSGA-II;UML class diagram;Unified Modeling Language;class diagrams retrieval;multiobjective;multiobjective algorithms;multiobjective solution;nondominated sorting genetic algorithms;search space;simple GA;software engineering;software reuse","","0","","28","","","19-24 Oct. 2013","","IEEE","IEEE Conference Publications"
"Entity Matching in Online Social Networks","O. Peled; M. Fire; L. Rokach; Y. Elovici","Dept. of Inf. Syst. Eng., Ben Gurion Univ., Beer-Sheva, Israel","2013 International Conference on Social Computing","20140102","2013","","","339","344","In recent years, Online Social Networks (OSNs) have essentially become an integral part of our daily lives. There are hundreds of OSNs, each with its own focus and offers for particular services and functionalities. To take advantage of the full range of services and functionalities that OSNs offer, users often create several accounts on various OSNs using the same or different personal information. Retrieving all available data about an individual from several OSNs and merging it into one profile can be useful for many purposes. In this paper, we present a method for solving the Entity Resolution (ER), problem for matching user profiles across multiple OSNs. Our algorithm is able to match two user profiles from two different OSNs based on machine learning techniques, which uses features extracted from each one of the user profiles. Using supervised learning techniques and extracted features, we constructed different classifiers, which were then trained and used to rank the probability that two user profiles from two different OSNs belong to the same individual. These classifiers utilized 27 features of mainly three types: name based features (i.e., the Soundex value of two names), general user info based features (i.e., the cosine similarity between two user profiles), and social network topological based features (i.e., the number of mutual friends between two users' friends list). This experimental study uses real-life data collected from two popular OSNs, Facebook and Xing. The proposed algorithm was evaluated and its classification performance measured by AUC was 0.982 in identifying user profiles across two OSNs.","","Electronic:978-0-7695-5137-1; POD:978-1-4799-1519-4","10.1109/SocialCom.2013.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693350","Entity Resolution;Machine Learning;Online Social Networks","Crawlers;Erbium;Facebook;Feature extraction;Training;Vectors","information retrieval;learning (artificial intelligence);social networking (online);topology","AUC;ER;Facebook;OSN;Xing;available data retrieval;entity matching;entity resolution;extracted features;machine learning techniques;online social networks;personal information;social network topological based features;supervised learning techniques;user profile matching","","15","1","9","","","8-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Extracting Cybersecurity Related Linked Data from Text","A. Joshi; R. Lal; T. Finin; A. Joshi","Comput. Sci. & Electr. Eng., Univ. of Maryland, Baltimore, MD, USA","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","252","259","The Web is typically our first source of information about new software vulnerabilities, exploits and cyber-attacks. Information is found in semi-structured vulnerability databases as well as in text from security bulletins, news reports, cyber security blogs and Internet chat rooms. It can be useful to cyber security systems if there is a way to recognize and extract relevant information and represent it as easily shared and integrated semantic data. We describe such an automatic framework that generates and publishes a RDF linked data representation of cyber security concepts and vulnerability descriptions extracted from the National Vulnerability Database and from text sources. A CRF-based system is used to identify cybersecurity-relatedentities, concepts and relations in text, which are then represented using custom ontologies for the cyber security domain and also mapped to objects in the DBpedia knowledge base. The resulting cyber security linked data collection can be used for many purposes, including automating early vulnerability identification, mitigation and prevention efforts.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693525","cybeesecurity;information extraction;linked data;ontology","Computer crime;Data mining;Ontologies;Resource description framework;Software","Internet;data structures;information retrieval;meta data;ontologies (artificial intelligence);security of data;statistical analysis;text analysis","CRF-based system;DBpedia knowledge base;National Vulnerability Database;RDF linked data representation;Web;conditional random field;cybersecurity linked data collection;cybersecurity related linked data extraction;cybersecurity-related concepts;cybersecurity-related entities;cybersecurity-related relations;vulnerability descriptions","","6","","25","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Keyword bid ranking system on the search engine business value impact","W. Lai; L. Chen","Dept. of Inf. Manage., Beijing Inf. Sci. & Technol. Univ., Beijing, China","2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering","20140109","2013","2","","439","443","This article describes the main profit model as the Internet company's search engine advertising, leads the search engine, users, customers tripartite relationship of the game, the game presents a search engine based on the core technology, and gives the model to analyze three different circumstances affecting revenues and Search engine commercial value factor. From the standpoint of the search engine, in order to improve the commercial value of the conclusions should have.","2155-1456;21551456","Electronic:978-1-4799-0245-3; POD:978-1-4799-0243-9","10.1109/ICIII.2013.6703181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703181","Bidding rank;Commercial value;Search engine advertising","Advertising;Engines;Games;Industries;Internet;Search engines","advertising data processing;business data processing;computer games;information retrieval;profitability;search engines;tendering","Internet company search engine advertisement;keyword bid ranking system;profit model;search engine business value impact;search engine commercial value factor;search engine-user-customer tripartite game relationship","","0","","14","","","23-24 Nov. 2013","","IEEE","IEEE Conference Publications"
"Mining relationships among user clusters in Facebook for language learning","C. Troussas; M. Virvou; J. Caro; K. J. Espinosa","Dept. of Inf., Univ. of Piraeus, Piraeus, Greece","2013 International Conference on Computer, Information and Telecommunication Systems (CITS)","20140109","2013","","","1","5","This paper describes the mining of relationships among user clusters in Facebook for tutoring languages. In this study, we have visualized the Facebook user characteristics used in classification procedure. We applied K-means clustering algorithm to determine the groups of users with the same learning styles and capabilities. The aforementioned algorithm groups them by taking as input, to initialize the process, several fundamental user characteristics. Our study exploits the fact that tutoring systems have a large number of users and we use a machine learning reasoning mechanism, which is based on recognized similarities between them. The overall goal of this data mining process is to extract information from the user data set and transform it into an understandable structure for further use. Future plans include deeper study on the relationship between the different Facebook characteristics and clarifying which characteristic has the strongest effect on the clustering procedure.","","Electronic:978-1-4799-0168-5; POD:978-1-4799-0167-8","10.1109/CITS.2013.6705722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6705722","Social Networking Sites;data mining;k-means algorithm;language learning;user characteristics","Clustering algorithms;Computers;Data mining;Educational institutions;Facebook","data mining;data visualisation;information retrieval;intelligent tutoring systems;learning (artificial intelligence);natural language processing;pattern classification;pattern clustering;social networking (online)","Facebook;classification procedure;data mining process;information extraction;k-means clustering algorithm;language learning;language tutoring;machine learning reasoning mechanism;relationship mining;social networks;user clusters;user data set","","3","","10","","","7-8 May 2013","","IEEE","IEEE Conference Publications"
"Semantic Computing and Drug Discovery - A Preliminary Report","C. C. N. Wang; D. A. Hecht; P. C. Y. Sheu; J. J. P. Tsai","Dept. of Bioinf., Asia Univ., Taichung, Taiwan","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","453","458","Computer-aided drug design methodologies have proven to be very effective, greatly enhancing the efficiency of drug discovery and development processes. In this paper we describe how to integrate complex drug discovery problems and computational solutions via a semantic interface. In particular we describe a Structured Natural Language approach to chemical similarity searches, quantitative structure activity relationship (QSAR) modeling and in silico protein-ligand docking.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693561","drug discovery;protein-ligand docking;quantitative structure-activity relationship (QSAR);semantic analytics","Biological system modeling;Compounds;Computational modeling;Drugs;Proteins;Semantics","drugs;information retrieval;medical computing;natural language processing;proteins","QSAR modeling;chemical similarity searches;complex drug discovery problems;computational solutions;computer-aided drug design methodologies;development processes;protein-ligand docking;quantitative structure activity relationship modeling;semantic computing;semantic interface;structured natural language approach","","1","","42","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Temporal awareness of changes in afflicted people's needs after East Japan Great Earthquake","T. Hashimoto; T. Kuboyama; B. Chakraborty","Commerce & Econ., Chiba Univ. of Commerce, Chiba, Japan","2013 IEEE International Conference of IEEE Region 10 (TENCON 2013)","20140123","2013","","","1","6","This paper proposes a time series topic detection method to investigate changes in afflicted people's needs after the East Japan Great Earthquake using latent semantic analysis and singular vectors' pattern similarities. Our target data is a blog about afflicted people's needs provided by a non-profit organization in Tohoku, Japan. The method crawls blog messages, extracts terms, and forms document-term matrix over time. Then, it adopts the latent semantic analysis to extract people's needs as hidden topics from each snapshot matrix. We form time series hidden topic-term matrix as 3rd order tensor, so that changes in topics (people's needs) are detected by investigating time-series similarities between hidden topics. In this paper, to show the effectiveness of our proposed method, we also provide the experimental results.","2159-3442;21593442","Electronic:978-1-4799-2827-9; POD:978-1-4799-2828-6","10.1109/TENCON.2013.6719012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719012","","Blogs;Earthquakes;Matrix decomposition;Media;Semantics;Time series analysis;Vectors","information analysis;information retrieval;matrix algebra;social networking (online);tensors;time series","East Japan Great Earthquake;Tohoku;afflicted peoples needs;blog messages;document-term matrix;hidden topic-term matrix;latent semantic analysis;nonprofit organization;singular vector pattern similarities;temporal awareness;tensor;term extraction;time series topic detection method;time-series similarities","","0","","15","","","22-25 Oct. 2013","","IEEE","IEEE Conference Publications"
"Data and social network analysis on Malaria","R. B. Sampaio; A. El Haddadi; W. Bahsoun; B. Dousset","Univ. de Brasilia - UnB, Brasilia, Brazil","2013 3rd International Symposium ISKO-Maghreb","20140130","2013","","","1","5","In order to understand the existent and in formation relationships that might surface from scientific publications it is necessary to use methods for data and network analysis, besides the concepts of information flow and knowledge creation within organizations. The aim of this work was to show the application of tools and methods for data and network analysis and how those methods can bring forward proposals to improve the understanding of a specific disease, Malaria, within the scientific publications. The study of relational data retrieved from different databases might be elucidating in an environment, health system, which happens to be quite complex due to its many elements involved. How these elements interact within each other in order to fulfill the need to serve the population needs to be understood. The study of scientific publications is just one of the areas that might help decision makers have a better grasp on how to deal and focus on the needed areas.","","CD-ROM:978-1-4799-3391-4; Electronic:978-1-4799-3392-1; POD:978-1-4799-3393-8","10.1109/ISKO-Maghreb.2013.6728198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728198","Scientific and technological vision;bibliometric;geo-strategy;graphs;interactivity;malaria;neglected diseases;social networks;visualization","Data visualization;Databases;Diseases;Organizations;Social network services;Sociology;Statistics","data analysis;diseases;electronic publishing;information retrieval;medical information systems;relational databases;social sciences computing","data analysis;decision making;health system;information flow;information relationships;knowledge creation;malaria disease;relational data retrieval;scientific publications;social network analysis","","0","","13","","","8-9 Nov. 2013","","IEEE","IEEE Conference Publications"
"Indian topographic map symbols understanding system","N. G. Ganpatrao; J. K. Ghosh","Civil Eng. Dept., Indian Inst. of Technol., Roorkee, Roorkee, India","2013 IEEE Second International Conference on Image Information Processing (ICIIP-2013)","20140109","2013","","","33","38","Recognizing symbol is the first step in using a topographic map. Despite the prerequisite for extraction of information from topographic map, automated understanding of symbols is a challenging task. The objective of this paper is to explain the development of a system for automatic understanding of symbols from the Indian topographic map. The system has been developed making use of shape analysis method in which complex valued chain coding has been used for representation of the exterior boundary of the shape of the symbol. Fourier discrete transform and Auto-correlation function have been used to define shape descriptors. Classification and recognition have been implemented through template matching method and Similarity measures. The system is trained with 150 samples of each of 20 types of symbols from National digital topographic database (NTDB) for OSM of Indian topographic maps. The developed system is tested for 200 samples of each type of symbol from NTDB. It is found that 84.68% of symbols are understood correctly by the developed system. However, there are some inherent limitations in understanding the symbols from an actual map.","","Electronic:978-1-4673-6101-9; POD:978-1-4673-6102-6","10.1109/ICIIP.2013.6707550","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707550","chain coding;pattern recognition;shape analysis;template matching","Conferences;Correlation;Encoding;Feature extraction;Pattern recognition;Shape;Vectors","cartography;discrete Fourier transforms;image classification;image coding;image matching;information retrieval;topography (Earth);visual databases","Fourier discrete transform;Indian topographic map symbol understanding system;NTDB;National digital topographic database;OSM;autocorrelation function;complex valued chain coding;exterior boundary representation;information extraction;shape analysis method;shape descriptors;similarity measures;symbol classification;symbol recognition;template matching method","","0","","46","","","9-11 Dec. 2013","","IEEE","IEEE Conference Publications"
"Multilingual search in cyber forensic analysis","J. N. Koshy; D. D. Gonsalvez; S. Dija; K. L. Thomas","Centre for Dev. of Adv. Comput., Trivandrum, India","2013 IEEE International Conference on Computational Intelligence and Computing Research","20140127","2013","","","1","5","In the present day scenario, large amount of information and data is being stored in the form of digital documents. Cyber forensics analysis tools need to deal with large volumes of data retrieved from the suspect's hard disk. Searching for relevant evidence from such vast volumes is not an easy task. Analyzing such massive volumes of data manually is impractical. It is obvious that the cyber investigator would need the help of forensic analysis software tools for this purpose. Besides, a number of multilingual documents may be present in the seized media. Especially in a country like India, the analysts may come across multilingual documents very often. Thus, there arises a need to provide support for multilingual search in cyber forensic analysis tools. Not many forensic analysis tools provide multilingual search facility. In this paper, we have discussed the need of multilingual search in forensic tools. Besides, we have also discussed the approach we used in order to attain this objective in our analysis tool.","","Electronic:978-1-4799-1597-2; POD:978-1-4799-1596-5","10.1109/ICCIC.2013.6724281","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724281","cyber forensics;multilingual search","","data analysis;digital forensics;information retrieval;natural language processing","India;cyber forensic analysis software tools;cyber investigator;data retrieval;digital documents;hard disk;manual data analysis;multilingual documents;multilingual search facility","","0","","6","","","26-28 Dec. 2013","","IEEE","IEEE Conference Publications"
"LibSearchNet: Library log file initiatives - As a part of semantic library interface development for the VirCA 3D virtual collaboration arena","G. Bujdos√≥; M. Csernoch; M. Borb√©ly; E. Dani; M. N√©methi-Tak√°cs; K. Koltay; L. Bal√°zs","Dept. of Libr. & Inf. Sci., Univ. of Debrecen, Debrecen, Hungary","2013 IEEE 4th International Conference on Cognitive Infocommunications (CogInfoCom)","20140123","2013","","","567","572","In this paper we examine the possibilities for analyzing the behavior of library users. We point out that the softwares that we can use cannot fulfill library requirements. There are many data given for on-line searches in library systems hidden from the analyzers. After examining the possibilities and some log files produced by the library systems, we propose how log files could give more usable information for the semantic design of the intelligent library in the VirCA virtual collaboration system and of other on-line systems, too. These data can be applied as input information for intelligent systems in learning user searching behavior and help them predict user needs more precisely.","","Electronic:978-1-4799-1546-0; POD:978-1-4799-1545-3; USB:978-1-4799-1544-6","10.1109/CogInfoCom.2013.6719312","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719312","VirCA;intelligent library systems;log file analysis;log file initiatives","Artificial intelligence;Collaboration;Conferences;Libraries;Semantics;Software;Three-dimensional displays","Internet;data analysis;digital libraries;information needs;information retrieval;virtual reality","LibSearchNet;VirCA 3D virtual collaboration arena;intelligent library;library log file initiatives;library requirements;library systems;library user behavior analysis;online search;semantic design;semantic library interface development;user needs prediction;user searching behavior","","3","","29","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Open Information Extraction Based on Lexical-Syntactic Patterns","C. C. Xavier; V. L. S. d. Lima; M. Souza","Grad. Program in Comput. Sci., Pontificia Univ. Catolica do Rio Grande do Sul-PUCRS, Porto Alegre, Brazil","2013 Brazilian Conference on Intelligent Systems","20140130","2013","","","189","194","Open Information Extraction (Open IE) is an unsupervised strategy to draw out relations from text without predefining these relations, regardless the domain. This paper describes a novel Open IE approach that performs unsupervised extraction of triples by applying a few lexical-syntactic patterns to POS-tagged texts. In order to validate this strategy we developed a prototype and compared its performance with two Open IE systems. The proposed approach achieved promising results, overcoming those from the state-of-the-art systems. The paper concludes with an analysis of errors and directions for future work.","","Electronic:978-0-7695-5092-3; POD:978-1-4799-1271-1","10.1109/BRACIS.2013.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726447","Relation extraction;information extraction;knowledge acquisition","Data mining;Electronic publishing;Encyclopedias;Gold;Internet;Semantics","computational linguistics;information retrieval;knowledge acquisition;pattern classification;text analysis;unsupervised learning","POS-tagged texts;lexical-syntactic patterns;open IE approach;open information extraction;unsupervised triples extraction","","0","","13","","","19-24 Oct. 2013","","IEEE","IEEE Conference Publications"
"Using web text to improve keyword spotting in speech","A. Gandhe; L. Qin; F. Metze; A. Rudnicky; I. Lane; M. Eck","","2013 IEEE Workshop on Automatic Speech Recognition and Understanding","20140109","2013","","","428","433","For low resource languages, collecting sufficient training data to build acoustic and language models is time consuming and often expensive. But large amounts of text data, such as online newspapers, web forums or online encyclopedias, usually exist for languages that have a large population of native speakers. This text data can be easily collected from the web and then used to both expand the recognizer's vocabulary and improve the language model. One challenge, however, is normalizing and filtering the web data for a specific task. In this paper, we investigate the use of online text resources to improve the performance of speech recognition specifically for the task of keyword spotting. For the five languages provided in the base period of the IARPA BABEL project, we automatically collected text data from the web using only Limited LP resources. We then compared two methods for filtering the web data, one based on perplexity ranking and the other based on out-of-vocabulary (OOV) word detection. By integrating the web text into our systems, we observed significant improvements in keyword spotting accuracy for four out of the five languages. The best approach obtained an improvement in actual term weighted value (ATWV) of 0.0424 compared to a baseline system trained only on LimitedLP resources. On average, ATWV was improved by 0.0243 across five languages.","","Electronic:978-1-4799-2756-2; POD:978-1-4799-2757-9; USB:978-1-4799-2755-5","10.1109/ASRU.2013.6707768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707768","data filtering;keyword spotting;language modeling;low resource;web text","Data models;Filtering;Internet;Speech;Speech recognition;Training data;Vocabulary","Internet;Web sites;information retrieval;natural language processing;speech recognition;text analysis","ATWV;IARPA BABEL project;LimitedLP resources;OOV;Web forums;Web text;acoustic models;actual term weighted value;keyword spotting accuracy;language models;low resource languages;native speakers;online encyclopedias;online newspapers;online text resources;out-of-vocabulary word detection;perplexity ranking;recognizer vocabulary;speech recognition;text data","","0","","20","","","8-12 Dec. 2013","","IEEE","IEEE Conference Publications"
"Ranking Twitter Influence by Combining Network Centrality and Influence Observables in an Evolutionary Model","D. Simmie; M. G. Vigliotti; C. Hankin","Imperial Coll. London, London, UK","2013 International Conference on Signal-Image Technology & Internet-Based Systems","20140130","2013","","","491","498","Influential agents in networks play a pivotal role in information diffusion. Influence may rise or fall quickly over time and thus capturing this evolution of influence is of benefit to a varied number of application domains such as: digital marketing, counter-terrorism or policing. In this paper we investigate the influence of users in programming communities on Twitter. We propose a new model for capturing both time-invariant influence and also temporal influence. The unified model is a combination of network topological methods and observation of influence-relevant events in the network. We provide an application of Hidden Markov Models (HMM) for capturing this effect on the network. There are many possible combinations of influence factors, hence we required a ground-truth for model configuration. We performed a primary survey of our population users to elicit their views on influential users. The survey allowed us to validate the results of our classifier. We introduce a novel reward-based transformation to the Viterbi path of the observed sequences which provides an overall ranking for users. Our results show an improvement in ranking accuracy over using solely topology-based methods for the particular area of interest we sampled. Utilising the evolutionary aspect of the HMM we attempt to predict future states using current evidence. Our prediction algorithm significantly outperforms a collection of naive models, especially in the short term (1-3 weeks).","","Electronic:978-1-4799-3211-5; POD:978-1-4799-3212-2","10.1109/SITIS.2013.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727234","Influence;Social Networks","Communities;Hidden Markov models;Measurement;Network topology;Predictive models;Twitter;Viterbi algorithm","evolutionary computation;hidden Markov models;information retrieval;network theory (graphs);social networking (online)","HMM;Twitter influence ranking;counter-terrorism;digital marketing;evolutionary model;hidden Markov models;influence evolution;influence factors;influence observables;influential agents;information diffusion;model configuration;network centrality;network topological methods;policing;programming communities;ranking accuracy;temporal influence;time-invariant influence","","1","","10","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"FIC WAN frequent itemset clustering of web articles by analyzing the article neighborhood","T. Kuƒçeƒçka; D. Chud√°; P. Sl√°deƒçek","Fac. of Inf. & Inf. Technol., Slovak Univ. of Technol., Bratislava, Slovakia","2013 IEEE 14th International Symposium on Computational Intelligence and Informatics (CINTI)","20140109","2013","","","509","514","Document clustering is a process of organizing text data into clusters where a cluster usually represents a group of topic related documents. Most effective text clustering approaches are based on frequent itemsets. A popular algorithm that uses this approach is FIHC (Frequent Itemset-based Hierarchical Clustering). In recent years, many modifications have been made to this algorithm. In this paper we focus on clustering web articles which represent a special type of text data. They contain hyperlinks through which they are linked with other articles on the web. We propose a FICWAN algorithm which is a modification of FIHC. FICWAN is especially suited for web data. We show that by considering the neighborhood of a web article and its HTML tags and CSS we are able to significantly improve the quality of created clusters. We experimented with our approach on several corpuses and the results clearly outperformed FIHC.","","Electronic:978-1-4799-0197-5; POD:978-1-4799-0196-8; USB:978-1-4799-0195-1","10.1109/CINTI.2013.6705250","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6705250","","Cascading style sheets;Clustering algorithms;HTML;Informatics;Itemsets;Partitioning algorithms;Web pages","Internet;data mining;information retrieval;pattern clustering;text analysis","CSS;FICWAN frequent itemset clustering;FIHC;HTML tags;Web articles clustering;article neighborhood;document clustering;frequent itemset-based hierarchical clustering;hyperlinks;topic related document","","0","","11","","","19-21 Nov. 2013","","IEEE","IEEE Conference Publications"
"Bibliomining on North South University library data","I. Azam; S. J. Sohrawardi; H. S. Das; M. S. Alam; M. S. Alvy; R. M. Rahman","Dept. of Electr. Eng. & Comput. Sci., North South Univ., Dhaka, Bangladesh","Eighth International Conference on Digital Information Management (ICDIM 2013)","20140102","2013","","","235","240","Bibliomining is a process that is based on applying data mining techniques on vast amounts of library data to extract valuable behavioral patterns that would aid in decision making or greater efficiency of service [1]. Much of this evolved from the more recognized, Market Basket Analysis (MBA), primarily used in shopping malls for analysis of product associations. The paper discusses various stages and techniques used to mine the North South University (NSU) library data and extract useful patterns among the borrowers. The findings and results of this work can be used to accomplish more efficient management and budget allocation of the library.","","Electronic:978-1-4799-0615-4; POD:978-1-4799-0614-7","10.1109/ICDIM.2013.6693969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693969","association mining;bibliomining;data mining;library","Business;Data mining;Databases;Economics;Educational institutions;Libraries;Spreadsheet programs","academic libraries;bibliographic systems;budgeting data processing;data mining;decision making;information retrieval","MBA;North South University library data;bibliomining;borrowers;budget allocation;data mining technique;decision making;market basket analysis;product association analysis;shopping malls;valuable behavioral pattern extraction","","0","","7","","","10-12 Sept. 2013","","IEEE","IEEE Conference Publications"
"Publishing institutional repositories metadata on the semantic web","H. Fari; S. Khan; M. Y. Javed","Coll. of Electr. & Mech. Eng., Nat. Univ. of Sci. & Technol., Islamabad, Pakistan","Eighth International Conference on Digital Information Management (ICDIM 2013)","20140102","2013","","","79","84","Institutional repositories (IRs) are often built to serve a specific institution's community of users. Therefore, the information a researcher requires is often scattered in various repositories. For bridging the gap in scholarly communication, there is a need to publish research material on semantic web in a meaningful way. Semantic web applications enable sharing and reusing of existing information and create an integrated view of multidisciplinary information. However, IRs use relational database to store their metadata. It is essential to transform an IR database into ontology and publish its data on semantic web. The aim of this work is to share and reuse the information that exists in IRs. The proposed system extracts metadata from IRs, transforms it into ontology and publishes their data on semantic web. The system was implemented and compared with an existing system. The evaluation demonstrates that the proposed system produces more accurate results.","","Electronic:978-1-4799-0615-4; POD:978-1-4799-0614-7","10.1109/ICDIM.2013.6694008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694008","Institutional digital repository;information sharing;metadata;semantic web","Communities;Data mining;Data models;Ontologies;Relational databases;Resource description framework","electronic publishing;information retrieval;meta data;ontologies (artificial intelligence);relational databases;research and development;semantic Web","IR database;institutional repositories metadata publishing;multidisciplinary information;ontology;relational database;research material;scholarly communication;semantic Web","","0","","25","","","10-12 Sept. 2013","","IEEE","IEEE Conference Publications"
"Simulating satellite downlink data loss and recovery due to rain attenuation","D. Shannon; R. Marymee","GreenDart Inc., San Pedro, CA, USA","2013 Winter Simulations Conference (WSC)","20140127","2013","","","2742","2750","This paper describes a simulation tool and trade study that models polar orbiting weather satellites, stored sensor data, downlinks to global receptors, and sensor data retrieval with sufficient fidelity to conduct design trades in autonomous satellite downlinks. This paper employs a stochastic rain model based on empirical rain data and a rain fade model for simulated data loss. Models have been implemented using the simulation tool ExtendSim with orbital data imported from Satellite Tool Kit (STK). The simulated satellite contacts and receptor environment are realistically modeled for data retrieval and lost data recovery.","0891-7736;08917736","Electronic:978-1-4799-3950-3; POD:978-1-4799-3727-1","10.1109/WSC.2013.6721645","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6721645","","Analytical models;Attenuation;Data models;Downlink;Rain;Satellites","digital simulation;information retrieval;rain;satellite communication;telecommunication computing","ExtendSim simulation tool;STK;autonomous satellite downlinks;data retrieval;empirical rain data;global receptors;orbital data;polar orbiting weather satellites;rain attenuation;rain fade model;satellite downlink data loss;satellite downlink data recovery;satellite tool kit;sensor data retrieval;simulation tool;stochastic rain model;trade study","","0","","8","","","8-11 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Novel Information Search and Recommendation Services Platform Based on an Indexing Network (Short Paper)","X. Deng; M. Jiang; H. Sun; Y. Zhang; J. Liu; Y. Guo; X. Wang; D. Ge; P. Wang; Z. Ding; H. Chen","Key Lab. of Embedded Syst. & Service Comput., Tongji Univ., Shanghai, China","2013 IEEE 6th International Conference on Service-Oriented Computing and Applications","20140123","2013","","","194","197","With the rapid development of Internet technology, information resources on the Internet become more abundant, but also bring some problems like diversity, heterogeneity, disorder, and redundancy. Given a brief expression like search keywords only, users' needs are ambiguous. Therefore, current technologies of search applications relying on direct keyword matching cannot meet the requirements of users exactly. Service applications are hoped to be more intelligent and knowledgeable. To solve such challenge, this paper attempts to organize web pages into a semantic association graph based on a novel model - indexing network, which can provide more valuable information and services for users. An information search and recommendation services platform is implemented using cloud distributed systems (Hadoop + Habse + Zookeeper) based on Sugon-Tongji cloud platform that is located at Tongji University. 70 million web pages are crawled on the Internet and their corresponding indexing network model are constructed. Several novel services are implemented and provided on the platform, such as search location, search navigation, category/keyword recommendation, and the interaction interface of the indexing network. System demonstration and experimental analysis show that the proposed platform can provide and support more knowledgeable and valuable information search-related services, thereby better meeting the growing needs of Internet users.","2163-2871;21632871","Electronic:978-1-4799-2702-9; POD:978-1-4799-3172-9","10.1109/SOCA.2013.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6717305","","Data mining;Educational institutions;Indexing;Internet;Navigation;Semantics","Web sites;cloud computing;indexing;information retrieval;portals;recommender systems;redundancy;search engines","Internet technology;Internet users;Sugon-Tongji cloud platform;Web pages;cloud distributed systems;heterogeneity;indexing network model;information resources;interaction interface;keyword matching;recommendation services platform;redundancy;semantic association graph;system demonstration;valuable information search-related services","","3","","14","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"High level data classification based on network entropy","F. A. Neto; L. Zhao","Dept. of Comput. Sci., Univ. of Sao Paulo (USP), Sao Carlos, Brazil","The 2013 International Joint Conference on Neural Networks (IJCNN)","20140109","2013","","","1","5","Traditional data classification is based only on physical features of input data. They are called low level classification. Data classification by considering not only physical attributes but also pattern formation is denominated high level classification. In this paper, we propose a new technique that performs high level classification by extracting information of networks constructed from the input data. Specifically, we calculate the network entropies before and after the insertion of a data item to be classified. Then, we classify it as belonging to the class which results in the largest increase of the entropy measures. We show that the proposed method can execute classification tasks according to both similarity and pattern formation of input data to reach good results in the experiments with artificial and real data sets. In summary, our technique can calculate how significant a data item is for each class performing a new way to classify data.","2161-4393;21614393","Electronic:978-1-4673-6129-3; POD:978-1-4673-6127-9","10.1109/IJCNN.2013.6707042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707042","","Accuracy;Databases;Entropy;Iris;Mathematical model;Pattern formation;Training","data analysis;entropy;information retrieval;learning (artificial intelligence);pattern classification","high level data classification;information extraction;low level classification;machine learning techniques;network entropy;pattern formation;similarity formation","","0","","11","","","4-9 Aug. 2013","","IEEE","IEEE Conference Publications"
"Reference and annotation in digital texts. From citation to ‚ÄúWatson‚Äù","K. M. Pr√§tor","Univ. of Wurzburg, Wu&#x0308;rzburg, Germany","2013 3rd International Symposium ISKO-Maghreb","20140130","2013","","","1","7","The lack of segmentation by pages and lines creates severe problems with scholarly citation of digital documents - in spite of all advantages of digital texts Not only citation, but the whole editorial work of identifying, comparing, manipulating and annotating text make use of reference to distinctive parts of text - and also the programs that support such tasks. The paper propagates to base reference in digital texts entirely on a structure of meaningful entities like sentences or words. Based on such a structure most annotational markup can be handled ‚Äústand-off‚Äù. I refer to an implementation of my own and to ‚ÄúWatson‚Äù, a very ambitious project of annotation. Using it a computer won in Jeopardy, a prominent US Quiz-Show.","","CD-ROM:978-1-4799-3391-4; Electronic:978-1-4799-3392-1; POD:978-1-4799-3393-8","10.1109/ISKO-Maghreb.2013.6728108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728108","annotation model;digital reference;digital text;domain model;line number;logical structure;meaningful entity;meaningful reference;open annotation;page structure;print edition;reference system;unstructured information management architecture","Abstracts;Computers;Editorials;Joining processes;Media;Resource description framework;Standards","citation analysis;question answering (information retrieval);text analysis","Jeopardy US quiz-show;Watson computer;base reference;digital document citation;digital text reference;sentences;text annotation;text comparison;text identification;text manipulation;words","","0","","10","","","8-9 Nov. 2013","","IEEE","IEEE Conference Publications"
"User Modelling for Interactive Optimization Using Neural Network","V. B. Singh; S. Mukhopadhyay; M. Babbar-Sebens","Dept. of Comput. & Inf. Sci., Indiana Univ. Purdue Univ. Indianapolis, Indianapolis, IN, USA","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","3288","3293","User modelling is one of the prominent research fields in information retrieval systems. In this paper, we model user's preferences and search criteria using an NN (Neural Network) to solve a multiobjective optimization problem specific to environmental planning systems. We argue that some NP hard problems cannot be solved alone either by a human or by a computer. Human participation in automated search is one way of combining human intuition with algorithmic search to solve such problems. However, even humans have some limitations for participation in that they cannot participate in search completely because of human fatigue. To overcome this, in our approach, an NN tries to model the user's rating criteria and preferences to help the user in rating large set of designs. Although training an NN with limited data is not always feasible, there are many situations where a simple modelling technique (e.g., linear/quadratic mapping) works better if the learning data set is small. In this paper we attempt to get more accuracy of the NN by generating data using other linear/non-linear techniques that fills the gap created by lack of sufficient training data. Also, we provided the architectural design of an HPC based framework we have proposed and compared the performance of the NN with fuzzy logic and other linear/non-linear user modelling techniques for the environmental resources optimization problem.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.560","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722313","collaborative search;environmental planning;genetic algorithm;interactive algorithm;neural network;user modelling","Adaptation models;Artificial neural networks;Computational modeling;Computers;Optimization;Search problems","environmental science computing;fuzzy logic;human factors;information retrieval;neural nets;optimisation;parallel processing;user modelling","HPC based framework;NP hard problems;algorithmic search;automated search;environmental planning systems;environmental resource optimization problem;fuzzy logic technique;human fatigue;human intuition;human participation;information retrieval systems;interactive optimization;multiobjective optimization problem;neural network;nonlinear user modelling technique;training data;user preferences;user rating criteria;user search criteria","","0","","15","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Intelligent crawler for web forums based on improved regular expressions","M. Pavkoviƒá; J. Protiƒá","Sch. of Electr. Eng., Univ. of Belgrade, Belgrade, Serbia","2013 21st Telecommunications Forum Telfor (TELFOR)","20140120","2013","","","817","820","In this paper, we present the development and characteristics of a specialized Web-scale forum crawler. The main idea is to crawl relevant forum content from the Web with minimal server resource consumption, and to organize crawled content into logical units, in order to make it easier for further processing and analysis. Forum posts contain relevant information that are of interest to forum crawler. Although forums have different designs, and are built on different technologies, they always have identical logic navigation that connects homepage and particular posts through forum lists and threads by specific URLs. Considering this common implicit navigation, we have optimized Web crawling problem to be URL-type recognition problem. URL-type database and regular expressions are used in order to achieve URL-type recognition. These regular expressions are expanded with special custom characters and commands that gave this forum crawler advantage over other Web based crawlers. The results shown in this paper are obtained by crawling a set of Web forums with different technology, location and design. Each test compared the results obtained by standard Web based crawler and our specialized forum crawler. Our test results show that by crawling only specific data and URL paths on the forum, we have managed to reduce the time of crawling and to achieve lower server resources consumption.","","Electronic:978-1-4799-1420-3; POD:978-1-4799-1418-0","10.1109/TELFOR.2013.6716355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716355","URL type;crawler;forum;regular expressions;web search","Crawlers;Databases;Educational institutions;Internet;Knowledge based systems;Message systems;Software packages","Web sites;information retrieval;knowledge based systems;search engines","URL paths;URL-type database;URL-type recognition problem;Web-scale forum crawler characteristics;Web-scale forum crawler development;custom characters;forum lists;forum posts;homepage;implicit navigation;information analysis;information processing;intelligent crawler;logical navigation;minimal server resource consumption;optimized Web crawling problem;regular expressions","","0","","14","","","26-28 Nov. 2013","","IEEE","IEEE Conference Publications"
"LibSearchNet: Analyses of library log files to identify search flows","M. Csernoch; G. Bujdos√≥; M. Borb√©ly; E. Dani; M. N√©methi-Tak√°cs; K. Koltay; L. Bal√°zs","Dept. of Libr. & Inf. Sci., Univ. of Debrecen, Debrecen, Hungary","2013 IEEE 4th International Conference on Cognitive Infocommunications (CogInfoCom)","20140123","2013","","","543","548","The online libraries of the next generation library users would mean creating 3D virtual spaces where they would navigate as they do in traditional libraries. To achieve this goal the surface has to be built and this new environment has offer options with which non-library educated users would navigate effectively. Reaching this state the activities of present day online library users and library systems should be thoroughly analyzed. The sources of the analyses are the library log files. Well-designed log files would reveal, on one hand, the patterns of the users' activities which are crucial in building algorithms for the mental representation of searches. On the other hand, the analyses of these log files would shed light on the operation of the system.","","Electronic:978-1-4799-1546-0; POD:978-1-4799-1545-3; USB:978-1-4799-1544-6","10.1109/CogInfoCom.2013.6719307","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719307","VirCA;log file analysis;search net;user- and system-launched searches;users' mental search lexikon","Conferences;Educational institutions;Libraries;Search problems;Software;Surface treatment;Three-dimensional displays","Internet;data analysis;digital libraries;information retrieval;virtual reality","3D virtual spaces;LibSearchNet;library log file analysis;library systems;mental search representation;next generation library users;nonlibrary educated users;online libraries;user activity pattern","","3","","18","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Integration and collection of heterogeneous data based on metedata","L. Zhang","Inst. of Sci. & Tech. Inf. of China, Beijing, China","2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering","20140109","2013","1","","205","208","In order to solve the problem of heterogeneous data collection and integration in different industries, metadata-based retrieval model and rule-based web wrapper are proposed. Retrieval metadata set and industry retrieval model are constructed by applying metadata extraction technology, and the rule tree of industry data attributes is built and web wrapper is designed based on industry data format analysis. On the basis of above work, industry data collection system is realized to complete industry data collection. Through the study, researchers can obtain research data rapidly and accurately.","2155-1456;21551456","Electronic:978-1-4799-0245-3; POD:978-1-4799-0243-9","10.1109/ICIII.2013.6702910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702910","retrieval metadata;retrieval model;rule tree;web wrapper","Data collection;Data mining;Data models;Industries;Patents;Search engines;Web pages","Internet;data analysis;distributed databases;information retrieval;meta data","heterogeneous data collection;heterogeneous data integration;industry data attributes;industry data collection system;industry data format analysis;industry retrieval model;metadata extraction technology;metadata-based retrieval model;metedata;retrieval metadata set;rule tree;rule-based Web wrapper","","0","","8","","","23-24 Nov. 2013","","IEEE","IEEE Conference Publications"
"Uncovering Cloaking Web Pages with Hybrid Detection Approaches","J. Deng; H. Chen; J. Sun","Coll. of Inf. Sci. & Eng., Hunan Univ., Changsha, China","2013 International Symposium on Computational and Business Intelligence","20140127","2013","","","291","296","Web search cloaking, used by spammers for the purpose of increasing the visiting rates of their website, is a challenging spamming technique to search engines. Existing cloaking detection systems have some shortcomings: the accuracy of their algorithms is not high enough, the types of cloaking techniques that be detected are limited. In this paper, we present a new system to attack these two problems. To improve the detection accuracy, our algorithm combines text, tag and URL based method. For the purpose of detecting more types of cloaking techniques, our system works as follows: driving a real browser to execute scripts in web pages, crawl a page for the second time by modifying the referrer field of our HTTP headers, obtaining search engine's cached page for further comparison. We apply our system to 104,800 URLs extracted from Yahoo. Results show that our system can gain a high accuracy: precision at 94.52% and recall at 98.57%. More types of cloaking techniques are successfully detected by our system.","","Electronic:978-0-7695-5066-4; POD:978-1-4799-0998-8","10.1109/ISCBI.2013.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724370","Cloak;Cloaking Techniques;SEO;search terms;similarity detection algorithm","Accuracy;Browsers;Crawlers;HTML;IP networks;Search engines;Web pages","Web sites;information retrieval;search engines;security of data;unsolicited e-mail","HTTP header;URL based method;Web pages cloaking;Web search cloaking;Web site;cloaking detection system;hybrid detection approach;search engines;spamming technique;tag based method;text based method","","0","","14","","","24-26 Aug. 2013","","IEEE","IEEE Conference Publications"
"Short Text Classification Using Wikipedia Concept Based Document Representation","X. Wang; R. Chen; Y. Jia; B. Zhou","Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2013 International Conference on Information Technology and Applications","20140111","2013","","","471","474","Short text classification is a difficult and challenging task in information retrieval systems since the text data is short, sparse and multidimensional. In this paper, we represent short text with Wikipedia concepts for classification. Short document text is mapped to Wikipedia concepts and the concepts are then used to represent document for text categorization. Traditional methods for classification such as SVM can be used to perform text categorization on the Wikipedia concept document representation. Experimental evaluation on real Google search snippets shows that our approach outperforms the traditional BOW method and gives good performance. Although it's not better than the state-of-the-art classifier (see e.g. Phan et al. WWW '08), our method can be easily implemented with low cost.","","Electronic:978-1-4799-2877-4; POD:978-1-4799-2878-1","10.1109/ITA.2013.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710030","Document Representation;Short Text Classification;Wikipedia","Electronic publishing;Encyclopedias;Indexes;Internet;Support vector machines;Text categorization","Web sites;information retrieval;pattern classification;text analysis","Google search snippets;SVM;information retrieval systems;multidimensional text data;short document text data mapping;short text classification;sparse text data;text categorization;wikipedia concept document representation","","1","","14","","","16-17 Nov. 2013","","IEEE","IEEE Conference Publications"
"Tagpref: User Preference Modeling by Social Tagging","W. Hu; Y. Zhang; Y. Zhou; K. Deng","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","2013 IEEE 10th International Conference on Ubiquitous Intelligence and Computing and 2013 IEEE 10th International Conference on Autonomic and Trusted Computing","20140130","2013","","","111","118","User preference modeling is the basis for the provision of personal information services because it can reflect the user's characteristics and interests. Tagging is a popular online activity that allows a user to discover, describe, and organize Internet contents. Tagging provides a new means of creating user preference. Tags explain and describe items so that a user's attitude toward a tag is his or her attitude toward an aspect of the item. In this paper we design Tagpref inspired by the method of establishing user preference with tags. The user's preference was described by the user's preference degrees for different tags. Different algorithms were proposed and evaluated for taggers and non-taggers on Movie Lens based on direct and indirect behavior. Evaluation results show that the proposed algorithms can accurately predict a user's tag preference. The user's attitude toward tag preference was also analyzed. Users' true preference was determined by an online user survey.","","Electronic:978-1-4799-2482-0; POD:978-1-4799-2483-7","10.1109/UIC-ATC.2013.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726198","Interesting mining;Preference model;Social tagging","Collaboration;Communities;Inference algorithms;Motion pictures;Mutual information;Prediction algorithms;Tagging","Internet;information retrieval","Internet content;Tagpref;personal information service;social tagging;user preference degree;user preference modeling","","0","","20","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Opening the loops ‚Äî Towards semantic, information-centric networking in the Internet of Things","H. Wirtz; K. Wehrle","Dept. of Commun. & Distrib. Syst., RWTH Aachen, Aachen, Germany","2013 IEEE International Workshop of Internet-of-Things Networking and Control (IoT-NC)","20140102","2013","","","18","24","The advent of the Internet of Things (IoT) paradigm in increasing deployments promises a pervasive proliferation of smart things, capable of sensing, actuating, and processing information. In typical designs, however, application of each thing is restricted to a dedicated use case in a single network of connected devices, resulting in a closed loop of information flow. We argue that, given the envisioned diversity, capabilities, and sheer number of smart things, this obstructs the possibility of creating diverse and exciting applications that benefit of the generated information in public, global usage scenarios. In this paper, we thus aim to initiate the discussion of creating a true Internet of Things, i.e., interconnected IoT networks, based on provision and requests of generated information in a public infrastructure. We highlight the challenges in designing this infrastructure for feasible integration in the current Internet and IoT designs, comprehensive provision and retrieval of information, and versatile derivation of higher information contexts from single information sources. Assessing advantages and shortcomings of existing approaches, we propose a suitable approach and discuss both a centralized and distributed implementation of the proposed infrastructure.","","Electronic:978-1-4799-0826-4; POD:978-1-4799-0824-0","10.1109/IoT-NC.2013.6694049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694049","","Context;Context modeling;Internet;Logic gates;Object oriented modeling;Sensors;Temperature measurement","Internet of Things;information retrieval","Internet of Things;centralized implementation;closed-loop information flow;comprehensive information provision;comprehensive information retrieval;distributed implementation;information actuation;information processing;information provision;information request;information sensing;information sources;interconnected IoT networks;pervasive proliferation;public infrastructure;semantic-information-centric networking;smart things","","0","","23","","","24-24 June 2013","","IEEE","IEEE Conference Publications"
"A proposal on support for reading of novels using question answering technology","S. Okada; T. Arakawa","Dept. of Adv. Production Syst. Eng. Course, Gunma Nat. Coll. of Technol., Gunma, Japan","2013 13th International Conference on Control, Automation and Systems (ICCAS 2013)","20140109","2013","","","1193","1198","In recent years, readings on text files become popular. We can use full-text search while we read text-files. However, full-text search has some weak points for supporting readings. We propose to introduce question-answering to readings of novels on text-files to avoid these problems and make a comfortable support system for readings of novels. We also propose several additional functions such as ‚ÄúWho? Function‚Äù and ‚ÄúSpoiler preventer‚Äù. We checked the act of our system with various examples to confirm that our system works correctly in actual reading scenes. We also examined the computational complexity of the system theoretically and experimentally, and found our proposed method does not take a long time so that the user will not feel unpleasant.","2093-7121;20937121","Electronic:978-89-93215-05-2; POD:978-1-4799-0549-2","10.1109/ICCAS.2013.6704136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6704136","question answering;restriction of spoiler;support for reading","Computational complexity;Random access memory","computational complexity;question answering (information retrieval);text analysis","Spoiler preventer;actual reading scenes;comfortable support system;computational complexity;full text search;question answering technology;text files","","0","","8","","","20-23 Oct. 2013","","IEEE","IEEE Conference Publications"
"A Fuzzy Tree Similarity Measure and Its Application in Telecom Product Recommendation","D. Wu; G. Zhang; J. Lu","Decision Syst. & e-Service Intell. Lab., Univ. of Technol., Sydney, NSW, Australia","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","3483","3488","The recommender systems field has been well developed in the last few years to provide item recommendations to related users. Existing recommendation approaches, however, assume that an item is described by a single value or a vector. Unfortunately, some items in real world applications, such as telecom products, could have a tree structure. This paper aims to handle this issue by developing a comprehensive fuzzy tree similarity measure. The fuzzy tree similarity measure compares both the concepts and values in two trees of items. The focus of this study is primarily on the fuzzy value similarity between two trees. In the similarity measure, each attribute is associated with a set of linguistic terms to express the value granularly. The node values are first transformed to membership vectors related to the linguistic terms, and the values of the conceptual corresponding nodes are then compared. These local similarities are aggregated into the final fuzzy value similarity between the two trees. A telecom product recommendation case study shows the effectiveness of the proposed fuzzy tree similarity measure and its applicability for telecom product recommendations.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722347","fuzzy similarity measure;recommender systems;tree similarity measure","Data models;Pragmatics;Recommender systems;Semantics;Telecommunications;Vectors;Vegetation","fuzzy set theory;information retrieval;marketing data processing;recommender systems;telecommunication industry;telecommunication services;trees (mathematics)","conceptual corresponding nodes;fuzzy tree similarity measure;fuzzy value similarity;granular value expression;item recommendation;linguistic terms;membership vectors;recommendation approach;recommender systems;telecom product recommendation","","3","","25","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Critical Infrastructures Governance Exploring SCADA Cybernetics through Architectured Policy Semantic","D. Khadraoui; C. Feltus","Service Sci. & Innovation, Public Res. Centre Henri Tudor, Luxembourg, Luxembourg","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","4766","4771","SCADA-systems are very complex, sophisticated and integrated systems which support people in monitoring and governing the huge volumes of knowledge engendered by critical infrastructures (industry, energy, transport, and healthcare). These systems are elaborated upon a colossal range of precontrived components which need to interact thoroughly with each other although, a priori, they all use heterogeneous technologies and protocols, they behave unevenly through the SCADA architecture, and they are all located in miscellaneous corners of the production system. Furthermore, these components interact, amongst other, by means of policies which formulate the reasoning for component behaviour in terms of expecting actions realization or in terms of accessed information. This paper explores these policies' semantic through a unified component modelling approach with the aim of providing a homogeneous and coherent framework, adapted for the governance of the system by all SCADA and non-SCADA operators.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722566","IS security;Policy management;SCADA system;architecture;critical infrastructure","Context;Correlation;Data visualization;Monitoring;Organizations;SCADA systems;Unified modeling language","SCADA systems;Unified Modeling Language;access control;critical infrastructures;inference mechanisms;information retrieval;protocols","SCADA system architecture;actions realization;component behaviour;critical infrastructure governance;heterogeneous technology;information access;policy management;precontrived components interaction;production system;protocols;reasoning;semantics;unified component modelling approach","","0","","26","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"A low cost medical image digitization setup for enhancement and analyzing of conventional X-ray images","H. Korkmaz; S. Alsan","Dept. of Electr. & Electron. Eng., Univ. of Marmara, Istanbul, Turkey","2013 IEEE International Conference on Signal and Image Processing Applications","20140109","2013","","","95","100","In medical industry, studies about storing, processing, analyzing and re-accessing the patient's information and images are intensively continuing. Both printed and digital medical images take more spaces than the others. In this paper, a mechanism which transfers easily the printed X-ray images to the digital environment enabling radiological assessment and archiving is set and a software is developed to help the analysis of those images. It is aimed to digitize the conventional images with a minimum loss while keeping the image quality. The setup which is in a closed box consists of a light source, a camera for image transfer and lenses. The software provides applying the image processing algorithms on digitized images and archiving them in DICOM format.","","Electronic:978-1-4799-0269-9; POD:978-1-4799-0268-2","10.1109/ICSIPA.2013.6707984","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707984","IEEE 1394 camera;Matlab;image acquisition;image digitization;lens","Image edge detection;Image segmentation;MATLAB;PSNR;X-ray imaging","X-ray imaging;image enhancement;information retrieval systems;medical image processing;radiology","DICOM format;X-ray images;archiving;digital medical images;image enhancement;medical image digitization;medical industry;patient information;printed medical images;radiological assessment","","0","","19","","","8-10 Oct. 2013","","IEEE","IEEE Conference Publications"
"The TAO of ATWV: Probing the mysteries of keyword search performance","S. Wegmann; A. Faria; A. Janin; K. Riedhammer; N. Morgan","Int. Comput. Sci. Inst., Berkeley, CA, USA","2013 IEEE Workshop on Automatic Speech Recognition and Understanding","20140109","2013","","","192","197","In this paper we apply diagnostic analysis to gain a deeper understanding of the performance of the the keyword search system that we have developed for conversational telephone speech in the IARPA Babel program. We summarize the Babel task, its primary performance metric, ‚Äúactual term weighted value‚Äù (ATWV), and our recognition and keyword search systems. Our analysis uses two new oracle ATWV measures, a bootstrap-based ATWV confidence interval, and includes a study of the underpinnings of the large ATWV gains due to system combination. This analysis quantifies the potential ATWV gains from improving the number of true hits and the overall quality of the detection scores in our system's posting lists. It also shows that system combination improves our systems' ATWV via a small increase in the number of true hits in the posting lists.","","Electronic:978-1-4799-2756-2; POD:978-1-4799-2757-9; USB:978-1-4799-2755-5","10.1109/ASRU.2013.6707728","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707728","keyword search;spoken term detection","Feature extraction;Indexes;Keyword search;Measurement;Merging;Speech;Speech recognition","information retrieval;speech recognition;statistical analysis","IARPA Babel program;TAO;actual term weighted value;bootstrap-based ATWV confidence interval;conversational telephone speech;detection scores;diagnostic analysis;keyword search performance;keyword search systems;oracle ATWV measures;primary performance metric;system combination","","8","","19","","","8-12 Dec. 2013","","IEEE","IEEE Conference Publications"
"A study on output sentence generation method for question answering using statistical machine translation","T. Yamada; T. Arakawa","Dept. of Adv. Production Syst. Eng. Course, Gunma Nat. Coll. of Technol., Gunma, Japan","2013 13th International Conference on Control, Automation and Systems (ICCAS 2013)","20140109","2013","","","1199","1202","Question answering generally generates the answer to the question by extracting the named entity from the sentences containing the answer to the question from information sources. However, it is not always true that a named entity is an answer to the question. So we propose a method for generating the answer sentence using statistical machine translation. The probability models are constructed by learning from enormous samples of the set of question sentence, extracted sentence, and answer sentence. The question sentence and the sentence extracted by the question answering from information source are regarded as an input of machine translation. They are translated to a suitable answer sentence to the question. In this paper, we attempted to apply our method to several simple types questions that can also be answered by the named entity extraction.","2093-7121;20937121","Electronic:978-89-93215-05-2; POD:978-1-4799-0549-2","10.1109/ICCAS.2013.6704146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6704146","beam search;phrase-based model;question answering;statistical machine translation","Decoding;Manuals","language translation;question answering (information retrieval);statistical analysis","answer sentence;extracted sentence;information sources;output sentence generation method;probability models;question answering;question sentence;statistical machine translation","","0","","5","","","20-23 Oct. 2013","","IEEE","IEEE Conference Publications"
"Content Repurposing Platform Utilizing Metadata Extracted from Rich Media","G. Kojima","Yokohama Res. Lab., HITACHI, Ltd., Yokohama, Japan","2013 International Conference on Signal-Image Technology & Internet-Based Systems","20140130","2013","","","950","957","The amounts of unstructured data stored in companies are rapidly growing up, and the needs for utilizing those data are coming up. We've been working on research and development of a platform that can ease utilization of unstructured data. In order to make situation aware information system in organizations such as hospitals, utilizing unstructured data such as texts, images, and voices, in combination with structured data is required. For example, most of the hospitals own several information systems for each purpose and each organization. Thus, searching patient information across multiple data sources or data types is difficult problem that must be solved. To solve this problem, we developed content repurposing platform that enables search refinement across data sources using metadata database which store metadata extracted from each data sources. The platform is constructed on top of object storage and includes metadata extraction engine, metadata DB, content router, and search engine. We applied the content repurposing platform to a hospital and made preliminary experimental evaluation. The result of experiment shown that the time to prepare data for a case conference was dramatically reduced to 1/68 meaning that most of the manual operations for data preparation could be removed.","","Electronic:978-1-4799-3211-5; POD:978-1-4799-3212-2","10.1109/SITIS.2013.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727304","metadata extraction;metadata search;unstructued data","Biomedical imaging;Data mining;Hospitals;Information systems;Search engines;Search problems;XML","content management;data preparation;data structures;information retrieval;meta data;search engines","content repurposing platform;content router;data preparation;data sources;data types;metadata DB;metadata database;metadata extraction engine;object storage;patient information searching;research and development;rich media extracted metadata;search engine;search refinement;situation aware information system;unstructured data","","0","","14","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Identification the shape of biconcave Red Blood Cells using Histogram of Oriented Gradients and covariance features","G. Apostolopoulos; S. V. Tsinopoulos; E. Dermatas","Electr. Eng. & Comput. Technol. Dept., Univ. of Patras, Patras, Greece","13th IEEE International Conference on BioInformatics and BioEngineering","20140109","2013","","","1","4","In this paper, a novel methodology for estimating the shape of human biconcave Red Blood Cells (RBCs), using color scattering images, is presented. The information retrieval process includes, image normalization, features extraction using both Histogram of Oriented Gradients (HoG) and region covariance features (RCoV); and features dimensionality reduction using the Independent Component Analysis (ICA). The points of interest (PoIs) are detected using the Harriscorner detector in order to extract the image features. A scheme using adjustable algorithms, i.e. support vectors machine (SVM) is adopted in order to fuse the multimodal features. A Radial Basis Function Neural Network (RBF-NN) estimates the RBC geometrical properties. The proposed method is evaluated in both regression and identification tasks by processing images of a simulated device used to acquire scattering phenomena of moving RBCs. The evaluation database includes 23625 scattering images, obtained by means of the Boundary Element Method. The regression and identification accuracy of the actual RBC shape is estimated using three feature sets in the presence of additive white Gaussian noise from 60 to 10 dB SNR, giving a mean error rate less than 1 percent of the actual RBC shape, and more than 99 percent mean identification rate in a set of valid RBCs size.","","Electronic:978-1-4799-3163-7; POD:978-1-4799-3164-4","10.1109/BIBE.2013.6701700","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701700","","Feature extraction;Histograms;Red blood cells;Scattering;Shape;Signal to noise ratio;Support vector machines","Gaussian noise;biomedical optical imaging;blood;boundary-elements methods;cellular biophysics;covariance analysis;feature extraction;independent component analysis;information retrieval;light scattering;medical image processing;radial basis function networks;regression analysis;support vector machines","Harris-corner detector;ICA;RBC geometrical properties;RBF-NN;SNR;SVM;acquire scattering phenomena;additive white Gaussian noise;adjustable algorithms;boundary element method;color scattering images;feature dimensionality reduction;feature extraction;histogram-of-oriented gradients;human biconcave red blood cells;identification accuracy;identification tasks;image features;image normalization;image processing;independent component analysis;information retrieval process;multimodal features;radial basis function neural network;region covariance features;regression accuracy;regression tasks;support vector machine","","1","","29","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Cloud data center optimization approach using dynamic data interchanges","E. Rappos; S. Robert; R. H. Riedi","Haute Ecole d'Ing. et de Geston du Canton de Vaud, Univ. of Appl. Sci. of Western Switzerland, Yverdon-les-Bains, Switzerland","2013 IEEE 2nd International Conference on Cloud Networking (CloudNet)","20140116","2013","","","175","179","Distributed data center architectures have been recently developed for a more efficient and economical storage of data. In many models of distributed storage, the aim is to store the data in such a way so that the storage costs are minimized and increased redundancy requirements are maintained. However, many approaches do not fully consider issues relating to delivering the data to the end user and the associated costs that this creates. We present an integer programming optimization model for determining the optimal allocation of data components among a network of Cloud data servers in such a way that the total costs of additional storage, estimated data retrieval costs and network delay penalties is minimized. The method is suitable for periodic dynamic reconfiguration of the Cloud data servers, so that the when localized data request spikes occur the data can be moved to a closer or cheaper data server for cost reduction and increased efficiency.","","Electronic:978-1-4799-0568-3; POD:978-1-4799-0567-6; USB:978-1-4799-0566-9","10.1109/CloudNet.2013.6710573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710573","cache storage;grid computing;mathematical programming","Conferences;Data models;Distributed databases;Mathematical model;Optimization;Resource management;Servers","cloud computing;computer centres;information retrieval;integer programming","cloud data center optimization approach;cloud data servers;data retrieval estimation;data server;distributed data center architectures;distributed storage;dynamic data interchanges;economical storage;integer programming optimization model;network delay penalties;optimal allocation","","1","","13","","","11-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"Approaches to establishing a metadata standard for field spectroscopy datasets","B. A. Rasaiah; T. J. Malthus; C. Bellman; L. Chisholm; J. Gamon; A. Hueni; A. Huete; S. D. Jones; C. Ong; S. Phinn; C. Roelfsema; L. Suarez; P. Townsend; R. Trevithick; M. Wyatt","RMIT Univ. Melbourne, Melbourne, VIC, Australia","2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS","20140127","2013","","","4523","4526","There is an urgent need within the international remote sensing community to establish a metadata standard for field spectroscopy that ensures high quality, interoperable metadata sets that can be archived and shared efficiently within Earth observation data sharing systems. Careful examination of all stages of metadata collection and analysis can inform a robust standard that is applicable to a range of field campaigns. This paper presents approaches towards a standard that encompasses in situ metadata collection and initiatives towards sharing metadata within intelligent archiving systems.","2153-6996;21536996","Electronic:978-1-4799-1114-1; POD:978-1-4799-1112-7","10.1109/IGARSS.2013.6723841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6723841","Calibration;Data Quality;Databases;Field Spectroscopy;Metadata;Validation","Australia;Global Earth Observation System of Systems;Instruments;Protocols;Remote sensing;Spectroscopy;Standards","data analysis;geophysical techniques;geophysics computing;information retrieval systems;meta data;open systems;remote sensing","Earth observation data sharing systems;field campaigns;field spectroscopy datasets;high quality interoperable metadata sets;in-situ metadata collection;intelligent archiving systems;international remote sensing community;metadata analysis;metadata standard","","0","","5","","","21-26 July 2013","","IEEE","IEEE Conference Publications"
"Automatic pronunciation clustering using a World English archive and pronunciation structure analysis","H. P. Shen; N. Minematsu; T. Makino; S. H. Weinberger; T. Pongkittiphan; C. H. Wu","Nat. Cheng Kung Univ., Tainan, Taiwan","2013 IEEE Workshop on Automatic Speech Recognition and Understanding","20140109","2013","","","222","227","English is the only language available for global communication. Due to the influence of speakers' mother tongue, however, those from different regions inevitably have different accents in their pronunciation of English. The ultimate goal of our project is creating a global pronunciation map of World Englishes on an individual basis, for speakers to use to locate similar English pronunciations. If the speaker is a learner, he can also know how his pronunciation compares to other varieties. Creating the map mathematically requires a matrix of pronunciation distances among all the speakers considered. This paper investigates invariant pronunciation structure analysis and Support Vector Regression (SVR) to predict the inter-speaker pronunciation distances. In experiments, the Speech Accent Archive (SAA), which contains speech data of worldwide accented English, is used as training and testing samples. IPA narrow transcriptions in the archive are used to prepare reference pronunciation distances, which are then predicted based on structural analysis and SVR, not with IPA transcriptions. Correlation between the reference distances and the predicted distances is calculated. Experimental results show very promising results and our proposed method outperforms by far a baseline system developed using an HMM-based phoneme recognizer.","","Electronic:978-1-4799-2756-2; POD:978-1-4799-2757-9; USB:978-1-4799-2755-5","10.1109/ASRU.2013.6707733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707733","World Englishes;f-divergence;pronunciation structure analysis;speaker-based pronunciation clustering;support vector regression","Correlation;Educational institutions;Grammar;Hidden Markov models;Speech;Support vector machines;Training","hidden Markov models;information retrieval systems;natural language processing;records management;regression analysis;support vector machines","HMM based phoneme recognizer;IPA narrow transcriptions;SAA;SVR;automatic pronunciation clustering;english pronunciation;global communication;interspeaker pronunciation;pronunciation structure analysis;speakers mother tongue;speech accent archive;speech data;support vector regression;world English archive","","2","","25","","","8-12 Dec. 2013","","IEEE","IEEE Conference Publications"
"Boosting the Innovation Process in Collaborative Environments","V. Bellandi; P. Ceravolo; E. Damiani; F. Frati; G. L. Cota; J. Maggesi","Dept. of Comput. Sci., Univ. degli Studi di Milano, Crema, Italy","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","1432","1437","In this paper we propose a new architecture and methodology to define a collaborative environment aimed at supporting the innovation process. In the first part of this paper we analyse the data collected during an experiment for testing a collaborative environment and, in the second part, we propose an architecture to support and stimulate innovation processes. Our solution is based on three components, namely a (i) collaborative platform, (ii) a tool able to extract knowledge from shared documents, external data sources, and collaborative activities, and (iii) a recommender system. More specifically, we focus on how knowledge items are extracted from incoming knowledge flows to be proposed to a team, whose members are capable of proposing values for design issues and/or evaluating these choices from her own specific perspective. Furthermore, the aim of the proposed framework is not limited to the selection of relevant knowledge but, more broadly, on aligning the team on a restricted set of information items, producing a convergence of objectives that accelerates the kinetics of the collaborative work.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.247","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722000","Collaborative Environment;Innovation Process;Recommender System","Collaboration;Companies;Knowledge based systems;Recommender systems;Tag clouds;Technological innovation","groupware;information retrieval;knowledge acquisition;recommender systems","collaborative environment;collaborative platform;innovation process;knowledge extraction;recommender system","","1","","23","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Web crawlers: To detect security holes","B. Arif; H. N. Qureshi; A. un Nisa; U. e. H. Siddiqui; Q. Shafi; T. Tariq","Univ. of Eng. & Technol., Lahore, Pakistan","2013 International Conference on Open Source Systems and Technologies","20140127","2013","","","133","140","Today, the web is all about the dynamic content; the information created whilst it is needed i.e. the resources are not readily available to the users. Then how it is possible that a web crawler finds a resource that is either protected by a session or hidden behind an authentication form? The query triggered to look-for the answers to the questions on web crawlers which are; what is a crawler? Why it's needed? How it works? Implementation of a typical crawler, How crawlers are categorized? For a comprehensive study on the existing web crawlers their comparative analysis on the basis of different attributes to find problems, from crawler and application perspective, research was conducted. Moreover, after discerning the grounds, architecture of a prototype that ensures and inspects the security of online assets in order to maintain the information security by finding where are the security holes that allow a web crawler to intrude in and fetch the location of a specific resource from a hidden database? Or what features are included in the crawlers that make them good enough to find hidden resources? This paper is an attempt to find out the answer to both questions in either way, to cope up with the security issues and vulnerabilities of online resources.","","CD-ROM:978-1-4799-2047-1; Electronic:978-1-4799-2046-4; POD:978-1-4799-2048-8","10.1109/ICOSST.2013.6720619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720619","Crawler;Dynamiccontent;Online Assets;Vulnerabilities","Crawlers;Databases;Educational institutions;Robots;Security;Servers;Web pages","Internet;query processing;question answering (information retrieval);security of data","Web crawler categorization;hidden database;information resources;information security;online assets security;online resource vulnerabilities;security hole detection;security issues","","1","","22","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Sparse Multi-Modal Hashing","F. Wu; Z. Yu; Y. Yang; S. Tang; Y. Zhang; Y. Zhuang","Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China","IEEE Transactions on Multimedia","20140115","2014","16","2","427","439","Learning hash functions across heterogenous high-dimensional features is very desirable for many applications involving multi-modal data objects. In this paper, we propose an approach to obtain the sparse codesets for the data objects across different modalities via joint multi-modal dictionary learning, which we call sparse multi-modal hashing (abbreviated as SM<sup>2</sup>H). In SM<sup>2</sup>H, both intra-modality similarity and inter-modality similarity are first modeled by a hypergraph, then multi-modal dictionaries are jointly learned by Hypergraph Laplacian sparse coding. Based on the learned dictionaries, the sparse codeset of each data object is acquired and conducted for multi-modal approximate nearest neighbor retrieval using a sensitive Jaccard metric. The experimental results show that SM<sup>2</sup>H outperforms other methods in terms of mAP and Percentage on two real-world data sets.","1520-9210;15209210","","10.1109/TMM.2013.2291214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6665155","Dictionary learning;multi-modal hashing;sparse coding","Artificial neural networks;Correlation;Data models;Dictionaries;Dinosaurs;Feature extraction;Search problems","data acquisition;file organisation;graph theory;information retrieval;learning (artificial intelligence)","SM<sup>2</sup>H;data object acquisition;heterogenous high-dimensional features;hypergraph Laplacian sparse coding;intermodality similarity;intramodality similarity;joint multimodal dictionary learning;multimodal approximate nearest neighbor retrieval;multimodal data objects;sensitive Jaccard metric;sparse codesets;sparse multimodal hashing","","22","","51","","20131114","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Micro-blog commercial word extraction based on improved TF-IDF algorithm","X. Huang; Q. Wu","Sch. of Comput. Sci. & Technol., Hangzhou Dianzi Univ., Hangzhou, China","2013 IEEE International Conference of IEEE Region 10 (TENCON 2013)","20140123","2013","","","1","5","Nowadays found some micro-blog commercial extraction algorithm only considering the relationship between the key words and the number of it appearing in texts, and ignoring the key words' distribution in a certain category, which leads the decreased accuracy problems of micro-blog commercial word extraction. To solve this problem, the application of TF-IDF algorithm in words weight calculation was researched in this paper. Combining the relevant knowledge of information theory and analyzing the distribution of keywords within a class, the article proposed improving TF-IDF algorithm and applying it in term weight calculation. To test the feasibility of the improved algorithm, this paper initially classified the massive micro-blog information into certain types, and then used improved TFIDF algorithm to calculate term weight among the categories, and, this calculation was realized under the Hadoop Distributed framework. The experiment results demonstrated that in the application of micro-blog commercial word extraction, the improved TF-IDF algorithm is effective and feasible. Compared with traditional algorithms, the improved algorithm greatly improved accuracy. In addition, the data processing speed has greatly improved under Hadoop framework.","2159-3442;21593442","Electronic:978-1-4799-2827-9; POD:978-1-4799-2828-6","10.1109/TENCON.2013.6718884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718884","Commercial Word Extract;Hadoop;Mass Data;Micro-blog;TF-IDF","Accuracy;Blogs;Classification algorithms;Data mining;Entertainment industry;Games;Internet","Web sites;distributed processing;information retrieval;pattern classification","Hadoop distributed framework;improved TF-IDF algorithm;information classification;information theory;keywords distribution;microblog commercial word extraction;term frequency-inverse document frequency algorithm;term weight calculation;words weight calculation","","2","","14","","","22-25 Oct. 2013","","IEEE","IEEE Conference Publications"
"Privacy-preserving recommender systems in dynamic environments","Z. Erkin; T. Veugen; R. L. Lagendijk","Inf. Security & Privacy Lab., Delft Univ. of Technol., Delft, Netherlands","2013 IEEE International Workshop on Information Forensics and Security (WIFS)","20140109","2013","","","61","66","Recommender systems play a crucial role today in on-line applications as they improve the customer satisfaction, and at the same time results in an increase in the profit for the service provider. However, there are serious privacy concerns as such systems rely on the personal data of the customers. There have been several proposals to provide privacy in recommender systems and, among many others, cryptographic techniques provide effective ways of protecting privacy-sensitive data of the customers. Unfortunately, existing methods only consider a static environment with constant number of customers in the system, which can be abused to extract more information on the customers when a cryptography based protocol is executed repeatedly. In this paper, we provide a privacy-preserving recommender system for a dynamic environment, which is more suitable for the real world applications.","2157-4766;21574766","Electronic:978-1-4673-5593-3; POD:978-1-4673-5591-9","10.1109/WIFS.2013.6707795","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707795","","Cryptography;Protocols;Servers","cryptographic protocols;customer satisfaction;data privacy;electronic commerce;information retrieval;recommender systems","cryptographic techniques;cryptography based protocol;customer satisfaction improvement;dynamic environments;e-commerce;information extraction;privacy-preserving recommender systems;serious privacy concerns","","0","","21","","","18-21 Nov. 2013","","IEEE","IEEE Conference Publications"
"Toward Enhancing Web Accessibility for Blind Users through the Semantic Web","B. Semaan; J. Tekli; Y. B. Issa; G. Tekli; R. Chbeir","LE2I Lab., Univ. of Bourgogne, Dijon, France","2013 International Conference on Signal-Image Technology & Internet-Based Systems","20140130","2013","","","247","256","The problems of Web data accessibility and navigation for blind users have become an active research field for the past decade. Many techniques have been created to solve them, some are hardware based and others are software based. Yet, the Web is rapidly evolving toward the far-anticipated Semantic Web (SW): a revolutionary vision extending Web information with well-defined meaning so that it becomes more easily accessible by human users and automated processes. As a result, SW technological breakthroughs such as ontologies and semantic data description, as well as data representation and manipulation technologies (i.e., RDF, OWL, and SPARQL) are being recently explored to improve data accessibility for blind Web surfers. In this paper, we briefly explore existing studies targeting Web data accessibility for blind users, ranging from traditional techniques (Braille output, screen readers, etc.) toward semantically enhanced techniques (using SW technologies). Then, we present an ongoing framework, exploring SW technologies (namely RDF, RDFa and OWL) in order to improve the representation of heterogeneous Web pages (typically pages not conforming to the W3C recommendations for Web page design), adapting the document's contents and presentation so that it best fits the blind user's needs.","","Electronic:978-1-4799-3211-5; POD:978-1-4799-3212-2","10.1109/SITIS.2013.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727199","Blind users;Braille;Multi-axial navigation;Screen readers;Semantic annotation;Web navigation;touch-screen semantic navigation","Browsers;Guidelines;Navigation;Ontologies;Resource description framework;Semantics;Visualization","data structures;handicapped aids;information retrieval;knowledge representation languages;ontologies (artificial intelligence);semantic Web;touch sensitive screens","Braille output;OWL;RDF;RDFa;SPARQL;SW technologies;W3C recommendations;Web data accessibility;Web data navigation;Web information;Web page design;Web surfers;blind users;data manipulation technology;data representation technology;document contents;heterogeneous Web page representation;ontologies;screen readers;semantic Web;semantic data description;semantically enhanced techniques","","2","","52","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"An efficient web recommender system based on approach of mining frequent sequential pattern from customized web log preprocessing","M. Valera; U. Chauhan","Dept. of Comput. Eng., C.U. Shah Coll. Of Eng. & Technol., Surendranagar, India","2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT)","20140130","2013","","","1","6","Internet has penetrated into every areas of society and has also become a huge, pervasive distribution and global information service center. In a real world The only option is to capture the attention of the user and provide them with the recommendation list to match the needs of user and keep their attention in their web site. Web usage mining is a kind of data mining method that provide Smart personalized online services such as web recommendations, it is usually necessary to model users' web access behavior. Web usage mining includes three process, namely, preprocessing, pattern discovery and pattern analysis. The data reduction is achieved through data preprocessing. The aim of discovering frequent sequential access patterns in Web log data is to obtain information about the navigational behavior of the users. In the proposed system, an efficient sequential pattern mining algorithm is used to identify frequent sequential web access patterns. The access patterns are retrieved from a Graph, which is then used for matching and generating web links for recommendations.","","Electronic:978-1-4799-3926-8; POD:978-1-4799-3927-5","10.1109/ICCCNT.2013.6726493","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726493","Pattern Analysis;Pattern Discovery;Preprocessing;Recommendation;Sequential Pattern Mining;Sequential Patterns;Web Mining;Web Usage Mining (WUM);Weblog","Cleaning;Data mining;IP networks;Servers;Silicon;Web pages","Internet;Web sites;data mining;information retrieval;recommender systems","Web link generation;Web link matching;Web recommender system;Web site;Web usage mining;customized Web log data preprocessing;data reduction;frequent sequential Web access pattern retrieval;global information service center;graph;navigational behavior;pattern analysis;pattern discovery;pervasive distribution;sequential access pattern mining algorithm;smart personalized online services;user Web access behavior","","0","","12","","","4-6 July 2013","","IEEE","IEEE Conference Publications"
"The design of an output data collection framework for NS-3","L. F. Perrone; T. R. Henderson; M. J. Watrous; V. Daly Felizardo","Dept. of Comput. Sci., Bucknell Univ., Lewisburg, PA, USA","2013 Winter Simulations Conference (WSC)","20140127","2013","","","2984","2995","An important design decision in the construction of a simulator is how to enable users to access the data generated in each run of a simulation experiment. As the simulator executes, the samples of performance metrics that are generated beg to be exposed either in their raw state or after having undergone mathematical processing. Also of concern is the particular format this data assumes when externalized to mass storage, since it determines the ease of processing by other applications or interpretation by the user. In this paper, we present a framework for the ns-3 network simulator for capturing data from inside an experiment, subjecting it to mathematical transformations, and ultimately marshaling it into various output formats. The application of this functionality is illustrated and analyzed via a study of common use cases. Although the implementation of our approach is specific to ns-3, this design presents lessons transferrable to other platforms.","0891-7736;08917736","Electronic:978-1-4799-3950-3; POD:978-1-4799-3727-1","10.1109/WSC.2013.6721666","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6721666","","Analytical models;Computational modeling;Data collection;Data models;Observers;Probes","information retrieval;mathematical analysis;storage management","NS-3;data access;mass storage;mathematical processing;output data collection framework;performance metrics","","3","1","14","","","8-11 Dec. 2013","","IEEE","IEEE Conference Publications"
"Model-based speech/non-speech segmentation of a heterogeneous multilingual TV broadcast collection","B. Desplanques; J. P. Martens","ELIS Multimedia Lab., Ghent Univ. - iMinds, Ghent, Belgium","2013 International Symposium on Intelligent Signal Processing and Communication Systems","20140109","2013","","","55","60","Multimedia Information Retrieval systems normally comprise a preprocessor that performs a speech/non-speech (SNS) segmentation of the audio stream. The goal of such a segmentation is to divide the audio into intervals that need a lexical transcription and intervals that just need some categorization in terms of jingle, applause, etc. In this paper a baseline SNS system that was trained on monolingual BN data is evaluated on a multilingual BN corpus and on a heterogeneous corpus, composed of diverse TV shows including discussions, soaps, animation films, etc. It appears that the system exhibits serious deficiencies when confronted with such out-of-domain data. Especially the heterogeneous corpus, characterized by many short speaker turns and a rich pallet of non-speech intervals, turns out to be challenging. However, employing a proper SNS information criterion, it is demonstrated that enhancing the acoustic representation of the audio, creating a richer music model and performing a file-wise adaptation of the acoustic models can significantly increase the performance. Complex architectures permitting explicit duration modeling and re-segmentation of the speech parts after speaker change detection on the other hand do not seem to help.","","Electronic:978-1-4673-6361-7; POD:978-1-4673-6359-4","10.1109/ISPACS.2013.6704522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6704522","","Acoustics;Adaptation models;Computational modeling;Data models;Hidden Markov models;Speech;TV","acoustic signal processing;audio acoustics;audio signal processing;audio streaming;information retrieval;multimedia systems;signal representation;speech processing;television broadcasting","SNS information criterion;acoustic models;acoustic representation;audio stream;heterogeneous corpus;heterogeneous multilingual TV broadcast collection;lexical transcription;model-based speech-nonspeech segmentation;multimedia information retrieval systems;speaker change detection","","0","","16","","","12-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Framework for Automatic Text Generation of Trends in Physiological Time Series Data","H. Banaee; M. U. Ahmed; A. Loutfi","Center for Appl. Autonomous Sensor Syst. (AASS), Orebro Univ., Orebro, Sweden","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","3876","3881","Health monitoring systems using wearable sensors have rapidly grown in the biomedical community. The main challenges in physiological data monitoring are to analyse large volumes of health measurements and to represent the acquired information. Natural language generation is an effective method to create summaries for both clinicians and patients as it can describe useful information extracted from sensor data in textual format. This paper presents a framework of a natural language generation system that provides a text-based representation of the extracted numeric information from physiological sensor signals. More specifically, a new partial trend detection algorithm is introduced to capture the particular changes and events of health parameters. The extracted information is then represented considering linguistic characterisation of numeric features. Experimental analysis was performed using a wearable sensor and demonstrates a possible output in natural language text.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722414","Health monitoring;body area networks;linguistic summarisation;natural language generation;physiological data analysis","Biomedical monitoring;Data analysis;Heart rate;Market research;Natural languages;Pragmatics;Time series analysis","biosensors;computerised monitoring;health care;information retrieval;natural language processing;text analysis;time series","automatic text generation;biomedical community;clinicians;health measurements;health monitoring systems;linguistic characterisation;natural language generation system;natural language text;numeric information extraction;partial trend detection algorithm;patients;physiological data monitoring;physiological sensor signals;physiological time series data;sensor data;text-based representation;textual format;wearable sensors","","3","","18","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Teenagers searching for information by using texts and hypertexts: How effective is it?","P. Gossin","LISEC, Univ. de Strasbourg, Strasbourg, France","2013 3rd International Symposium ISKO-Maghreb","20140130","2013","","","1","4","In 2012, ten years after the original study, we researched this subject for a second time. The exact conditions of the original study were reproduced. We wanted to measure the generational effect. Does the increased use of digital media change the results found in 2002? Are the students as skilled today with hypertext as they are with traditional text? The results showed that the increased use of information technology and communication had no effect on the efficiency of students while searching for information.","","CD-ROM:978-1-4799-3391-4; Electronic:978-1-4799-3392-1; POD:978-1-4799-3393-8","10.1109/ISKO-Maghreb.2013.6728171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728171","Computer science education;Information;digital media;documentation","Educational institutions;Grammar;Information technology;Media;Protocols;Sociology;Statistics","information retrieval;text analysis","digital media;hypertexts;information seeking strategies;of information technology and communication;traditional text","","0","","15","","","8-9 Nov. 2013","","IEEE","IEEE Conference Publications"
"A lightweight operating system-oriented web server realization","L. L. Wang; P. F. Zeng","Coll. of Comput. Sci. & Technol., Donghua Univ., Shanghai, China","2013 10th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20140123","2013","","","186","190","This paper describes a web server which is oriented to a lightweight operating system. The real-time server is used for remote control and data access. Both the characteristics of the lightweight operating system and the communication principle of HTTP are analyzed when implementing the server. To satisfy its practical requirements, the server is designed to achieve its major function with the limited resources of devices. The processes of request response and data package parsing are described in this paper in details. Meanwhile, this paper gives a new method to obtain the entity bodies from multiple request messages. Though limited by the low-performance hardware, the web server achieves strong portability and practicability. The experience shows that the server responds rapidly and runs steadily. The server also can be applied to the similar lightweight operating systems.","","CD-ROM:978-1-4799-2444-8; Electronic:978-1-4799-2446-2; POD:978-1-4799-2447-9","10.1109/ICCWAMTIP.2013.6716628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716628","HTTP protocol;Web server;embedded device;lightweight operating system","Hardware;Message systems;Operating systems;Performance evaluation;Real-time systems;Web servers","Internet;file servers;information retrieval;operating systems (computers);real-time systems;transport protocols","HTTP communication principle;data access;data package parsing;lightweight operating system-oriented Web server realization;low-performance hardware;real-time server;remote control;request response","","0","","9","","","17-19 Dec. 2013","","IEEE","IEEE Conference Publications"
"SSTCSC: A Semantic Structure of Test Cases and Source Code","M. B. Bashir; T. Malik; T. Afzal","Center for Software Dependability, Mohammad Ali Jinnah Univ., Islamabad, Pakistan","2013 11th International Conference on Frontiers of Information Technology","20140123","2013","","","241","246","If the World Wide Web is taken as a mountain of information containing data regarding every aspect of life, then Semantic Web is its extended version, that structures the information and makes it machine process able. Semantic Web has many advantages which have proved it as an innovative approach to structure the data for multipurpose domains. Its characteristics of annotation enable the extraction of precise information which is required by the user. Software testing is the process which evaluates a systems behavior to ensure whether it meets user's requirement or not. In software engineering, specifically in the software testing domain, semantic structuring the relevant artifacts is new. Researchers provided XML based representations for many languages and approaches but their context is different when we try to apply it on the software testing domain. In this paper, we focus on the shortcomings of the software testing domain when its concerned activities are required to represent semantically. We present a novel approach, Semantic Structure of Test Cases and Source Code (SSTCSC) which relates the RDF based test cases satisfying white box testing coverage criterion statement coverage, with the RDF based target java class(s). After the execution of semantically presented information (test cases against program) is then passes through two phases further i.e. Code Categorization and Code Visualization which shows the final output of the classified code segments visually. Whole process of the presented approach is supported by the tool which performs the related steps with ease automatically.","","Electronic:978-1-4799-2503-2; POD:978-1-4799-2700-5","10.1109/FIT.2013.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6717260","Resource Discription Frameowrk (RDF);Semantic Web;Source Code;Test Cases","Java;Resource description framework;Semantics;Software;Software testing;XML","Java;XML;information retrieval;program testing;semantic Web;source code (software)","RDF based target Java class;RDF based test cases;SSTCSC;World Wide Web;XML based representations;code categorization;code segments;code visualization;multipurpose domains;precise information extraction;semantic Web;semantic structure;semantic structuring;software engineering;software testing domain;source code;systems behavior;white box testing coverage criterion","","0","","27","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Socially-Aware Venue Recommendation for Conference Participants","F. Xia; N. Y. Asabere; J. J. P. C. Rodrigues; F. Basso; N. Deonauth; W. Wang","Sch. of Software, Dalian Univ. of Technol., Dalian, China","2013 IEEE 10th International Conference on Ubiquitous Intelligence and Computing and 2013 IEEE 10th International Conference on Autonomic and Trusted Computing","20140130","2013","","","134","141","Current research environments are witnessing high enormities of presentations occurring in different sessions at academic conferences. This situation makes it difficult for researchers (especially juniors) to attend the right presentation session(s) for effective collaboration. In this paper, we propose an innovative venue recommendation algorithm to enhance smart conference participation. Our proposed algorithm, Social Aware Recommendation of Venues and Environments (SARVE), computes the Pearson Correlation and social characteristic information of conference participants. SARVE further incorporates the current context of both the smart conference community and participants in order to model a recommendation process using distributed community detection. Through the integration of the above computations and techniques, we are able to recommend presentation sessions of active participant presenters that may be of high interest to a particular participant. We evaluate SARVE using a real world dataset. Our experimental results demonstrate that SARVE outperforms other state-of-the-art methods.","","Electronic:978-1-4799-2482-0; POD:978-1-4799-2483-7","10.1109/UIC-ATC.2013.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726201","Social awareness;community;context;recommender systems;smart conference","Collaboration;Communities;Conferences;Context;Correlation;Mobile communication;Recommender systems","information retrieval;mobile computing;recommender systems;social sciences computing","Pearson correlation;SARVE;Social Aware Recommendation of Venues and Environments;academic conferences;conference participants;distributed community detection;effective collaboration;innovative venue recommendation algorithm;mobile device;presentation sessions;research environment;smart conference community;smart conference participation;social characteristic information;socially-aware venue recommendation","","3","","19","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Modelings and techniques in Named Entity Recognition-an Information Extraction task","N. Kanya; T. Ravi","Manonmaniam Sundaranar Univ., Thirunelveli, India","IET Chennai 3rd International on Sustainable Energy and Intelligent Systems (SEISCON 2012)","20140123","2012","","","1","5","Information Extraction, which is an area of natural language processing that deals with finding factual information in free text. The task of Information Extraction (IE) is to identify a predefined set of concepts i.e., a representation of the information that is machine understandable. The classic IE tasks include Named Entity Recognition (NER) addresses the problem of the identification and classification of predefined types of named entities. Co-reference Resolution (CO), Relation Extraction (RE),Event Extraction (EE) Named Entity Recognition (NER) aims to extract and to classify rigid designators in text such as proper names, biological species, and temporal expressions. In this paper, we present various efficient NER techniques and modeling's . Named entity recognition addresses the problem of locating textual mentions of predefined types of entities, where the entity categories can be very diverse, ranging from people and companies in business applications to cells and proteins in biomedical applications.","","Electronic:978-1-84919-797-7","10.1049/cp.2012.2199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719105","Information Extraction;Named Entity Recognition;Text Mining","","information retrieval;learning (artificial intelligence);pattern classification;text analysis","CO;EE;IE tasks;NER techniques;RE;biological species;co-reference resolution;entity categories;event extraction;factual information;free-text;information extraction task;machine understandable information representation;named entity classification;named entity identification;named entity recognition modeling;named entity recognition technique;natural language processing;proper names;relation extraction;rigid designator classification;rigid designator extraction;temporal expressions;textual mention location","","0","","","","","27-29 Dec. 2012","","IET","IET Conference Publications"
"Boundary regularization and building reconstruction based on terrestrial laser scanning data","F. Wang; X. Xi; C. Wang; Y. Xiao; Y. Wan","Inst. of Remote Sensing & Digital Earth, Beijing, China","2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS","20140127","2013","","","1509","1512","Digitization and modeling of city buildings is always one of the most important issues in Virtual 3D City. Traditional methods are usually expensive and time-consuming. Nowadays reconstruction methods based on LiDAR (Light Detection And Range) data have been widely used [1] due to its powerful capacity of data acquisition. Airborne Laser Scanning (ALS) data have got some promising results [2]. However the obvious disadvantage is that it can hardly get the profile information except for the roof of building, and the result is that people can not get complete building model. On the contrary, Terrestrial Laser Scanning (TLS) could get points cloud of buildings with high density and accuracy by multi-stations scanning for realistic 3D model reconstruction. The information includes not only building roofs, but also building profiles. In this paper, the authors use TLS data, and explore an automatic model reconstruction approach to establish digital building model. The registered cloud points from multiple scanning stations are taken as input parameters. Profiles information of building is extracted from raw points cloud by a segmentation algorithm. And a regular polyhedron model of building is finally presented. The experiment results show that the automatic reconstruction procedure and algorithms are easy to implement and can get reasonable building model after facade boundary regularization.","2153-6996;21536996","Electronic:978-1-4799-1114-1; POD:978-1-4799-1112-7","10.1109/IGARSS.2013.6723073","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6723073","","Algorithm design and analysis;Fitting;Image reconstruction;Laser modes;Three-dimensional displays;Windows","airborne radar;buildings (structures);data acquisition;feature extraction;image reconstruction;image segmentation;information retrieval;optical information processing;optical radar;optical scanners;roofs;solid modelling;virtual reality","LiDAR;TLS data;airborne laser scanning;automatic model reconstruction approach;boundary regularization;building profiles information extraction;building reconstruction;building roof;city buildings digitization;city buildings modeling;data acquisition;digital building model;light detection and range;multistations scanning;points cloud registration;raw points cloud;realistic 3D model reconstruction;regular polyhedron model;segmentation algorithm;terrestrial laser scanning data;virtual 3D city","","1","","8","","","21-26 July 2013","","IEEE","IEEE Conference Publications"
"Semi-supervised framework for writer identification using structural learning","U. Porwal; V. Govindaraju","Dept. of Comput. Sci. & Eng., SUNY - Univ. at Buffalo, Amherst, NY, USA","IET Biometrics","20140109","2013","2","4","208","215","Writer identification is a complex task as the handwriting of an individual encapsulates lot of information pertaining to text and personality of a writer. To learn a model to distinguish one writer from the other, it is important to capture every nuance of the handwriting of an individual. Learning such model poses two challenges. First, discriminatory variables maybe large and potentially related leading to a complex discriminatory function. Second, it will require large amount of training data to learn a complex and possibly high-dimensional function. In this study, the authors are proposing a semi-supervised framework for writer identification for offline handwritten documents that leverages the information hidden in the unlabelled samples. Proposed framework models the complexity of approximating the optimal hypothesis by breaking the main task into several subtasks and learning a separate hypothesis for each subtask. All the hypotheses pertaining to the subtasks will be used for the best model selection by retrieving a common substructure that has high correspondence with all the candidate hypotheses. The obtained substructure acts as a knowledge base that has the contextual information, which is otherwise difficult to retrieve. The extra information can be used to improve the performance of the identification model.","2047-4938;20474938","","10.1049/iet-bmt.2013.0018","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6679093","","","document handling;handwriting recognition;information retrieval;learning (artificial intelligence)","IAM data set;best model selection;complex discriminatory function;contextual information;discriminatory variables;handwritten text;high-dimensional function;offline handwritten documents;optimal hypothesis;semisupervised framework;structural learning;substructure retrieval;writer identification model","","1","","","","","December 2013","","IET","IET Journals & Magazines"
"A multi-terabyte relational database for geo-tagged social network data","L. Dobos; J. Sz√ºle; T. Bodn√°r; T. Hanyecz; T. Seb≈ëk; D. Kondor; Z. Kallus; J. St√©ger; I. Csabai; G. Vattay","Dept. of Phys. of Complex Syst., Eotvos Lorand Univ., Budapest, Hungary","2013 IEEE 4th International Conference on Cognitive Infocommunications (CogInfoCom)","20140123","2013","","","289","294","Despite their relatively low sampling factor, the freely available, randomly sampled status streams of Twitter are very useful sources of geographically embedded social network data. To statistically analyze the information Twitter provides via these streams, we have collected a year's worth of data and built a multi-terabyte relational database from it. The database is designed for fast data loading and to support a wide range of studies focusing on the statistics and geographic features of social networks, as well as on the linguistic analysis of tweets. In this paper we present the method of data collection, the database design, the data loading procedure and special treatment of geo-tagged and multi-lingual data. We also provide some SQL recipes for computing network statistics.","","Electronic:978-1-4799-1546-0; POD:978-1-4799-1545-3; USB:978-1-4799-1544-6","10.1109/CogInfoCom.2013.6719259","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719259","","Global Positioning System;Indexes;Loading;Servers;Twitter","SQL;geography;information retrieval;relational databases;social networking (online);statistical analysis","SQL recipes;Twitter;data collection;data loading procedure;database design;geo-tagged social network data;geographic features;geographically embedded social network data;linguistic analysis;multiterabyte relational database;network statistics;random sampled status streams;statistical analysis","","3","","20","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Evaluation and error recovery methods of an IVR based real time speech recognition application","S. Khan; J. Basu; M. S. Bepari; R. Roy","CDAC, Kolkata, India","2013 International Conference Oriental COCOSDA held jointly with 2013 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE)","20140111","2013","","","1","6","Field trial and evaluation of any real world speech recognition application using Interactive Voice Response technology are likely to be a daunting task. It has to face challenges regarding spoken language conventions, pronunciation variations, recognition issues in noisy environment, limitations of human cognition, working memory and differences between users. Present study illustrates the entire evaluation process of such an agricultural information retrieval system mainly targeted towards semi-literate or illiterate farmers. A new set of evaluation metrics as per the designed evaluation strategies, details of field trial processes, feedback analysis and finally system performance results are presented in a well organized way. Additionally to meet users' expectations, distinctive error recovery methods like Signal Analysis and Decision, Confidence Measure and Polling, Complementary Information, Runtime model generation etc. are introduced and incorporated to confirm performance enhancement in final trial. Evaluation methods and metrics used here are domain independent and applicable to similar systems.","","Electronic:978-1-4799-2378-6; POD:978-1-4799-3675-5","10.1109/ICSDA.2013.6709847","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6709847","ASR evaluation metrics;ASR field trial analysis;Error recovery methods","Accuracy;Data models;Measurement;Speech;System performance;Testing;Training","agricultural engineering;cognition;human factors;information retrieval;interactive systems;natural languages;real-time systems;speech recognition;voice communication","IVR based real time speech recognition application;agricultural information retrieval system;complementary information;confidence measure and polling;distinctive error recovery methods;feedback analysis;field trial processes;human cognition;illiterate farmers;interactive voice response technology;noisy environment;pronunciation variations;real world speech recognition application;runtime model generation;semiliterate farmers;signal analysis and decision;spoken language conventions;user expectations;working memory","","1","","11","","","25-27 Nov. 2013","","IEEE","IEEE Conference Publications"
"An Ontology-Based Reasoning Approach for Document Annotation","C. A. Fontes; M. C. Cavalcanti; A. M. d. C. Moura","Comput. Eng. Dept., Mil. Inst. of Eng. (IME), Rio de Janeiro, Brazil","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","160","167","Information management has become an important challenge, especially when most of their relevant and strategic documents are available on the Web only for human interpretation. Annotating documents rises as an interesting strategy to diminish the hard task of retrieving important documents from the Web. Annotations consist of associating metadata with text segments of a document, in order to facilitate its retrieval by search engines. Besides improving their performance, annotations enable an optimized indexation of documents. However, due to the huge amount of existing documents, the idea of generating document annotations is not a trivial task. This paper presents a proposal for automatically enriching documents with semantic annotations, where document terms are annotated according to a domain ontology. Currently there already exist some document annotation tools to automate this process. However, the main contribution of this work is focused on the ability of exploring the ontology inference capability and on the meta-annotation concept, which aim at providing users and automatic agents with a more powerful mechanism to retrieve information.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693512","Semantic annotation;document annotation;ontology-based retrieval","Cognition;Context;HTML;Ontologies;Semantics;Taxonomy;Vocabulary","document handling;inference mechanisms;information retrieval;ontologies (artificial intelligence)","automatic agents;document annotation;document retrieval;document terms;domain ontology;information management;meta data;meta-annotation concept;ontology-based reasoning approach;search engines;semantic annotations;text segments","","0","","27","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Labeling Turkish news stories with CRF","S. Kazkilinc; E. Adali","Istanbul Tech. Univ., Istanbul, Turkey","2013 7th International Conference on Application of Information and Communication Technologies","20140127","2013","","","1","5","Drastically document increase in Web requires semantic web applications in order to lead the Web to its full potential. Extracting important phrases in a document facilitates finding expected information. In this paper, a new approach that is labeling the main subject, main predicate, main location and main date of an electronic document is introduced. The main subject label tells whom or what the document about. The main predicate label tells what the subject is or does. The main location label tells where the activities passed and the main date label tells when the document passed. With the help of this new methodology, extraction of not only high level description of the content, but also the attribute of a phrase in a document is provided. As experimental set, Turkish news stories are selected. To use as a training and test set, manual labeling is made by human annotators. Then, different models for each label are implemented to extract the labels automatically and they are compared to manually labeled results to evaluation process of this study.","","Electronic:978-1-4673-6420-1; POD:978-1-4673-6421-8","10.1109/ICAICT.2013.6722634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722634","Conditional Random Fields;Information Extraction;Natural Language Processing","Data mining;Equations;Feature extraction;Labeling;Machine learning algorithms;Mathematical model;Training","document handling;information retrieval;natural language processing;semantic Web;statistical analysis","CRF;Turkish news stories;conditional random fields;electronic document;human annotators;label extraction;natural language processing;phrase extraction;semantic Web applications","","0","","19","","","23-25 Oct. 2013","","IEEE","IEEE Conference Publications"
"Hot topic extraction based on frequency, position, scattering and topical weight for time sliced news documents","Y. Jahnavi; Y. Radhika","Comput. Sci. & Eng. Dept., GITAM Univ., Hyderabad, India","2013 15th International Conference on Advanced Computing Technologies (ICACT)","20140116","2013","","","1","6","Internet based news documents are the basic information transmission media. In such a case detecting hot topics and tracking the event development is most important. However, it is almost impossible to view all the generated topics, due to its large amount of size. Therefore it is necessary to rank the topics. The topic ranking should be done on the importance basis. But this importance is determined by how frequently a topic appears and this importance varies in different time slots. For extracting hot topics, most of the text mining approaches with vector space model need to determine the weighting of the feature terms. Existing traditional algorithms can't achieve high accuracy for retrieving hot terms, because they have not considered position, scattering and topicality. This paper presents an innovative and effective hot term extraction by considering position, scattering and topicality of terms along with frequency.","","CD-ROM:978-1-4673-2816-6; Electronic:978-1-4673-2818-0; POD:978-1-4673-2817-3","10.1109/ICACT.2013.6710495","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710495","TF-PDF;Term Weighting;Text Mining;Vector Space Model (VSM)","Algorithm design and analysis;Feature extraction;Scattering;Text mining;Time-frequency analysis;Vectors","Internet;data mining;document handling;information retrieval;text analysis","Internet based news documents;event development tracking;hot term retrieval;hot topic extraction;information transmission media;innovative hot term extraction;text mining approach;time sliced news documents;topic frequency;topic position;topic scattering;topical weight;vector space model","","1","","22","","","21-22 Sept. 2013","","IEEE","IEEE Conference Publications"
"A novel defense mechanism against web crawlers intrusion","A. Aghamohammadi; A. Eydgahi","Sch. of Eng. Technol., Eastern Michigan Univ., Ypsilanti, MI, USA","2013 International Conference on Electronics, Computer and Computation (ICECCO)","20140123","2013","","","269","272","Web robots also known as crawlers or spiders are used by search engines, hackers and spammers to gather information about web pages. Timely detection and prevention of unwanted crawlers increases privacy and security of websites. In this paper, a novel method to identify web crawlers is proposed to prevent unwanted crawler to access websites. This new method suggests Five-factor identification process to detect unwanted crawlers. This work provides the pretest and posttest results along with a systematic evaluation of web pages with the proposed identification technique versus web pages without the proposed identification process. The outputs of logistic regression analysis for both treatment and control groups are provided to evaluate hypotheses and to answer the research questions. An experiment is performed with repeated measures for two groups with each group containing the same web pages. The main goal of this work was to address the challenge of identifying and preventing unwanted web crawlers by proposing a novel defense mechanism with identification process.","","Electronic:978-1-4799-3343-3; POD:978-1-4799-3344-0","10.1109/ICECCO.2013.6718280","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718280","Privacy;Security;Web crawler detection;Web robot detection;World Wide Web","Crawlers;IP networks;Internet;Robots;Search engines;Servers;Web pages","Web sites;data privacy;information retrieval;regression analysis;security of data","Web crawlers intrusion;Web page systematic evaluation;Web robots;Web site privacy;Web site security;Web spiders;defense mechanism;five-factor identification process;hackers;logistic regression analysis;search engines;spammers","","0","","17","","","7-9 Nov. 2013","","IEEE","IEEE Conference Publications"
"Medoop: A medical information platform based on Hadoop","Wang Lijun; Huang Yongfeng; Chen Ji; Zhou Ke; Li Chunhua","Inst. for Network Sci. & Cyberspace, Tsinghua Univ., Beijing, China","2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)","20140127","2013","","","1","6","Heath information exchange (HIE) is the next step of health informatics development in China. Conformed to the administration feature, the design of HIE platform adopts a centralized architecture, which has to accommodate large amount of health information and support various types of query and data retrieval. Cloud computing is a suitable for the technology requirements of centralized design. In this paper, we proposed a medical information platform based on Hadoop, named after Medoop. The present Medoop utilizes HDFS to store the merged CDA documents efficiently, organize the feature information in CDA documents according to frequent business queries, and compute statistic distributedly in MapReduce paradigm. The objective of Medoop is to construct a comprehensive platform for health information storage and exchange, utilizing the components in Hadoop ecosystem.","","Electronic:978-1-4673-5801-9; POD:978-1-4673-5799-9","10.1109/HealthCom.2013.6720779","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720779","Clinical Document Architecture (CDA);Cloud computing;Hadoop;Health Information Exchange (HIE)","Business;Cloud computing;Computer architecture;Indexing;Medical services;Merging;Semantics","cloud computing;health care;information retrieval;medical information systems;statistical analysis","CDA documents;China;HDFS;HIE;Hadoop ecosystem;MapReduce paradigm;Medoop;centralized architecture;cloud computing;data query;data retrieval;health informatics development;heath information exchange;medical information platform","","1","","10","","","9-12 Oct. 2013","","IEEE","IEEE Conference Publications"
"The Analysis and Comparison of Vital Acoustic Features in Content-Based Classification of Music Genre","Z. Wang; J. Xia; B. Luo","Coll. of Sci., Huazhong Agric. Univ., Wuhan, China","2013 International Conference on Information Technology and Applications","20140111","2013","","","404","408","Digital music is becoming increasingly popular in the Internet, and content-based musical genre classification has gained significant attentions in the field of musical retrieval. In this paper, the acoustic musical features are extracted from the viewpoints of both signal processing and the musical dimension. By comparing the performance of classifier of different combination of acoustic features, the contributions of corresponding features are evaluated. Finally, timbre and tonality feature sets are found to be the most effective features in music genre recognition.","","Electronic:978-1-4799-2877-4; POD:978-1-4799-2878-1","10.1109/ITA.2013.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710015","Feature extraction;Support Vector Machine (SVM) Introduction;contend-based musical classification;musical dimension","Accuracy;Feature extraction;Rhythm;Support vector machines;Timbre","Internet;information retrieval;music;pattern classification","Internet;acoustic musical features;content-based musical genre classification;digital music;musical dimension;musical retrieval;signal processing;timbre feature sets;tonality feature sets;vital acoustic features","","0","","20","","","16-17 Nov. 2013","","IEEE","IEEE Conference Publications"
"Analyzing the dictionary properties and sparsity constraints for a dictionary-based music genre classification system","P. K. Jao; L. Su; Y. H. Yang","Res. Center for Inf. Technol. Innovation, Acad. Sinica, Taipei, Taiwan","2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference","20140102","2013","","","1","8","Learning dictionaries from a large-scale music database is a burgeoning research topic in the music information retrieval (MIR) community. It has been shown that classification systems based on such learned features exhibit state-of-the-art accuracy in many music classification benchmarks. Although the general approach of dictionary-based MIR has been shown effective, little work has been done to investigate the relationship between system performance and dictionary properties, such as the dictionary sparsity, coherence, and conditional number of the dictionary. This paper aims at addressing this issue by systematically evaluating the performance of three types of dictionary learning algorithms for the task of genre classification, including the least-square based RLS (recursive least square) algorithm, and two variants of the stochastic gradient descent-based algorithm ODL (online dictionary learning) with different regularization functions. Specifically, we learn the dictionary with the USPOP2002 dataset and perform genre classification with the GTZAN dataset. Our result shows that setting strict sparsity constraints in the RLS-based dictionary learning (i.e., <;1% of the signal dimension) leads to better accuracy in genre classification (around 80% when linear kernel support vector classifier is adopted). Moreover, we find that different sparsity constraints are needed for the dictionary learning phase and the encoding phase. Important links between dictionary properties and classification accuracy are also identified, such as a strong correlation between reconstruction error and classification accuracy in all algorithms. These findings help the design of future dictionary-based MIR systems and the selection of important dictionary learning parameters.","","Electronic:978-986-90006-0-4; POD:978-1-4799-2794-4","10.1109/APSIPA.2013.6694278","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694278","","Accuracy;Algorithm design and analysis;Classification algorithms;Dictionaries;Encoding;Kernel;Support vector machines","audio databases;gradient methods;information retrieval;learning (artificial intelligence);least squares approximations;music;pattern classification;stochastic processes","GTZAN dataset;MIR community;RLS-based dictionary learning algorithms;USPOP2002 dataset;classification accuracy;dictionary coherence;dictionary properties;dictionary sparsity;dictionary-based MIR systems;genre classification;large-scale music database;least-square based RLS algorithm;linear kernel support vector classifier;music information retrieval community;online dictionary learning;performance evaluation;reconstruction error;recursive least square algorithm;regularization functions;signal dimension;sparsity constraints;stochastic gradient descent-based algorithm ODL","","1","","26","","","Oct. 29 2013-Nov. 1 2013","","IEEE","IEEE Conference Publications"
"Recognizing the languages in WebPages ‚Äî A framework for NLP","S. Rajesh; L. Vandana; C. A. Carie; B. Marapelli","Dept. Of Cse, Nalla Narasimha Reddy Educ. Soc.'s Group of Instn., Hyderabad, India","2013 IEEE International Conference on Computational Intelligence and Computing Research","20140127","2013","","","1","5","In this paper we describe an experimental system using java programming language which demonstrates a variety of application level tradeoffs available to distributed NLP applications. In this paper, we proposed language identification system with N-gram-based matching for document retrieval. By using a well known N-gram based algorithm for automatic language identification, we construct a system that dynamically adds language labels for whole documents or text fragments.","","Electronic:978-1-4799-1597-2; POD:978-1-4799-1596-5","10.1109/ICCIC.2013.6724269","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724269","IRS;JAVA;NLP;Object Oriented;language Model","Computational intelligence;Conferences;Internet;Search engines;Software;Training;Web pages","Internet;Java;document handling;information retrieval;natural language processing","Java programming language;N-gram-based matching algorithm;Web pages;automatic language identification system;distributed NLP applications;document retrieval;text fragments","","0","","17","","","26-28 Dec. 2013","","IEEE","IEEE Conference Publications"
"Web OPAC end user satisfaction from Library Science and Information System Perspectives","H. B. Zainal; A. R. B. C. Hussin; N. F. B. Sa'don","Fac. of Comput., Univ. Teknol. Malaysia, Skudai, Malaysia","2013 International Conference on Research and Innovation in Information Systems (ICRIIS)","20140123","2013","","","487","492","Web Online Public Access Catalogue (OPAC) is widely used electronic library catalogues giving a wealth of remote access to library information resources. The end user satisfaction of the system is vital to ensure the continuation usage of Web OPAC. Most of the previous studies focused on the interface and the system itself instead of the end user satisfaction. This study is aim to integrate end user satisfaction criteria between Library Science and Information System Expectation Disconfirmation Theory (EDT). The conclusion from this study is an integrated approach from both fields is needed to provide a much comprehensive perspective to evaluate and measure the Web OPAC end user satisfaction.","2324-8149;23248149","Electronic:978-1-4799-2487-5; POD:978-1-4799-2488-2","10.1109/ICRIIS.2013.6716758","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716758","Expectation Disconfirmation Theory;Web OPAC;end user satisfaction","Computers;Graphical user interfaces;Information systems;Libraries;Materials;Navigation;Technological innovation","Internet;cataloguing;digital libraries;information retrieval","EDT;Web OPAC end user satisfaction;Web online public access catalogue;electronic library catalogue;expectation disconfirmation theory;information system;library information resources;library science;remote access","","0","","26","","","27-28 Nov. 2013","","IEEE","IEEE Conference Publications"
"Research of mobile recommendation system based on hybrid recommendation technology","B. Xiang; Z. Zhang; H. Dong; Q. Wu; L. Hu","Software Sch., Xiamen Univ., Xiamen, China","2013 3rd International Conference on Consumer Electronics, Communications and Networks","20140109","2013","","","508","512","The invention and wide use of the network satisfy the information needs of a large number of users, but introduce the problem of information overload. Intelligent recommendation system is an effective way to solve the information overload and has developed for many years on the PC side. In the context of the vigorous development of mobile communication, this paper raises the prospective that integrating the mobile technology into recommendation system to build a mobile intelligent recommendation model, and takes the social activities for example to realize the model.","","DVD:978-1-4799-2858-3; Electronic:978-1-4799-2860-6; POD:978-1-4799-2861-3","10.1109/CECNet.2013.6703381","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703381","hybrid recommendation;mobile platform;recommendation system","Algorithm design and analysis;Artificial intelligence;Data collection;Data models;Heuristic algorithms;Mobile communication;Vectors","information retrieval;mobile computing;recommender systems","hybrid recommendation technology;information overload;intelligent recommendation system;mobile communication;mobile intelligent recommendation model;mobile technology","","0","","9","","","20-22 Nov. 2013","","IEEE","IEEE Conference Publications"
"Secured e-health data retrieval in DaaS and Big Data","D. Shin; T. Sahama; R. Gajanayake","Sci. & Eng. Fac., Queensland Univ. of Technol., Brisbane, QLD, Australia","2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)","20140127","2013","","","255","259","Big Data is one of rising IT trends such as cloud computing, social networking or ubiquitous computing. Big Data can offer beneficial scenarios in the e-health arena. However, one of the scenarios can be that Big Data needs to be kept secured for a long time in order to gain its benefits such as finding cures for infectious diseases and keeping patients' privacy. From this connection, it is beneficial to analyze Big Data to make meaningful information while the data are stored in a secure manner. Thus, the analysis of various database encryption techniques is essential. In this study, we simulated 3 types of technical environments such as Plain-text, Microsoft Built-in Encryption, and custom Advanced Encryption Standard using Bucket Index in Data-as-a-Service. The results showed that custom AES-DaaS has faster range query response time than MS built-in encryption. In addition, while carrying out the scalability test, we acknowledged there are performance thresholds according to physical IT resources. Therefore, for the purpose of efficient Big Data management in e-health, it is noteworthy to examine its scalability limits as well even if it is under cloud computing environment. Furthermore, when designing an e-health database, both patients' privacy and system performance needs to be dealt as top priorities.","","Electronic:978-1-4673-5801-9; POD:978-1-4673-5799-9","10.1109/HealthCom.2013.6720677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720677","AES;Big Data;Bloom filter;Bucket Index;DaaS;cloud;e-health;formatting;security","Data handling;Data storage systems;Encryption;Indexes;Information management;Scalability","cloud computing;cryptography;data analysis;data privacy;database management systems;diseases;health care;information retrieval;medical computing;ubiquitous computing","AES-DaaS;IT trends;Microsoft built-in encryption;big data analysis;big data management;bucket index;cloud computing environment;custom advanced encryption standard;data-as-a-service;database encryption techniques;infectious diseases;patient privacy;plain-text;scalability limits;secured e-health data retrieval;social networking;ubiquitous computing","","1","","18","","","9-12 Oct. 2013","","IEEE","IEEE Conference Publications"
"Speaker identification model for Assamese language using a neural framework","M. Sarma; K. K. Sarma","Dept. of Electron. & Electr. Eng., IIT Guwahati, Guwahati, India","The 2013 International Joint Conference on Neural Networks (IJCNN)","20140109","2013","","","1","7","This paper presents a neural model of speaker identification using the vowel sound segmented out from words spoken by a speaker. Vowel sounds occur in a speech more frequently and with higher energy. Therefore, situations where acoustic information is noise corrupted vowel sounds can be used to extract different amounts of speaker discriminative information. The model explained here uses a neural framework formed with Probabilistic Neural Network (PNN) and Learning Vector Quantization (LVQ) where a novel Self Organizing Map (SOM) based vowel segmentation technique is used. The work extracts glottal source information of the speakers by Empirical-Mode Decomposition (EMD) of the speech signal and depending on which a LVQ based speaker code book is formed. The work shows the use of residual signal obtained from EMD of speech as a speaker discriminative feature. The neural approach of speaker identification gives superior performance in comparison to the conventional statistical approach like Hidden Markov Models (HMMs), Gaussian Mixture Models (GMMs) etc. found in literature. The work formulates a framework for the design of a ANN based speaker recognition model for Assamese language which is spoken by around three million people in the North East Indian state of Assam. Although the proposed model has been experimented in case of the speakers of Assamese language, it shall also be suitable for other Devanagari based languages for which the speaker database should contain samples of that specific language.","2161-4393;21614393","Electronic:978-1-4673-6129-3; POD:978-1-4673-6127-9","10.1109/IJCNN.2013.6707000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707000","","Artificial neural networks;Databases;Hidden Markov models;Speaker recognition;Speech;Speech processing;Speech recognition","audio databases;information retrieval;learning (artificial intelligence);natural language processing;probability;self-organising feature maps;speaker recognition","ANN based speaker recognition model;Assamese language;Devanagari based languages;EMD;LVQ;LVQ based speaker code book;North East Indian state;PNN;SOM-based vowel segmentation technique;acoustic information;empirical-mode decomposition;glottal source information extraction;learning vector quantization;neural framework;neural model;noise corrupted vowel sounds;probabilistic neural network;residual signal;self organizing map based vowel segmentation technique;speaker database;speaker discriminative feature;speaker discriminative information;speaker identification model;speech signal","","1","","36","","","4-9 Aug. 2013","","IEEE","IEEE Conference Publications"
"Applying Search Words and BBS Posts to Societal Risk Perception and Harmonious Society Measurement","X. Tang","Acad. of Math. & Syst. Sci., Inst. of Syst. Sci., Beijing, China","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","2191","2196","Current China is undergoing social transformation with economic miracle and emerging big poor-rich gap. Mission to a Harmonious Society has been promoted by Chinese top leaders. This paper briefly outlines several indicators to evaluate the harmony society. As a variety of Internet tools provides ways to record and disseminate fresh community opinions conveniently, mining of those kinds of public opinions is expected. This paper discusses one approach to societal risk perception using hot search words and BBS posts, which aims to provide another access to societal risk perception different from those in traditional socio psychology studies. Problems are also indicated.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722128","BBS posts;Baidu hot search words;harmony society measures;societal risk perception","Economic indicators;Government;Green products;Indexes;Media;Psychology","Internet;information retrieval;psychology;risk analysis;social sciences computing","BBS posts;Chinese top leaders;Internet tools;economic miracle;fresh community opinions;harmonious society measurement;hot search words;poor-rich gap;public opinions;search words;social transformation;societal risk perception;socio psychology studies","","3","","40","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Fast search of locally repetitive elements based on auto-correlation property in genome","K. S. Shin; B. C. Chung; W. C. Kim; D. H. Cho","Dept. of Electr. Eng., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea","13th IEEE International Conference on BioInformatics and BioEngineering","20140109","2013","","","1","4","Since the beginning of a human genome project, 12 years have passed. There are many studies regarding the meaning of human genome sequences and the effort to identify the whole genome of other species. Although genes significantly affect phenotype, the importance of other factors have increased. In this paper, we propose an autocorrelation based method to arrange the repetitive elements which demonstrate a major part of the genomic sequences. The search for the entire genome based on a simple mathematical analysis will be given. The performance of our proposed self autocorrelation based method will be compared with that of conventional scheme for the human chromosome sequence. Fast scanning of the genome sequence based on our proposed scheme can give a clue to analyze the complex function of the genomic sequences.","","Electronic:978-1-4799-3163-7; POD:978-1-4799-3164-4","10.1109/BIBE.2013.6701582","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701582","","Algorithm design and analysis;Bioinformatics;Biological cells;Correlation;DNA;Genomics;Mathematical analysis","biochemistry;bioinformatics;correlation methods;genomics;information retrieval;mathematical analysis;molecular biophysics;sequences","autocorrelation property;entire genome search;fast genome sequence scanning;fast locally repetitive element search;genes;genomic repetitive elements arrangement;genomic sequence complex function analysis;human chromosome sequence;human genome project;human genome sequences;mathematical analysis;phenotype;self autocorrelation based method;species genome identification","","0","","11","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"Information search for children using Faceted navigation","K. A. Ullah; M. A. Iftikhar","Dept. of Inf. Technol., Univ. of Gujrat, Gujrat, Pakistan","2013 International Conference on Open Source Systems and Technologies","20140127","2013","","","28","33","Information search is one of the most common activities over Internet. Several search engines crawl the web round the clock and fetch useful information according to users' interest. To date, most of these search engines exploit the keyword based searching procedure which might be inappropriate for some naive users such as children. It may be very intricate for children to search their desired content effectively using the traditional `keyword based' search mechanism. They may fail to map the desired concept into appropriate keywords. To circumvent this situation, Faceted navigation is proposed as an effective alternate search method for children. Faceted navigation, also termed as Faceted search, is a specialized form of exploratory search that allows the users to search a domain on the basis of its attributes. We have performed several experiments to compare faceted search to the traditional query-based search mechanism. In particular, a faceted search based test interface has been designed. Children were asked to perform some pre-designated tasks on this system and their performance was analyzed on the said faceted search interface. A quantitative comparison was made with a query based search system using few quantitative performance metrics: keyword and spelling mistakes, number of missed pages and average accuracy. It is evident from experimental results that children performed much better on the proposed faceted search interface than query based search system.","","CD-ROM:978-1-4799-2047-1; Electronic:978-1-4799-2046-4; POD:978-1-4799-2048-8","10.1109/ICOSST.2013.6720601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720601","exploratory search;faceted search;information search for children;keyword-based search","Accuracy;Internet;Prototypes;Search engines;Search problems;Sun;Web pages","information retrieval;search engines","Faceted search;accuracy metric;alternate search method;children;exploratory search;faceted navigation;information fetch;information search;keyword based searching procedure;keyword metric;missed pages metric;naive users;quantitative comparison;quantitative performance metrics;query-based search mechanism;search engines;spelling mistakes metric;user interest;web crawling","","0","","19","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Community structure discovery and community topic analysis in microblog","C. Xiaolei; C. Xiang; C. Yijie","Sch. of Manage. & Econ., Beijing Inst. of Technol., Beijing, China","2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering","20140109","2013","1","","590","595","With the rise of media like microblog, discovering community and analysing the characteristics of network in the microblog network have gradually became a hotspot of research in the field of social network analysis in recent years. In this paper, based on the property contents of microblog users namely users' interest, and considering the structural similarity and attribute similarity of cliques got from Clique Percolation Method (CPM algorithm), we improved the CMP algorithm from the perspective of its output by mergering the cliques. This improvement resolves the problems that the definition of clique by CPM algorithm is too strict and does not meet the reality. Then, our research analysed the topic of the communities found by the improved CPM algorithm using Fuzzy Comprehensive Evaluation Method. And we obtained communities with a higher application value finally. In the end, we verified our research using the real data crawling from Sina Weibo, a microblog site which is the most popular in China.","2155-1456;21551456","Electronic:978-1-4799-0245-3; POD:978-1-4799-0243-9","10.1109/ICIII.2013.6703006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703006","CPM algorithm;Fuzzy Comprehensive Evaluation;community topics;microblog;social network","Algorithm design and analysis;Blogs;Communities;Correlation;Indexes;Social network services;Vectors","data mining;fuzzy set theory;information retrieval;merging;social networking (online)","CPM algorithm;attribute similarity;clique merging;clique percolation method;community structure discovery;community topic analysis;data crawling;fuzzy comprehensive evaluation method;improved CPM algorithm;microblog network;property contents;social network analysis;structural similarity;user interest","","0","","10","","","23-24 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Taxonomy of SQL Injection Attacks","A. Sadeghian; M. Zamani; S. M. Abdullah","Adv. Inf. Sch., Univ. Teknol. Malaysia, Kuala Lumpur, Malaysia","2013 International Conference on Informatics and Creative Multimedia","20140109","2013","","","269","273","Nowadays web applications play an important role in online business including social networks, online services, banking, shopping, classes, email and etc. Ease of use and access to web application make them more popular in offering online services instead of in person services. a simple user just need a computer and an internet connection to access web application and use online services provided by that application. There is one core in common between all dynamic web application and that is their need to use a database to store information inside that and retrieve that information upon the user request or add, edit and delete them. Among all database types, rational databases are very popular. Most of relational database management systems such as MySQL, Oracle, MS SQL Server, MS Access, Postgres use SQL as their language. Flexibility of SQL makes it a powerful language. It allows the user to ask what information he wants without having any knowledge about how the information will be fetch. However vast use of SQL based databases make it the center of attention of hackers. SQL injection attack is a well-known security threat to database driven web applications. A successful SQL injection attack reveals critical confidential information to the hacker. In this paper first we provided background information on this vulnerability. Next we present a comprehensive review of different types of SQL injection attack. For each attack we provide an example that shows how the attack launches. Finally we propose the best solution at development phase to defeat SQL injection and conclusion.","","Electronic:978-0-7695-5133-3; POD:978-1-4799-3702-8","10.1109/ICICM.2013.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702822","Information Security;SQL Injection;SQLIA;Web Application Vulnerability","Delays;Encoding;Programming;Relational databases;Security;Servers","Internet;SQL;computer crime;information retrieval systems;relational databases","Internet connection;MS Access;MS SQL Server;MySQL;Oracle;Postgres;SQL based databases;SQL injection attack taxonomy;banking;database driven Web applications;dynamic Web application;email;hackers;information retrieval;information storage;online business;online services;rational databases;relational database management systems;security threat;shopping;social networks","","6","","10","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Unsupervised multi-view dimensionality reduction with application to audio-visual speaker retrieval","X. Zhao; N. Evans; J. L. Dugelay","Multimedia Commun. Dept., EURECOM, Sophia Antipolis, France","2013 IEEE International Workshop on Information Forensics and Security (WIFS)","20140109","2013","","","7","12","This paper presents a novel approach to unsupervised multi-view dimensionality reduction and reports its application to multi-modal biometrics retrieval, specifically audio-visual speaker retrieval. We propose a new concept referred to as multi-view subspace agreement, which aims to learn a subspace for each view which respects the similarity relationships between data points in the other view. The proposed algorithm is unsupervised but exhibits discriminative characteristics and is thus well suited to applications such as retrieval and clustering where class labels are generally unavailable. The effectiveness of the proposed algorithm is evaluated under an audio-visual speaker retrieval experiment with the MOBIO database. The retrieval performance of the proposed approach out-performs other single-view or multi-view dimensionality reduction methods with a significant margin.","2157-4766;21574766","Electronic:978-1-4673-5593-3; POD:978-1-4673-5591-9","10.1109/WIFS.2013.6707786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707786","","Databases;Face;Noise measurement;Principal component analysis;Training","biometrics (access control);image recognition;information retrieval;pattern clustering;speaker recognition","MOBIO database;audio-visual speaker retrieval;class labels;clustering;multimodal biometrics retrieval;multiview subspace agreement;single-view dimensionality reduction methods;unsupervised multiview dimensionality reduction","","3","","15","","","18-21 Nov. 2013","","IEEE","IEEE Conference Publications"
