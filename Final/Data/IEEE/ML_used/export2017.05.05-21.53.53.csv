"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7153947,7154888,7154887,7154880,7153949,7154739,7086287,7154756,7153970,7152517,7150789,7151584,6894210,7148389,7050255,7148531,7148378,7149312,7140323,7140318,7140247,7147261,6975182,7136417,7136632,7039288,7133015,7132993,7133592,7132999,7132997,7130397,7130033,7130137,7130362,7129554,7106400,7130427,7130062,7130365,7130002,7128941,7124851,7125354,7125329,7125351,6902826,7084586,6883191,7038203,7117476,7119932,7119725,7120795,7120587,7119716,7069203,7112625,7116617,7117018,7116989,7116970,7116968,6910312,7116280,7116910,7109822,7114508,7006762,7021960,7110808,7045422,7111178,7078918,7079489,7031434,7039196,7108185,7106171,6598669,7051209,7069264,7103460,7102446,7100524,7100739,6868981,6872807,7100286,7100693,7098675,7047827,7098042,7097339,6971126,6967781,6945865,6990607,7006788,7095056",2017/05/05 21:53:53
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Iterative-tuning support vector machine for network traffic classification","Y. Hong; C. Huang; B. Nandy; N. Seddigh","Dept. of Systems and Computer Engineering, Carleton University, Ottawa, Ontario, Canada","2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)","20150702","2015","","","458","466","Accurate and timely traffic classification is a key to providing Quality of Service (QoS), application-level visibility, and security monitoring for network operations and management. A class of traffic classification techniques have emerged that apply machine learning technology to predict the application class of a traffic flow based on the statistical properties of flow-features. In this paper, we propose a novel iterative-tuning scheme to increase the training speed of the classification algorithm using Support Vector Machine (SVM) learning. Meanwhile we derive the equations to obtain SVM parameters by conducting theoretical analysis of iterative-tuning SVM. Traffic classification is carried out using flow-level information extracted from NetFlow data. Performance evaluation demonstrates that the proposed iterative-tuning SVM exhibits a training speed that is two to ten times faster than eight other previously proposed SVM techniques found in the literature, while maintaining comparable classification accuracy as those eight SVM techniques. In the presence of millions of flows and Terabytes of data in the network, faster training speeds is essential to making SVM techniques a viable option for real-world deployment of traffic classification modules. In addition, network operators and cloud service providers can apply network traffic classification to address a range of issues including semi-real-time security monitoring and traffic engineering.","1573-0077;15730077","Electronic:978-1-4799-8241-7; POD:978-1-4799-8242-4","10.1109/INM.2015.7140323","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140323","machine learning;network management;quality of service;support vector machine;traffic classification","Accuracy;Mathematical model;Protocols;Support vector machines;Telecommunication traffic;Testing;Training","iterative methods;learning (artificial intelligence);quality of service;support vector machines;telecommunication computing;telecommunication network management;telecommunication scheduling;telecommunication traffic","NetFlow data;QoS;SVM learning;SVM parameters;application-level visibility;cloud service providers;flow-features;flow-level information;iterative-tuning SVM;iterative-tuning scheme;machine learning technology;network management;network operations;network operators;network traffic classification;quality of service;semi-real-time security monitoring;statistical properties;support vector machine learning;traffic classification modules;traffic classification techniques;traffic engineering;traffic flow","","0","","42","","","11-15 May 2015","","IEEE","IEEE Conference Publications"
"Credit Risk Analysis Using Sparse Non-negative Matrix Factorizations","H. Sun; Z. Chen; J. Chen","Dept. of Stat., Southwestern Univ. of Finance & Econ., Chengdu, China","2015 2nd International Conference on Information Science and Control Engineering","20150611","2015","","","181","184","Credit risk analysis is to determine if a customer is likely to default on the financial obligation. In this paper, we will introduce sparse non-negative matrix factorization method to discovery the lower dimensional space for reducing the data dimensionality, which will contribute to good performance and fast computation in the credit risk classification performed by support vector machine. We test the sparse NMF in a real-world credit risk prediction task, and the empirical results demonstrate the advantage of sparse NMF by comparing with other state of art methods.","","Electronic:978-1-4673-6850-6; POD:978-1-4673-6851-3","10.1109/ICISCE.2015.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120587","SVM;credit risk analysis;feature extraction;machine learning;non-negative matrix factorization;sparsity","Accuracy;Classification algorithms;Principal component analysis;Risk analysis;Sparse matrices;Support vector machines;Training","data reduction;financial data processing;matrix decomposition;pattern classification;risk analysis;sparse matrices;support vector machines","credit risk analysis;credit risk classification;data dimensionality;financial obligation;lower dimensional space;real-world credit risk prediction task;sparse NMF;sparse nonnegative matrix factorizations;support vector machine","","0","","11","","","24-26 April 2015","","IEEE","IEEE Conference Publications"
"Multitask Classification Hypothesis Space With Improved Generalization Bounds","C. Li; M. Georgiopoulos; G. C. Anagnostopoulos","Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA","IEEE Transactions on Neural Networks and Learning Systems","20150616","2015","26","7","1468","1479","This paper presents a pair of hypothesis spaces (HSs) of vector-valued functions intended to be used in the context of multitask classification. While both are parameterized on the elements of reproducing kernel Hilbert spaces and impose a feature mapping that is common to all tasks, one of them assumes this mapping as fixed, while the more general one learns the mapping via multiple kernel learning. For these new HSs, empirical Rademacher complexity-based generalization bounds are derived, and are shown to be tighter than the bound of a particular HS, which has appeared recently in the literature, leading to improved performance. As a matter of fact, the latter HS is shown to be a special case of ours. Based on an equivalence to Group-Lasso type HSs, the proposed HSs are utilized toward corresponding support vector machine-based formulations. Finally, experimental results on multitask learning problems underline the quality of the derived bounds and validate this paper's analysis.","2162-237X;2162237X","","10.1109/TNNLS.2014.2347054","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6883191","Machine learning;pattern recognition;statistical learning;supervised learning;support vector machines","Context;Hilbert space;Kernel;Learning systems;Support vector machines;Training;Upper bound","Hilbert spaces;generalisation (artificial intelligence);learning (artificial intelligence);pattern classification;vectors","empirical Rademacher complexity-based generalization bounds;feature mapping;group-Lasso type HS;kernel Hilbert spaces reproduction;multitask classification context;multitask classification hypothesis space;multitask learning;vector-valued functions","","0","","35","","20140826","July 2015","","IEEE","IEEE Journals & Magazines"
"Mobile malware classification based on permission data","E. Egemen; E. İnal; A. Levi","Bilgisayar Bilimleri ve M&#x00FC;hendisli&#x011F;i Program&#x0131;, M&#x00FC;hendislik ve Do&#x011F;a Bilimleri Fak&#x00FC;ltesi, Sabanc&#x0131; &#x00DC;niversitesi, &#x0130;stanbul, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1529","1532","The prevalence of mobile devices in today's world caused the security of these devices questioned more frequently than ever. Android, as one of the most widely used mobile operating systems, is the most likely target for malwares through third party applications. In this work, a method has been devised to detect malwares that target Android platform, by using classification based machine learning. In this study, we use permissions of applications as the features. After the training and test steps on the dataset consisting 5271 malwares and 5097 goodwares, we conclude that Random Forest classification results in 98% performance on the classification of applications. This work emphasizes how much mobile malware classification result can be improved by a system using only the permissions data.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130137","android;classification;machine learning;malware;mobile;permissions","Androids;Google;Humanoid robots;Malware;Mobile communication;Support vector machines","Android (operating system);invasive software;learning (artificial intelligence);mobile computing;pattern classification","Android;classification based machine learning;device security;malware detection;mobile devices;mobile malware classification;mobile operating systems;permission data;random forest classification;third party applications","","0","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Determination of glucose concentration from near infrared spectra using least square support vector machine","B. A. Malik","University Science & Instrumentation Centre, University of Kashmir, Srinagar, India","2015 International Conference on Industrial Instrumentation and Control (ICIC)","20150709","2015","","","475","478","One of the many challenges for translating noninvasive glucose measurement into clinical practice is the calibration of the measuring instrument. In this work, least squares support vector regression (LS-SVR) has been used to develop a multivariate calibration model for determination of glucose concentration from near infra-red (NIR) spectra. The behaviour of developed model is studied on NIR spectra of a mixture composed of glucose, urea, and triacetin which spans from 2100 nm to 2400 nm with a spectral resolution of 1nm. The proposed model improved the standard error of prediction (SEP) from 49.4 mg/dL in case of Principal Component Regression (PCR) and 27.5 mg/dL in case of Principal Least Squares Regression (PLSR) to 19.4mg/dL.","","Electronic:978-1-4799-7165-7; POD:978-1-4799-7166-4","10.1109/IIC.2015.7150789","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7150789","Calibration;LS-SVM;Machine Learning;NIR;Non-invasive glucose measurement;SEC;SEP","Calibration;Diabetes;Kernel;Predictive models;Spectroscopy;Sugar;Support vector machines","biochemistry;calibration;chemical variables measurement;infrared spectra;least squares approximations;medical computing;principal component analysis;regression analysis;sugar;support vector machines","LS-SVR;NIR spectra;PCR;PLSR;SEP;clinical practice;glucose concentration;least square support vector machine;least squares support vector regression;mixture;multivariate calibration;near infrared spectra;noninvasive glucose measurement;principal component regression;principal least squares regression;spectral resolution;standard error-of-prediction","","0","","28","","","28-30 May 2015","","IEEE","IEEE Conference Publications"
"Domain Adaptation for Microscopy Imaging","C. Becker; C. M. Christoudias; P. Fua","Computer Vision Lab, &#x00C9;cole Polytechnique F&#x00E9;d&#x00E9;rale de Lausanne (EPFL), Lausanne, Switzerland","IEEE Transactions on Medical Imaging","20150429","2015","34","5","1125","1139","Electron and light microscopy imaging can now deliver high-quality image stacks of neural structures. However, the amount of human annotation effort required to analyze them remains a major bottleneck. While machine learning algorithms can be used to help automate this process, they require training data, which is time-consuming to obtain manually, especially in image stacks. Furthermore, due to changing experimental conditions, successive stacks often exhibit differences that are severe enough to make it difficult to use a classifier trained for a specific one on another. This means that this tedious annotation process has to be repeated for each new stack. In this paper, we present a domain adaptation algorithm that addresses this issue by effectively leveraging labeled examples across different acquisitions and significantly reducing the annotation requirements. Our approach can handle complex, nonlinear image feature transformations and scales to large microscopy datasets that often involve high-dimensional feature spaces and large 3D data volumes. We evaluate our approach on four challenging electron and light microscopy applications that exhibit very different image modalities and where annotation is very costly. Across all applications we achieve a significant improvement over the state-of-the-art machine learning methods and demonstrate our ability to greatly reduce human annotation effort.","0278-0062;02780062","","10.1109/TMI.2014.2376872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971126","AdaBoost;boosting;domain adaptation;electron and light microscopy;machine learning;transfer learning","Boosting;Electron microscopy;Regression tree analysis;Three-dimensional displays;Training;Training data","biomedical optical imaging;electron microscopy;learning (artificial intelligence);medical image processing;neurophysiology;optical microscopy","3D data volumes;annotation process;classifier;domain adaptation algorithm;electron microscopy imaging;high-dimensional feature spaces;high-quality image stacks;human annotation effort;image modalities;light microscopy imaging;machine learning algorithms;microscopy datasets;neural structures;nonlinear image feature transformations;training data","Algorithms;Animals;Brain;Data Curation;Databases, Factual;Humans;Image Processing, Computer-Assisted;Machine Learning;Microscopy;Rats","3","","42","","20141202","May 2015","","IEEE","IEEE Journals & Magazines"
"Improving accuracy of on-chip diagnosis via incremental learning","X. Ren; M. Martin; R. D. Blanton","Department of Electrical and Computer Engineering, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, USA","2015 IEEE 33rd VLSI Test Symposium (VTS)","20150604","2015","","","1","6","On-chip test/diagnosis is proposed to be an effective method to ensure the lifetime reliability of integrated systems. In order to manage the complexity of such an approach, an integrated system is partitioned into multiple modules where each module can be periodically tested, diagnosed and repaired if necessary. The limitation of on-chip memory and computing capability, coupled with the inherent uncertainty in diagnosis, causes the occurrence of misdiagnoses. To address this challenge, a novel incremental-learning algorithm, namely dynamic k-nearest-neighbor (DKNN), is developed to improve the accuracy of on-chip diagnosis. Different from the conventional KNN, DKNN employs online diagnosis data to update the learned classifier so that the classifier can keep evolving as new diagnosis data becomes available. Incorporating online diagnosis data enables tracking of the fault distribution and thus improves diagnostic accuracy. Experiments using various benchmark circuits (e.g., the cache controller from the OpenSPARC T2 processor design) demonstrate that diagnostic accuracy can be more than doubled.","1093-0167;10930167","Electronic:978-1-4799-7597-6; POD:978-1-4799-7598-3","10.1109/VTS.2015.7116280","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116280","On-chip diagnosis;diagnostic accuracy;k-nearest-neighbor;lifetime reliability;machine learning","Accuracy;Benchmark testing;Circuit faults;Delays;Heuristic algorithms;System-on-chip","learning (artificial intelligence);program diagnostics;program testing;software reliability","DKNN;OpenSPARC T2 processor design;cache controller;dynamic k-nearest-neighbor;incremental-learning algorithm;integrated system reliability;on-chip diagnosis;on-chip testing;online diagnosis data","","3","","29","","","27-29 April 2015","","IEEE","IEEE Conference Publications"
"Digital pathology: Identifying spongiosis in unstained histopathology specimen","S. Abeysekera; N. Kar; W. Siew; M. Po-Leen Ooi; Y. C. Kuang; S. Syed Hassan; S. Demidenko","School of Engineering, Monash University Malaysia, Malaysia","2015 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) Proceedings","20150709","2015","","","1970","1975","Histopathological specimens are prepped through a process called staining prior to analysis by the pathologist. Staining of a pathological specimen is a standard procedure used to increase the contrast between the cell and tissue structures against the background. Unfortunately, staining is a lengthy process that requires hours of preparation. Moreover, the chemicals used to perform the procedure can affect the specimen's characteristics. The entire problem of staining can be eliminated if detection and diagnosis can be performed on unstained specimen. However the low-contrast unstained samples can seriously affect the diagnosis reliability. Currently, no established technique exists for the detection and diagnosis of unstained histhopathological samples. This project aims to detect and diagnose spongiosis, a type of cerebral edema, in unstained histopathological samples taken from poultry brains. Success of this research is the first step towards detecting various classes of cerebral edema. It is a fast and accurate clinical tool that greatly enhances the analytic capability of the histopathological laboratory. The computer-aided diagnosis enables short turn-around time and higher consistency in the histopathological laboratory that services hospitals and clinics.","1091-5281;10915281","Electronic:978-1-4799-6114-6; POD:978-1-4799-6115-3; USB:978-1-4799-6113-9","10.1109/I2MTC.2015.7151584","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7151584","digital pathology;machine learning;spectral imaging","Accuracy;Algorithm design and analysis;Classification algorithms;Feature extraction;Multispectral imaging;Pathology;Standards","biological specimen preparation;biological tissues;biomedical optical imaging;brain;cellular biophysics;diseases;feature extraction;medical diagnostic computing;neurophysiology","cell structure contrast;cerebral edema class;cerebral edema detection;clinical tool;computer-aided diagnosis;digital pathology;histopathological laboratory analytic capability;histopathological laboratory consistency;histopathological specimen preparation;histopathological specimen staining;hospital;low-contrast unstained sample effect;poultry brain;short turn-around time;specimen characteristics;spongiosis detection;spongiosis diagnosis reliability;spongiosis identification;staining chemical effect;tissue structure contrast;unstained histopathological specimen","","0","","16","","","11-14 May 2015","","IEEE","IEEE Conference Publications"
"A comparative study of file-type identification techniques","N. S. Alamri; W. H. Allen","Computer Science and Cybersecurity, Florida Institute of Technology, Melbourne, USA","SoutheastCon 2015","20150625","2015","","","1","5","Research in file-type identification has employed a number of different approaches to classify unknown files according to their actual file type. However, due to the lack of implementation details in much of the published research and the use of private datasets for many of those projects, it is often not possible to compare new techniques with the prior work. In this paper, we present a comparison of five common file-type identification approaches, along with the parameters used to perform the comparisons. All approaches were evaluated with the same dataset which was drawn from public or widely-available sources. Our results show that each approach can produce good results with 88% to 97% classification rates, but achieving these results requires “tuning” the parameters of the inputs to the classifiers.","1091-0050;10910050","Electronic:978-1-4673-7300-5; POD:978-1-4673-7301-2","10.1109/SECON.2015.7132993","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7132993","cybersecurity;digital forensics;feature extraction;file-type identification;machine learning","Data models;Feature extraction;Kernel;Neural networks;Principal component analysis;Support vector machines;Training data","digital forensics;file organisation;pattern classification","classifier;cybersecurity;digital forensics;file classification;file-type identification technique;input parameter tuning","","0","","16","","","9-12 April 2015","","IEEE","IEEE Conference Publications"
"Randomized General Regression Network for Identification of Defect Patterns in Semiconductor Wafer Maps","F. Adly; P. D. Yoo; S. Muhaidat; Y. Al-Hammadi; U. Lee; M. Ismail","ATIC-Khalifa Semiconductor Research Center, Khalifa University, Abu Dhabi, UAE","IEEE Transactions on Semiconductor Manufacturing","20150501","2015","28","2","145","152","Defect detection and classification in semiconductor wafers has received an increasing attention from both industry and academia alike. Wafer defects are a serious problem that could cause massive losses to the companies' yield. The defects occur as a result of a lengthy and complex fabrication process involving hundreds of stages, and they can create unique patterns. If these patterns were to be identified and classified correctly, then the root of the fabrication problem can be recognized and eventually resolved. Machine learning (ML) techniques have been widely accepted and are well suited for such classification-/identification problems. However, none of the existing ML model's performance exceeds 96% in identification accuracy for such tasks. In this paper, we develop a state-of-the-art classifying algorithm using multiple ML techniques, relying on a general-regression-network-based consensus learning model along with a powerful randomization technique. We compare our proposed method with the widely used ML models in terms of model accuracy, stability, and time complexity. Our method has proved to be more accurate and stable as compared to any of the existing algorithms reported in the literature, achieving its accuracy of 99.8%, stability of 1.128, and TBM of 15.8 s.","0894-6507;08946507","","10.1109/TSM.2015.2405252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7047827","Semiconductor wafer defect patterns;ensembles;machine-learning;neural-networks;randomization;semiconductor wafer defect patterns,","Accuracy;Computational modeling;Data models;Predictive models;Semiconductor device modeling;Support vector machines;Training","learning (artificial intelligence);regression analysis;semiconductor technology","ML technique;complex fabrication process;defect classification;defect detection;defect patterns identification;general-regression-network-based consensus learning model;machine learning;randomization technique;randomized general regression network;semiconductor wafer map;state-of-the-art classifying algorithm;wafer defect","","2","","35","","20150224","May 2015","","IEEE","IEEE Journals & Magazines"
"Transfer Learning Improves Supervised Image Segmentation Across Imaging Protocols","A. van Opbroek; M. A. Ikram; M. W. Vernooij; M. de Bruijne","Biomedical Imaging Group Rotterdam, Departments of Medical Informatics and Radiology, Erasmus MC &#x2013; University Medical Center Rotterdam, Rotterdam, The Netherlands","IEEE Transactions on Medical Imaging","20150429","2015","34","5","1018","1030","The variation between images obtained with different scanners or different imaging protocols presents a major challenge in automatic segmentation of biomedical images. This variation especially hampers the application of otherwise successful supervised-learning techniques which, in order to perform well, often require a large amount of labeled training data that is exactly representative of the target data. We therefore propose to use transfer learning for image segmentation. Transfer-learning techniques can cope with differences in distributions between training and target data, and therefore may improve performance over supervised learning for segmentation across scanners and scan protocols. We present four transfer classifiers that can train a classification scheme with only a small amount of representative training data, in addition to a larger amount of other training data with slightly different characteristics. The performance of the four transfer classifiers was compared to that of standard supervised classification on two magnetic resonance imaging brain-segmentation tasks with multi-site data: white matter, gray matter, and cerebrospinal fluid segmentation; and white-matter-/MS-lesion segmentation. The experiments showed that when there is only a small amount of representative training data available, transfer learning can greatly outperform common supervised-learning approaches, minimizing classification errors by up to 60%.","0278-0062;02780062","","10.1109/TMI.2014.2366792","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945865","Image Segmentation;machine learning;magnetic resonance imaging;pattern recognition;transfer learning","Biomedical imaging;Image segmentation;Kernel;Protocols;Support vector machines;Training;Training data","biomedical MRI;brain;image classification;image segmentation;learning (artificial intelligence);medical image processing;neurophysiology","automatic segmentation;biomedical images;cerebrospinal fluid segmentation;classification scheme;gray matter;image variation;imaging protocols;labeled training data;magnetic resonance imaging brain-segmentation tasks;minimizing classification errors;multisite data;representative training data;standard supervised classification;supervised image segmentation;supervised-learning techniques;target data distributions;transfer classifiers;transfer learning;white-matter-MS-lesion segmentation","Brain;Humans;Image Processing, Computer-Assisted;Machine Learning;Magnetic Resonance Imaging;Multiple Sclerosis;Pattern Recognition, Automated;Support Vector Machine","8","","44","","20141104","May 2015","","IEEE","IEEE Journals & Magazines"
"A composite classification model for web services based on semantic & syntactic information integration","Sowmya Kamath S.; A. Ahmed; M. Shankar","Department of IT, National Institute of Technology, Surathkal, Karnataka 575025, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","1169","1173","Automatic and semi-automatic approaches for classification of web services have garnered much interest due to their positive impact on tasks like service discovery, matchmaking and composition. Currently, service registries support only human classification, which results in limited recall and low precision in response to queries, due to keyword based matching. The syntactic features of a service along with certain semantics based measures used during classification can result in accurate and meaningful results. We propose an approach for web service classification based on conversion of services into a class dependent vector by applying the concept of semantic relatedness and to generate classes of services ranked by their semantic relatedness to a given query. We used the OWLS-tc service dataset for evaluating our approach and the experimental results are presented in this work.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154887","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154887","Web service classification;machine learning;semantic relatedness","Accuracy;Decision trees;Multilayer perceptrons;Principal component analysis;Semantics;Syntactics;Web services","Web services;learning (artificial intelligence);pattern classification;query processing;semantic Web;word processing","Web service;composite classification model;machine learning;query processing;semantic relatedness;syntactic information integration;word vector","","0","","23","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"A collaborative distributed multi-agent reinforcement learning technique for dynamic agent shortest path planning via selected sub-goals in complex cluttered environments","D. B. Megherbi; M. Kim","CMINDS Research Center, Department of Electrical and Computer Engineering, University of Massachusetts, Lowell, MA, USA","2015 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision","20150518","2015","","","118","124","Collaborative monitoring of large infrastructures, such as military, transportation and maritime systems are decisive issues in many surveillance, protection, and security applications. In many of these applications, dynamic multi-agent systems using reinforcement learning for agents' autonomous path planning, where agents could be moving randomly to reach their respective goals and avoiding topographical obstacles intelligently, becomes a challenging problem. This is specially so in a dynamic agent environment. In our prior work we presented an intelligent multi-agent hybrid reactive and reinforcement learning technique for collaborative autonomous agent path planning for monitoring Critical Key Infrastructures and Resources (CKIR) in a geographically and a computationally distributed systems. Here agent monitoring of large environments is reduced to monitoring of relatively smaller track-able geographically distributed agent environment regions. In this paper we tackle this problem in the challenging case of complex and cluttered environments, where agents' initial random-walk paths become challenging and relatively nonconverging. Here we propose a multi-agent distributed hybrid reactive re-enforcement learning technique based on selected agent intermediary sub-goals using a learning reward scheme in a distributed-computing memory setting. Various case study scenarios are presented for convergence study to the shortest minimum-amount-of-time exploratory steps for faster and efficient agent learning. In this work the distributed dynamic agent communication is done via a Message Passing Interface (MPI).","2379-1667;23791667","Electronic:978-1-4799-8015-4; POD:978-1-4799-8016-1; USB:978-1-4799-8014-7","10.1109/COGSIMA.2015.7108185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7108185","Intelligent multi-agent systems;Key infrastructures and resources;Machine learning;distributed systems and networks;sub-goals;tracking of friendly and enemy targets","Computer architecture;Conferences;Learning (artificial intelligence);Monitoring;Multi-agent systems;Path planning;Peer-to-peer computing","application program interfaces;computerised monitoring;critical infrastructures;groupware;learning (artificial intelligence);message passing;multi-agent systems;path planning","CKIR;MPI;agent initial random-walk path;collaborative autonomous agent path planning;collaborative distributed multiagent reinforcement learning technique;complex cluttered environments;critical key infrastructures and resources monitoring;distributed dynamic agent communication;distributed-computing memory setting;dynamic agent shortest path planning;dynamic multiagent systems;geographically distributed agent environment regions;intelligent multiagent hybrid reactive reinforcement learning technique;large infrastructure collaborative monitoring;learning reward scheme;message passing interface;shortest minimum-amount-of-time exploratory steps;subgoal selecion;topographical obstacle avoidance","","1","","50","","","9-12 March 2015","","IEEE","IEEE Conference Publications"
"Personalized online search for fashion products","C. Gray; M. Beattie; H. Belay; S. Hill; N. Lerch","University of Virginia","2015 Systems and Information Engineering Design Symposium","20150608","2015","","","91","96","In this paper we develop a methodology for personalizing online search for fashion products. Most search functions on fashion retail sites currently rely on objective data, such as colors or brands, to filter their products. Adding a subjective component of fashion style would allow for a more personalized and relevant search experience for the end user. The proposed methodology is based upon a topic modeling technique - latent Dirichlet allocation - which has been successfully used for classifying unstructured text data. This technique is used to quantitatively define distinct fashion styles based upon text obtained from clothing product information available through APIs with affiliate networks. Using the fashion style definitions, individual clothing brands and looks are then classified. We compare the performance of the proposed methodology with Genostyle's proprietary methodology (Genostyle is a fashion styling analytics company). An experiment was executed to display custom recommendations made using each methodology to participants. The team measured performance by comparing median 5-point Likert scale responses to the recommended looks. Results indicate the latent Dirichlet allocation methodology has higher median Likert responses for the top recommended style. However, the Likert scores for Genostyle's methodology, the latent Dirichlet allocation methodology, and the control group are statistically indistinguishable (p=0.05). Given these results, further experimentation with more diverse participation or presentation of looks may give insights into how to better fashion style predictions that more closely match consumers' preferences.","","Electronic:978-1-4799-1832-4; POD:978-1-4799-1833-1","10.1109/SIEDS.2015.7117018","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7117018","Fashion;Latent Dirichlet allocation;MALLET;Machine learning;Topic modeling","Algorithm design and analysis;Classification algorithms;Clothing;Context;Industries;Machine learning algorithms;Resource management","Web sites;application program interfaces;classification;clothing industry;electronic commerce;query formulation;recommender systems;text analysis","API;Genostyle proprietary methodology;clothing product information;custom recommendations;fashion products;fashion retail sites;latent Dirichlet allocation;median 5-point Likert scale response;personalized online search;search functions;unstructured text data classification","","0","","13","","","24-24 April 2015","","IEEE","IEEE Conference Publications"
"Predicting real-time service-level metrics from device statistics","R. Yanggratoke; J. Ahmed; J. Ardelius; C. Flinta; A. Johnsson; D. Gillblad; R. Stadler","ACCESS Linnaeus Center, KTH Royal Institute of Technology, Sweden","2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)","20150702","2015","","","414","422","While real-time service assurance is critical for emerging telecom cloud services, understanding and predicting performance metrics for such services is hard. In this paper, we pursue an approach based upon statistical learning whereby the behavior of the target system is learned from observations. We use methods that learn from device statistics and predict metrics for services running on these devices. Specifically, we collect statistics from a Linux kernel of a server machine and predict client-side metrics for a video-streaming service (VLC). The fact that we collect thousands of kernel variables, while omitting service instrumentation, makes our approach service-independent and unique. While our current lab configuration is simple, our results, gained through extensive experimentation, prove the feasibility of accurately predicting client-side metrics, such as video frame rates and RTP packet rates, often within 10-15% error (NMAE), also under high computational load and across traces from different scenarios.","1573-0077;15730077","Electronic:978-1-4799-8241-7; POD:978-1-4799-8242-4","10.1109/INM.2015.7140318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140318","Quality of service;cloud computing;machine learning;network analytics;statistical learning;video streaming","Computational modeling;Generators;Load modeling;Measurement;Predictive models;Servers;Streaming media","Linux;cloud computing;operating system kernels;software performance evaluation;video streaming","Linux kernel;VLC;client-side metrics prediction;device statistics;performance metrics;real-time service assurance;real-time service-level metrics prediction;server machine;service instrumentation;statistical learning;telecom cloud services;video-streaming service","","1","","29","","","11-15 May 2015","","IEEE","IEEE Conference Publications"
"Hyperspectral target detection - An experimental study","B. Günyel; R. G. Cinbiş; S. Türe; A. C. Gürbüz","Milsoft Yaz&#x0131;l&#x0131;m Teknolojileri, Ankara, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","2627","2630","In hyperspectral imaging, the measured spectra are affected by the materials and objects that reside within or in close vicinity of the pixel which is being imaged. The detection of a material or object of interest in an imaged region is a common problem in various application areas. In this work, an experimental study is performed for target detection in hyperspectral images, supported by a performance comparison.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130427","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130427","hyperspectral target detection;machine learning;spectral signature","Hyperspectral imaging;Matched filters;Object detection;Reactive power;Support vector machines","hyperspectral imaging;object detection","hyperspectral imaging;hyperspectral target detection;material detection;object detection","","0","","11","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Homogeneous Spiking Neuromorphic System for Real-World Pattern Recognition","X. Wu; V. Saxena; K. Zhu","Electrical and Computer Engineering Department, Boise State University, Boise, Idaho, USA","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","20150609","2015","5","2","254","266","A neuromorphic chip that combines CMOS analog spiking neurons and memristive synapses offers a promising solution to brain-inspired computing, as it can provide massive neural network parallelism and density. Previous hybrid analog CMOS-memristor approaches required extensive CMOS circuitry for training, and thus eliminated most of the density advantages gained by the adoption of memristor synapses. Further, they used different waveforms for pre and post-synaptic spikes that added undesirable circuit overhead. Here we describe a hardware architecture that can feature a large number of memristor synapses to learn real-world patterns. We present a versatile CMOS neuron that combines integrate-and-fire behavior, drives passive memristors and implements competitive learning in a compact circuit module, and enables in situ plasticity in the memristor synapses. We demonstrate handwritten-digits recognition using the proposed architecture using transistor-level circuit simulations. As the described neuromorphic architecture is homogeneous, it realizes a fundamental building block for large-scale energy-efficient brain-inspired silicon chips that could lead to next-generation cognitive computing.","2156-3357;21563357","","10.1109/JETCAS.2015.2433552","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116617","Brain-inspired computing;machine learning;memristor;neuromorphic;resistive memory;silicon neuron;spike-timing dependent plasticity;spiking neural network","Biological neural networks;CMOS integrated circuits;Computer architecture;Memristors;Neuromorphics;Neurons;Silicon","","","","2","1","77","","20150602","June 2015","","IEEE","IEEE Journals & Magazines"
"Shape, Illumination, and Reflectance from Shading","J. T. Barron; J. Malik","Department of Electrical Engineering and Computer Science, University of California at Berkeley, Berkeley, CA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20150630","2015","37","8","1670","1687","A fundamental problem in computer vision is that of inferring the intrinsic, 3D structure of the world from flat, 2D images of that world. Traditional methods for recovering scene properties such as shape, reflectance, or illumination rely on multiple observations of the same scene to overconstrain the problem. Recovering these same properties from a single image seems almost impossible in comparison-there are an infinite number of shapes, paint, and lights that exactly reproduce a single image. However, certain explanations are more likely than others: surfaces tend to be smooth, paint tends to be uniform, and illumination tends to be natural. We therefore pose this problem as one of statistical inference, and define an optimization problem that searches for the most likely explanation of a single image. Our technique can be viewed as a superset of several classic computer vision problems (shape-from-shading, intrinsic images, color constancy, illumination estimation, etc) and outperforms all previous solutions to those constituent problems.","0162-8828;01628828","","10.1109/TPAMI.2014.2377712","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975182","Color Constancy;Computer Vision;Computer vision;Intrinsic Images;Machine Learning;Shape Estimation;Shape from Shading;color constancy;intrinsic images;machine learning;shape estimation;shape from shading","Computer vision;GSM;Image color analysis;Lighting;Optimization;Paints;Shape","computer vision;image colour analysis","2D images;3D structure;color constancy;computer vision;illumination estimation;image explanation;intrinsic images;paint;reflectance;scene properties;shape-from-shading","","27","","64","","20141204","Aug. 1 2015","","IEEE","IEEE Journals & Magazines"
"Detecting Sentiment in Nepali texts: A bootstrap approach for Sentiment Analysis of texts in the Nepali language","C. P. Gupta; B. K. Bal","Department of Computer Science and Engineering, Kathmandu University, Dhulikhel, Nepal","2015 International Conference on Cognitive Computing and Information Processing(CCIP)","20150504","2015","","","1","4","The increasing amount of Nepali content on the Web has opened doors for the research and development of a number of Natural Language Processing applications including Sentiment Analysis (SA). However, to best of our knowledge there has been no work in this area for Nepali language. In this paper we present two main approaches for sentiment detection of Nepali texts. We have developed Nepali Sentiment Corpus and Nepali SentiWordNet. In our first approach we develop a lexical resource called Bhavanakos, which is a Nepali SentiWordNet and implement a strategy in which sentiment words are detected in Nepali texts to detect the sentiment in documents. The second of our approach we train a machine learning based text classifier with annotated Nepali text data to classify the document.","","Electronic:978-1-4799-7171-8; POD:978-1-4799-7172-5","10.1109/CCIP.2015.7100739","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100739","Machine Learning;Nepali Language;Opinion Mining;SentiWordNet;Sentiment Analysis","Accuracy;Dictionaries;Manuals;Probability;Sentiment analysis;Training","emotion recognition;learning (artificial intelligence);natural language processing;pattern classification;statistical analysis;text analysis","Bhavanakos;Nepali SentiWordNet;Nepali Sentiment Corpus;Nepali content;Nepali language;Nepali text sentiment detection;bootstrap approach;document classification;lexical resource;machine learning based text classifier;natural language processing applications;research and development;text sentiment analysis","","1","","12","","","3-4 March 2015","","IEEE","IEEE Conference Publications"
"Sentiment classification in online reviews using FRN algorithm","I. Hemalatha; G. P. S. Varma; A. Govardhan","Inf. Technol. Dept., S.R.K.R. Eng. Coll., Bhimavaram, China","IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013)","20150611","2013","","","357","362","The internet is rich in directional text (i.e., text containing opinions and emotions). World Wide Web provides volumes of text-based data about consumer preferences, stored in online review websites, web forums, blogs, etc. Sentiment analysis is a technique to classify people's opinions in product reviews, blogs or social networks has emerged as a method for mining opinions from such text archives. It uses machine learning methods combined with linguistic attributes/features in order to identify among other things the sentiment polarity (e.g., positive, negative, and neutral) We investigated supervised learning by incorporating linguistic rules and constraints that could improve the performance of calculations and classifications.","","Paper:978-1-78561-030-1","10.1049/ic.2013.0338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119725","Machine Learning;Opinions;Sentiment analysis","","Internet;data mining;learning (artificial intelligence);pattern classification;social networking (online);text analysis","FRN algorithm;blogs;linguistic attributes;linguistic rules;machine learning methods;opinion mining;people opinion classification;product reviews;sentiment analysis;sentiment classification;sentiment polarity;social networks;supervised learning;text archives","","0","","","","","12-14 Dec. 2013","","IET","IET Conference Publications"
"Neural network based approach for time to crash prediction to cope with software aging","M. Yakhchi; J. Alonso; M. Fazeli; A. A. Bitaraf; A. Patooqhy","School of Computer Science, Institute for Research in Fundamental Sciences (IPM), Tehran 19395-5746, Iran","Journal of Systems Engineering and Electronics","20150521","2015","26","2","407","414","Recent studies have shown that software is one of the main reasons for computer systems unavailability. A growing accumulation of software errors with time causes a phenomenon called software aging. This phenomenon can result in system performance degradation and eventually system hang/crash. To cope with software aging, software rejuvenation has been proposed. Software rejuvenation is a proactive technique which leads to removing the accumulated software errors by stopping the system, cleaning up its internal state, and resuming its normal operation. One of the main challenges of software rejuvenation is accurately predicting the time to crash due to aging factors such as memory leaks. In this paper, different machine learning techniques are compared to accurately predict the software time to crash under different aging scenarios. Finally, by comparing the accuracy of different techniques, it can be concluded that the multilayer perceptron neural network has the highest prediction accuracy among all techniques studied.","","","10.1109/JSEE.2015.00047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7111178","machine learning;software rejuvenation;software reliability","Aging;Computer crashes;Least squares approximations;Machine learning algorithms;Prediction algorithms;Software;Software algorithms","","","","0","","","","","April 2015","","BIAI","BIAI Journals & Magazines"
"Time series forecasting by means of SOM aided Fuzzy Inference Systems","D. Zurita; J. A. Carino; E. Sala; M. Delgado-Prieto; J. A. Ortega","MCIA Research Center, Department of Electronic Engineering, Technical University of Catalonia (UPC), Rbla. San Nebridi n&#x00BA;22, Gaia Research Building, 08222 Terrassa, Spain","2015 IEEE International Conference on Industrial Technology (ICIT)","20150618","2015","","","1772","1778","The forecast of industrial process time series represents a critical factor in order to assure a proper operation of the whole manufacturing chain, as it allows to act against any process deviation before it affects the final manufactured product. In this paper, in order to take advantage from process relations and improve forecasting performance, a prediction method based in Adaptive Neuro Fuzzy Inference System (ANFIS) and Self-Organizing Maps is presented. The novelties of the proposed method are based on considering, as an input of an ANFIS model, the interrelations of process variables regarding the signal that wants to be forecasted, by means of topology preservation SOM. An experimental study performed with real industrial data from a cooper manufacturing plant indicated the suitability of the proposed method in time series forecasting applications.","","Electronic:978-1-4799-7800-7; POD:978-1-4799-7801-4; USB:978-1-4799-7799-4","10.1109/ICIT.2015.7125354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7125354","Artificial intelligence;Condition monitoring;Fuzzy neural networks;Machine learning;Predictive models;Prognosis;Time series analysis","Data models;Forecasting;Fuzzy logic;Manufacturing;Neurons;Predictive models;Training","forecasting theory;fuzzy reasoning;fuzzy set theory;manufacturing industries;manufacturing processes;production engineering computing;self-organising feature maps;time series;topology","ANFIS model;SOM;adaptive neuro fuzzy inference system;cooper manufacturing plant;industrial process time series forecasting;manufacturing chain;prediction method;self-organizing map;topology preservation","","1","","20","","","17-19 March 2015","","IEEE","IEEE Conference Publications"
"News classification based on their headlines: A review","M. I. Rana; S. Khalid; M. U. Akbar","Department of Computer Engineering, Bahria University Islamabad, Pakistan","17th IEEE International Multi Topic Conference 2014","20150430","2014","","","211","216","For the last few years, text mining has been gaining significant importance. Since Knowledge is now available to users through variety of sources i.e. electronic media, digital media, print media, and many more. Due to huge availability of text in numerous forms, a lot of unstructured data has been recorded by research experts and have found numerous ways in literature to convert this scattered text into defined structured volume, commonly known as text classification. Focus on full text classification i.e. full news, huge documents, long length texts etc. is more prominent as compared to the short length text. In this paper, we have discussed text classification process, classifiers, and numerous feature extraction methodologies but all in context of short texts i.e. news classification based on their headlines. Existing classifiers and their working methodologies are being compared and results are presented effectively.","","Electronic:978-1-4799-5755-2; POD:978-1-4799-5756-9","10.1109/INMIC.2014.7097339","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097339","Classification model;Machine Learning;News classification;News headlines classification;Text Mining;Text classifiers","Accuracy;Classification algorithms;Decision trees;Indexing;Support vector machines;Text categorization;Text mining","electronic publishing;feature extraction;pattern classification;text analysis","classifiers;feature extraction methodologies;headlines;news classification;short texts;text classification process","","1","","29","","","8-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"Takagi-Sugeno fuzzy systems structure identification based on piecewise linear initialization","I. A. Hodashinsky; K. S. Sarin; D. D. Zykov","Department of Complex Information Security, Tomsk State University of Control Systems and Radioelectronics, Russia","2015 International Siberian Conference on Control and Communications (SIBCON)","20150702","2015","","","1","4","A new method is proposed for structure identification of Takagi-Sugeno fuzzy systems, which is called piecewise linear initialization (PLI). This method is based on clustering of input data and has only one parameter: mean-square deviation of a hyperplane in the cluster from data. Each cluster is a particular rule of the fuzzy system. Based on the cluster are constructed Gaussian membership functions, otherwise consequents of fuzzy rules are constructed using the recursive least square method. The proposed method is compared with other methods by analyzing the mean-square error and the average number of rules on various datasets from the KEEL repository.","","CD-ROM:978-1-4799-7102-2; Electronic:978-1-4799-7103-9; POD:978-1-4799-7104-6","10.1109/SIBCON.2015.7147261","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7147261","artificial intelligence;fuzzy systems;machine learning;structure identification","Algorithm design and analysis;Approximation algorithms;Clustering algorithms;Fuzzy systems;Least squares approximations;Mean square error methods;Pragmatics","Gaussian processes;fuzzy control;fuzzy systems;least mean squares methods;piecewise linear techniques","Gaussian membership function;KEEL repository;PLI;Takagi-Sugeno fuzzy systems structure identification;fuzzy rule;hyperplane;mean-square deviation;mean-square error;particular rule;piecewise linear initialization;recursive least square method","","1","","8","","","21-23 May 2015","","IEEE","IEEE Conference Publications"
"MRI: Model-Based Radio Interpolation for Indoor War-Walking","H. Shin; Y. Chon; Y. Kim; H. Cha","Department of Computer Science, Yonsei University, Seoul, Korea","IEEE Transactions on Mobile Computing","20150504","2015","14","6","1231","1244","Location estimation methods using radio fingerprint have been studied extensively. The approach constructs a database that associates ambient radio signals with physical locations in training phase, and then estimates the location by finding the most similar signal pattern within the database. To achieve robust and accurate location estimation, the training phase should be conducted across the entire target space. In practice, however, a user may only access limited or authorized places in a building, that causes degradation in accuracy. In this paper, we present a smartphone-based autonomous indoor war-walking scheme, which automatically constructs the location fingerprint database, even covering unvisited locations. While a smartphone user explores the target area, the proposed system tracks the user's trajectory and simultaneously trains the location fingerprint database. Furthermore, our scheme interpolates radio signals in the database with an appropriate radio propagation model, and supplements fingerprints for unvisited places. As a result, although a user may sparsely explore the target site, the scheme returns the complete database. We implemented our solution and demonstrated the feasibility of the solution.","1536-1233;15361233","","10.1109/TMC.2014.2345654","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6872807","Data interpolation;indoor positioning system;localization;machine learning;war-walking","Databases;Estimation;Fingerprint recognition;Magnetic resonance imaging;Mathematical model;Mobile handsets;Training","indoor navigation;indoor radio;interpolation","MRI;ambient radio signals;location estimation methods;location fingerprint database;model-based radio interpolation;physical locations;radio fingerprint;radio propagation model;signal pattern;smartphone user;smartphone-based autonomous indoor war-walking scheme;training phase;unvisited locations","","0","","34","","20140807","June 1 2015","","IEEE","IEEE Journals & Magazines"
"Devanagari offline handwritten numeral and character recognition using multiple features and neural network classifier","V. J. Dongre; V. H. Mankar","Department of Electronics and communication, Government Polytechnic, Gondia, Maharashtra, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","425","431","This paper presents an attempt to solve the challenging problem of Devanagari numeral and character recognition. It uses structural and geometric features to represent the Devanagari numerals and characters. Each image is zoned in 9 blocks and 8 structural features are extracted from each block. Similarly 9 global geometric features are extracted. These 81 features are used for representing the image. Multilayer perceptron neural network (MLP-NN) is used for classification. 3000 handwritten samples of Devanagari numerals and 5375 handwritten samples of Devanagari alphabetic characters are used for training and testing. Experimental results show 93.17% recognition accuracy using 40 hidden neurons for numerals and 82.7% recognition accuracy using 60 hidden neurons for characters. Fivefold cross validation is used for verifying the results.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100286","Cross validation;Feature extraction;Machine learning;Neural network;Optical character recognition","Accuracy;Biological neural networks;Character recognition;Databases;Feature extraction;Neurons;Training","feature extraction;handwritten character recognition;image representation;multilayer perceptrons;natural language processing","Devanagari alphabetic characters;Devanagari numerals;Devanagari offline handwritten character recognition;feature extraction;geometric features;image representation;multilayer perceptron neural network;neural network classifier;structural features","","0","","24","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Integrated STEM learning within health science, mathematics and computer science","M. Droppa; W. Lu; S. Bemis; L. Ocker; M. Miller","Keene State College","2015 IEEE Integrated STEM Education Conference","20150611","2015","","","242","245","In this integrated STEM learning module we developed a data collection tool and used innovative analysis methods to investigate the relationship between academic achievement and risky wellness behaviors among college students. Exploratory factor analysis (EFA) was performed using data from college students (n = 1,499) at a large north-central university. Advanced machine learning analysis techniques found a strong connection between student wellness behavior and academic achievement and that this relationship can be predicted using wellness behavior data. The real world research project in this study integrated educational activities among Mathematics, Computer Science, and Health Science creating an interdisciplinary learning experience within Science, Technology, Engineering and Mathematics (STEM).","","Electronic:978-1-4799-1829-4; POD:978-1-4799-1830-0","10.1109/ISECon.2015.7119932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119932","STEM;academic achievement;machine learning techniques;risky wellness behavior","Big data;Clustering algorithms;Computer science;Drugs;Education","behavioural sciences computing;data analysis;educational administrative data processing;educational institutions;further education;health care;learning (artificial intelligence);mathematics","Mathematics;Science-Technology-Engineering-and-Mathematics;academic achievement;advanced machine learning analysis techniques;computer science;data collection tool;exploratory factor analysis;health science;innovative analysis methods;integrated STEM learning module;integrated educational activities;interdisciplinary learning experience;north-central university;risky wellness behaviors","","0","","17","","","7-7 March 2015","","IEEE","IEEE Conference Publications"
"Key-Recovery Attacks on KIDS, a Keyed Anomaly Detection System","J. E. Tapiador; A. Orfila; A. Ribagorda; B. Ramos","Dept. of Comput. Sci., Univ. Carlos III de Madrid, Leganes, Spain","IEEE Transactions on Dependable and Secure Computing","20150512","2015","12","3","312","325","Most anomaly detection systems rely on machine learning algorithms to derive a model of normality that is later used to detect suspicious events. Some works conducted over the last years have pointed out that such algorithms are generally susceptible to deception, notably in the form of attacks carefully constructed to evade detection. Various learning schemes have been proposed to overcome this weakness. One such system is Keyed IDS (KIDS), introduced at DIMVA “10. KIDS” core idea is akin to the functioning of some cryptographic primitives, namely to introduce a secret element (the key) into the scheme so that some operations are infeasible without knowing it. In KIDS the learned model and the computation of the anomaly score are both key-dependent, a fact which presumably prevents an attacker from creating evasion attacks. In this work we show that recovering the key is extremely simple provided that the attacker can interact with KIDS and get feedback about probing requests. We present realistic attacks for two different adversarial settings and show that recovering the key requires only a small amount of queries, which indicates that KIDS does not meet the claimed security properties. We finally revisit KIDS' central idea and provide heuristic arguments about its suitability and limitations.","1545-5971;15455971","","10.1109/TDSC.2013.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6598669","Adversarial classification;anomaly detection;intrusion detection systems;secure machine learning","Computational modeling;Feature extraction;Intrusion detection;Machine learning algorithms;Payloads;Training","learning (artificial intelligence);security of data","KIDS;anomaly detection systems;evasion attacks;key-recovery attacks;keyed anomaly detection system;machine learning algorithms","","0","","23","","20130913","May-June 2015","","IEEE","IEEE Journals & Magazines"
"Predicting clicks: CTR estimation of advertisements using Logistic Regression classifier","R. Kumar; S. M. Naik; V. D. Naik; S. Shiralli; Sunil V. G; M. Husain","B V Bhoomaraddi College of Engineering and Technology, Hubli, 580031, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","1134","1138","Search engine advertising in the present day is a pronounced component of the Web. Choosing the appropriate and relevant ad for a particular query and positioning of the ad critically impacts the probability of being noticed and clicked. It also strategically impacts the revenue, the search engine shall generate from a particular Ad. Needless to say, showing the user an Ad that is relevant to his/her need greatly improves users satisfaction. For all the aforesaid reasons, its of utmost importance to correctly determine the click-through rate (CTR) of ads in a system. For frequently appearing ads, CTR is empirically measurable, but for the new ads, other means have to be devised. In this paper we propose and establish a model to predict the CTRs of advertisements adopting Logistic Regression as the effective framework for representing and constructing conditions and vulnerabilities among variables. Logistic Regression is a type of probabilistic statistical classification model that predicts a binary response from a binary predictor, based on one or more predictor variables. Advertisements that have the most elevated to be clicked are chosen using supervised machine learning calculation. We tested Logistic Regression algorithm on a one week advertisement data of size around 25 GB by considering position and impression as predictor variables. Using this prescribed model we were able to achieve around 90% accuracy for CTR estimation.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154880","Ads;click through rate(C.T.R);ranking;supervised machine learning","Advertising;Cost function;Estimation;Feature extraction;Logistics;Predictive models;Training","Internet;advertising data processing;estimation theory;pattern classification;probability;regression analysis;search engines","CTR estimation;World Wide Web;advertisement;binary predictor;binary response;click-through rate;logistic regression classifier;probabilistic statistical classification model;probability;search engine advertising;user satisfaction","","1","","23","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"An application of deep learning for trade signal prediction in financial markets","A. C. Türkmen; A. T. Cemgil","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Bo&#x011F;azi&#x00E7;i &#x00DC;niversitesi, Istanbul, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","2521","2524","We know algorithms for predicting price movement direction and time are in practical use, despite being disputed at a theoretical level. In this study, we analyze the benefits of various machine learning algorithms to the price movement direction prediction problem, on selected stocks from the U.S. stock markets. To this end, we generate an array of features known to be beneficial in technical analysis of securities, and show the efficacy of several supervised learning methods. Lastly, we demonstrate that Stacked Denoising Auto-Encoders, an example of “deep learning” that has grown popular in recent years, yields significant prediction power.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130397","Deep Learning;Finance;Machine Learning","Forecasting;Machine learning algorithms;Market research;Neural networks;Noise reduction;Stock markets;Time series analysis","economic forecasting;learning (artificial intelligence);pricing;stock markets","US stock markets;deep learning;financial markets;machine learning algorithms;price movement direction prediction problem;securities;stacked denoising auto-encoders;supervised learning methods;trade signal prediction","","0","","14","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Motor-Primed Visual Attention for Humanoid Robots","L. Lukic; A. Billard; J. Santos-Victor","VISLAB/ISR, Instituto Superior T&#x00E9;cnico, Lisbon, Portugal","IEEE Transactions on Autonomous Mental Development","20150610","2015","7","2","76","91","We present a novel, biologically inspired, approach to an efficient allocation of visual resources for humanoid robots in a form of a motor-primed visual attentional landscape. The attentional landscape is a more general, dynamic and a more complex concept of an arrangement of spatial attention than the popular “attentional spotlight” or “zoom-lens” models of attention. Motor-priming of attention is a mechanism for prioritizing visual processing to motor-relevant parts of the visual field, in contrast to other, motor-irrelevant, parts. In particular, we present two techniques for constructing a visual “attentional landscape”. The first, more general, technique, is to devote visual attention to the reachable space of a robot (peripersonal space-primed attention). The second, more specialized, technique is to allocate visual attention with respect to motor plans of the robot (motor plans-primed attention). Hence, in our model, visual attention is not exclusively defined in terms of visual saliency in color, texture or intensity cues, it is rather modulated by motor information. This computational model is inspired by recent findings in visual neuroscience and psychology. In addition to two approaches to constructing the attentional landscape, we present two methods for using the attentional landscape for driving visual processing. We show that motor-priming of visual attention can be used to very efficiently distribute limited computational resources devoted to the visual processing. The proposed model is validated in a series of experiments conducted with the iCub robot, both using the simulator and the real robot.","1943-0604;19430604","","10.1109/TAMD.2015.2417353","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069203","Cognitive robotics;computer vision;humanoid robots;machine learning","Adaptation models;Biological system modeling;Computational modeling;Grasping;Robots;Visualization","cognition;humanoid robots;learning (artificial intelligence);psychology;robot vision","attentional spotlight;computational model;computational resource;humanoid robot;iCub robot;motor information;motor plans-primed attention;motor-primed visual attentional landscape;motor-relevant part;peripersonal space-primed attention;psychology;reachable space;spatial attention;visual neuroscience;visual processing;visual resource allocation;visual saliency;zoom-lens model","","0","","70","","20150326","June 2015","","IEEE","IEEE Journals & Magazines"
"A High-Throughput Neural Network Accelerator","T. Chen; Z. Du; N. Sun; J. Wang; C. Wu; Y. Chen; O. Temam","State Key Laboratory of Computer Architecture","IEEE Micro","20150622","2015","35","3","24","32","The authors designed an accelerator architecture for large-scale neural networks, with an emphasis on the impact of memory on accelerator design, performance, and energy. In this article, they present a concrete design at 65 nm that can perform 496 16-bit fixed-point operations in parallel every 1.02 ns, that is, 452 gop/s, in a 3.02mm<sup>2</sup>, 485-mw footprint (excluding main memory accesses).","0272-1732;02721732","","10.1109/MM.2015.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106400","hardware accelerator;machine learning;neural network","Accelerators;Artificial neural networks;Computer architecture;Graphics processing units;Machine learning;Market research;Neural networks","neural nets","accelerator architecture;accelerator design;high-throughput neural network accelerator;size 65 nm","","2","","23","","20150513","May-June 2015","","IEEE","IEEE Journals & Magazines"
"Sentiment analysis for Turkish Twitter feeds","Ö. Çoban; B. Özyer; G. T. Özyer","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Atat&#x00FC;rk &#x00DC;niversitesi, Erzurum, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","2388","2391","Sentiment analysis is one of the most useful tools in social media monitoring. Implementing sentiment analysis on data gained from social media (Blogs, Twitter, and Facebook) can increase the customer satisfaction and decrease the costs for a company. Also sentiment analysis can be used in various domains, such as economic, commercial and opinion mining for the users to get meaningful information. In this study, Turkish Twitter feeds collected from Twitter API have been analyzed in terms of the sentiment context whether positive or negative using document classification methods. Experimental results have been conducted on machine learning algorithms such as SVM, Naive Bayes, Multinomial Naive Bayes and KNN. The features represented by vector space are extracted from two different models which are Bag of Words and N-Gram. The experimental results have been investigated on the effect of classification methods.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130362","machine learning;sentiment analysis;sentiment classification;text classification;twitter","Blogs;Facebook;Media;Sentiment analysis;Support vector machines;Twitter;Uniform resource locators","Bayes methods;customer satisfaction;data mining;feature extraction;learning (artificial intelligence);natural language processing;pattern classification;social networking (online);support vector machines","Blogs;Facebook;KNN;SVM;Turkish Twitter feeds;Twitter API;bag of words;customer satisfaction;document classification method;feature extraction;machine learning algorithm;multinomial naive Bayes;n-gram;opinion mining;sentiment analysis;sentiment context;social media monitoring;vector space","","0","","16","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"An Approach to Predict Drive-by-Download Attacks by Vulnerability Evaluation and Opcode","T. Adachi; K. Omote","Japan Adv. Inst. of Sci. & Technol., Ishikawa, Japan","2015 10th Asia Joint Conference on Information Security","20150713","2015","","","145","151","Drive-by-download attacks exploit vulnerabilities in Web browsers, and users are unnoticeably downloading malware which accesses to the compromised Web sites. A number of detection approaches and tools against such attacks have been proposed so far. Especially, it is becoming easy to specify vulnerabilities of attacks, because researchers well analyze the trend of various attacks. Unfortunately, in the previous schemes, vulnerability information has not been used in the detection/prediction approaches of drive-by-download attacks. In this paper, we propose a prediction approach of ""malware downloading"" during drive-by-download attacks (approach-I), which uses vulnerability information. Our experimental results show our approach-I achieves the prediction rate (accuracy) of 92%, FNR of 15% and FPR of 1.0% using Naive Bayes. Furthermore, we propose an enhanced approach (approach-II) which embeds Opcode analysis (dynamic analysis) into our approach-I (static approach). We implement our approach-I and II, and compare the three approaches (approach-I, II and Opcode approaches) using the same datasets in our experiment. As a result, our approach-II has the prediction rate of 92%, and improves FNR to 11% using Random Forest, compared with our approach-I.","","Electronic:978-1-4799-1989-5; POD:978-1-4799-1990-1; USB:978-1-4799-1988-8","10.1109/AsiaJCIS.2015.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153949","Drive-by-Download Attacks;Malware;Supervised Machine Learning","Browsers;Feature extraction;Machine learning algorithms;Malware;Predictive models;Probability;Web pages","Web sites;invasive software;learning (artificial intelligence);system monitoring","FNR;FPR;Opcode analysis;Web browsers;Web sites;attack vulnerabilities;drive-by-download attack prediction;dynamic analysis;malware downloading;naive Bayes;prediction rate;random forest;static approach;vulnerability evaluation;vulnerability information","","1","","14","","","24-26 May 2015","","IEEE","IEEE Conference Publications"
"An efficient learning technique to predict link quality in WSN","D. Marinca; P. Minet; N. Ben Hassine","Inria, Rocquencourt, 78153 Le Chesnay, France","2014 IEEE 25th Annual International Symposium on Personal, Indoor, and Mobile Radio Communication (PIMRC)","20150629","2014","","","1564","1569","In this paper, we apply learning techniques to predict link quality evolution in a WSN and take advantage of wireless links with the best possible quality to improve the packet delivery rate. We model this problem as a forecaster prediction game based on the advice of several experts. The forecaster learns on-line how to adjust its prediction to better fit the environment metric values. Simulations using traces collected in a real WSN show the improvement of the prediction when the experts use the SES prediction strategy, whereas the forecaster uses the EWA learning strategy.","2166-9570;21669570","Electronic:978-1-4799-4912-0; POD:978-1-4799-4911-3","10.1109/PIMRC.2014.7136417","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7136417","Machine learning;cumulated loss;expert;forecaster;link quality;prediction;wireless sensor networks","Accuracy;Games;Measurement;Predictive models;Signal to noise ratio;Wireless communication;Wireless sensor networks","game theory;learning (artificial intelligence);prediction theory;radio links;telecommunication computing;wireless sensor networks","EWA learning strategy;SES prediction strategy;WSN;efficient learning technique;environment metric values;forecaster prediction game;packet delivery rate;wireless link quality evolution;wireless sensor networks","","0","","11","","","2-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Dual Sentiment Analysis: Considering Two Sides of One Review","R. Xia; F. Xu; C. Zong; Q. Li; Y. Qi; T. Li","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Knowledge and Data Engineering","20150706","2015","27","8","2120","2133","Bag-of-words (BOW) is now the most popular way to model text in statistical machine learning approaches in sentiment analysis. However, the performance of BOW sometimes remains limited due to some fundamental deficiencies in handling the polarity shift problem. We propose a model called dual sentiment analysis (DSA), to address this problem for sentiment classification. We first propose a novel data expansion technique by creating a sentiment-reversed review for each training and test review. On this basis, we propose a dual training algorithm to make use of original and reversed training reviews in pairs for learning a sentiment classifier, and a dual prediction algorithm to classify the test reviews by considering two sides of one review. We also extend the DSA framework from polarity (positive-negative) classification to 3-class (positive-negative-neutral) classification, by taking the neutral reviews into consideration. Finally, we develop a corpus-based method to construct a pseudo-antonym dictionary, which removes DSA's dependency on an external antonym dictionary for review reversion. We conduct a wide range of experiments including two tasks, nine datasets, two antonym dictionaries, three classification algorithms, and two types of features. The results demonstrate the effectiveness of DSA in supervised sentiment classification.","1041-4347;10414347","","10.1109/TKDE.2015.2407371","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050255","Natural language processing;machine learning;natural language processing;opinion mining;sentiment analysis","Analytical models;Classification algorithms;Dictionaries;Logistics;Pragmatics;Sentiment analysis;Training","data mining;learning (artificial intelligence);pattern classification;statistical analysis;text analysis","3-class classification;BOW;DSA framework;bag-of-words;corpus-based method;data expansion technique;dual prediction algorithm;dual sentiment analysis;dual training algorithm;external antonym dictionary;polarity classification;polarity shift problem;positive-negative classification;positive-negative-neutral classification;pseudoantonym dictionary;reversed training reviews;sentiment classification problem;sentiment-reversed review;statistical machine learning approaches;supervised sentiment classification;test review;text model","","7","","49","","20150226","Aug. 1 2015","","IEEE","IEEE Journals & Magazines"
"A comparison of supervised classification methods for a statistical set of features: Application: Amazigh OCR","N. Aharrane; K. E. Moutaouakil; K. Satori","Computer sciences, Imaging and Numerical Analysis Laboratory (LIIAN), USMBA University, Fez, Morocco","2015 Intelligent Systems and Computer Vision (ISCV)","20150514","2015","","","1","8","This paper is devoted to the study of supervised learning methods as part of pattern recognition and especially the Amazigh Characters Recognition. The goal is to compare a partial list of the popular automatic classification methods, and test the performance of the proposed features set extracted from isolated characters using statistical methods with these different classifiers. In Experimental evaluation, several runs have been conducted for the different algorithms and the best accuracy observed is for the multilayer perceptron with a recognition rate about 96,47% which is very satisfactory.","","Electronic:978-1-4799-7511-2; POD:978-1-4799-7512-9","10.1109/ISACV.2015.7106171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106171","Amazigh;Machine learning;OCR;features extraction;intelligent data analysis;supervised classification","Bayes methods;Classification algorithms;Decision trees;Feature extraction;Histograms;Image segmentation;Optical character recognition software","character recognition;feature extraction;image classification;multilayer perceptrons;set theory;statistical analysis","Amazigh character recognition;automatic classification methods;isolated characters;multilayer perceptron;pattern recognition;statistical feature set extraction;statistical methods;supervised classification methods;supervised learning methods","","3","","29","","","25-26 March 2015","","IEEE","IEEE Conference Publications"
"An intelligent framework for recognizing sign language from continuous video sequence using boosted subunits","R. Elakkiya; K. Selvamani; A. Kannan","Dept. of Comput. Sci. & Eng., Agni Coll. of Technol., Chennai, India","IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013)","20150611","2013","","","297","304","In this research paper, the problem of vision-based sign language recognition which is used to translate signs to native or foreign language is addressed. This paper aims in designing a framework for segmenting and tracking skin objects from continuous signing videos and developing a fully automatic system to recognize signs that starts with breaking up signs into manageable subunits. A variety of spatiotemporal discriminative descriptors are extracted to form a feature vector for each subunit. A boosting algorithm is applied to the subunits to learn the subset of weak classifiers and combining them to strong classifier for each sign. The results obtained from the system shows that this proposed approach is promising for an effective and scalable system on real-world hand gesture recognition from continuous video sequences using boosted subunits.","","Paper:978-1-78561-030-1","10.1049/ic.2013.0329","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119716","Boosted Subunits;Hand Gesture Recognition;Machine Learning;Sign Language Recognition;Support Vector Machine","","gesture recognition;image sequences;video signal processing","boosted subunits;boosting algorithm;continuous video sequence;continuous video sequences;feature vector;foreign language;gesture recognition;intelligent framework;native language;recognizing sign language;skin object segmentation;skin object tracking;spatiotemporal discriminative descriptors;vision based sign language recognition","","0","","","","","12-14 Dec. 2013","","IET","IET Conference Publications"
"System Failure Prediction through Rare-Events Elastic-Net Logistic Regression","J. M. Navarro; G. H. A. Parada; J. C. Dueñas","Center for Open Middleware, Univ. Politec. de Madrid, Madrid, Spain","2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation","20150507","2014","","","120","125","Predicting failures in a distributed system based on previous events through logistic regression is a standard approach in literature. This technique is not reliable, though, in two situations: in the prediction of rare events, which do not appear in enough proportion for the algorithm to capture, and in environments where there are too many variables, as logistic regression tends to over fit on this situations, while manually selecting a subset of variables to create the model is error-prone. On this paper, we solve an industrial research case that presented this situation with a combination of elastic net logistic regression, a method that allows us to automatically select useful variables, a process of cross-validation on top of it and the application of a rare events prediction technique to reduce computation time. This process provides two layers of cross-validation that automatically obtain the optimal model complexity and the optimal model parameters values, while ensuring even rare events will be correctly predicted with a low amount of training instances. We tested this method against real industrial data, obtaining a total of 60 out of 80 possible models with a 90% average model accuracy.","","Electronic:978-1-4799-7600-3; POD:978-1-4799-7601-0","10.1109/AIMS.2014.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102446","Automatic Feature Selection;Logistic Regression;Machine Learning;Multivariable Prediction;Online Failure Prediction;System Management","Complexity theory;Computational modeling;Data models;Logistics;Prediction algorithms;Predictive models;Training","computational complexity;distributed processing;failure analysis;feature selection;regression analysis","computation time;cross-validation;distributed system;elastic net logistic regression;industrial research case;optimal model complexity;optimal model parameters value;predicting failure;rare events prediction technique;rare-events elastic-net logistic regression;system failure prediction","","0","","22","","","18-20 Nov. 2014","","IEEE","IEEE Conference Publications"
"To detect malicious nodes in the Mobile Ad-hoc Networks using soft computing technique","P. Kavitha; R. Mukesh","Department of Computer Science and Engineering, Hindustan University, Padur, Chennai, Tamil Nadu, India","2015 2nd International Conference on Electronics and Communication Systems (ICECS)","20150618","2015","","","1564","1573","A Mobile Ad-hoc Network (MANET) is a constantly self-configuring, infrastructure-less network of mobile devices where each device is wireless, moves without restraint and be a router to put across traffic unassociated to its own use. Every device must be prepared to constantly sustain the information obligatory for routing the traffic. And this is the main challenge in building a MANET. Such networks may be self operating or linked to a larger internet and may have one or multiple different transceivers between nodes resulting in a highly dynamic and autonomous topology. The first focus is on MANET attacks followed by detection of the malicious node from MANET via Polynomial-Reduction Algorithm. Although scientists have assessed many algorithms for the detection and rectification of the malicious nodes in the MANETs, the problem still persists. Due to the unprecedented growth in technology, the unidentified vulnerabilities are also intensifying. Therefore, it is very crucial to come up with some ground-breaking ideas to prevent the MANET. In this paper we are used NS2 simulator to implementing malicious nodes in MANET.","","Electronic:978-1-4799-7225-8; POD:978-1-4799-7226-5","10.1109/ECS.2015.7124851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7124851","Machine Learning Algorithm;Mobile Ad-hoc Networks;Polynomial-Reduction Algorithm","Mobile ad hoc networks;Mobile communication;Routing;Routing protocols;Security","Internet;learning (artificial intelligence);mobile ad hoc networks;polynomials;telecommunication network routing;telecommunication network topology;telecommunication security;telecommunication traffic;uncertainty handling","Internet;MANET attacks;NS2 simulator;autonomous topology;dynamic topology;infrastructure-less network;machine learning algorithm;malicious node detection;malicious node rectification;mobile ad-hoc networks;mobile devices;polynomial-reduction algorithm;self-configuring network;soft computing technique;traffic routing;transceivers","","0","","27","","","26-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"Online and semi-online sentiment classification","K. Ravi; V. Ravi; C. Gautam","School of Computer & Information Sciences, University of Hyderabad, Hyderabad-500046 (AP), India","International Conference on Computing, Communication & Automation","20150706","2015","","","938","943","With the advent of social media and e-commerce sites, people are posting their unilateral, possibly subjective views on different products and services. Sentiment classification is the process of determining whether a given text is expressing positive or negative sentiment towards an entity (product or service) or its attributes. In this regard, we employed text mining involving steps like text preprocessing, feature extraction and selection and finally classification by machine learning algorithms to classify the customers' reviews on four mobile phone brands. The trio of TF-IDF, chi-square based feature selection and recurrent (Jordan/Elman)neural network classifier outperformed all other alternatives. The proposed combination yielded 19.13% higher accuracy compared to that of SVM, which is reported as the best classifier for sentiment classification in several studies. It also outperformed two semi-online classifiers proposed by us here.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148531","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148531","Chi-square;Machine Learning;Probabilistic Neural Network;Sentiment classification;Text Mining","Accuracy;Classification algorithms;Logistics;Motion pictures;Neural networks;Support vector machines;Training","data mining;feature extraction;feature selection;learning (artificial intelligence);pattern classification;recurrent neural nets;statistical distributions;text analysis","chi-square;feature extraction;feature selection;machine learning algorithm;recurrent neural network classifier;semionline sentiment classification;text mining;text preprocessing","","3","","40","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"iF2: An Interpretable Fuzzy Rule Filter for Web Log Post-Compromised Malicious Activity Monitoring","C. H. Hsieh; Y. S. Shen; C. W. Li; J. S. Wu","Inst. of Informaiton Ind., Taipei, Taiwan","2015 10th Asia Joint Conference on Information Security","20150713","2015","","","130","137","To alleviate the loads of tracking web log file by human effort, machine learning methods are now commonly used to analyze log data and to identify the pattern of malicious activities. Traditional kernel based techniques, like the neural network and the support vector machine (SVM), typically can deliver higher prediction accuracy. However, the user of a kernel based techniques normally cannot get an overall picture about the distribution of the data set. On the other hand, logic based techniques, such as the decision tree and the rule-based algorithm, feature the advantage of presenting a good summary about the distinctive characteristics of different classes of data such that they are more suitable to generate interpretable feedbacks to domain experts. In this study, a real web-access log dataset from a certain organization was collected. An efficient interpretable fuzzy rule filter (iF<sup>2</sup>) was proposed as a filter to analyze the data and to detect suspicious internet addresses from the normal ones. The historical information of each internet address recorded in web log file is summarized as multiple statistics. And the design process of iF<sup>2</sup> is elaborately modeled as a parameter optimization problem which simultaneously considers 1) maximizing prediction accuracy, 2) minimizing number of used rules, and 3) minimizing number of selected statistics. Experimental results show that the fuzzy rule filter constructed with the proposed approach is capable of delivering superior prediction accuracy in comparison with the conventional logic based classifiers and the expectation maximization based kernel algorithm. On the other hand, though it cannot match the prediction accuracy delivered by the SVM, however, when facing real web log file where the ratio of positive and negative cases is extremely unbalanced, the proposed iF<sup>2</sup> of having optimization flexibility results in a better recall rate and enjoys one major advantage due to providing th- user with an overall picture of the underlying distributions.","","Electronic:978-1-4799-1989-5; POD:978-1-4799-1990-1; USB:978-1-4799-1988-8","10.1109/AsiaJCIS.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153947","Fuzzy Rule Based Filter;Machine Learning;Parameter Optimization;Pattern Recognition;Post-Compromised Threat Identification;Web Log Analysis","Accuracy;Internet;Kernel;Monitoring;Optimization;Prediction algorithms;Support vector machines","Internet;data mining;fuzzy set theory;learning (artificial intelligence);neural nets;pattern classification;statistical analysis;support vector machines","Internet address;SVM;Web log file tracking;Web log post-compromised malicious activity monitoring;Web-access log dataset;decision tree;expectation maximization based kernel algorithm;fuzzy rule filter;iF<sup>2</sup>;interpretable fuzzy rule filter;kernel based techniques;log data analysis;logic based classifiers;logic based techniques;machine learning methods;malicious activities;neural network;parameter optimization problem;recall rate;rule-based algorithm;support vector machine","","0","","21","","","24-26 May 2015","","IEEE","IEEE Conference Publications"
"A Survey and Analysis of Techniques for Player Behavior Prediction in Massively Multiplayer Online Role-Playing Games","B. Harrison; S. G. Ware; M. W. Fendt; D. L. Roberts","School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Transactions on Emerging Topics in Computing","20150604","2015","3","2","260","274","While there has been much research done on player modeling in single-player games, player modeling in massively multiplayer online role-playing games (MMORPGs) has remained relatively unstudied. In this paper, we survey and evaluate three classes of player modeling techniques: 1) manual tagging; 2) collaborative filtering; and 3) goal recognition. We discuss the strengths and weaknesses that each technique provides in the MMORPG environment using desiderata that outline the traits an algorithm should posses in an MMORPG. We hope that this discussion as well as the desiderata help future research done in this area. We also discuss how each of these classes of techniques could be applied to the MMORPG genre. In order to demonstrate the value of our analysis, we present a case study from our own work that uses a model-based collaborative filtering algorithm to predict achievements in World of Warcraft. We analyze our results in light of the particular challenges faced by MMORPGs and show how our desiderata can be used to evaluate our technique.","2168-6750;21686750","","10.1109/TETC.2014.2360463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6910312","Computational Modeling;Computational modeling;Games;Machine Learning;data mining;games;machine learning;performance evaluation","Collaboration;Computational modeling;Data models;Games;Licenses;Prediction algorithms;Predictive models","behavioural sciences computing;collaborative filtering;computer games","MMORPG environment;World of Warcraft;desiderata;goal recognition;manual tagging;massively multiplayer online role-playing games;model-based collaborative filtering algorithm;player behavior prediction;player modeling techniques;single-player games","","1","","56","","20140925","June 2015","","IEEE","IEEE Journals & Magazines"
"Full model selection using Bat algorithm","B. Bansal; A. Sahoo","Computer Science Department, JSS Academy of Technical Education, C-20/1, Sector-62, Noida, India","2015 International Conference on Cognitive Computing and Information Processing(CCIP)","20150504","2015","","","1","4","Full Model Selection (FMS) selects the optimal amalgamation of pre-processing technique, feature subset and learning algorithm that obtains the least classification error for a given dataset. Meta-heuristic optimization algorithms are quite suitable for FMS, since it needs to explore and exploit a large solution space. This paper investigates the ability of an efficient meta-heuristic, named Bat algorithm for FMS. Traditional Bat algorithm has been modified and applied for FMS in gene expression analysis. Experiments are conducted on Gene Expression benchmark datasets that shows the suitability and effectiveness of the proposed approach in FMS.","","Electronic:978-1-4799-7171-8; POD:978-1-4799-7172-5","10.1109/CCIP.2015.7100693","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100693","Bat Algorithm;Classification;Feature selection;Machine Learning;Meta-heuristics;Model selection","Algorithm design and analysis;Classification algorithms;Computational modeling;Gene expression;Mathematical model;Sociology;Statistics","evolutionary computation;feature selection;learning (artificial intelligence);optimisation","FMS;bat algorithm;feature subset;full model selection;gene expression analysis;gene expression benchmark datasets;learning algorithm;least classification error;meta-heuristic optimization algorithms;optimal amalgamation selection;preprocessing technique","","0","","9","","","3-4 March 2015","","IEEE","IEEE Conference Publications"
"Classifying emotion in Thai youtube comments","P. Sarakit; T. Theeramunkong; C. Haruechaiyasak; M. Okumura","School of ICT, Sirindhorn International Institute of Technology, Thammasat University, Thailand","2015 6th International Conference of Information and Communication Technology for Embedded Systems (IC-ICTES)","20150525","2015","","","1","5","To add more value on YouTube, a popular portal of social media clips, it is worth recognizing automatically the mood of a media clip using the comments given to such clip. This paper presents a method to classify emotion of a Thai media clip on YouTube using the comments given to the clip. Six basic emotions considered are Anger, Disgust, Fear, Happiness, Sadness and Surprise. Performances using three alternative machine learning algorithms, namely multinomial naïve Bayes (MNB), decision tree (DT) and support vector machine (SVM) are compared. As the result, SVM achieves the highest accuracy in the commercial advertisement (AD) genre with an accuracy of 76.14% while MNB with yields the best result in the music video (MV) genre with an accuracy of 84.48%.","","Electronic:978-1-4799-8565-4; POD:978-1-4799-8566-1; USB:978-1-4799-8564-7","10.1109/ICTEmSys.2015.7110808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7110808","Emotion Classification;Emotion Detection;Machine Learning;Text Analysis","Accuracy;Conferences;Media;Sentiment analysis;Support vector machines;Twitter;YouTube","Bayes methods;decision trees;emotion recognition;human computer interaction;learning (artificial intelligence);pattern classification;portals;social networking (online);support vector machines","AD genre;DT;MNB;MV genre;SVM;Thai YouTube comments;Thai media clip;anger;commercial advertisement genre;decision tree;disgust;emotion classification;fear;happiness;machine learning algorithms;media clip mood;multinomial naïve Bayes;music video genre;portal;sadness;social media clips;support vector machine;surprise","","1","","22","","","22-24 March 2015","","IEEE","IEEE Conference Publications"
"Textual extraction and classification for medical risk management: A new Risk Management Platform to manage undesired medical events","S. Zidi; T. Julien; A. Mjirda; F. Maaloul","MIS Departement - CBE - Qassim University P.O. Box 6633, 14452, Saudi Arabia","2015 4th International Conference on Advanced Logistics and Transport (ICALT)","20150629","2015","","","235","239","In this paper, we propose a semi-automatic system to deal with the undesired events that may happen in the medical field. Based on algorithms of textual extraction and classifications, it performs a preprocessing of undesired events' declarations. The proposed system is currently running on different hospitals and some medical institutions in France. Computational study were made on a real-case instances and experimentations shows good results for the proposed approaches.","","Electronic:978-1-4799-8400-8; POD:978-1-4799-8401-5","10.1109/ICAdLT.2015.7136632","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7136632","Classifications;Machine learning;Medical field;Risk Management;Support Vector Machines;Textual extraction;Undesired events","Accidents;Gravity;Servers","decision support systems;hospitals;medical administrative data processing;pattern classification;risk management","France;RMP;hospitals;information-based decision support system;medical institutions;medical risk management;risk management platform;semiautomatic system;textual classification;textual extraction;undesired medical events management","","0","","12","","","20-22 May 2015","","IEEE","IEEE Conference Publications"
"A Probabilistic Discriminative Model for Android Malware Detection with Decompiled Source Code","L. Cen; C. S. Gates; L. Si; N. Li","Purdue University, West Lafayette, IN","IEEE Transactions on Dependable and Secure Computing","20150707","2015","12","4","400","412","Mobile devices are an important part of our everyday lives, and the Android platform has become a market leader. In recent years a number of approaches for Android malware detection have been proposed, using permissions, source code analysis, or dynamic analysis. In this paper, we propose to use a probabilistic discriminative model based on regularized logistic regression for Android malware detection. Through extensive experimental evaluation, we demonstrate that it can generate probabilistic outputs with highly accurate classification results. In particular, we propose to use Android API calls as features extracted from decompiled source code, and analyze and explore issues in feature granularity, feature representation, feature selection, and regularization. We show that the probabilistic discriminative model also works well with permissions, and substantially outperforms the state-of-the-art methods for Android malware detection with application permissions. Furthermore, the discriminative learning model achieves the best detection results by combining both decompiled source code and application permissions. To the best of our knowledge, this is the first research that proposes probabilistic discriminative model for Android malware detection with a thorough study of desired representation of decompiled source code and is the first research work for Android malware detection task that combines both analysis of decompiled source code and application permissions.","1545-5971;15455971","","10.1109/TDSC.2014.2355839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6894210","Android;discriminative model;machine learning;malicious application","Androids;Feature extraction;Humanoid robots;Malware;Measurement;Probabilistic logic;Smart phones","Android (operating system);application program interfaces;feature extraction;feature selection;invasive software;learning (artificial intelligence);mobile computing;probability;program compilers;regression analysis;source code (software)","Android API;Android malware detection;application permissions;decompiled source code analysis;discriminative learning model;feature extraction;feature granularity;feature representation;feature selection;mobile devices;probabilistic discriminative model;regularized logistic regression","","7","","32","","20140908","July-Aug. 1 2015","","IEEE","IEEE Journals & Magazines"
"Improving software quality based on relationship among the change proneness and object oriented metrics","A. Tripathi; K. Sharma","Department of computer Engineering, Delhi Technological University, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","1633","1636","With the demand of increasing functionality and arrival of defects, software goes through a lot of changes therefore its quite challenging task to maintain the quality of the software. In this paper we developed models to predict the change proneness of the classes in the object oriented system by analyzing the relationship between the object oriented metrics and change proneness. The model proposed is also validated by object oriented open source software. We have analyzed our results by the Receiver Operator Characteristics Curve. The results thus obtained shows that there is a significance relationship between the object oriented metrics and change proneness. We have analyzed statistical as well as machine learning techniques and the results shows that machine learning techniques are the good predictors of the change proneness. Rigorous testing of these change prone classes may improve the quality of the software and it may also reduce our work at the maintenance phase.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100524","Empirical Validation;Machine Learning;Object Oriented;Receiver Operating Characteristics;Statistical Methods;change Prediction","Analytical models;Measurement;Object oriented modeling;Open source software;Predictive models;Unified modeling language","learning (artificial intelligence);object-oriented methods;public domain software;software quality","change proneness;machine learning techniques;maintenance phase;object oriented metrics;open source software;receiver operator characteristics curve;software quality","","0","","16","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Detecting tunneled video streams using traffic analysis","Yan Shi; S. Biswas","Electrical and Computer Engineering, Michigan State University, East Lansing, USA","2015 7th International Conference on Communication Systems and Networks (COMSNETS)","20150504","2015","","","1","8","Detecting access to video streaming websites is the first step for an organization to regulate unwanted accesses to such sites by its employees. Adversaries often adopt circumvention techniques using proxy servers and Virtual Private Networks (VPNs) in order to avoid such detection. This paper presents a traffic analysis based technique that can detect such tunneled traffic at an organization's firewall using signatures found in traffic amount and timing in targeted video traffic. We present the detection results on the traffic data for several popular video streaming sites. Additional results are presented to validate the detection framework when detecting access to video streaming sites from a wide range of clients with a classifier trained with traffic data collected from a limited number of clients. The results show that the classifier works in both cases. It detects same-client traffic with high true positive rate, while it detects traffic from an unknown client with lower true positive rate but very low false positive rate. The results validate the effectiveness of traffic analysis based detection of video streaming sites.","2155-2487;21552487","Electronic:978-1-4799-8439-8; POD:978-1-4799-8440-4","10.1109/COMSNETS.2015.7098675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7098675","classifiers;machine learning;traffic analysis;virtual private networks;website fingerprinting","Cryptography;Firewalls (computing);Motion pictures;Payloads;Servers;Streaming media;Virtual private networks","digital signatures;firewalls;learning (artificial intelligence);telecommunication traffic;video streaming;wide area networks","classifier training;digital signatures;false positive rate;organization firewall;same-client traffic detection;traffic analysis;traffic data collection;true positive rate;tunneled video stream detection;unknown client traffic detection;unwanted accesses regulate;video streaming Web site access detection;video streaming sites;video traffic","","0","","20","","","6-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Neural network based attack on a masked implementation of AES","R. Gilmore; N. Hanley; M. O'Neill","Center for Secure Information Technologies, ECIT, Queen's University Belfast, Belfast, BT3 9DT, UK","2015 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)","20150702","2015","","","106","111","Masked implementations of cryptographic algorithms are often used in commercial embedded cryptographic devices to increase their resistance to side channel attacks. In this work we show how neural networks can be used to both identify the mask value, and to subsequently identify the secret key value with a single attack trace with high probability. We propose the use of a pre-processing step using principal component analysis (PCA) to significantly increase the success of the attack. We have developed a classifier that can correctly identify the mask for each trace, hence removing the security provided by that mask and reducing the attack to being equivalent to an attack against an unprotected implementation. The attack is performed on the freely available differential power analysis (DPA) contest data set to allow our work to be easily reproducible. We show that neural networks allow for a robust and efficient classification in the context of side-channel attacks.","","Electronic:978-1-4673-7421-7; POD:978-1-4673-7422-4; USB:978-1-4673-7420-0","10.1109/HST.2015.7140247","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140247","AES;SCA;machine learning;masking;neural network","Artificial neural networks;Cryptography;Error analysis;Hardware;Power demand;Principal component analysis;Training","cryptography;neural nets;pattern classification;principal component analysis","AES;Advanced Encryption Standard;DPA;PCA;cryptographic algorithms;differential power analysis contest data set;embedded cryptographic devices;machine learning;mask value identification;masked implementation;neural network based attack;principal component analysis;secret key value identification;side channel attacks","","1","","40","","","5-7 May 2015","","IEEE","IEEE Conference Publications"
"Automated cervical cancer detection using photonic crystal based bio-sensor","Nithin S; P. Sharma; Vivek M; P. Sharan","Department of ECE, The Oxford College of Engineering Bangalore, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","1174","1178","In this paper we are going to propose a logic by simulation, that an automatic system for detection of cervical cancer based on spectrum obtained from photonic crystal based bio-sensor, is possible. A 2-dimensional photonic crystal based bio-sensor in a static environment under the influence of electromagnetic radiation, whose range spans from UV to IR, designed to be highly sensitive for the changes in the dielectric constant e under the applied electric and magnetic induction for a set of concentration ranges of the analyte. As the refractive index of normal and cancer infected tissue is inferred, the sensor can easily differentiate normal tissue and cancer infected cervical tissue. The output of the sensor is known to exhibit distinct signatures in the frequency and amplitude spectra even while slight changes in the refractive index of the cervical cell takes place. A machine learning technique Naïve Bayesian classifier is used to distinguish the normal and cancerous tissue spectrum based on automatically extracted parameters of the attributed sensor output. The combined amalgamation of the sensor data and the incorporated automated classification archive into photonic crystal based bio-sensor, achieves better performance in detecting cervical cancer.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154888","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154888","Machine learning;Naïve Bayesian classifier;bio-sensor;cervical cancer;photonic crystal","Cervical cancer;MATLAB;Mathematical model;Photonic crystals;Time-domain analysis","Bayes methods;biological tissues;biosensors;cancer;electromagnetic induction;electromagnetic waves;formal logic;learning (artificial intelligence);medical computing;photonic crystals;simulation","automated cervical cancer detection;cancer infected tissue;electric induction;electromagnetic radiation;logic;machine learning technique;magnetic induction;naïve Bayesian classifier;photonic crystal based bio-sensor;simulation","","0","","7","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"Predicting behavior","A. Abbasi; R. Y. K. Lau; D. E. Brown","University of Virginia, VA, USA","IEEE Intelligent Systems","20150522","2015","30","3","35","43","Behavior prediction has become an important area of emphasis, with applications ranging from e-commerce, marketing analytics, and financial forecasting to smart health, security informatics, and crime prevention. However, traditional behavior modeling approaches have shortcomings: heavy reliance on objective, observed data, and a failure to consider the granular, micro-level decisions and actions that collectively drive macro-level behavior. To address these shortcomings, the authors present a behavior prediction framework that advocates the integration of objective and perceptual information and decomposes behavior into a series of closely interrelated stages to facilitate enhanced behavior prediction performance. The utility of the framework is demonstrated through a series of experiments pertaining to prediction of auction fraud, e-commerce conversions, and customer churn.","1541-1672;15411672","","10.1109/MIS.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045422","artificial intelligence;behavior prediction;data mining;intelligent systems;machine learning;predictive analytics","Behavioral science;Intelligent systems;Predictive models;Support vector machines","data analysis;data mining","auction fraud prediction;behavior modeling approach;behavior prediction framework;behavior prediction performance;customer churn prediction;e-commerce conversions prediction;electronic commerce;macro-level behavior","","2","","12","","20150219","May-June 2015","","IEEE","IEEE Journals & Magazines"
"Smart multi-task scheduling for OpenCL programs on CPU/GPU heterogeneous platforms","Y. Wen; Z. Wang; M. F. P. O'Boyle","School of Informatics, The University of Edinburgh","2014 21st International Conference on High Performance Computing (HiPC)","20150604","2014","","","1","10","Heterogeneous systems consisting of multiple CPUs and GPUs are increasingly attractive as platforms for high performance computing. Such platforms are usually programmed using OpenCL which provides program portability by allowing the same program to execute on different types of device. As such systems become more mainstream, they will move from application dedicated devices to platforms that need to support multiple concurrent user applications. Here there is a need to determine when and where to map different applications so as to best utilize the available heterogeneous hardware resources. In this paper, we present an efficient OpenCL task scheduling scheme which schedules multiple kernels from multiple programs on CPU/GPU heterogeneous platforms. It does this by determining at runtime which kernels are likely to best utilize a device. We show that speedup is a good scheduling priority function and develop a novel model that predicts a kernel's speedup based on its static code structure. Our scheduler uses this prediction and runtime input data size to prioritize and schedule tasks. This technique is applied to a large set of concurrent OpenCL kernels. We evaluated our approach for system throughput and average turn-around time against competitive techniques on two different platforms: a Core i7/Nvidia GTX590 and a Core i7/AMD Tahiti 7970 platforms. For system throughput, we achieve, on average, a 1.21x and 1.25x improvement over the best competitors on the NVIDIA and AMD platforms respectively. Our approach reduces the turnaround time, on average, by at least 1.5x and 1.2x on the NVIDIA and AMD platforms respectively, when compared to alternative approaches.","1094-7256;10947256","Electronic:978-1-4799-5976-1; POD:978-1-4799-5977-8","10.1109/HiPC.2014.7116910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116910","GPU;OpenCL;machine learning;task scheduling","Feature extraction;Graphics processing units;Kernel;Runtime;Schedules;Throughput;Training","concurrency (computers);graphics processing units;multiprocessing programs;parallel processing;scheduling","CPU-GPU heterogeneous platforms;Core i7-AMD Tahiti 7970 platform;Core i7-Nvidia GTX590 platform;OpenCL programs;OpenCL task scheduling scheme;concurrent OpenCL kernels;heterogeneous hardware resources;high performance computing;kernel speedup;scheduling priority function;smart multitask scheduling;static code structure","","4","","36","","","17-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"Information-Theoretic Syndrome Evaluation, Statistical Root-Cause Analysis, and Correlation-Based Feature Selection for Guiding Board-Level Fault Diagnosis","F. Ye; Z. Zhang; K. Chakrabarty; X. Gu","Qualcomm Atheros Inc, San Jose, CA, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20150520","2015","34","6","1014","1026","Reasoning-based functional-fault diagnosis has recently been advocated to achieve high diagnosis accuracy, low defect escapes, and reducing manufacturing cost. However, such diagnosis method requires a rich set of test items (syndromes) and a sizable database of faulty boards to learn from. An insufficient number of failed boards, ambiguous root-cause identification, and redundant or irrelevant syndromes can render reasoning-based diagnosis ineffective. Periodic evaluation and analysis can help locate weaknesses in a diagnosis system and thereby provide guidelines for redesigning the tests, which facilitates better diagnosis. We propose an information-theoretic framework for evaluating the effectiveness of and providing guidance to a reasoning-based functional-fault diagnosis system. Syndrome analysis based on feature selection methods provides a representative set of syndromes and suggests irrelevant syndromes in diagnosis. Root-cause analysis measures the discriminative ability of differentiating a given root cause from others. Results are presented for four types of diagnosis systems for three complex boards that are in volume production.","0278-0070;02780070","","10.1109/TCAD.2015.2399438","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031434","Board-level;diagnosis;evaluation;functional failure;information-theory;machine learning","Accuracy;Circuit faults;Databases;Fault diagnosis;Maintenance engineering;Manufacturing;Measurement","cause-effect analysis;fault diagnosis;feature selection;functional analysis;printed circuit testing","ambiguous root-cause identification;discriminative ability;faulty boards;feature selection methods;information-theoretic framework;irrelevant syndromes;periodic evaluation;reasoning-based functional-fault diagnosis;syndrome analysis;test items","","4","","23","","20150204","June 2015","","IEEE","IEEE Journals & Magazines"
"A hybrid feature subset selection by combining filters and genetic algorithm","S. Singh; S. Selvakumar","Department of Computer Science and Engineering, National Institute of Technology, Tiruchirappalli, Tamil Nadu, India","International Conference on Computing, Communication & Automation","20150706","2015","","","283","289","The presence of a large number of irrelevant features degrades the classifier accuracy, reduces the understanding of data, and increases the overall time needed for training and classification. Hence, Feature selection is a critical step in the machine learning process. The role of feature selection is to select a subset of size `d' (d<;n) from the given set of `n' features that leads to the smallest classification error. Feature selection problem can be seen as the optimization problem where the goal is to pick the optimal or near optimal feature subset with respect to an objective function. Based on the literature, it is intuitively felt that the classifier will give its optimum performance if the high dimensional data is reduced to include only relevant attributes with low redundancy. Further, it is seen that the filter method is performance centric and the genetic algorithms are insensitive to noise data. This motivated us to combine the advantages of filter method with the genetic algorithm to make a hybrid system to select the optimal feature subset from the given original feature set. The contribution of this paper includes, simultaneous optimization of feature subset and classifier parameters, a multi-objective function that reduces the classification error with reduction in cardinality of feature subset and its cost. The vital aspect of this model is to generate an initial population through various filter approaches for the initialization stage. Further, to evaluate the effectiveness of the model, experiments were conducted using KNN and decision tree (such as cart) on various UCI machine learning and generated datasets. The experiment results show that the proposed model effectively reduces the number of features without degrading the classification accuracy.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148389","Chi-Square;Decision tree;Dimensionality reduction;Genetic Algorithm;Machine learning;Ratio Gain","Accuracy;Decision trees;Frequency selective surfaces;Genetic algorithms;Optimization;Sociology;Statistics","data reduction;decision trees;feature selection;genetic algorithms;information filtering;learning (artificial intelligence);pattern classification","KNN;UCI machine learning process;classification error reduction;combining filter method;data classification;decision tree;genetic algorithm;high dimensional data reduction;hybrid feature subset selection;multiobjective function;noise data;optimization problem","","0","","18","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"Astrological prediction for profession using classification techniques of artificial intelligence","N. Chaplot; P. Dhyani; O. P. Rishi","Department of Computer Science, Banasthali University, Banasthali, Rajasthan, India","International Conference on Computing, Communication & Automation","20150706","2015","","","233","236","Astrology has started around 4000 years back and has significantly developed over a period of time. Till date no unified rules or standards for astrological prediction exist in the world. Astrologers concentrate on providing quality services to persons rather than defining universal rules and standards for astrological prediction. Advances in artificial intelligence resulted in large number of applications for analysis and prediction. In these applications computer learn from unknown, large, noisy or complex data sets and perform prediction and classification of data. In this paper we are trying to find universal rules and validity of astrology using various scientific methods. In this paper we are going to predict profession of person using ZeroR, Simple Cart and Decision Table classification algorithm. The data set for learning classification consisted of 24 records of Singer, 24 records of Player and 10 records of Scientist. Weka tool[1] available under General public license is use to perform analysis and prediction task.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148378","Artificial Intelligencet;Astrological Predection;Clasification;Machine Learning;Prediction of Profession","Accuracy;Algorithm design and analysis;Artificial intelligence;Automation;Classification algorithms;Data mining;Prediction algorithms","artificial intelligence;pattern classification;prediction theory","Simple Cart;ZeroR;artificial intelligence;astrological prediction;astrology;classification techniques;data set;decision table classification algorithm;general public license;profession;universal rules","","0","","13","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"Data-driven low-complexity nitrate loss model utilizing sensor information — Towards collaborative farm management with wireless sensor networks","H. Zia; N. Harris; G. Merrett; M. Rivers","Electronics and Computer Science, University of Southampton, Southampton, United Kingdom","2015 IEEE Sensors Applications Symposium (SAS)","20150625","2015","","","1","6","Excessive or poorly timed application of irrigation and fertilizers, coupled with the inherent inefficiency of nutrient uptake by crops result in nutrient fluxes into the water system. The ability to predict nutrient-rich discharges, in real time, can be very valuable to enable reuse mechanisms within farm systems. Wireless Sensor Networks (WSNs) offer an opportunity to monitor environmental systems with unprecedented temporal and spatial resolution. As part of our previous work, we proposed a novel framework (WQMCM) to combine increasingly common local farm-scale sensor networks across a catchment to learn and predict (using predictive models) the impact of catchment events on their downstream environments, allowing dynamic decision. Existing models use complex parameters which are difficult to extract and this, coupled with constraints on network nodes (battery life, computing power etc., availability of sensors) makes it necessary to develop simplified models for deployment within the networks. The paper investigates data-driven model for predicting daily total oxidized nitrate (TON) fluxes by seeking simplification in model parameters and using only a yearlong training data set. Data from a catchment in Ireland is used for training the model. Model simplification is investigated by abstracting details from an existing nitrate loss model. By using M5 decision tree model on the training samples of the proposed parameters, results give R2 as 0.92 and RRMSE as 0.26. The proposed novel model gives better results with fewer samples and simple parameters when compared to the traditional model. This shows promise for enabling real time nutrient control and management within the collaborative networked farm system.","","Electronic:978-1-4799-6117-7; POD:978-1-4799-6118-4; USB:978-1-4799-6116-0","10.1109/SAS.2015.7133592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7133592","M5 trees;agriculture;machine learning;nitrate losses;wireless sensor networks","Agriculture;Computational modeling;Data models;Mathematical model;Predictive models;Training;Wireless sensor networks","agriculture;decision trees;learning (artificial intelligence);wireless sensor networks","M5 decision tree model;data-driven low-complexity nitrate loss model;farm management;farm-scale sensor networks;sensor information;total oxidized nitrate fluxes;wireless sensor networks","","1","","40","","","13-15 April 2015","","IEEE","IEEE Conference Publications"
"A Reconstruction-Classification Method for Multifrequency Electrical Impedance Tomography","E. Malone; G. S. dos Santos; D. Holder; S. Arridge","Department of Medical Physics and Biomedical Engineering, University College London, London, UK","IEEE Transactions on Medical Imaging","20150629","2015","34","7","1486","1497","Multifrequency Electrical Impedance Tomography is an imaging technique which distinguishes biological tissues by their unique conductivity spectrum. Recent results suggest that the use of spectral constraints can significantly improve image quality. We present a combined reconstruction-classification method for estimating the spectra of individual tissues, whilst simultaneously reconstructing the conductivity. The advantage of this method is that a priori knowledge of the spectra is not required to be exact in that the constraints are updated at each step of the reconstruction. In this paper, we investigate the robustness of the proposed method to errors in the initial guess of the tissue spectra, and look at the effect of introducing spatial smoothing. We formalize and validate a frequency-difference variant of reconstruction-classification, and compare the use of absolute and frequency-difference data in the case of a phantom experiment.","0278-0062;02780062","","10.1109/TMI.2015.2402661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7039288","Electrical impedance tomography;electrophysical imaging;image reconstruction—iterative;inverse methods;machine learning","Conductivity;Finite element analysis;Frequency measurement;Image reconstruction;Tomography;Voltage measurement","biological tissues;electric impedance imaging;image classification;image reconstruction;medical image processing;phantoms","biological tissues;frequency-difference data;image quality;multifrequency electrical impedance tomography;phantom experiment;reconstruction-classification method;spatial smoothing;tissue spectra;unique conductivity spectrum","","3","","27","","20150211","July 2015","","IEEE","IEEE Journals & Magazines"
"Learning based automated teleoperation system","H. Coşkun; Ş. Yücer; A. Akay; Y. S. Akgül","Vision Lab., Gebze Teknik Univ., Kocaeli, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1240","1243","Teleoperation systems are inefficient due to operator errors and system delays. Moreover, complexity is even higher for teleoperation tasks that involve repetitions. In this paper a technique that consists of automatic learning of operator commands and scene objects is proposed. Exploiting learned action patterns and scene objects, system is able to take the appropriate actions for it's current state. A number of experiments prepared to assess the proposed system. Experimental results show that the system can solve some known problems of teleoperation and increase the throughput of the operators.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130062","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130062","3D Reconstruction;Computer Vision;Kinect;Machine learning;RGB-D cameras;Teleoperation;Unsupervised Learning","Cameras;Computer vision;Delays;Histograms;Robot vision systems;Three-dimensional displays","learning (artificial intelligence);telecommunication computing","automatic learning;learned action patterns;learning based automated teleoperation system;operator errors;system delays;teleoperation tasks","","0","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Pruning Strategies in Adaptive Off-Line Tuning for Optimized Composition of Components on Heterogeneous Systems","L. Li; U. Dastgeer; C. Kessler","IDA, Linkoping Univ., Linkoping, Sweden","2014 43rd International Conference on Parallel Processing Workshops","20150511","2014","","","255","264","Adaptive program optimizations, such as automatic selection of the expected fastest implementation variant for a computation component depending on runtime context, are important especially for heterogeneous computing systems but require good performance models. Empirical performance models based on trial executions which require no or little human efforts show more practical feasibility if the sampling and training cost can be reduced to a reasonable level. In previous work we proposed an early version of adaptive pruning algorithm for efficient selection of training samples, a decision-tree based method for representing, predicting and selecting the fastest implementation variants for given run-time call context properties, and a composition tool for building the overall composed application from its components. For adaptive pruning we use a heuristic convexity assumption. In this paper we consolidate and improve the method by new pruning techniques to better support the convexity assumption and better control the trade-off between sampling time, prediction accuracy and runtime prediction overhead. Our results show that the training time can be reduced by up to 39 times without noticeable prediction accuracy decrease. Furthermore, we evaluate the effect of combinations of pruning strategies and compare our adaptive sampling method with random sampling. We also use our smart-sampling method as a preprocessor to a state-of-the-art decision tree learning algorithm and compare the result to the predictor directly calculated by our method.","0190-3918;01903918","Electronic:978-1-4799-5615-9; POD:978-1-4799-5616-6","10.1109/ICPPW.2014.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103460","Adaptive sampling;Autotuning;GPU;Heterogeneous computing;Implementation selection;Machine learning;Performance optimization","Accuracy;Adaptation models;Benchmark testing;Context;Predictive models;Training;Tuning","decision trees;parallel processing;random processes;sampling methods","adaptive off-line tuning;adaptive program optimization;decision-tree;heterogeneous computing system;pruning strategy;random sampling;sampling time;smart-sampling method","","0","","18","","","9-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"API call and permission based mobile malware detection (in english)","A. İ. AYşan; S. Şen","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Hacettepe &#x00DC;niversitesi, Ankara, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","2400","2403","Sales of smartphones have substantially increased in recent years. This demand has turned attackers' attention to mostly Android based smartphones. Attackers develop malwares especially for Android which is open source operating system and they share source code with each other in order to develop malwares. Most of the researchers proposed solutions to detect malwares. However, most of the solutions are appeared that they are needed high computationally power and have low accuracy rate. In this study, we developed API call and permission based static analysis methodology for Android applications.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130365","API call;Android;machine learning;mobile malware;permission;static analysis","Androids;Google;Humanoid robots;Malware;Mobile communication;Smart phones","application program interfaces;invasive software;mobile computing;operating systems (computers);public domain software;smart phones","API call;Android based smartphones;open source operating system;permission based mobile malware detection;permission based static analysis methodology;source code sharing","","0","","20","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Cluster-Based Boosting","L. D. Miller; L. K. Soh","Computer Science and Engineering Department, University of Nebraska, Lincoln, NE","IEEE Transactions on Knowledge and Data Engineering","20150428","2015","27","6","1491","1504","Boosting is an iterative process that improves the predictive accuracy for supervised (machine) learning algorithms. Boosting operates by learning multiple functions with subsequent functions focusing on incorrect instances where the previous functions predicted the wrong label. Despite considerable success, boosting still has difficulty on data sets with certain types of problematic training data (e.g., label noise) and when complex functions overfit the training data. We propose a novel cluster-based boosting (CBB) approach to address limitations in boosting for supervised learning systems. Our CBB approach partitions the training data into clusters containing highly similar member data and integrates these clusters directly into the boosting process. CBB boosts selectively (using a high learning rate, low learning rate, or not boosting) on each cluster based on both the additional structure provided by the cluster and previous function accuracy on the member data. Selective boosting allows CBB to improve predictive accuracy on problematic training data. In addition, boosting separately on clusters reduces function complexity to mitigate overfitting. We provide comprehensive experimental results on 20 UCI benchmark data sets with three different kinds of supervised learning systems. These results demonstrate the effectiveness of our CBB approach compared to a popular boosting algorithm, an algorithm that uses clusters to improve boosting, and two algorithms that use selective boosting without clustering.","1041-4347;10414347","","10.1109/TKDE.2014.2382598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6990607","Artificial Intelligence;Artificial intelligence;Clustering Algorithms;Machine Learning;clustering algorithms;machine learning","Accuracy;Assembly;Boosting;Clustering algorithms;Filtering;Noise;Training data","iterative methods;learning (artificial intelligence);pattern clustering","CBB approach;UCI benchmark data sets;cluster-based boosting;function complexity;iterative process;predictive accuracy;supervised machine learning algorithms","","1","","37","","20141218","June 1 2015","","IEEE","IEEE Journals & Magazines"
"Signal Processing Approaches to Minimize or Suppress Calibration Time in Oscillatory Activity-Based Brain–Computer Interfaces","F. Lotte","Bordeaux Sud-Ouest, Talence, France","Proceedings of the IEEE","20150601","2015","103","6","871","890","One of the major limitations of brain-computer interfaces (BCI) is their long calibration time, which limits their use in practice, both by patients and healthy users alike. Such long calibration times are due to the large between-user variability and thus to the need to collect numerous training electroencephalography (EEG) trials for the machine learning algorithms used in BCI design. In this paper, we first survey existing approaches to reduce or suppress calibration time, these approaches being notably based on regularization, user-to-user transfer, semi-supervised learning and a priori physiological information. We then propose new tools to reduce BCI calibration time. In particular, we propose to generate artificial EEG trials from the few EEG trials initially available, in order to augment the training set size. These artificial EEG trials are obtained by relevant combinations and distortions of the original trials available. We propose three different methods to do so. We also propose a new, fast and simple approach to perform user-to-user transfer for BCI. Finally, we study and compare offline different approaches, both old and new ones, on the data of 50 users from three different BCI data sets. This enables us to identify guidelines about how to reduce or suppress calibration time for BCI.","0018-9219;00189219","","10.1109/JPROC.2015.2404941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7109822","Brain–computer interfaces (BCI);Brain???computer interfaces (BCI);calibration;electroencephalography (EEG);machine learning;signal processing;small sample settings","Band-pass filters;Brain-computer interfaces;Covariance matrices;Electroencephalography;Machine learning;Signal processing algorithms;Spatial filters;Training data","brain-computer interfaces;calibration;electroencephalography;learning (artificial intelligence);medical signal processing","BCI calibration time reduction;EEG;electroencephalography;machine learning algorithms;oscillatory activity-based brain-computer interfaces;priori physiological information;semisupervised learning;signal processing approaches;user-to-user transfer","","10","","84","","20150518","June 2015","","IEEE","IEEE Journals & Magazines"
"Reliable Physical Unclonable Functions Using Data Retention Voltage of SRAM Cells","X. Xu; A. Rahmati; D. E. Holcomb; K. Fu; W. Burleson","Department of Electrical and Computer Engineering, University of Massachusetts Amherst, Amherst, MA, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20150520","2015","34","6","903","914","Physical unclonable functions (PUFs) are circuits that produce outputs determined by random physical variations from fabrication. The PUF studied in this paper utilizes the variation sensitivity of static random access memory (SRAM) data retention voltage (DRV), the minimum voltage at which each cell can retain state. Prior work shows that DRV can uniquely identify circuit instances with 28% greater success than SRAM power-up states that are used in PUFs [1]. However, DRV is highly sensitive to temperature, and until now this makes it unreliable and unsuitable for use in a PUF. In this paper, we enable DRV PUFs by proposing a DRV-based hash function that is insensitive to temperature. The new hash function, denoted DRV-based hashing (DH), is reliable across temperatures because it utilizes the temperature-insensitive ordering of DRVs across cells, instead of using the DRVs in absolute terms. To evaluate the security and performance of the DRV PUF, we use DRV measurements from commercially available SRAM chips, and use data from a novel DRV prediction algorithm. The prediction algorithm uses machine learning for fast and accurate simulation-free estimation of any cell's DRV, and the prediction error in comparison to circuit simulation has a standard deviation of 0.35 mV. We demonstrate the DRV PUF using two applications-secret key generation and identification. In secret key generation, we introduce a new circuit-level reliability knob as an alternative to error correcting codes. In the identification application, our approach is compared to prior work and shown to result in a smaller false-positive identification rate for any desired true-positive identification rate.","0278-0070;02780070","","10.1109/TCAD.2015.2418288","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078918","Chip Identification;Chip identification;Data Retention Voltage;Key Generation;Machine Learning;Physical Unclonable Function;data retention voltage (DRV);key generation;machine learning (ML);physical unclonable function (PUF)","Integrated circuit modeling;Reliability;SRAM cells;Temperature measurement;Temperature sensors;Transistors","SRAM chips;cryptography;integrated circuit reliability;learning (artificial intelligence)","SRAM cells;circuit-level reliability;data retention voltage;error correcting codes;hash function;machine learning;reliable physical unclonable functions;secret key generation;static random access memory","","4","","50","","20150402","June 2015","","IEEE","IEEE Journals & Magazines"
"Analysis of social media messages for disasters via semi supervised learning","S. Nar; Y. S. Akgul","Bilgisayar Muhendisligi Bolumu, Gebze Teknik Univ., Kocaeli, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1126","1129","Automated analysis of social media messages about social disturbances and natural disasters is important for managing relief and rescue work. This paper proposes a new method that uses semi supervised training approach to analyze social media messages about disasters. Compared to fully supervised methods, the approach needs a smaller number of messages to be hand labeled. The social media messages are analyzed with term frequency vectors that are later fed to SVM and logistic regression based machine learning methods. The training dataset is grouped into online and offline messages that makes the semi supervised learning even more effective. The experiments performed on the Twitter messages provided promising validation data towards the employment of the system in practical applications. The current work is applied only to earthquake messages but it can be extended for other types of disasters and social disturbances.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130033","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130033","disaster analysis;earthquake;machine learning;semi supervised learning;social media analysis","Barium;Java","emergency management;information analysis;learning (artificial intelligence);social networking (online);support vector machines","SVM;Twitter message;automated analysis;data validation;disaster message analysis;earthquake messages;logistic regression;machine learning method;semisupervised learning;social disturbance;social media message analysis;support vector machine","","0","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Unsupervised dynamic fuzzy cognitive map","Boyuan Liu; Wenhui Fan; Tianyuan Xiao","Department of Automation, Tsinghua University, Beijing 100084, China","Tsinghua Science and Technology","20150619","2015","20","3","285","292","Fuzzy Cognitive Map (FCM) is an inference network, which uses cyclic digraphs for knowledge representation and reasoning. Along with the extensive applications of FCMs, there are some limitations that emerge due to the deficiencies associated with FCM itself. In order to eliminate these deficiencies, we propose an unsupervised dynamic fuzzy cognitive map using behaviors and nonlinear relationships. In this model, we introduce dynamic weights and trend-effects to make the model more reasonable. Data credibility is also considered while establishing a machine learning model. Subsequently, we develop an optimized Estimation of Distribution Algorithm (EDA) for weight learning. Experimental results show the practicability of the dynamic FCM model. In comparison to the other existing algorithms, the proposed algorithm has better performance in terms of convergence and stability.","","","10.1109/TST.2015.7128941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128941","Estimation of Distribution Algorithm (EDA);Fuzzy Cognitive Map (FCM);machine learning;nonlinear relation","Estimation;Heuristic algorithms;Machine learning algorithms;Optimization;Roads;Sociology;Statistics","cognition;data analysis;inference mechanisms;knowledge representation;unsupervised learning","EDA;FCM model;convergence;cyclic digraph;data credibility;estimation-of-distribution algorithm;inference network;knowledge reasoning;knowledge representation;machine learning model;unsupervised dynamic FCM;unsupervised dynamic fuzzy cognitive map;weight learning","","0","","","","","June 2015","","TUP","TUP Journals & Magazines"
"A Semiautomated Probabilistic Framework for Tree-Cover Delineation From 1-m NAIP Imagery Using a High-Performance Computing Architecture","S. Basu; S. Ganguly; R. R. Nemani; S. Mukhopadhyay; G. Zhang; C. Milesi; A. Michaelis; P. Votava; R. Dubayah; L. Duncanson; B. Cook; Y. Yu; S. Saatchi; R. DiBiano; M. Karki; E. Boyda; U. Kumar; S. Li","Dept. of Comput. Sci., Louisiana State Univ., Baton Rouge, LA, USA","IEEE Transactions on Geoscience and Remote Sensing","20150610","2015","53","10","5690","5708","Accurate tree-cover estimates are useful in deriving above-ground biomass density estimates from very high resolution (VHR) satellite imagery data. Numerous algorithms have been designed to perform tree-cover delineation in high-to-coarse-resolution satellite imagery, but most of them do not scale to terabytes of data, typical in these VHR data sets. In this paper, we present an automated probabilistic framework for the segmentation and classification of 1-m VHR data as obtained from the National Agriculture Imagery Program (NAIP) for deriving tree-cover estimates for the whole of Continental United States, using a high-performance computing architecture. The results from the classification and segmentation algorithms are then consolidated into a structured prediction framework using a discriminative undirected probabilistic graphical model based on conditional random field, which helps in capturing the higher order contextual dependence relations between neighboring pixels. Once the final probability maps are generated, the framework is updated and retrained by incorporating expert knowledge through the relabeling of misclassified image patches. This leads to a significant improvement in the true positive rates and reduction in false positive rates (FPRs). The tree-cover maps were generated for the state of California, which covers a total of 11 095 NAIP tiles and spans a total geographical area of 163 696 sq. miles. Our framework produced correct detection rates of around 88% for fragmented forests and 74% for urban tree-cover areas, with FPRs lower than 2% for both regions. Comparative studies with the National Land-Cover Data algorithm and the LiDAR high-resolution canopy height model showed the effectiveness of our algorithm for generating accurate high-resolution tree-cover maps.","0196-2892;01962892","","10.1109/TGRS.2015.2428197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7112625","Aerial imagery;National Agriculture Imagery Program (NAIP);conditional random field (CRF);high-performance computing (HPC);machine learning;neural network (NN);statistical region merging (SRM)","Accuracy;Feature extraction;Image resolution;Image segmentation;Laser radar;NASA;Vegetation","forestry;geophysical image processing;image classification;image segmentation;land cover;probability;remote sensing;vegetation","1-m NAIP imagery;1-m VHR data classification;1-m VHR data segmentation;California;LiDAR high-resolution canopy height model;VHR dataset;aboveground biomass density;conditional random field;continental United States;discriminative undirected probabilistic graphical model;expert knowledge;fragmented forest;high-performance computing architecture;high-resolution tree-cover map;misclassified image patch;national agriculture imagery program;national land-cover data algorithm;neighboring pixel;probability map;semiautomated probabilistic framework;terabyte;tree-cover delineation;tree-cover estimation;urban tree-cover area;very high resolution satellite imagery data","","1","","52","","20150526","Oct. 2015","","IEEE","IEEE Journals & Magazines"
"System-level test coverage prediction by structural stress test data mining","B. Y. Lin; C. W. Wu; H. H. Chen","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan","VLSI Design, Automation and Test(VLSI-DAT)","20150601","2015","","","1","4","To achieve high quality of silicon ICs, system-level test (SLT) can be performed after regular final test. This is important for chips manufactured in advanced technologies, as systematic failures are getting harder to detect by conventional structural tests. However, due to long test time and extra human efforts, the cost for SLT is high. A possible way to replace SLT without quality loss is to identify SLT failure suspects with stress tests. In this work, we apply 60,000 structural stress test patterns to the CPU blocks of a real SOC product, using 20 stressed voltage-frequency corners. We try to identify the correlation between the stress test data and SLT-pass/fail results of the CPU blocks. By the proposed differential feature-based methodology, 32 outliers are identified, which are assumed to be CPU-fail chips. Because of the lack of exact CPU-fail chip IDs for verification, the identified chip IDs are compared with the IDs identified from previous works, which use the same data but different machine-learning features and method for the same purpose. After comparison, 30 out of a total of 33 CPU-fail suspects matched. Although this does not immediately imply that the SLT can be replaced by the structural stress tests, it shows more evidence that test data mining can be further explored for test time reduction and/or quality improvement.","","Electronic:978-1-4799-6275-4; POD:978-1-4799-6276-1","10.1109/VLSI-DAT.2015.7114508","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7114508","data mining;higher-than-at-speed test;low-voltage test;machine learning;structural test;system-level test","Correlation;Data mining;Feature extraction;Integrated circuits;Principal component analysis;Silicon;Stress","data mining;electronic engineering computing;failure analysis;integrated circuit manufacture;integrated circuit testing;learning (artificial intelligence);losses;silicon;stress analysis","CPU blocks;CPU-fail chip ID;IC quality loss;SLT-pass-fail results;SOC product;Si;differential feature-based methodology;extra human efforts;machine learning features;regular final test;structural stress test data mining;system-level test coverage prediction;systematic failures;test time reduction;voltage-frequency corners","","0","","19","","","27-29 April 2015","","IEEE","IEEE Conference Publications"
"Detection of oil pollution in seawater: Biosecurity prevention using electronic nose technology","R. Chandler; A. Das; T. Gibson; R. Dutta","AutoNose Manufacturing Limited, Leeds, United Kingdom","2015 31st IEEE International Conference on Data Engineering Workshops","20150622","2015","","","98","100","In this paper-conducting polymer gas sensor based AutoNose electronic nose (E-Nose) technology has been used for detection of oil contamination in seawater samples. AutoNose E-nose is a headspace analyzer based on six conducting polymer sensors. Seawater samples with known (or induced) oil contamination were tested and classified against the unpolluted seawater samples using machine learning based ensemble classifiers with very high accuracy. We show that a simple headspace sensing E-Nose could be used to rapidly detect oil pollution in seawater for early biosecurity prevention.","","Electronic:978-1-4799-8442-8; POD:978-1-4799-8443-5","10.1109/ICDEW.2015.7129554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129554","biosecurity;conducting polymer gas sensor;electronic nose;ensemble classifier;machine learning","Chemical sensors;Chemicals;Electronic noses;Neural networks;Nose;Polymers;Sensors","conducting polymers;electronic noses;learning (artificial intelligence);marine safety;oil pollution;pattern classification;seawater","AutoNose e-nose;AutoNose electronic nose;biosecurity prevention;conducting polymer gas sensor;electronic nose technology;headspace analyzer;machine learning based ensemble classifiers;oil contamination detection;oil pollution detection;unpolluted seawater","","0","","26","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"The tour construction framework for the dynamic Travelling Salesman Problem","B. Ahrens","Graduate School of Computer and Information Sciences, Nova Southeastern University, Fort Lauderdale-Davie, Florida, USA","SoutheastCon 2015","20150625","2015","","","1","8","The dynamic Travelling Salesman Problem (TSP) is a variation of the TSP with important real world applications. In the static TSP, the dataset must be complete and never change throughout the processing of the solution. The static TSP provides a rich theoretical framework in which to study the full optimization of the shortest route for a given set of points. The points in a static dataset are fixed forever, and there is no concept of time in the traversal of the dataset. On the other hand, the dynamic TSP considers the actual traversal of the dataset with respect to time. The dynamic TSP is more suited to a wide range of real-world problems, in which the dataset is incomplete and changeable. Most of the existing high-performing TSP solvers are constrained to static TSP datasets only, and these solvers are not readily transformed to handle dynamic TSP datasets. A recently introduced TSP solver is the Tour Construction Framework (TCF), which integrates both global and local heuristics in a complementary framework in order to efficiently solve the Travelling Salesman Problem (TSP). A potential advantage of the TCF is the ability to robustly solve dynamic TSP problems. In this research, standard TSP datasets are used to formulate dynamic TSP datasets and the TCF and mainstream TSP solvers are applied to solve these large dynamic TSP datasets. The performance of the TCF is evaluated for speed and accuracy.","1091-0050;10910050","Electronic:978-1-4673-7300-5; POD:978-1-4673-7301-2","10.1109/SECON.2015.7132999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7132999","combinatorial optimization;dynamic solutions;machine learning;scheduling;travelling salesman problem","Cities and towns;Dynamics;Heuristic algorithms;Memory management;Optimization;Standards;Tin","travelling salesman problems","dynamic TSP datasets;dynamic TSP problems;dynamic travelling salesman problem;high-performing TSP solvers;static TSP;tour construction framework","","0","","23","","","9-12 April 2015","","IEEE","IEEE Conference Publications"
"Identification of high performing equities using financial characteristic attributes","Y. Jing; F. Li; A. Lightner; Y. Wang","University of Virginia","2015 Systems and Information Engineering Design Symposium","20150608","2015","","","278","282","Long-term investors are interested in identifying the characteristics of companies that are likely to triple in value over the next five years, which equates to return of approximately 25 percent per year over the period. Such companies are known as compounders due to their high compounded rate of return. This paper reports on an analysis of corporate and market data undertaken with the goal of identifying specific characteristics that tend to separate compounders from other equities. We consider a wide ranging set of characteristics designed to bear on corporate financial performance. Characteristics are constructed using historical stock prices and financial reports from the years December 1992 to June 2014. The analysis includes both high and standard market return equities. Classification techniques such as Naïve Bayes, logistic regression, and random forests are then applied to the characteristics to try and identify high return equities. The research has the goal of identifying the characteristics of high return equities so that in the future these characteristics can be used to filter investment candidates using classification techniques and models.","","Electronic:978-1-4799-1832-4; POD:978-1-4799-1833-1","10.1109/SIEDS.2015.7116989","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116989","Finance;Machine learning;Modeling;Stock market","Companies;Investment;Logistics;Measurement;Portfolios;Predictive models;Stock markets","Bayes methods;financial data processing;investment;marketing data processing;organisational aspects;pattern classification;pricing;random processes;regression analysis;stock markets","classification technique;corporate data;corporate financial performance;financial characteristic attribute;financial report;high performing equity;high return equity;historical stock price;investment candidate;logistic regression;long-term investor;market data;market return equity;naive Bayes;random forest;rate of return","","0","","12","","","24-24 April 2015","","IEEE","IEEE Conference Publications"
"Recognition of Nutrition Intake Using Time-Frequency Decomposition in a Wearable Necklace Using a Piezoelectric Sensor","N. Alshurafa; H. Kalantarian; M. Pourhomayoun; J. J. Liu; S. Sarin; B. Shahbazi; M. Sarrafzadeh","Department of Computer ScienceWireless Health Institute, University of California at Los Angeles, Los Angeles, CA, USA","IEEE Sensors Journal","20150518","2015","15","7","3909","3916","Food intake levels, hydration, ingestion rate, and dietary choices are all factors known to impact the risk of obesity. This paper presents a novel wearable system in the form of a necklace, which aggregates data from an embedded piezoelectric sensor capable of detecting skin motion in the lower trachea during ingestion. The skin motion produces an output voltage with varying frequencies over time. As a result, we propose an algorithm based on time-frequency decomposition, spectrogram analysis of piezoelectric sensor signals, to accurately distinguish between food types, such as liquid and solid, hot and cold drinks, and hard and soft foods. The necklace transmits data to a smartphone, which performs the processing of the signals, classifies the food type, and provides visual feedback to the user to assist the user in monitoring their eating habits over time. We compare our spectrogram analysis with other time-frequency features, such as matching pursuit and wavelets. Experimental results demonstrate promise in using time-frequency features, with high accuracy of distinguishing between food categories using spectrogram analysis and extracting key features representative of the unique swallow patterns of various foods.","1530-437X;1530437X","","10.1109/JSEN.2015.2402652","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7039196","Classification;Machine Learning;Nutrition Monitoring;Nutrition monitoring;Piezoelectric Sensor;Spectrogram Analysis;Wearable Necklace;classification;machine learning;piezoelectric sensor;spectrogram analysis;wearable necklace","Batteries;Feature extraction;Monitoring;Sensors;Skin;Spectrogram;Time-frequency analysis","body sensor networks;feature extraction;feedback;medical signal processing;piezoelectric transducers;skin;smart phones;time-frequency analysis","feature extraction;food intake level;nutrition intake recognition;obesity;piezoelectric sensor signal;signal processing;skin motion detection;smartphone;spectrogram analysis;time-frequency decomposition;trachea;visual feedback;wearable necklace","","7","","37","","20150211","July 2015","","IEEE","IEEE Journals & Magazines"
"Hierarchical Fuzzy Inductive Reasoning Classifier","S. Bagherpour; À. Nebot; F. Mugica","Soft Computing Research Group, Technical University of Catalonia, Jordi Girona Salgado 1-3, Barcelona, Spain","2014 4th International Conference On Simulation And Modeling Methodologies, Technologies And Applications (SIMULTECH)","20150427","2014","","","434","442","Many of the inductive reasoning algorithms and techniques, including Fuzzy Inductive Reasoning (FIR), that learn from labelled data don't provide the possibility of involving domain expert knowledge to induce rules. In those cases that learning fails, this capability can guide the learning mechanism towards a hypothesis that seems more promising to a domain expert. One of the main reasons for omitting such involvement is the difficulty of knowledge acquisition from experts and, also, the difficulty of combining it with induced hypothesis. One of the successful solutions to such a problem is an alternative approach in machine learning called Argument Based Machine Learning (ABML) which involves experts in providing specific explanations in the form of arguments to only specific cases that fail, rather than general knowledge on all cases. Inspired by this study, the idea of Hierarchical Fuzzy Inductive Reasoning (HFIR) is proposed in this paper as the first step towards design and development of an Argument Based Fuzzy Inductive Reasoning method capable of providing domain expert involvement in its induction process. Moreover, HFIR is able to obtain better classifications results than classical FIR methodology. In this work, the concept of Hierarchical Fuzzy Inductive Reasoning is introduced and explored by means of the Zoo UCI benchmark.","","Electronic:978-989-758-060-4; POD:978-1-4799-7921-9","10.5220/0005041604340442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095056","Argument based Machine Learning (ABML);Fuzzy Inductive Reasoning (FIR);Hierarchical FIR;Zoo Benchmark","Benchmark testing;Classification algorithms;Cognition;Complexity theory;Finite impulse response filters;Predictive models;Uncertainty","","","","0","","13","","","28-30 Aug. 2014","","IEEE","IEEE Conference Publications"
"Predictive models for severe sepsis in adult ICU patients","J. Guillén; J. Liu; M. Furr; T. Wang; S. Strong; C. C. Moore; A. Flower; L. E. Barnes","University of Virginia","2015 Systems and Information Engineering Design Symposium","20150608","2015","","","182","187","Intensive Care Unit (ICU) patients have significant morbidity and mortality, often from complications that arise during the hospital stay. Severe sepsis is one of the leading causes of death among these patients. Predictive models have the potential to allow for earlier detection of severe sepsis and ultimately earlier intervention. However, current methods for identifying and predicting severe sepsis are biased and inadequate. The goal of this work is to identify a new framework for the prediction of severe sepsis and identify early predictors utilizing clinical laboratory values and vital signs collected in adult ICU patients. We explore models with logistic regression (LR), support vector machines (SVM), and logistic model trees (LMT) utilizing vital signs, laboratory values, or a combination of vital and laboratory values. When applied to a retrospective cohort of ICU patients, the SVM model using laboratory and vital signs as predictors identified 339 (65%) of the 3,446 patients as developing severe sepsis correctly. Based on this new framework and developed models, we provide a recommendation for the use in clinical decision support in ICU and non-ICU environments.","","Electronic:978-1-4799-1832-4; POD:978-1-4799-1833-1","10.1109/SIEDS.2015.7116970","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116970","ICU;Machine Learning;Prediction;Predictive Monitoring;Risk;Severe Sepsis","Blood;Data models;Logistics;Measurement;Predictive models;Regression tree analysis;Support vector machines","decision support systems;diseases;patient diagnosis;regression analysis;support vector machines;trees (mathematics)","Adult ICU patient;LMT;LR;SVM;clinical decision support;intensive care unit patient;logistic model tree;logistic regression;predictive model;sepsis detection;support vector machine","","1","","28","","","24-24 April 2015","","IEEE","IEEE Conference Publications"
"Perception and Automatic Recognition of Laughter from Whole-Body Motion: Continuous and Categorical Perspectives","H. J. Griffin; M. S. H. Aung; B. Romera-Paredes; C. McLoughlin; G. McKeown; W. Curran; N. Bianchi-Berthouze","UCL Interaction Centre, University College London, London, United Kingdom","IEEE Transactions on Affective Computing","20150601","2015","6","2","165","178","Despite its importance in social interactions, laughter remains little studied in affective computing. Intelligent virtual agents are often blind to users’ laughter and unable to produce convincing laughter themselves. Respiratory, auditory, and facial laughter signals have been investigated but laughter-related body movements have received less attention. The aim of this study is threefold. First, to probe human laughter perception by analyzing patterns of categorisations of natural laughter animated on a minimal avatar. Results reveal that a low dimensional space can describe perception of laughter “types”. Second, to investigate observers’ perception of laughter (hilarious, social, awkward, fake, and non-laughter) based on animated avatars generated from natural and acted motion-capture data. Significant differences in torso and limb movements are found between animations perceived as laughter and those perceived as non-laughter. Hilarious laughter also differs from social laughter. Different body movement features were indicative of laughter in sitting and standing avatar postures. Third, to investigate automatic recognition of laughter to the same level of certainty as observers’ perceptions. Results show recognition rates of the Random Forest model approach human rating levels. Classification comparisons and feature importance analyses indicate an improvement in recognition of social laughter when localized features and nonlinear models are used.","1949-3045;19493045","","10.1109/TAFFC.2015.2390627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006762","H.5.mMiscellaneous;I.2.6.g Machine learning;I.5.4.d Face and gesture recognition;J.4.b Psychology;Miscellaneous;face and gesture recognition;machine learning;psychology","Acoustics;Animation;Avatars;Face;Face recognition;Observers;Videos","","","","8","","59","","20150112","April-June 1 2015","","IEEE","IEEE Journals & Magazines"
"Generic trajectory model for Network Centric Warfare enhanced using data mining","N. B. Mordani; N. Tamhane; R. R. Tipare; V. Zagade","Computer Engineering Department, Pune Institute of Computer Technology, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","487","490","The field of Network Centric Warfare seeks to use information technology in order to gain competitive advantage over the enemies during war. An essential part of network centric warfare deals with the firing of highly destructive weapons. It includes the determination of exact direction of firing the weapon so as to successfully destroy the target for a given unguided shell. This can be done using different trajectory models. The major challenge is that this decision be quick in the time critical scenario of war and this urges the use of previous experience using data mining.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154756","data mining;machine learning;prediction;regression analysis;simulation","Computational modeling;Computers;Data mining;Mathematical model;Projectiles;Trajectory","data mining;information technology;military computing;weapons","data mining;firing direction;generic trajectory model;highly destructive weapons;information technology;network centric warfare","","0","","8","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"A Similarity-Based Learning Algorithm Using Distance Transformation","Y. J. Hu; M. C. Yu; H. A. Wang; Z. Y. Ting","College of Computer Science, National Chiao Tung University, Hsinchu, Taiwan","IEEE Transactions on Knowledge and Data Engineering","20150428","2015","27","6","1452","1464","Numerous theories and algorithms have been developed to solve vectorial data learning problems by searching for the hypothesis that best fits the observed training sample. However, many real-world applications involve samples that are not described as feature vectors, but as (dis)similarity data. Converting vectorial data into (dis)similarity data is more easily performed than converting (dis)similarity data into vectorial data. This study proposes a stochastic iterative distance transformation model for similarity-based learning. The proposed model can be used to identify a clear class boundary in data by modifying the (dis)similarities between examples. The experimental results indicate that the performance of the proposed method is comparable with those of various vector-based and proximity-based learning algorithms.","1041-4347;10414347","","10.1109/TKDE.2015.2391109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006788","Classifier design and evaluation;Data mining;Knowledge modeling;Machine learning;classifier design and evaluation;data mining;knowledge modeling","Classification algorithms;Data models;Educational institutions;Kernel;Search problems;Training;Training data","iterative methods;learning (artificial intelligence);pattern classification","dissimilarity data;distance transformation;feature vectors;proximity-based learning algorithms;similarity-based learning algorithm;stochastic iterative distance transformation model;vectorial data learning problems","","0","","49","","20150112","June 1 2015","","IEEE","IEEE Journals & Magazines"
"An assistant for an incremental learning based image processing system","Y. Wang; M. Weyrich","Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, Germany","2015 IEEE International Conference on Industrial Technology (ICIT)","20150618","2015","","","1624","1629","Supervised learning has been applied in image processing system for object recognition, inspection and measurement. However the teaching-learning mode of supervised learning is not practical in real application, because it is impossible to teach a system all possible samples in one time. Therefore, incremental learning is considered to be a promising solution which supports the iteration of teaching-learning in cycles. An incremental learning based system can always be taught and can learn new samples of objects. However, from engineering perspective, incremental learning is not so practical for user in a teaching-learning cycle. For this reason, an assistant is proposed to support teaching-learning cycles. The assistant includes the following four functions: “result monitoring”, “auxiliary teaching”, “incremental learning” and “classifier evaluation”. With the help of an assistant, system user is able to control the whole teaching-learning cycle, and interact with the image processing system easily. The concept of an assistant is tested by experiments of classifying agricultural products. It is proved that the assistant is a practical manner in image processing system.","","Electronic:978-1-4799-7800-7; POD:978-1-4799-7801-4; USB:978-1-4799-7799-4","10.1109/ICIT.2015.7125329","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7125329","assistant;image processing;incremental learning;machine learning;supervised learning","Databases;Education;IP networks;Image processing;Learning (artificial intelligence);Monitoring;Supervised learning","agricultural products;image classification;learning (artificial intelligence);monitoring;teaching","agricultural product classification;auxiliary teaching;classifier evaluation;image processing system;incremental learning based system;result monitoring;teaching-learning cycle iteration","","0","","21","","","17-19 March 2015","","IEEE","IEEE Conference Publications"
"An Approach to Detect Remote Access Trojan in the Early Stage of Communication","D. Jiang; K. Omote","Sch. of Inf. Sci., Japan Adv. Inst. of Sci. & Technol., Ishikawa, Japan","2015 IEEE 29th International Conference on Advanced Information Networking and Applications","20150430","2015","","","706","713","As data leakage accidents occur every year, the security of confidential information is becoming increasingly important. Remote Access Trojans (RAT), a kind of spyware, are used to invade the PC of a victim through targeted attacks. After the intrusion, the attacker can monitor and control the victim's PC remotely, to wait for an opportunity to steal the confidential information. Since it is hard to prevent the intrusion of RATs completely, preventing confidential information being leaked back to the attacker is the main issue. Various existing approaches introduce different network behaviors of RAT to construct detection systems. Unfortunately, two challenges remain: one is to detect RAT sessions as early as possible, the other is to remain a high accuracy to detect RAT sessions, while there exist normal applications whose traffic behave similarly to RATs. In this paper, we propose a novel approach to detect RAT sessions in the early stage of communication. To differentiate network behaviors between normal applications and RAT, we extract the features from the traffic of a short period of time at the beginning. Afterward, we use machine learning techniques to train the detection model, then evaluate it by K-Fold cross-validation. The results show that our approach is able to detect RAT sessions with a high accuracy. In particular, our approach achieves over 96% accuracy together with the FNR of 10% by Random Forest algorithm, which means that our approach is valid to detect RAT sessions in the early stage of communication.","1550-445X;1550445X","Electronic:978-1-4799-7905-9; POD:978-1-4799-7906-6","10.1109/AINA.2015.257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7098042","Remote Access Trojan detection;machine learning;network behavior;targeted attack","Accuracy;Feature extraction;Machine learning algorithms;Rats;Support vector machines;Training;Trojan horses","","","","1","","14","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Beyond the lock icon: real-time detection of phishing websites using public key certificates","Z. Dong; A. Kapadia; J. Blythe; L. J. Camp","Indiana University, Bloomington, IN 47405","2015 APWG Symposium on Electronic Crime Research (eCrime)","20150611","2015","","","1","12","We propose a machine-learning approach to detect phishing websites using features from their X.509 public key certificates. We show that its efficacy extends beyond HTTPS-enabled sites. Our solution enables immediate local identification of phishing sites. As such, this serves as an important complement to the existing server-based anti-phishing mechanisms which predominately use blacklists. Blacklisting suffers from several inherent drawbacks in terms of correctness, timeliness, and completeness. Due to the potentially significant lag prior to site blacklisting, there is a window of opportunity for attackers. Other local client-side phishing detection approaches also exist, but primarily rely on page content or URLs, which are arguably easier to manipulate by attackers. We illustrate that our certificate-based approach greatly increases the difficulty of masquerading undetected for phishers, with single millisecond delays for users. We further show that this approach works not only against HTTPS-enabled phishing attacks, but also detects HTTP phishing attacks with port 443 enabled.","2159-1237;21591237","Electronic:978-1-4799-8909-6; POD:978-1-4799-8910-2","10.1109/ECRIME.2015.7120795","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120795","certificates;machine learning;security","Browsers;Electronic mail;Feature extraction;Public key;Servers;Uniform resource locators","Web sites;computer crime;learning (artificial intelligence);public key cryptography","HTTPS-enabled phishing attack;Web site phishing detection;machine-learning approach from;public key certificate;server-based antiphishing mechanism;site blacklisting","","0","","38","","","26-29 May 2015","","IEEE","IEEE Conference Publications"
"Segment Delay Learning From Quantized Path Delay Measurements","J. Chung; J. Kim","Department of Electronic Engineering, Incheon National University, Incheon, Korea","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20150520","2015","34","6","1038","1042","Our understanding on a silicon chip is limited due to low measurement resolution or model-silicon miscorrelation including variations. This paper shows that chips are better understood by combining noisy measurement results and model information through a mathematical algorithm. Our proposed method learns segment delays in logic circuits from quantized path delay measurements using ridge regression. During the learning process, we take advantage of both nominal segment delays and the delay sensitivity with respect to variations. We also interpret the ridge regression in Bayesian context and in doing so, propose an analytic formula to set the regularization parameter of the ridge regression. For the silicon measurement environments where low measurement resolution is the dominant source of measurement noise, this formula allows us to predict post-silicon results more accurately and speed up the algorithm eliminating inefficient and inaccurate cross-validation. We also demonstrate our method in enhancing the resolution of already measured path delays. We learn segment delays from quantized path delay measurements and predict the path delays prior to the quantization. Our simulation results show that the predicted path delays are much closer to actual values than the measured values and the nominal values.","0278-0070;02780070","","10.1109/TCAD.2015.2419631","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079489",", Defect Diagnosis;Defect diagnosis;Machine Learning;Post-Silicon Debug;Post-Silicon Validation;machine learning;post-silicon debug;post-silicon validation","Delays;Integrated circuit modeling;Mathematical model;Quantization (signal);Semiconductor device measurement;Silicon","Bayes methods;elemental semiconductors;learning (artificial intelligence);logic circuits;regression analysis;sensitivity analysis;silicon","Si;delay sensitivity;logic circuits;low measurement resolution;mathematical algorithm;measurement noise;model-silicon miscorrelation;path delay prediction;quantized path delay measurements;regularization parameter;ridge regression;segment delay learning process;silicon chip;silicon measurement environments","","0","","12","","20150403","June 2015","","IEEE","IEEE Journals & Magazines"
"Neural Network On-Line Modeling for Mechanically Coupled Vehicle","T. Ogitsu; T. Ikegami; S. Kato; H. Mizoguchi","Dept. of Mech. Eng., Tokyo Univ. of Sci., Chiba, Japan","2014 European Modelling Symposium","20150713","2014","","","27","32","This study was conducted to increase the usefulness of personal vehicles. Single-occupant personal vehicles are easy to handle, but their load capacities are smaller than other types of vehicles. This paper presents a solution to this problem in the form of a system for vehicles that couple mechanically. However, if vehicles are only coupled, their performance in braking, accelerating, and steering is degraded. The proposed system employs a neural network algorithm, constructs the whole coupled-vehicle model automatically while the vehicles are being driven, and makes drivers feel as if they are driving stand-alone vehicles. In this paper, we present the details of the proposed method and the results of computer simulation experiments that demonstrate the effectiveness of the system.","","Electronic:978-1-4799-7412-2; POD:978-1-4799-7413-9","10.1109/EMS.2014.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153970","personal vehicle; coupled vehicle; platoon; machine learning; neural network; on-line modeling","Acceleration;Computational modeling;Couplings;Neural networks;Sensor phenomena and characterization;Vehicles","mechanical engineering computing;neural nets;road vehicles","mechanically coupled vehicle;neural network algorithm;neural network on-line modeling;stand-alone vehicles;whole coupled-vehicle model","","0","","11","","","21-23 Oct. 2014","","IEEE","IEEE Conference Publications"
"Automatic Channel Fault Detection and Diagnosis System for a Small Animal APD-Based <newline/>Digital PET Scanner","J. Charest; J. F. Beaudoin; J. Cadorette; R. Lecomte; C. A. Brunet; R. Fontaine","Department of Electrical Engineering and Computer Engineering, Universit&#x00E9; de Sherbrooke, Sherbrooke, Canada","IEEE Transactions on Nuclear Science","20150612","2015","62","3","1070","1076","Fault detection and diagnosis is critical to many applications in order to ensure proper operation and performance over time. Positron emission tomography (PET) systems that require regular calibrations by qualified scanner operators are good candidates for such continuous improvements. Furthermore, for scanners employing one-to-one coupling of crystals to photodetectors to achieve enhanced spatial resolution and contrast, the calibration task is even more daunting because of the large number of independent channels involved. To cope with the additional complexity of the calibration and quality control procedures of these scanners, an intelligent system (IS) was designed to perform fault detection and diagnosis (FDD) of malfunctioning channels. The IS can be broken down into four hierarchical modules: parameter extraction, diagnosis, channel fault detection and fault prioritization. Of these modules, parameter extraction and fault detection have previously been reported and this paper focuses on diagnosis, improved fault detection and fault prioritization. The status diagnosis module will diagnose all channels and propose an explanation of the reasons that lead to the diagnosis. The purpose of the fault prioritization module is to help the operator to zero in on the faults that need immediate attention. The FDD system was implemented on a LabPET avalanche photodiode (APD)-based digital PET scanner. Experiments demonstrated a FDD Sensitivity of 99.9% (with a 95% confidence interval (CI) of [99.6, 100.0]) for major faults. Globally, the balanced accuracy of the diagnosis for varying fault severities is 91%. This suggests the IS can greatly benefit the operators in their maintenance task.","0018-9499;00189499","","10.1109/TNS.2015.2425794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7117476","Artificial intelligence (AI);biomedical imaging;expert systems;fault diagnosis;fuzzy logic;machine learning;positron emission tomography (PET)","Accuracy;Expert systems;Fault detection;Fuzzy logic;Noise;Positron emission tomography;Sensitivity","avalanche photodiodes;biomedical equipment;calibration;fault diagnosis;photodetectors;positron emission tomography;quality control","FDD Sensitivity;automatic channel fault detection-diagnosis system;calibration task;enhanced spatial resolution;fault prioritization;independent channels;intelligent system;labPET avalanche photodiode-based digital PET scanner;malfunctioning channels;photodetectors;positron emission tomography;quality control procedures;small animal APD-based digital PET scanner","","2","","19","","20150603","June 2015","","IEEE","IEEE Journals & Magazines"
"Online Sparsifying Transform Learning—Part II: Convergence Analysis","S. Ravishankar; Y. Bresler","Department of Electrical and Computer Engineering and the Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, IL, USA","IEEE Journal of Selected Topics in Signal Processing","20150512","2015","9","4","637","646","Sparsity-based techniques have been widely popular in signal processing applications such as compression, denoising, and compressed sensing. Recently, the learning of sparsifying transforms for data has received interest. The advantage of the transform model is that it enables cheap and exact computations. In Part I of this work, efficient methods for online learning of square sparsifying transforms were introduced and investigated (by numerical experiments). The online schemes process signals sequentially, and can be especially useful when dealing with big data, and for real-time, or limited latency signal processing applications. In this paper, we prove that although the associated optimization problems are non-convex, the online transform learning algorithms are guaranteed to converge to the set of stationary points of the learning problem. The guarantee relies on a few simple assumptions. In practice, the algorithms work well, as demonstrated by examples of applications to representing and denoising signals.","1932-4553;19324553","","10.1109/JSTSP.2015.2407860","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051209","Sparse representations;big data;convergence guarantees;dictionary learning;machine learning;online learning;sparsifying transforms","Convergence;Dictionaries;Encoding;Optimization;Signal processing algorithms;Transforms;Vectors","Big Data;learning (artificial intelligence);signal denoising;transforms","big data;convergence analysis;latency signal processing applications;online sparsifying transform learning algorithms;sparsity-based techniques;square sparsifying transforms;transform model","","4","","17","","20150227","June 2015","","IEEE","IEEE Journals & Magazines"
"Boosting Mobile Apps under Imbalanced Sensing Data","X. Zhang; Z. Yang; L. Shangguan; Y. Liu; L. Chen","School of Software and Tsinghua National Lab for Information Science and Technology (TNLIST), Tsinghua University, China","IEEE Transactions on Mobile Computing","20150504","2015","14","6","1151","1161","Mobile sensing apps have proliferated rapidly over the recent years. Most of them rely on inference components heavily for detecting interesting activities or contexts. Existing work implements inference components using traditional models designed for balanced data sets, where the sizes of interesting (positive) and non-interesting (negative) data are comparable. Practically, however, the positive and negative sensing data are highly imbalanced. For example, a single daily activity such as bicycling or driving usually occupies a small portion of time, resulting in rare positive instances. Under this circumstance, the trained models based on imbalanced data tend to mislabel positive ones as negative. In this paper, we propose a new inference framework SLIM based on several machine learning techniques in order to accommodate the imbalanced nature of sensing data. Especially, guided under-sampling is employed to obtain balanced labelled subsets, followed by a similarity-based sampling that draws massive unlabelled data to enhance training. To the best of our knowledge, SLIM is the first model that considers data imbalance in mobile sensing. We prototype two sensing apps and the experimental results show that SLIM achieves higher recall (activity recognition rate) while maintaining the precision compared with five classical models. In terms of the overall recall and precision, SLIM is around 12 percent better than the compared solutions on average.","1536-1233;15361233","","10.1109/TMC.2014.2345053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6868981","Mobile sensing applications;imbalanced sensing data;machine learning;semi-supervised learning;under-sampling","Data models;Mobile communication;Mobile computing;Semisupervised learning;Sensors;Smart phones;Training","learning (artificial intelligence);mobile computing","SLIM;imbalanced sensing data;inference components;machine learning techniques;mobile sensing apps;negative data;noninteresting data;positive data;precision;recall","","1","","40","","20140731","June 1 2015","","IEEE","IEEE Journals & Magazines"
"Enhanced SMOTE algorithm for classification of imbalanced big-data using Random Forest","R. C. Bhagat; S. S. Patil","Department of CSE, Rajarambapu Institute of Technology, Islampur (Sangli), MS, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","403","408","In the era of big data, the applications generating tremendous amount of data are becoming the main focus of attention as the wide increment of data generation and storage that has taken place in the last few years. This scenario is challenging for data mining techniques which are not arrogated to the new space and time requirements. In many of the real world applications, classification of imbalanced data-sets is the point of attraction. Most of the classification methods focused on two-class imbalanced problem. So, it is necessary to solve multi-class imbalanced problem, which exist in real-world domains. In the proposed work, we introduced a methodology for classification of multi-class imbalanced data. This methodology consists of two steps: In first step we used Binarization techniques (OVA and OVO) for decomposing original dataset into subsets of binary classes. In second step, the SMOTE algorithm is applied against each subset of imbalanced binary class in order to get balanced data. Finally, to achieve classification goal Random Forest (RF) classifier is used. Specifically, oversampling technique is adapted to big data using MapReduce so that this technique is able to handle as large data-set as needed. An experimental study is carried out to evaluate the performance of proposed method. For experimental analysis, we have used different datasets from UCI repository and the proposed system is implemented on Apache Hadoop and Apache Spark platform. The results obtained shows that proposed method outperforms over other methods.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154739","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154739","Data mining;Machine Learning;MapReduce;Multi-class Imbalanced data;Oversampling","Big data;Classification algorithms;Computational modeling;Data mining;Machine learning algorithms;Radio frequency;Sparks","Big Data;data mining;parallel processing;pattern classification","Apache Hadoop;Apache Spark platform;Big Data classification;MapReduce;OVA;RF classifier;SMOTE algorithm;binarization technique;data generation;data mining technique;data storage;one-vs.-all approach;oversampling technique;random forest","","2","","20","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"Application of Energy-Based Power System Features for Dynamic Security Assessment","J. Geeganage; U. D. Annakkage; T. Weekes; B. A. Archer","Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, Canada","IEEE Transactions on Power Systems","20150616","2015","30","4","1957","1965","This paper presents a novel approach to enable frequent computational cycles in online dynamic security assessment by using the terms of the transient energy function (TEF) as input features to a machine learning algorithm. The aim is to train a single classifier that is capable of classifying stable and unstable operating points independent of the contingency. The network is trained based on the current system topology and the loading conditions. The potential of the proposed approach is demonstrated with the New England 39-bus test power system model using the support vector machine as the machine learning technique. It is shown that the classifier can be trained using a small set of data when the terms of the TEF are used as input features. The prediction accuracy of the proposed scheme was tested under the balanced and unbalanced faults with the presence of voltage sensitive and dynamic loads for different operating points.","0885-8950;08858950","","10.1109/TPWRS.2014.2353048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6902826","Direct methods;machine learning;real-time security assessment;transient stability","Computational modeling;Load modeling;Numerical stability;Power system stability;Security;Stability analysis;Training","learning (artificial intelligence);power system analysis computing;power system security;support vector machines","New England 39-bus test power system model;TEF;computational cycles;dynamic loads;energy-based power system features;input features;loading conditions;machine learning algorithm;online dynamic security assessment;prediction accuracy;support vector machine;system topology;transient energy function;unbalanced faults;unstable operating points","","10","","34","","20140918","July 2015","","IEEE","IEEE Journals & Magazines"
"Affect burst detection using multi-modal cues","B. B. Türker; S. Marzban; M. T. Sezgin; Y. Yemez; E. Erzin","Elektrik ve Elektron. Muhendisligi Bolumu, Koc Univ., I&#x0307;stanbul, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1006","1009","Recently, affect bursts have gained significant importance in the field of emotion recognition since they can serve as prior in recognising underlying affect bursts. In this paper we propose a data driven approach for detecting affect bursts using multimodal streams of input such as audio and facial landmark points. The proposed Gaussian Mixture Model based method learns each modality independently followed by combining the probabilistic outputs to form a decision. This gives us an edge over feature fusion based methods as it allows us to handle events when one of the modalities is too noisy or not available. We demonstrate robustness of the proposed approach on 'Interactive emotional dyadic motion capture database' (IEMOCAP) which contains realistic and natural dyadic conversations. This database is annotated by three annotators to segment and label affect bursts to be used for training and testing purposes. We also present performance comparison between SVM based methods and GMM based methods for the same configuration of experiments.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130002","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130002","Affect Burst Detection;Affective Computing and Interaction;Applied Machine Learning","Affective computing;Artificial neural networks;Computational modeling;Databases;Emotion recognition;Hidden Markov models;Speech","Gaussian processes;emotion recognition;mixture models;object detection","Gaussian mixture model;IEMOCAP;affect burst detection;audio landmark points;data driven approach;emotion recognition;facial landmark points;interactive emotional dyadic motion capture database;multimodal cues;multimodal streams;natural dyadic conversations;probabilistic outputs;realistic dyadic conversations","","1","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Comparing dimensionality reduction techniques","W. Nick; J. Shelton; G. Bullock; A. Esterline; K. Asamene","Dept. of Computer Science, North Carolina A&T State University, USA","SoutheastCon 2015","20150625","2015","","","1","2","Feature selection techniques are investigated to increase the accuracy of classification while reducing the dimensionality of the feature space. Dimensionality reduction techniques investigated include principal component analysis (PCA), recursive feature elimination (RFE), and Genetic and Evolutionary Feature Weighting & Selection (GEFeWS). A support vector machine (SVM) with linear kernel functions was used with all three techniques for consistency. In our experiment, RFE and GEFeWS performed comparably and both resulted in more accurate classifiers than PCA.","1091-0050;10910050","Electronic:978-1-4673-7300-5; POD:978-1-4673-7301-2","10.1109/SECON.2015.7132997","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7132997","Dimensionality reduction;Genetic and evolutionary computation;Machine learning","Accuracy;Evolutionary computation;Frequency modulation;Genetics;Kernel;Principal component analysis;Support vector machines","data reduction;feature selection;genetic algorithms;pattern classification;principal component analysis;support vector machines","GEFeWS;PCA;dimensionality reduction techniques;feature selection techniques;genetic and evolutionary feature weighting & selection;linear kernel functions;principal component analysis;recursive feature elimination;support vector machine","","0","","6","","","9-12 April 2015","","IEEE","IEEE Conference Publications"
"Learning Structured Models for Segmentation of 2-D and 3-D Imagery","A. Lucchi; P. Márquez-Neila; C. Becker; Y. Li; K. Smith; G. Knott; P. Fua","Department of Computer Science, ETH, Z&#x00FC;rich, Switzerland","IEEE Transactions on Medical Imaging","20150429","2015","34","5","1096","1110","Efficient and accurate segmentation of cellular structures in microscopic data is an essential task in medical imaging. Many state-of-the-art approaches to image segmentation use structured models whose parameters must be carefully chosen for optimal performance. A popular choice is to learn them using a large-margin framework and more specifically structured support vector machines (SSVM). Although SSVMs are appealing, they suffer from certain limitations. First, they are restricted in practice to linear kernels because the more powerful nonlinear kernels cause the learning to become prohibitively expensive. Second, they require iteratively finding the most violated constraints, which is often intractable for the loopy graphical models used in image segmentation. This requires approximation that can lead to reduced quality of learning. In this paper, we propose three novel techniques to overcome these limitations. We first introduce a method to “kernelize” the features so that a linear SSVM framework can leverage the power of nonlinear kernels without incurring much additional computational cost. Moreover, we employ a working set of constraints to increase the reliability of approximate subgradient methods and introduce a new way to select a suitable step size at each iteration. We demonstrate the strength of our approach on both 2-D and 3-D electron microscopic (EM) image data and show consistent performance improvement over state-of-the-art approaches.","0278-0062;02780062","","10.1109/TMI.2014.2376274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967781","Computer vision;electron microscopy;image processing;image segmentation;kernel methods;mitochondria;segmentation;statistical machine learning;structured prediction;superpixels;supervoxels","Approximation methods;Fasteners;Image segmentation;Kernel;Labeling;Support vector machines;Training","biological tissues;cellular biophysics;electron microscopy;image segmentation;learning (artificial intelligence);medical image processing;neurophysiology;support vector machines","2D electron microscopic image data;2D imagery segmentation;3D electron microscopic image data;3D imagery segmentation;cellular structures;large-margin framework;learning structured models;linear SSVM framework;linear kernels;loopy graphical models;microscopic data;neural tissue;nonlinear kernels;optimal performance;specifically structured support vector machines","Algorithms;Animals;CA1 Region, Hippocampal;Imaging, Three-Dimensional;Machine Learning;Microscopy, Electron;Mitochondria;Models, Statistical;Models, Theoretical","1","","59","","20141126","May 2015","","IEEE","IEEE Journals & Magazines"
"An Algorithm for the Automatic Analysis of Signals From an Oyster Heart Rate Sensor","A. D. Hellicar; A. Rahman; D. V. Smith; G. Smith; J. McCulloch; S. Andrewartha; A. Morash","Commonwealth Scientific and Industrial Research Organisation, Battery Point, Australia","IEEE Sensors Journal","20150616","2015","15","8","4480","4487","An in situ optical oyster heart rate sensor generates signals requiring frequency estimation with properties different to human ECG and speech signals. We discuss the method of signal generation and highlight a number of these signal properties. An optimal heart rate estimation approach was identified by application of a variety of frequency estimation techniques and comparing results to manually acquired values. Although a machine learning approach achieved the best performance, accurately estimating 96.8% of the heart rates correctly, a median filtered autocorrelation approach achieved 93.7% with significantly less computational requirement. A method for estimating heart rate variation is also presented.","1530-437X;1530437X","","10.1109/JSEN.2015.2422375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7084586","Biomedical signal processing;Frequency estimation;Machine learning;frequency estimation;machine learning","Correlation;Estimation;Frequency estimation;Heart rate;Optical sensors","bioelectric potentials;electrocardiography;learning (artificial intelligence);median filters;medical signal processing","frequency estimation technique;heart rate estimation approach;heart rate variation;human ECG signal;machine learning approach;median filtered autocorrelation approach;optical oyster heart rate sensor;signal analysis;signal generation;signal properties;speech signal","","2","","19","","20150413","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"<italic>Why so many people</italic>? Explaining Nonhabitual Transport Overcrowding With Internet Data","F. C. Pereira; F. Rodrigues; E. Polisciuc; M. Ben-Akiva","Singapore-MIT Alliance for Res. & Technol., Singapore, Singapore","IEEE Transactions on Intelligent Transportation Systems","20150601","2015","16","3","1370","1379","Public transport smartcard data can be used for detection of large crowds. By comparing statistics on habitual behavior (e.g., average by time of day), one can specifically identify nonhabitual crowds, which are often very problematic for transport systems. While habitual overcrowding (e.g., peak hour) is well understood both by traffic managers and travelers, nonhabitual overcrowding hotspots can become even more disruptive and unpleasant because they are generally unexpected. By quickly understanding such cases, a transport manager can react and mitigate transport system disruptions. We propose a probabilistic data analysis model that breaks each nonhabitual overcrowding hotspot into a set of explanatory components. The potential explanatory components are initially retrieved from social networks and special events websites and then processed through text-analysis techniques. Finally, for each such component, the probabilistic model estimates a specific share in the total overcrowding counts. We first validate with synthetic data and then test our model with real data from the public transport system (EZLink) of Singapore, focused on three case study areas. We demonstrate that it is able to generate explanations that are intuitively plausible and consistent both locally (correlation coefficient, i.e., CC, from 85% to 99% for the three areas) and globally (CC from 41.2% to 83.9%). This model is directly applicable to any other domain sensitive to crowd formation due to large social events (e.g., communications, water, energy, waste).","1524-9050;15249050","","10.1109/TITS.2014.2368119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7021960","Information extraction;machine learning;smartcards;special events;travel demand modeling;web mining","Bayes methods;Data models;Facebook;Google;Intelligent transportation systems;Internet;Predictive models","Internet;behavioural sciences computing;data analysis;information retrieval;probability;public transport;smart cards;social networking (online);text analysis;traffic engineering computing","Internet data;Web sites;correlation coefficient;crowd formation;habitual behavior;nonhabitual transport overcrowding hotspot;probabilistic data analysis;probabilistic model;public transport smart card data;public transport system;social events;social networks;text-analysis techniques;traffic managers","","1","","26","","20150126","June 2015","","IEEE","IEEE Journals & Magazines"
"Remaining useful life estimation of ball bearings by means of monotonic score calibration","J. A. Carino; D. Zurita; M. Delgado; J. A. Ortega; R. J. Romero-Troncoso","MCIA Research Center, Department of Electronic Engineering, Polytechnic University of Catalonia (UPC) Terrassa, Spain","2015 IEEE International Conference on Industrial Technology (ICIT)","20150618","2015","","","1752","1758","The estimation of remaining useful life applied to industrial machinery and its components is one of the current trends in the advanced manufacturing field. In this context, this work presents a reliable methodology applied to ball bearings health monitoring. First, the proposed methodology analyses the available vibration and temperature data by means of the Spearman coefficient. This step allows the identification of the most significant monotonic relationship between features and the evolution of the remaining useful life. The method is complemented by means of the application of one-class support vector machine in order to obtain the remaining useful life indication trough the mapping of the classification scores. The proposed scheme shows a significant accuracy and reliability of the degradation detection due to the coherent management of the information. This fact is experimentally demonstrated by a run-to-failure test bench and the comparison with classical approaches.","","Electronic:978-1-4799-7800-7; POD:978-1-4799-7801-4; USB:978-1-4799-7799-4","10.1109/ICIT.2015.7125351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7125351","Artificial Intelligence;Classification Algorithms;Machine Learning;One Class Support Vector Machines;Remeaning Useful Life","Calibration;Degradation;Life estimation;Monitoring;Support vector machines;Training","ball bearings;benchmark testing;condition monitoring;failure analysis;mechanical engineering computing;remaining life assessment;support vector machines;vibrations","Spearman coefficient;ball bearings;classification score mapping;health monitoring;industrial machinery;monotonic score calibration;remaining useful life estimation;run-to-failure bench test;support vector machine;vibration analyses","","1","","16","","","17-19 March 2015","","IEEE","IEEE Conference Publications"
"Service Clustering for Autonomic Clouds Using Random Forest","R. B. Uriarte; S. Tsaftaris; F. Tiezzi","IMT Inst. for Adv. Studies, Lucca, Italy","2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","20150709","2015","","","515","524","Managing and optimising cloud services is one of the main challenges faced by industry and academia. A possible solution is resorting to self-management, as fostered by autonomic computing. However, the abstraction layer provided by cloud computing obfuscates several details of the provided services, which, in turn, hinders the effectiveness of autonomic managers. Data-driven approaches, particularly those relying on service clustering based on machine learning techniques, can assist the autonomic management and support decisions concerning, for example, the scheduling and deployment of services. One aspect that complicates this approach is that the information provided by the monitoring contains both continuous (e.g. CPU load) and categorical (e.g. VM instance type) data. Current approaches treat this problem in a heuristic fashion. This paper, instead, proposes an approach, which uses all kinds of data and learns in a data-driven fashion the similarities and resource usage patterns among the services. In particular, we use an unsupervised formulation of the Random Forest algorithm to calculate similarities and provide them as input to a clustering algorithm. For the sake of efficiency and meeting the dynamism requirement of autonomic clouds, our methodology consists of two steps: (i) off-line clustering and (ii) on-line prediction. Using datasets from real-world clouds, we demonstrate the superiority of our solution with respect to others and validate the accuracy of the on-line prediction. Moreover, to show the applicability of our approach, we devise a service scheduler that uses the notion of similarity among services and evaluate it in a cloud test-bed.","","Electronic:978-1-4799-8006-2; POD:978-1-4799-8007-9","10.1109/CCGrid.2015.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152517","Autonomic Computing;Cloud Computing;Machine Learning;Random Forest;SImilarity Learning","Clustering algorithms;Monitoring;Prediction algorithms;Radio frequency;Security;Training;Vegetation","cloud computing;decision support systems;fault tolerant computing;learning (artificial intelligence);pattern clustering;scheduling;unsupervised learning","CPU load;abstraction layer;autonomic clouds;autonomic computing;autonomic management;autonomic managers;categorical data;cloud service management;cloud service optimisation;cloud test-bed;data-driven approach;machine learning techniques;off-line clustering;on-line prediction;random forest algorithm;resource usage patterns;service clustering;service scheduler","","7","","46","","","4-7 May 2015","","IEEE","IEEE Conference Publications"
"An Adaptive Spatial Filter for User-Independent Single Trial Detection of Event-Related Potentials","H. Woehrle; M. M. Krell; S. Straube; S. K. Kim; E. A. Kirchner; F. Kirchner","DFKI Robotics Innovation Center, Bremen, Germany","IEEE Transactions on Biomedical Engineering","20150616","2015","62","7","1696","1705","Goal: Current brain-computer interfaces (BCIs) are usually based on various, often supervised, signal processing methods. The disadvantage of supervised methods is the requirement to calibrate them with recently acquired subject-specific training data. Here, we present a novel algorithm for dimensionality reduction (spatial filter), that is ideally suited for single-trial detection of event-related potentials (ERPs) and can be adapted online to a new subject to minimize or avoid calibration time. Methods: The algorithm is based on the well-known xDAWN filter, but uses generalized eigendecomposition to allow an incremental training by recursive least squares (RLS) updates of the filter coefficients. We analyze the effectiveness of the spatial filter in different transfer scenarios and combinations with adaptive classifiers. Results: The results show that it can compensate changes due to switching between different users, and therefore allows to reuse training data that has been previously recorded from other subjects. Conclusions: The presented approach allows to reduce or completely avoid a calibration phase and to instantly use the BCI system with only a minor decrease of performance. Significance: The novel filter can adapt a precomputed spatial filter to a new subject and make a BCI system user independent.","0018-9294;00189294","","10.1109/TBME.2015.2402252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7038203","Adaptation;Brain Computer Interfaces;Online Machine Learning;Spatial Filtering;brain–computer interfaces (BCI);online machine learning;spatial filtering","Correlation;Memory management;Noise;Standards;Support vector machines;Training;Training data","adaptive filters;adaptive signal processing;bioelectric potentials;brain-computer interfaces;eigenvalues and eigenfunctions;learning (artificial intelligence);least squares approximations;medical signal processing;spatial filters","BCI;BCI system;RLS;adaptive spatial filter;brain-computer interfaces;event-related potentials;generalized eigendecomposition;recursive least squares;single-trial detection;spatial filter;subject-specific training data;supervised signal processing methods;training data;user-independent single trial detection;xDAWN filter","1","4","","48","","20150210","July 2015","","IEEE","IEEE Journals & Magazines"
"Hybrid classification for tweets related to infection with influenza","X. Dai; M. Bikdash","Department of Computational Science and Engineering, North Carolina A&T State University, Greensboro, USA","SoutheastCon 2015","20150625","2015","","","1","5","Traditional public health surveillance methods such as those employed by the CDC (United States Centers for Disease Control and Prevention) rely on regular clinical reports, which are almost always manual and labor intensive. Twitter, a popular micro-blogging service, provides the possibility of automated public health surveillance. Tweets, however, are less than 140 characters, and do not provide sufficient word occurrences for conventional classification methods to work reliably. Moreover, natural language is complex. This makes health-related classification more challenging. In this study, we use flu-related classification as a demonstration to propose a hybrid classification method, which combines two classification approaches: manually- defined features and auto-generated features by machine learning approaches. Preprocessing based on Natural Language Processing (NLP) is used to help extract useful information, and to eliminate noise features. Our simulations show an improved accuracy.","1091-0050;10910050","Electronic:978-1-4673-7300-5; POD:978-1-4673-7301-2","10.1109/SECON.2015.7133015","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7133015","Big data;Classification;Machine learning;Natural Language Processing;Public Health;Social Network;Twitter","Influenza;Manuals;Natural language processing;Public healthcare;Surveillance;Training;Twitter","health care;learning (artificial intelligence);medical computing;natural language processing;pattern classification;social networking (online)","CDC;NLP;Twitter;United States Centers for Disease Control and Prevention;auto-generated features classification;flu-related classification;health-related classification;hybrid classification method;hybrid tweet classification;influenza infection;information extraction;machine learning approach;manually-defined features classification;natural language processing;noise feature elimination;public health surveillance methods","","3","","21","","","9-12 April 2015","","IEEE","IEEE Conference Publications"
"Information-Theoretic Measures on Intrinsic Mode Function for the Individual Identification Using EEG Sensors","P. Kumari; A. Vaish","Indian Institute of Information Technology, Allahabad, India","IEEE Sensors Journal","20150713","2015","15","9","4950","4960","In spite of recent advances, the interest in extracting knowledge hidden in the electroencephalogram (EEG) signals is rapidly growing, as well as their application in the computational neuroengineering field, such as mobile robot control, wheelchair control, and person identification using brainwaves. The large number of methods for the EEG feature extraction demands a good feature for every task. Digging up the most unique feature would be worthy for the identification of individual using EEG signal. This research presents a novel approach for feature extraction of EEG signal using the empirical mode decomposition (EMD) and information-theoretic method. The EMD technique is applied to decompose an EEG signal into a set of intrinsic mode function. These decomposed signals are of the same length and in the same time domain as the original signal. Hence, the EMD method preserves varying frequencies in time. To measure the performance of the features, we have used hybrid learning for classification where we have selected learning vector quantization neural network with fuzzy algorithm. In order to test the performance of proposed classifier based on fuzzy theory, we have tested classification accuracy of each cognitive task over all participated subjects. The results are compared with the past methods in the literature for feature extraction and classification methods. Results confirm that the proposed features present a satisfactory performance.","1530-437X;1530437X","","10.1109/JSEN.2015.2423152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7086287","Artificial Neural network;Biometric;EEG;Empirical Mode Decomposition (EMD);Fuzzy algorithm in LVQ;Machine Learning;Machine learning;artificial neural network;biometric;empirical mode decomposition (EMD);learning vector quantization (LVQ-NN);learning vector quantization (LVQ-NN) and fuzzy algorithm in LVQ","Data mining;Electroencephalography;Entropy;Feature extraction;Neurons;Random variables;Sensors","bioelectric potentials;electroencephalography;feature extraction;fuzzy systems;learning (artificial intelligence);medical signal processing;mobile robots;neurophysiology;signal classification;wheelchairs","EEG sensors;EEG signal;EMD technique;brainwaves;classification accuracy;cognitive task;computational neuroengineering field;electroencephalogram signals;empirical mode decomposition;feature extraction;fuzzy algorithm;fuzzy theory;hybrid learning;individual identification;information-theoretic measurement;intrinsic mode function;learning vector quantization neural network;mobile robot control;person identification;wheelchair control","","2","","48","","20150415","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Online Sparsifying Transform Learning— Part I: Algorithms","S. Ravishankar; B. Wen; Y. Bresler","Department of Electrical and Computer Engineering and the Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, IL, USA","IEEE Journal of Selected Topics in Signal Processing","20150512","2015","9","4","625","636","Techniques exploiting the sparsity of signals in a transform domain or dictionary have been popular in signal processing. Adaptive synthesis dictionaries have been shown to be useful in applications such as signal denoising, and medical image reconstruction. More recently, the learning of sparsifying transforms for data has received interest. The sparsifying transform model allows for cheap and exact computations. In this paper, we develop a methodology for online learning of square sparsifying transforms. Such online learning can be particularly useful when dealing with big data, and for signal processing applications such as real-time sparse representation and denoising. The proposed transform learning algorithms are shown to have a much lower computational cost than online synthesis dictionary learning. In practice, the sequential learning of a sparsifying transform typically converges faster than batch mode transform learning. Preliminary experiments show the usefulness of the proposed schemes for sparse representation, and denoising.","1932-4553;19324553","","10.1109/JSTSP.2015.2417131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069264","Sparse representations;big data;denoising;dictionary learning;image representation;machine learning;online learning;sparsifying transforms","Adaptation models;Analytical models;Computational modeling;Dictionaries;Encoding;Noise reduction;Transforms","adaptive signal processing;learning (artificial intelligence);signal denoising;signal representation","online adaptive synthesis dictionary learning;online sparsifying transform learning algorithm;sequential learning;signal denoising;signal processing application;signal sparsity;sparse signal representation;square sparsifying transform","","11","","57","","20150326","June 2015","","IEEE","IEEE Journals & Magazines"
"A Data-Driven Probabilistic CTU Splitting Algorithm for Fast H.264/HEVC Video Transcoding","A. J. D. Honrubia; J. L. Martínez; P. Cuenca; J. A. Gámez; J. M. Puerta","Albacete Res. Inst. of Inf., Univ. of Castilla-La Mancha, Albacete, Spain","2015 Data Compression Conference","20150706","2015","","","449","449","High Efficiency Video Coding was developed by the JCT-VC to replace the current H.264/AVC standard, which has dominated digital video services in all segments of the domestic and professional markets for over ten years. Therefore, there is a lot of legacy content encoded with H.264/AVC, and an efficient video transcoding from H.264 to HEVC will be needed to enable gradual migration to HEVC. HEVC adopts a quad tree-based Coding Unit block partitioning structure that is flexible in adapting various texture characteristics at the expense of a high computational cost. This paper presents a data-driven probabilistic CTU splitting algorithm that is designed to exploit the information gathered at the H.264/AVC decoder in order to make faster decisions on CU splitting in HEVC. Experimental results show that the proposed algorithm can achieve a good tradeoff between coding efficiency and complexity compared with the anchor transcoder, and, moreover, it outperforms other related works available in the literature.","1068-0314;10680314","Electronic:978-1-4799-8430-5; POD:978-1-4799-8431-2","10.1109/DCC.2015.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7149312","H.264/AVC;HEVC;Machine Learning;Naive Bayes;Transcoding","Data compression;Niobium;Probabilistic logic;Rate-distortion;Transcoding;Video coding","quadtrees;video coding","anchor transcoder;data-driven probabilistic CTU splitting algorithm;digital video services;fast H.264-HEVC video transcoding;quad tree-based coding unit block partitioning structure","","0","","1","","","7-9 April 2015","","IEEE","IEEE Conference Publications"
"Monitoring quality indicators for screening colonoscopies","M. Charles; T. N. Miano; X. Zhang; L. E. Barnes; J. M. Lobo","University of Virginia","2015 Systems and Information Engineering Design Symposium","20150608","2015","","","171","175","The detection rate of adenomas in screening colonoscopies is an important quality indicator for endoscopists. Successful detection of adenomas is linked to reduced cancer incidence and mortality. This study focuses on evaluating the performance of endoscopists on adenoma detection rate (ADR), polyp detection rate (PDR), and scope withdrawal time. The substitution of PDR for ADR has been suggested due the reliance of ADR calculation on pathology reports. We compare these metrics to established clinical guidelines and to the performance of other individual endoscopists. Our analysis (n = 2730 screening colonoscopies) found variation in ADR for 14 endoscopists, ranging from 0.20 to 0.41. PDR ranged from 0.38 to 0.62. Controlling for age, sex, race, withdrawal time, and the presence of a trainee endoscopist accounted for 34% of variation in PDR but failed to account for any variation in ADR. The Pearson correlation between PDR and ADR is 0.82. These results suggest that PDR has significant value as a quality indicator. The reported variation in detection rates after controlling for case mix signals the need for greater scrutiny of individual endoscopist skill. Understanding the root cause of this variation could potentially lead to better patient outcomes.","","Electronic:978-1-4799-1832-4; POD:978-1-4799-1833-1","10.1109/SIEDS.2015.7116968","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116968","Colonoscopy;Electronic Medical Records;Health Data;Machine Learning;Physician Performance","Cancer;Colonoscopy;Endoscopes;Guidelines;Logistics;Measurement;Predictive models","cancer;endoscopes;medical image processing;object detection","ADR;PDR;Pearson correlation;adenomas detection rate;cancer incidence;cancer mortality;clinical guidelines;endoscopists;pathology reports;polyp detection rate;quality indicator monitoring;screening colonoscopies","","0","","19","","","24-24 April 2015","","IEEE","IEEE Conference Publications"
