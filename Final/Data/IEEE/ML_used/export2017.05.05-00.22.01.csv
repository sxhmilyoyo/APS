"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6064595,6064577,6064578,6064602,6064611,6064600,6064606,6064610,6064599,6064582,6064605,6064609,6064585,6064571,6064624,6064589,6064552,6064557,6064598,6064581,6064604,6064613,6064608,6064584,6064626,6064591,6064559,6064570,6064593,6064623,6064636,6064588,6064629,6064618,6064621,6064575,6064556,6064597,6064640,6064564,6064548,6064634,6064580,6064603,6064612,6064607,6064567,6064583,6064586,6064572,6064590,6064553,6064558,6064614,6064569,6064592,6064560,6064616,6064594,6064544,6064637,6064630,6064619,6064622,6064576,6064635,6064587,6064573,6064554,6064628,6064561,6064617,6064638,6064631,6064620,6064550,6064574,6064555,6064562,6064596,6064546,6064639,6064632,6064563,6064547,6064633,6064579,6016930,6016932,6016840,6016732,6016939,6016937,6016936,6016745,6016931,6016934,6016831,6016744,6016933",2017/05/05 00:22:01
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Instances selection for NN with fuzzy rough technique","X. M. Kang; X. P. Liu; J. H. Zhai; M. Y. Zhai","Key Lab. of Machine Learning and Computational Intelligence, College of Mathematics and Computer Science, Hebei University, Baoding 071002, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1097","1100","The NN algorithm is a simple and well-known supervised learning scheme which classifies an unseen instance by finding its closest neighbor in training set. The main drawback of NN is that the whole training set must be stored in the computer to classify an unseen instance. In order to deal with this problem, P. Hart proposed the condensed nearest neighbor (CNN) algorithm. However, CNN select the important instances from the whole training set, which suffers from the problem of large memory requirement same as NN. In this paper, we propose an algorithm to select instances from the border region with fuzzy rough technique. The experimental results demonstrate the effectiveness of our proposed method.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016939","Border region;Condensed nearest neighbor;Fuzzy rough set;Instances selection;Nearest neighbor","Accuracy;Classification algorithms;Cybernetics;Machine learning;Rough sets;Testing;Training","fuzzy set theory;learning (artificial intelligence);rough set theory","NN algorithm;condensed nearest neighbor algorithm;fuzzy rough technique;instances selection;nearest neighbor rule;supervised learning scheme","","2","","13","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Modeling musicological information as trigrams in a system for simultaneous chord and local key extraction","J. Pauwels; J. P. Martens; M. Leman","Digital Speech and Signal Processing group (ELIS-DSSP), Ghent University, Belgium","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper, we discuss the introduction of a trigram musicological model in a simultaneous chord and local key extraction system. By enlarging the context of the musicological model, we hoped to achieve a higher accuracy that could justify the associated higher complexity and computational load of the search for the optimal solution. Experiments on multiple data sets have demonstrated that the trigram model has indeed a larger predictive power (a lower perplexity). This raised predictive power resulted in an improvement in the key extraction capabilities, but no improvement in chord extraction when compared to a system with a bigram musicological model.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064602","Chord extraction;key extraction;music information retrieval;music signal processing","Acoustics;Computational modeling;Context;Context modeling;Data models;Harmonic analysis;Psychoacoustic models","audio signal processing;information retrieval;music","bigram musicological model;computational load;key extraction capability;local key extraction system;multiple data sets;musicological information modeling;optimal solution;predictive power;simultaneous chord extraction system;trigram musicological model","","1","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A survey of the initialization of centers and widths in radial basis function network for classification","C. R. Dong; P. P. K. Chan; W. W. Y. Ng; D. S. Yeung","Machine Learning and Cybernetics Research Center, School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1082","1087","The radial basis function network (RBFN) has been widely used in various fields such as function regression, pattern recognition, and error detection, etc. However, the structural parameters of RBFN including the number of hidden units, centers vectors, and widths (variances) are one of the most important issues when training a RBFN, which greatly affect the performance of RBFN. So, the objective of this paper is to construct an elementary survey about this problem. Firstly, the fundamental knowledge and notations of RBFN is introduced. Secondly, we summarize most existing network structure initialization methods for RBFN and categorize them into four goups. Then some typical appraoches for each category are introduced and discussed. The disadvantages and virtues for parts of methods are also introduced. Finally, the paper is concluded with a discussion of current difficulties and possible future directions about RBFN architecture selection.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016937","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016937","Clustering;Learning Vector Quantization;Network structure initialization;RBFN","Artificial neural networks;Clustering algorithms;Machine learning;Neurons;Optimization;Training","learning (artificial intelligence);pattern classification;radial basis function networks","RBFN;center vectors;error detection;function regression;hidden units;network structure initialization;pattern recognition;radial basis function network;structural parameters","","0","","40","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Non-parametric co-clustering of large scale sparse bipartite networks on the GPU","T. J. Hansen; M. Mørup; L. Kai Hansen","Section for Cognitive Systems, DTU Informatics, Technical University of Denmark, Denmark","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Co-clustering is a problem of both theoretical and practical importance, e.g., market basket analysis and collaborative filtering, and in web scale text processing. We state the co-clustering problem in terms of non-parametric generative models which can address the issue of estimating the number of row and column clusters from a hypothesis space of an infinite number of clusters. To reach large scale applications of co-clustering we exploit that parameter inference for co-clustering is well suited for parallel computing. We develop a generic GPU framework for efficient inference on large scale sparse bipartite networks and achieve a speedup of two orders of magnitude compared to estimation based on conventional CPUs. In terms of scalability we find for networks with more than 100 million links that reliable inference can be achieved in less than an hour on a single GPU. To efficiently manage memory consumption on the GPU we exploit the structure of the posterior likelihood to obtain a decomposition that easily allows model estimation of the co-clustering problem on arbitrary large networks as well as distributed estimation on multiple GPUs. Finally we evaluate the implementation on real-life large scale collaborative filtering data and web scale text corpora, demonstrating that latent mesoscale structures extracted by the co-clustering problem as formulated by the Infinite Relational Model (IRM) are consistent across consecutive runs with different initializations and also relevant for interpretation of the underlaying processes in such large scale networks.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064611","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064611","","Collaboration;Data models;Generators;Graphics processing unit;Instruction sets;Memory management;Motion pictures","Internet;computer graphic equipment;coprocessors;inference mechanisms;information filtering;parallel processing;pattern clustering;text analysis","GPU;Web scale text corpora;Web scale text processing;collaborative filtering;infinite relational model;large scale sparse bipartite networks;market basket analysis;nonparametric coclustering;nonparametric generative models;parallel computing;parameter inference;posterior likelihood","","5","1","34","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Multiple classifier system for short term load forecast of Microgrid","P. P. K. Chan; W. C. Chen; W. W. Y. Ng; D. S. Yeung","Machine Learning and Cybernetics Research Center, School of Computer Science and Engineering, South China, University of Technology, 510006, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1268","1273","During last decade, Microgrid has been an area of intense study. It also becomes more important in Smart Grid (SG). Short-term load forecast (STLF) in Microgrid is an important factor for planning and optimization of distributed generation. However, STLF for Microgrid is a tough and complex assignment because load of a Microgrid could be change rapidly within a short period of time. The present work proposes on-line learning model of Microgrid short-term load forecast using Multiple Classifier Systems (MCSs). This model is constructed from different training sets and dynamic weighting fusion is used. The proposed method is evaluated by the real Microgrid dataset in Hong Kong comparing with other existing methods experimentally.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016936","Microgrid;Multiple classifier system;Short-term load forecast (STLF)","Cybernetics;Distributed power generation;Electricity;Forecasting;Load forecasting;Machine learning","distributed power generation;learning (artificial intelligence);load forecasting;power distribution planning;power engineering computing;smart power grids","Hong Kong;MCS;SG;STLF;distributed generation optimization;distributed generation planning;dynamic weighting fusion;microgrid;multiple-classifier system;on-line learning model;short-term load forecast;smart grid;training sets","","11","","25","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Bayesian compressive sensing using iterated conditional modes","R. M. Taylor","The MITRE Corporation, McLean, VA 22102, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper we develop a new Bayesian compressive sensing (BCS) decoding algorithm based on iterated conditional modes (ICM) as the inference engine. This approach has the advantage of admitting relatively simple closed-form update rules even for heavy-tailed distributions without resort to conjugate priors and hierarchical models. To demonstrate the simplicity of this approach we derive the ICM update rules for Gaussian, Student's t, and Levy priors and apply the algorithm to random sparse signals and to the problem of coded aperture superresolution in computational imaging. Simulation results show that the algorithm generally outperforms existing BCS algorithms such as FastLaplace and non-Bayesian sparsity maximization algorithms such as L<sub>1</sub>-Magic even in the case of no hyperparameter learning. The BCS-ICM algorithm is highly tunable depending on the nature and amount of prior knowledge. We tune the BCS-ICM algorithm by offline learning of Student's t parameters for modeling the detail wavelet coefficients for vastly superior performance in the coded aperture superresolution problem.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064600","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064600","","Apertures;Arrays;Bayesian methods;Compressed sensing;Image reconstruction;Image resolution;Signal processing algorithms","iterative decoding;optimisation","Bayesian compressive sensing;FastLaplace;closed-form update rules;coded aperture superresolution problem;computational imaging;decoding algorithm;hyperparameter learning;inference engine;iterated conditional mode;non-Bayesian sparsity maximization algorithm;random sparse signal;wavelet coefficient","","0","","11","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Convex optimization for exact rank recovery in topic models","B. Behmardi; R. Raich","School of EECS, Oregon State University, Corvallis, 97331, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Topic models are widely used in a variety of applications including document classification and computer vision. The number of topics in the model plays an important role in terms of accuracy. We consider the problem of estimating the number of topics. In [1], a convex optimization approach was proposed to solve the problem via a constrained nuclear norm minimization. A standard semidefinite programming (SDP) was applied to solve the convex optimization only for a small size problem (e.g. 100× 100 matrix) due to its high computational complexity. To extend the applicability of the approach to large scale problems, we propose an accelerated gradient algorithm (AGA). Numerical results show that proposed algorithm can reliably solve a wide range of large scale problems in a shorter time than SDP solvers. Moreover, algorithms applied to a fairly large size real world dataset and results are provided.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064606","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064606","convex optimization;low rank matrix recovery;nuclear norm minimization;topic models","Accuracy;Computational complexity;Convergence;Convex functions;Minimization;Optimization;Sparse matrices","computer vision;convex programming;document handling;gradient methods;image classification;statistical analysis","accelerated gradient algorithm;computer vision;constrained nuclear norm minimization;convex optimization;document classification;exact rank recovery;semidefinite programming;topic models","","1","","20","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Methods for learning adaptive dictionary in underdetermined speech separation","T. Xu; W. Wang","Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, United Kingdom","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Underdetermined speech separation is a challenging problem that has been studied extensively in recent years. A promising method to this problem is based on the so-called sparse signal representation. Using this technique, we have recently developed a multi-stage algorithm, where the source signals are recovered using a pre-defined dictionary obtained by e.g. the discrete cosine transform (DCT). In this paper, instead of using the pre-defined dictionary, we present three methods for learning adaptive dictionaries for the reconstruction of source signals, and compare their performance with several state-of-the-art speech separation methods.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064610","Underdetermined blind speech separation;adaptive dictionary learning;sparse representation","Dictionaries;Discrete cosine transforms;Signal processing algorithms;Source separation;Speech;Vectors","signal reconstruction;source separation;speech processing","adaptive dictionary;discrete cosine transform;multistage algorithm;source signal reconstruction;sparse signal representation;underdetermined speech separation","","4","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"3D Goods allocation in warehouse with L-GEM based 3-D RFID positioning","W. W. Y. Ng; L. Lin; P. P. K. Chan; D. S. Yeung","Machine Learning and Cybernetic Research Center, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","1","","324","329","Radio frequency identification (RFID) technology has a wide range of industrial applications because of its low cost. In this paper, RFID is used for indoor object positioning system and we focus on the scenario of goods allocation in a warehouse. An Radial Basis Function Neural Network (RBFNN) is trained via a minimization of the Localized Generalization Error (L-GEM) to learn the object location based on received RFID signals from multiple RFID readers. Goods are stacked in 3-Dimensional ways in a warehouse, the RBFNN outputs 3-D vectors as the predicted locations of target goods. The proposed method is robust to uncertainty and changes in environment. Using MATLAB simulations, the experimental result shows that the proposed method yields an efficient indoor positioning.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016745","3D Indoor Positioning;L-GEM;RBFNN;RFID","Accuracy;Cybernetics;Machine learning;Neurons;Noise;Radiofrequency identification;Training","goods distribution;radial basis function networks;radiofrequency identification;warehouse automation","3D RFID positioning;3D goods allocation;L-GEM;MATLAB simulations;RFID readers;RFID signals;indoor object positioning system;localized generalization error;radial basis function neural network;radio frequency identification;warehouse","","2","","15","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Two Stage Classifier Chain Architecture for efficient pair-wise multi-label learning","D. Gjorgjevikj; G. Madjarov","FEEIT, Ss. Cyril and Methodius University, Skopje, Macedonia","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","A common approach for solving multi-label learning problems using problem-transformation methods and dichotomizing classifiers is the pair-wise decomposition strategy. One of the problems with this approach is the need for querying a quadratic number of binary classifiers for making a prediction that can be quite time consuming, especially in learning problems with large number of labels. To tackle this problem we propose a Two Stage Classifier Chain Architecture (TSCCA) for efficient pair-wise multi-label learning. Six different real-world datasets were used to evaluate the performance of the TSCCA. The performance of the architecture was compared with six methods for multi-label learning and the results suggest that the TSCCA outperforms the concurrent algorithms in terms of predictive accuracy. In terms of testing speed TSCCA shows better performance comparing to the pair-wise methods for multi-label learning.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064599","Multi-label learning;classifier chains;two stage architecture","Computational complexity;Computational modeling;Computer architecture;Predictive models;Testing;Training","learning (artificial intelligence);pattern classification","TSCCA;dichotomizing classifiers;learning problems;pairwise decomposition strategy;pairwise multilabel learning;problem transformation methods;quadratic number;two stage classifier chain architecture","","1","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A randomized heuristic for kernel parameter selection with large-scale multi-class data","T. J. Hansen; T. J. Abrahamsen; L. K. Hansen","Section for Cognitive Systems, DTU Informatics, Technical University of Denmark, Denmark","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Over the past few years kernel methods have gained a tremendous amount of attention as existing linear algorithms can easily be extended to account for highly non-linear data in a computationally efficient manner. Unfortunately most kernels require careful tuning of intrinsic parameters to correctly model the distribution of the underlying data. For large-scale problems the multiplicative scaling in time complexity imposed by introducing free parameters in a cross-validation setup will prove computationally infeasible, often leaving pure ad-hoc estimates as the only option. In this contribution we investigate a novel randomized approach for kernel parameter selection in large-scale multi-class data. We fit a minimum enclosing ball to the class means in Reproducing Kernel Hilbert Spaces (RKHS), and use the radius as a quality measure of the space, defined by the kernel parameter. We apply the developed algorithm to a computer vision paradigm where the objective is to recognize 72.000 objects among 1.000 classes. Compared to other distance metrics in the RKHS we find that our randomized approach provides better results together with a highly competitive time complexity.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064582","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064582","","Accuracy;Approximation algorithms;Approximation methods;Clustering algorithms;Complexity theory;Kernel;Support vector machines","Hilbert spaces;computational complexity;computer vision;pattern classification","ad hoc estimates;computer vision paradigm;kernel parameter selection;large scale multiclass data;linear algorithms;minimum enclosing ball;multiplicative scaling;randomized heuristic;reproducing kernel Hilbert spaces;time complexity","","0","","15","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Bayesian linear regression for Hidden Markov Model based on optimizing variational bounds","S. Watanabe; A. Nakamura; Biing-Hwang Juang","NTT Communication Science Laboratories, NTT Corporation, Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Linear regression for Hidden Markov Model (HMM) parameters is widely used for the adaptive training of time series pattern analysis especially for speech processing. This paper realizes a fully Bayesian treatment of linear regression for HMMs by using variational techniques. This paper analytically derives the variational lower bound of the marginalized log-likelihood of the linear regression. By using the variational lower bound as an objective function, we can optimize the model topology and hyper-parameters of the linear regression without controlling them as tuning parameters; thus, we realize linear regression for HMM parameters in a non-parametric Bayes manner. Experiments on large vocabulary continuous speech recognition confirm the generalizability of the proposed approach, especially for small quantities of adaptation data.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064605","","Bayesian methods;Data models","hidden Markov models;regression analysis;speech recognition;time series","Bayesian linear regression;Bayesian treatment;HMM;adaptive training;hidden Markov model;marginalized log-likelihood;speech processing;time series pattern analysis;variational bounds;variational technique;vocabulary continuous speech recognition","","5","","24","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Disturbance rejection using error estimation in neural network controller design","P. P. K. Chan; B. Peng; W. W. Y. Ng; D. S. Yeung","Machine Learning and Cybernetic Research Center, School of Computer Science and Engineering, South China, University of Technology, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1220","1225","Disturbance rejection is an important factor in evaluating the performance of a control system. By using error estimations, we expand a virtual area among actual error points in the error space which is composed of runtime errors and their derivatives. Rather than driving our neural network controller (NNC) with actual error signals, we utilize virtual error signals under different expanding parameters. Simulations have successfully shown that out method could resist unexpected disturbance in many cases.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016931","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016931","Disturbance rejection;Error estimations;Intelligent control;Neural network controller;Sensitivity","Artificial neural networks;Chaos;Control systems;Cybernetics;Error analysis;Machine learning","control system synthesis;estimation theory;neurocontrollers","control system;disturbance rejection;error estimation;neural network controller design;performance evaluation;virtual error signals","","0","","22","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"A block-based approach to adaptively bias the weights of adaptive filters","L. A. Azpicueta-Ruiz; M. Lázaro-Gredilla; A. R. Figueiras-Vidal; J. Arenas-García","Dept. Signal Theory and Commun., Univ. Carlos III de Madrid, Spain","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Adaptive filters are crucial in many signal processing applications. Recently, a simple configuration was presented to introduce a bias in the estimation of adaptive filters using a multiplicative factor, showing important gains in terms of mean square error with respect to standard adaptive filter operation, mainly for low signal to noise ratios. In this paper, we modify that scheme to obtain further advantages by splitting the adaptive filter coefficients into non-overlapping blocks, and employing a different multiplicative factor for the coefficients in each block. In this way, bias vs variance compromise is managed independently in each block, allowing an enhancement if the energy of the unknown system is non-uniformly distributed. In order to give some insight on the behavior of the scheme, a theoretical analysis of the optimal scaling factors is developed. In addition, several sets of experiments are included to widely study the new scheme performance.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064609","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064609","Adaptive filters;biased estimation;combination of filters;sparse system identification","Estimation;Gain;Indexes;Proposals;Signal to noise ratio;Steady-state","adaptive filters;mean square error methods","adaptive filter;biased estimation;block-based approach;mean square error;multiplicative factor;nonoverlapping block;optimal scaling factor;signal processing;signal-to-noise ratio","","4","","10","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A Bayesian approach to tracking with kernel recursive least-squares","M. Lázaro-Gredilla; S. Van Vaerenbergh; I. Santamaría","Department of Communications Engineering, University of Cantabria, Spain","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper we introduce a kernel-based recursive least-squares (KRLS) algorithm that is able to track nonlinear, time-varying relationships in data. To this purpose we first derive the standard KRLS equations from a Bayesian perspective (including a principled approach to pruning) and then take advantage of this framework to incorporate forgetting in a consistent way, thus enabling the algorithm to perform tracking in non-stationary scenarios. In addition to this tracking ability, the resulting algorithm has a number of appealing properties: It is online, requires a fixed amount of memory and computation per time step and incorporates regularization in a natural manner. We include experimental results that support the theory as well as illustrate the efficiency of the proposed algorithm.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064585","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064585","Bayesian inference;adaptive filtering;forgetting;kernel recursive-least squares;tracking","Bayesian methods;Dictionaries;Equations;Joints;Kernel;Signal processing algorithms;Vectors","Bayes methods;adaptive filters;least squares approximations;tracking","Bayesian approach;adaptive filtering;kernel-based recursive least-squares algorithm;nonlinear relationship tracking;principled approach;pruning;time-varying relationship tracking","","7","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Sensitivity based Growing and Pruning method for RBF network in online learning environments","P. P. K. Chan; X. R. Wu; W. W. Y. Ng; D. S. Yeung","Machine Learning and Cybernetic Research Center, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1107","1112","How to define the architecture of classifiers dynamically is one of the major research topics in online learning. This paper presents a new online learning algorithm for Radial Basis Function Network named Sensitivity Based Neurons Growing and Pruning Method for RBF network (SBGAP). The performance of SBGAP is evaluated experimentally by comparing accuracy and the number of neurons with the existing methods. The experimental results show that SBGAP achieve litter higher accuracy with fewer hidden units in most situations.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016934","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016934","Decouple Extended Kalman Filter (DEKF);L-GEM;SBGAP;Sensitivity","Accuracy;Heart;Machine learning;Neurons;Radial basis function networks;Sensitivity;Training","learning (artificial intelligence);pattern classification;radial basis function networks","RBF network;SBGAP;classifier architecture;online learning algorithm;pruning method;radial basis function network;sensitivity based neuron growing","","2","","13","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Fast alternating volume maximization algorithm for blind separation of non-negative sources","T. H. Chan; Chang-Jin Song; A. Ambikapathi; C. Y. Chi; W. K. Ma","Inst. Commun. Eng., National Tsing Hua Univ., Hsinchu, Taiwan, 30013","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","We recently reported an iterative non-negative blind source separation (nBSS) method, called convex analysis of mixtures of nonnegative sources via alternating volume maximization (CAMNSAVM) [1], and demonstrated that it provides promising separation performance in image analysis. Nonetheless, the amount of data may be quite large in practical applications, and this may limit the real-time applicability of CAMNS-AVM. In this paper, we propose a fast CAMNS-AVM algorithm involving three complexity reduction methods, specifically problem equivalence, redundant constraints removal, and customized algorithm implementation. The problem equivalence provides sufficiency in solving one linear program (LP) for each partial volume maximization problem, rather than the two LPs required by the original CAMNS-AVM. Then, we remove redundant constraints of each LP involved in CAMNS-AVM by using Quickhull algorithm to enumerate all the extreme points of the constraint-set-constructed convex hull. Finally, we implement a customized primal-dual interior-point method (IPM) for LP. Some Monte Carlo simulation results demonstrate that the fast CAMNS-AVM algorithm is thirty times more computationally efficient than the original CAMNS-AVMalgorithm, without any performance loss.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064571","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064571","Alternating volume maximization;Complexity reduction;Interior-point method;Linear programming;Non-negative blind source separation","Algorithm design and analysis;Blind source separation;Computational complexity;Linear matrix inequalities;Signal processing algorithms;Vectors","Monte Carlo methods;blind source separation;optimisation","CAMNS-AVM algorithm;Monte Carlo simulation;Quickhull algorithm;complexity reduction method;constraint-set-constructed convex hull;convex analysis;customized algorithm;customized primal-dual interior-point method;image analysis;iterative nonnegative blind source separation;linear program;partial volume maximization problem;redundant constraint;volume maximization algorithm","","0","","17","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Compact and robust fisher descriptors for large-scale image retrieval","Huiwen Cai; Xiaoyan Wang; Yangsheng Wang","Institute of Automation, Chinese Academy of Sciences 100190 Beijing, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Vector of locally aggregated descriptors (VLAD) has overcome the lossy quantization of bag-of-words model (BOW), but its dimensionality is high for direct use. We reduce the dimensionality of VLAD by a special coding scheme. First descriptors are clustered, and then linear discriminant analysis (LDA) is performed separately within each cluster. For different cluster, we allow different dimensionality but retain the same discriminant power, aiming at optimization of total dimensionality. Furthermore, we use each feature's nearest set of cluster centers as its expression bases, which is chosen using nearest neighbor distance ratio, so that the correspondence between a feature and its nearest set is more stable. The goal of the above scheme is to adapt the feature representation to distribution of feature classes in each cluster and distribution of cluster centers in feature space. Experiments demonstrate that our approach outperforms the state-of-the-art in computational complexity, accuracy, and robustness.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064624","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064624","Linear Discriminant Analysis;Vector of Locally Aggregated Descriptors","Clustering algorithms;Computational complexity;Eigenvalues and eigenfunctions;Encoding;Principal component analysis;Training;Vectors","image coding;image retrieval;quantisation (signal)","Fisher descriptor;VLAD dimensionality;bag-of-words model;coding scheme;large-scale image retrieval;linear discriminant analysis;lossy quantization;nearest neighbor distance ratio;vector of locally aggregated descriptor","","1","","14","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Second order impropriety based complex-valued algorithm for frequency-domain blind separation of convolutive speech mixtures","F. Cong; Qiu-Hua Lin; Peng Jia; Xizhi Shi; T. Ristaniemi","Department of Mathematical Information Technology, University of Jyv&#x00E4;skyl&#x00E4;, 40014, Finland","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The performance of the complex-valued blind source separation (BSS) is studied in the frequency domain approach to separate convolutive speech mixtures. In this context, the strong uncorrelating transform (SUT) and complex maximization of non-Gaussianity (CMN) do not produce satisfactory separation results since their assumptions about the independence among the frequency-domain complex-valued sources and the different diagonal elements of the pseudo-covariance of those sources are not met at each frequency bin. The proposed strong second order statistics (SSOS) algorithm exploits the second order impropriety of the frequency-domain complex-valued sources with the assumption that the complex-valued sources are improper and uncorrelated, and can well separate the mixtures at about 50% of frequency bins, outperforming SUT and CMN. Thus, it is promising to recover the time-domain speech sources by combing SSOS and the following indeterminacy correction in the frequency domain approach to separate convolutive speech mixtures.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064589","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064589","complex-valued BSS;convolutive speech;frequency domain;improper;second order","Correlation;Source separation;Speech;Time domain analysis;Time frequency analysis;Vectors","blind source separation;frequency-domain analysis;optimisation;speech processing;statistical analysis;time-domain analysis;transforms","blind source separation;complex maximization;complex-valued algorithm;convolutive speech mixture separation;convolutive speech mixtures;frequency-domain blind separation;nonGaussianity;pseudo-covariance;second order impropriety;strong second order statistics algorithm;strong uncorrelating transform;time-domain speech source recovery","","2","","24","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Evolutionary neural network for ghost in Ms. Pac-Man","J. Y. Dai; Y. Li; J. F. Chen; F. Zhang","Machine Learning Center, Faculty of Mathematics and Computer Science, Hebei University, Baoding 071002, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","2","","732","736","Ms. Pac-Man is a popular chasing and evading game and the ghost character in the game is controlled by script. This article evolved an evolutionary neural network for the red ghost to chase Pac-Man. Red ghost' position, Pac-Man's position and Pac-Man's state are considered to be the inputs of the neural network, and the output is the direction of Red ghost to move in the next step. We also proposed a fitness function to raise capture ability in evolution so that the Red ghost learns by itself in simulation. Experimental results show that the agent learns well and plays better in teamwork than the traditional script controlled ghost.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016831","Chasing and evading game;Evolutionary neural network;Game AI;Pac-Man","Biological cells;Biological neural networks;Cybernetics;Games;Learning systems;Machine learning;Teamwork","computer games;evolutionary computation;neural nets;team working","Ms.Pac-Man game;Red ghost character;capture ability;evolutionary neural network;teamwork","","2","","15","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Noise reduction using modified phase spectra and Wiener Filter","Xin Dang; T. Nakai","Dept. of Electrical and Electronic Engineering, Graduate School of Engineering, Shizuoka Univ. 3-5-1, Johoku, Naka-ku Hamamatsu, 432-8561 Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","In this paper our aim is to investigate a modified Wiener filter for the enhancement of speech that has been corrupted by fluctuating noise. In real noise environment, where the SNR of speech maybe fluctuating about 5 to 10dB, because typical speech enhancement methods always estimate the noise power spectrum directly by the average noise power spectrum of the pauses in speech, but there still some error and it is impossible to track the noise in speech interval. In order to settle this problem, our proposed method estimates the noise spectrum in the form of Posteriori SNR according to its Gaussian statistical model and track the noise spectrum form degraded speech directly and changes at every frame in the noise reduction processing of speech. Then use an iterative structure contains noise estimation, modified wiener filter and phase spectrum. Finally, the performance of the proposed method was tested in 4 kinds of fluctuating noises, and resulting in improved results over classical MMSE algorithms at the low fluctuating SNR.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064552","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064552","Modified Wiener filter;noise estimation;noise reduction;phase spectrum;spectrum estimation","Estimation;Noise measurement;Signal to noise ratio;Speech;Speech enhancement;Wiener filter","Gaussian processes;Wiener filters;iterative methods;signal denoising;speech enhancement","Gaussian statistical model;MMSE algorithm;Wiener filter;fluctuating noise;iterative structure;modified phase spectra;noise power spectrum estimation;noise reduction processing;noise tracking;phase spectrum;posteriori SNR;speech enhancement","","0","","9","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Efficiency of applying virtual reference tag to neural network based RFID indoor positioning method","W. W. Y. Ng; H. L. Ding; P. P. K. Chan; D. S. Yeung","Machine Learning and Cybernetic Research Center, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","1","","447","453","With the growth of context-aware applications, indoor location positioning receives much attention. RFID is one of the most widely adopted wireless positioning technologies. This paper applies Radial Basis Function Neural Network (RBFNN) to estimate locations of objects based on RFID signal strengths. The architecture of RBFNN is selected via a minimization of the Localized Generalization Error (L-GEM) which selects RBFNN with better generalization ability to unseen samples. Virtual reference tags are adopted to improve positioning performance without additional cost and RF interference. A nonlinear interpolation algorithm is proposed to calculate Received Signal Strength (RSS) for Virtual reference tags which is more reasonable than linear interpolation algorithm. Simulation experiments show that the proposed method outperforms existing method based RFID and virtual reference tags based on nonlinear interpolation algorithm improve positioning accuracy.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016744","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016744","Indoor Positioning;L-GEM;RBFNN;RFID;Virtual Reference Tag","Cybernetics;Interpolation;Machine learning;Neurons;Radiofrequency identification;Training;Wireless LAN","generalisation (artificial intelligence);interpolation;radial basis function networks;radiofrequency identification;telecommunication computing;ubiquitous computing","L-GEM;RBFNN;RFID signal strengths;context aware application;generalization ability;indoor location positioning;localized generalization error;neural network based RFID indoor positioning method;nonlinear interpolation algorithm;positioning accuracy improvement;radial basis function neural network;received signal strength;virtual reference tag;wireless positioning technologies","","5","","19","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Image segmentation via manifold spectral clustering","Cheolkon Jung; L. C. Jiao; Juan Liu; Yanbo Shen","Key Lab of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper, we propose a novel image segmentation method based on manifold spectral clustering. This method is based on the simple idea that image can be represented as the set of several manifolds which are also referred as super-pixels, and thus image segmentation problem are solved by manifold clustering. Based on this idea, we have designed a novel manifold spectral clustering method for image segmentation. The proposed method consists of four main steps: manifold generation, manifold representation, manifold distance, and manifold clustering. Experiments are performed on many different kinds of synthetic data and natural images to verify the effectiveness of the proposed method.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064557","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064557","","Algorithm design and analysis;Clustering algorithms;Euclidean distance;Histograms;Image color analysis;Image segmentation;Manifolds","image representation;image segmentation;pattern clustering","image segmentation;manifold distance;manifold generation;manifold representation;manifold spectral clustering;natural image;super-pixels;synthetic data","","0","","21","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Efficient temporal decomposition of local field potentials","A. J. Brockmeier; J. C. Príncipe; B. Mahmoudi; J. C. Sanchez","University of Florida, Electrical and Computer Engineering, Gainesville, 32611 USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Local field potentials (LFPs) arise from dendritic currents that are summed by the brain tissue's impedance. By assuming that the rhythms existing in the LFPs result from the coordinated neural activity of sparse and transient neural assemblies transformed by the neural tissue, we propose to recover these neural assemblies sources using an independent component analysis on segments of a single LFP channel. The corresponding source signals and the set of temporal filters that operate on them constitute an efficient time-frequency decomposition of the LFP. This decomposition has the potential to identify sources that are more statistically dependent with stimuli or single-cell activity than the raw signal. In this work we show preliminary results on a synthetic dataset and a real dataset recorded from a rats nucleus accumbens during a reward administering experiment. When compared with the standard time-frequency analysis, this computational model for LFP analysis is totally data-driven because the filters, which form the basis for the decomposition, are estimated directly from the data.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064598","ICA;local field potential;multiscale neural signal analysis;statistical decoding","Discrete Fourier transforms;Electric potential;Neurons;Robots;Time domain analysis;Time frequency analysis","bioelectric potentials;biological tissues;brain;cellular biophysics;decomposition;electric impedance;independent component analysis;medical signal processing;neurophysiology;time-frequency analysis","LFP channel;brain tissue impedance;dendritic current;independent component analysis;local field potential;neural activity;neural tissue;nucleus accumbens;single cell activity;sparse neural assembly;stimuli;synthetic dataset;temporal decomposition;temporal filter;time frequency analysis;time frequency decomposition;transient neural assembly","","0","","21","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Collaborative Kalman filters for vehicle tracking","X. Cao; Zhengrong Shi; P. Yan; X. Li","University of Science and Technology of China, Hefei, 230026, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Airborne vehicle tracking system is receiving increasing attention because of its high mobility and large surveillance scope. However, tracking multiple vehicles simultaneously on airborne platform is a challenging problem, owing to uncertain vehicle motion and visible frame-to-frame jitter caused by camera vibration. To address these problems, a new collaborative tracking framework is proposed. The framework consists of two level tracking processes: to track vehicles as groups, the higher level builds the relevance network and divides target vehicles into different groups; the relevance is calculated based on the status information of vehicles obtained by the lower level. This kind of group tracking takes into account the relevance of vehicles and reduces the impact of camera vibration, so the proposed method is applicable for multi-vehicle tracking in airborne videos. Experimental results demonstrate that the proposed method has better performance in terms of the tracking speed and accuracy compared to other existing approaches.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064581","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064581","Kalman filter;airborne platforms;group tracking;multi-target tracking;relevance network","Cameras;Histograms;Kalman filters;Target tracking;Vehicles;Videos","Kalman filters;target tracking;traffic engineering computing;vibrations;video signal processing","airborne vehicle tracking system;airborne videos;camera vibration;collaborative Kalman filters;collaborative tracking framework;frame-to-frame jitter;group tracking;multiple vehicle tracking;multivehicle tracking","","0","","12","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Irregular Tree-Structured Bayesian Network for image segmentation","K. Kampa; D. Putthividhya; J. C. Principe","Department of Electrical and Computer Engineering, University of Florida, Gainesville, 32611, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Unsupervised image segmentation algorithms rely heavily on a probabilistic smoothing prior to enforce local homogeneity in the segmentation results. The tree-structured prior [1, 2, 3] is one such prior which allows important multi-scale spatial correlations that exist in natural images to be captured. Two main types of tree structure prior have been previously proposed: 1) fixed quadtree structure [1], which suffers from “blockiness” in the segmentation results and 2) flexible tree structure [2, 3] which can adapt its structure to the natural object boundary but at a significant computational cost. This paper presents a novel probabilistic unsupervised image segmentation framework called Irregular Tree-Structured Bayesian Networks (ITSBN) which introduces the notion of irregular tree structure that combines the merits of the two previous approaches. As in [2, 3], more natural object boundaries can be modeled in our framework since a tree is learned for each input image. Our method, however, does not update the adaptive structure at every iteration which drastically reduces the computation required. We derive a time-efficient exact inference algorithm based on a sum-product framework using factor graphs [4]. Furthermore, a novel methodology for the evaluation of unsupervised image segmentation is proposed. By integrating non-parametric density estimation techniques with the traditional precision-recall framework, the proposed method is more robust to boundary inconsistency due to human subjects.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064604","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064604","Bayesian networks;Unsupervised image segmentation;graphical models;precision-recall framework;tree structure","Adaptation models;Bayesian methods;Computational modeling;Graphical models;Image color analysis;Image segmentation;Inference algorithms","graph theory;image segmentation;natural scenes;nonparametric statistics;probability;quadtrees;smoothing methods;unsupervised learning","ITSBN;adaptive structure;boundary inconsistency;factor graphs;fixed quadtree structure;flexible tree structure;irregular tree structure;irregular tree-structured Bayesian networks;multiscale spatial correlations;natural images;natural object boundary;nonparametric density estimation techniques;precision-recall framework;probabilistic smoothing;probabilistic unsupervised image segmentation framework;sum-product framework;time-efficient exact inference algorithm;tree structure prior;tree-structured prior;unsupervised image segmentation algorithms","","3","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Protein subcellular localization prediction based on profile alignment and Gene Ontology","Shibiao Wan; M. W. Mak; S. Y. Kung","Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hung Hom, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The functions of proteins are closely related to their subcellular locations. Computational methods are required to replace the laborious and time-consuming experimental processes for proteomics research. This paper proposes combining homology-based profile alignment methods and functional-domain based Gene Ontology (GO) methods to predict the subcellular locations of proteins. The feature vectors constructed by these two methods are recognized by support vector machine (SVM) classifiers, and their scores are fused to enhance classification performance. The paper also investigates different approaches to constructing the GO vectors based on the GO terms returned from InterProScan. The results demonstrate that the GO methods are comparable to profile-alignment methods and overshadow those based on amino-acid compositions. Also, the fusion of these two methods can outperform the individual methods.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064613","Gene Ontology;InterProScan;PairProSVM;Profile Alignment;Protein subcellular localization;Support vector machines","Amino acids;Databases;Ontologies;Proteins;Support vector machines;Training;Vectors","biology computing;genetics;molecular biophysics;proteins;proteomics;support vector machines","GO methods;GO vectors;InterProScan;amino-acid compositions;classification performance;computational methods;feature vectors;functional-domain based gene ontology;homology-based profile alignment methods;profile-alignment methods;protein functions;protein subcellular localization prediction;proteomics research;subcellular locations;support vector machine classifiers","","4","","19","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A study on the effect of scaling functions to feature weighting performance","W. W. Y. Ng; Q. C. Wang; R. J. Yang; P. P. K. Chan; D. S. Yeung","Machine Learning and Cybernetic Research Center, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1077","1081","In this paper, we perform a study on several data scaling functions for feature weighting. In our former study, we have proposed a feature weighting method based on the Localized Generalization Error Model (L-GEM). The function of weighting those inputs is influential to the performance of resulting classifiers. However, there are few researches focusing on how to use feature weights in a better way. In this paper, we study data scaling function for automatic image annotation with Radial Basis Function Neural Network (RBFNN). Experimental results show that a good data scaling functions yields a better image annotation performance for the same set of feature weights.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016930","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016930","Automatic image annotation;Data scaling function;Feature weighting;Localized Generalization Error Model;RBFNN","Accuracy;Classification algorithms;Cybernetics;Equations;Machine learning;Neurons;Testing","image processing;learning (artificial intelligence);radial basis function networks","L-GEM;Localized Generalization Error Model;automatic image annotation;data scaling functions;feature weighting performance;radial basis function neural network","","0","","20","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Implementation and evaluation of statistical parametric speech synthesis methods for the Persian language","S. Bahaadini; H. Sameti; S. Khorram","Speech Processing Lab, Department of Computer Engineering, Sharif University of Technology, Tehran, Iran","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Scattered and little research in the field of Persian speech synthesis systems has been performed during the last ten years. Comprehensive framework that properly implements and adapts statistical speech synthesis methods for Persian has not been conducted yet. In this paper, recent statistical parametric speech synthesis methods including CLUSTERGEN, traditional HMM-based speech synthesis and its STRAIGHT version, are implemented and adapted for Persian language. CCR test is carried out to compare these methods with each other and with unit selection method. Listeners Score samples based on CMOS. The methods were ranked by averaging the CCR scores. The results show that STRAIGHT-based system produces the best quality. Traditional HMM-based and unit selection are second and third in quality ranking. These approximately produce the same quality. Finally CLUSTERGEN produces the worst quality among these four systems.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064608","CCR test;Persian language;speech synthesis;statistical parametric;text to speech","Adaptation models;CMOS integrated circuits;Databases;Hidden Markov models;Speech;Speech synthesis;Training","hidden Markov models;natural language processing;speech synthesis","CLUSTERGEN;HMM-based speech synthesis;Persian language;Persian speech synthesis system;quality ranking;statistical parametric speech synthesis;statistical speech synthesis;unit selection","","3","","21","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A maximum likelihood approach for independent vector analysis of Gaussian data sets","J. Vía; M. Anderson; X. L. Li; T. Adalı","Dept. of Communications Engineering. University of Cantabria. Spain","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","This paper presents a novel algorithm for independent vector analysis (IVA) of Gaussian data sets. Following a maximum likelihood (ML) approach, we show that the cost function to be minimized by the proposed GML-IVA algorithm reduces to an estimate of the mutual information among the different sets of latent variables. The proposed method, which can be seen as a new generalization of canonical correlation analysis (CCA), is based on the sequential solution of different least squares problems obtained from the quadratic approximation of the non-convex IVA cost function. The convergence and performance of the proposed algorithm are illustrated by means of several simulation examples, including an application consisting in the joint blind source separation (J-BSS) of three color images.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064584","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064584","Independent vector analysis (IVA);canonical correlation analysis (CCA);joint blind source separation (J-BSS);second-order statistics (SOS)","Algorithm design and analysis;Approximation algorithms;Convergence;Cost function;Covariance matrix;Maximum likelihood estimation;Vectors","Gaussian processes;correlation methods;least squares approximations;maximum likelihood estimation","GML-IVA algorithm;Gaussian data set;canonical correlation analysis;color image;independent vector analysis;joint blind source separation;least squares problem;maximum likelihood approach;nonconvex IVA cost function;quadratic approximation","","5","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Dynamic base classifier pool for classifier selection in Multiple Classifier Systems","P. P. K. Chan; Q. Q. Zhang; W. W. Y. Ng; D. S. Yeung","Machine Learning and Cybernetics Research Center, School of Computer Science and Engineering, South China, University of Technology, Guangzhou 510006, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1093","1096","Multiple Classifier Systems (MCSs) are a method combining decisions of base classifiers. The set of the base classifiers is fixed in traditional MCSs. When applying MCSs in online learning environment, the base classifiers have to be updated frequently to adapt the change of the environment. However, updating classifiers is time consumed, especially when the number of base classifier is big. Therefore, a selection method with dynamic base classifier pool is proposed in this paper. Rather than updating the existing base classifiers, a new base classifier is added to MCSs. The new base classifier is trained by using the samples which far away from the training set. Experimental results show that that the proposed method outperforms the MCSs with the fix base classifier pool in term of accuracy.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016933","Classifier selection;Dynamic base classifier pool;Dynamically adding;Neighborhood","Accuracy;Cancer;Cybernetics;Diversity reception;Machine learning;Testing;Training","learning (artificial intelligence);pattern classification","MCS;classifier selection;dynamic base classifier pool;multiple classifier systems;online learning environment","","0","","10","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Kernel entropy component analysis: New theory and semi-supervised learning","R. Jenssen","Department of Physics and Technology, University of Troms&#x00F8;, Norway","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","A new theory for kernel entropy component analysis (kernel ECA) is developed, based on distribution dependent convolution operators, ensuring the validity of the method for any positive semi-definite kernel. Furthermore, a new semi-supervised kernel ECA classification method is derived with positive results compared to the state-of-the-art.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064626","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064626","Kernel entropy component analysis;classification;convolution operators;semi-supervised;spectral","Convolution;Eigenvalues and eigenfunctions;Entropy;Indexes;Kernel;Principal component analysis;Vectors","entropy;learning (artificial intelligence);pattern classification;principal component analysis","ECA classification method;distribution dependent convolution operators;kernel entropy component analysis;semisupervised learning","","4","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"User and device localization using probabilistic device log trilateration","G. Bouchard; L. R. Ulloa; J. M. Andreoli; V. Ciriza; O. Zoeter","Xerox Research Centre Europe, 6 Chemin de Maupertuis, 38240 Meylan, France","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","This paper describes a method to learn demand models and find relative locations of users and devices based on usage logs only. It therefore allows the monitoring and optimization of infrastructures using a signal that is often already available. Absolute positions can be obtained by combining the usage logs with a small number of hand-labeled positions of users and/or devices. The method exploits the characteristic that each time a user uses the infrastructure he typically interacts with the device that is closest to his physical position. This gives information about closest pairs. Special jobs that cannot be performed on all devices, the temporary unavailability of devices, or other reasons that prevent users from using the closest device, allow relative locations to be determined based on relationships beyond pairs, hence breaking the symmetries and ambiguities that would remain if only pairs could be used. This procedure is similar in spirit to the process of trilateration: a geometric method for determining the intersections of spheres given their centers and radii. Experiments show that a probabilistic model combined with Bayesian inference makes it possible to infer user and device locations relatively accurately in many settings and gives sensible descriptions of uncertainty in cases the logs do not provide enough information.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064591","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064591","","Image edge detection;Legged locomotion;Markov processes;Printers;Probabilistic logic;Switches;Uncertainty","Bayes methods;inference mechanisms;mobile computing;probability","Bayesian inference;device localization;infrastructure usage logs;probabilistic device log trilateration;sphere intersection;user localization","","0","","9","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A convolutive spectral decomposition approach to the separation of feedback from target speech","G. J. Mysore; P. Smaragdis","Advanced Technology Labs, Adobe Systems Inc., USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Feedback is a common problem in teleconferencing systems. Typical usage of an adaptive filter can be effective for feedback reduction but it relies on the presence of such a filter on the side of the far speaker in order to reduce feedback on the side of the near speaker. In order to avoid this reliance on the far speaker's setup, we can use an adaptive filter on the side of the near speaker. Unfortunately, due to non-linear speech coding typically used during speech transmission, these filters perform poorly in this situation. In this paper, we present a novel probabilistic method, using a non-negative convolutive decomposition of spectrogram data to perform feedback reduction by posing the problem as a source separation problem. Our method is robust to non-linear speech coding as well as continuous double-talk, which often presents a challenge to adaptive filters. We compare our method to the use of an adaptive filter and show superior results with respect to standard source separation metrics.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064559","Feedback Reduction;Non-Negative Spectrogram Factorization;Source Separation","Adaptation models;Interference;Reverberation;Spectrogram;Speech;Speech coding;Speech processing","adaptive filters;source separation;speech coding","adaptive filter;continuous double-talk;convolutive spectral decomposition;feedback reduction;nonlinear speech coding;nonnegative convolutive decomposition;probabilistic method;source separation problem;spectrogram data;speech transmission;standard source separation metrics;target speech;teleconferencing system","","0","","8","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Parametric validity index of clustering for microarray gene expression data","Rui Fa; A. K. Nandi","Signal Processing and Communications Research Group, Department of Electrical Engineering and Electronics, The University of Liverpool, L69 3GJ, UK","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","An important area of genomic signal processing is microarray gene expression data analysis, which employs clustering algorithms to group individual genes or samples in a population. Due to the non-unique nature of clustering, the cluster validation is necessary for evaluating the results of clustering algorithms. In this paper, we propose a parametric validity index (PVI) which employs two tunable parameter α and β to control the proportions of objects being taken into account to calculate the dissimilarities. There are two advantages of the proposed PVI: on one hand, its computational complexity is low, and on the other hand, it has flexibility of tuning the parameters to meet different datasets, especially the microarray datasets. The PVI can be averaged over a range of values of α and β. We investigate the new PVI for assessing five clustering algorithms in four microarray datasets. The experimental results appear to suggest that the proposed PVI has relatively robust performance and provides fairly accurate judgements.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064570","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064570","","Aerospace electronics;Algorithm design and analysis;Clustering algorithms;Correlation;Gene expression;Indexes;Principal component analysis","biology computing;computational complexity;genetics;pattern clustering","cluster validation;computational complexity;genomic signal processing;microarray datasets;microarray gene expression data clustering;parametric validity index","","2","","17","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A robust point matching algorithm for non-rigid registration using the Cauchy-Schwarz divergence","E. Hasanbelliu; L. S. Giraldo; J. C. Príncipe","Electrical and Computer Engineering Department, University of Florida, Gainesville, 32611, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper, we describe an algorithm that provides both rigid and non-rigid point-set registration. The point sets are represented as probability density functions and the registration problem is treated as distribution alignment. Using the PDFs instead of the points provides a more robust way of dealing with outliers and noise, and it mitigates the need to establish a correspondence between the points in the two sets. The algorithm operates on the distance between the two PDFs to recover the spatial transformation function needed to register the two point sets. The distance measure used is the Cauchy-Schwarz divergence. The algorithm is robust to noise and outliers, and performswell in varying degrees of transformations and noise.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064593","Cauchy-Schwarz divergence;information theoretic learning;non-rigid registration;shape matching","Algorithm design and analysis;Bandwidth;Feature extraction;Kernel;Noise;Robustness;Shape","image matching;image registration;probability","Cauchy-Schwarz divergence;PDF;distribution alignment;non-rigid registration;probability density functions;robust point matching algorithm","","1","","17","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"An asymptotic analysis of Bayesian state estimation in hidden Markov models","K. Yamazaki","Precision and Intelligence Laboratory, Tokyo Institute of Technology, G5-19 4259 Nagatsuta, Midori-ku Yokohama, Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Hidden Markov models are widely used for modeling underlying dynamics of sequence data. The accurate hidden state estimation is one of the central issues on practical application since the dynamics is described as a sequence of hidden states. However, while there are many studies on parameter estimation, mathematical properties of the hidden state estimation have not been clarified yet. The present paper analyzes the accuracy of a Bayesian hidden state estimation and shows that the dominant order of an error function depends on redundancy of states.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064623","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064623","Bayes statistics;Hidden Markov models;algebraic geometry;asymptotic analysis;latent variable estimation","Accuracy;Analytical models;Bayesian methods;Data models;Hidden Markov models;Mathematical model;State estimation","Bayes methods;estimation theory;hidden Markov models;mathematical analysis","Bayesian state estimation;asymptotic analysis;data sequence;error function;hidden Markov models;hidden state estimation;mathematical properties;parameter estimation","","1","","12","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Fast multi-class sample reduction for speeding up support vector machines","Jingnian Chen; C. L. Liu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, 95 Zhongguancun East Road, Beijing 100190, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Despite the superior classification performance of support vector machines (SVMs), training SVMs on large datasets is still a challenging problem. Sample reduction methods have been proposed and shown to reduce the training complexity significantly, but more or less trade off the generalization performance. This paper presents an efficient sample reduction method for multi-class classification using one-vs-rest SVMs, called Multi-class Sample Selection (MUSS). For each binary one-vs-rest classification problem, positive samples and negative samples are selected based on the distances from the cluster centers of positive class, assuming that positive samples with large distances from the positive centers and negative samples with small distances from the positive centers are near the classification boundary. The intention of clustering is to improve the computation efficiency of sample selection, other than to select from cluster centers as previous methods did. Experiments on a wide variety of datasets demonstrate the superiority of the proposed MUSS over other competitive algorithms in respect of the tradeoff between reduced sample size and classification performance. The experimental results show that MUSS also works well for binary classification problems.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064636","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064636","Clustering;Multi-class classification;SVM;Sample selection","Accuracy;Algorithm design and analysis;Clustering algorithms;Complexity theory;Glass;Support vector machines;Training","generalisation (artificial intelligence);pattern classification;pattern clustering;support vector machines","binary one-vs-rest classification problem;cluster centers;competitive algorithms;fast multiclass sample reduction methods;multiclass classification;multiclass sample selection;support vector machines;training complexity","","1","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"False alarm reduction by improved filler model and post-processing in speech keyword spotting","A. Tavanaei; H. Sameti; S. H. Mohammadi","Department of Computer Engineering, Sharif University of Technology, Tehran, Iran","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","This paper proposes four methods for improving the performance of keyword spotting (KWS) systems. Keyword models are usually created by concatenating the phoneme HMMs and garbage models consist of all phonemes HMMs. We present the results of investigations involving the use of skips in states of keyword HMMs and we focus on improving the hit ratio; then for false alarm reduction in KWS we model the words that are similar to keywords and we create HMMs for highly frequent words. These models help to improve the performance of the filler model. Two post-processing steps based on phoneme and word probabilities are used on the results of KWS to reduce the false alarms. We evaluate the performance of the improved keyword spotting in FarsDat corpus and compare the approaches. The presented techniques depict better performances than the popular KWS systems.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064588","False alarm;False alarm reduction;Filler model;Hit ratio;Keyword model;Keyword spotting","Accuracy;Computational modeling;Databases;Grammar;Hidden Markov models;Speech;Speech recognition","hidden Markov models;natural language processing;speech recognition","FarsDat corpus;HMM;false alarm reduction;garbage models;improved filler model;keyword spotting systems;phonemes;post processing;speech keyword spotting","","0","","12","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Underdetermined convolutive blind source separation using a novel mixing matrix estimation and MMSE-based source estimation","J. Cho; J. Choi; C. D. Yoo","Div. of EE, Korea Advanced Institute of Science & Technology, Korea","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","This paper considers underdetermined blind source separation of super-Gaussian signals that are convolutively mixed. The separation is performed in three stages. In the first stage, the mixing matrix in each frequency bin is estimated by the proposed single source detection and clustering (SSDC) algorithm. In the second stage, by assuming complex-valued super-Gaussian distribution, the sources are estimated by minimizing a mean-square-error (MSE) criterion. Special consideration is given to reduce computational load without compromising accuracy. In the last stage, the estimated sources in each frequency bin are aligned for recovery. In our simulations, the proposed algorithm outperformed conventional algorithm in terms of the mixing-error-ratio and the signal-to-distortion ratio.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064629","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064629","","Clustering algorithms;Estimation;Frequency estimation;Signal processing algorithms;Silicon;Source separation;Vectors","blind source separation;matrix algebra","MMSE-based source estimation;complex-valued super-Gaussian distribution;frequency bin;mean square error criterion;mixing error ratio;mixing matrix estimation;signal-to-distortion ratio;super-Gaussian signal;underdetermined convolutive blind source separation","","5","","11","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"IVA for multi-subject FMRI analysis: A comparative study using a new simulation toolbox","J. T. Dea; M. Anderson; E. Allen; V. D. Calhoun; T. Adalı","University of Maryland Baltimore County, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Joint blind source separation (JBSS) techniques have proven to be a natural solution for achieving source separation of multiple data sets. JBSS algorithms, such as independent vector analysis (IVA), are a promising alternative to independent component analysis (ICA) based approaches for the analysis of multi-subject functional magnetic resonance imaging (fMRI) data. Unlike ICA, little is known about the effectiveness of JBSS methods for fMRI analysis. In this paper, a new fMRI simulation toolbox (SimTB) is used to simulate multi-subject realistic fMRI datasets that include inter-subject variability. We study the performance of two JBSS algorithms representing two different approaches to the problem: (1) a recently proposed IVA algorithm combining second-order and higher-order statistics denoted by IVA-GL; and (2) a JBSS solution found by jointly diagonalizing cross-cumulant matrices denoted IVA-GJD. We compare these two JBSS algorithms with similar ICA algorithms implemented in the widely used group ICA for fMRI toolbox (GIFT). The results show that in addition to offering an effective solution for making group inferences, IVA algorithms provide superior performance in terms of capturing spatial inter-subject variability.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064618","IVA;fMRI;functional;group ICA;independent component analysis;independent vector analysis;simulation","Algorithm design and analysis;Approximation algorithms;Inference algorithms;Joints;Mutual information;Source separation;Vectors","biomedical MRI;blind source separation;medical signal processing","SimTB;functional magnetic resonance imaging;independent component analysis;independent vector analysis;joint blind source separation;multisubject FMRI analysis;simulation toolbox;spatial intersubject variability","","8","","21","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Detection of playfield with shadow and its application to player tracking","Y. Liu; Maozu Guo; Wanyu Liu","School of computer science and technology, Harbin institute of technology, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","Playfield detection is a key technology for content analysis in sports video, on which many semantic clue mining methods rely. However, shadow produced by substantial illumination change causes the general detection method fail and degenerate the performance of the following processing based on it. This paper presents a method for detecting playfield, which can find shadow region under the guidance of the intrinsic image proposed by Finlayson. Firstly, this method automatically finds the dominant color; secondly, according to the dominant color and the intrinsic image, it determines the playfield colors. At last, we apply it to player tracking in soccer video. Experimental results show that the proposed method can handle the problem brought by shadow and improve the performance of the application based on it.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064621","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064621","","Calibration;Gaussian distribution;Histograms;Image color analysis;Image segmentation;Lighting;Reflectivity","data mining;image colour analysis;object detection;object tracking;sport;video signal processing","content analysis;dominant color;intrinsic image;player tracking;playfield colors;playfield detection;semantic clue mining methods;shadow region;sports video;substantial illumination change","","0","","9","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Minimum classification error training with automatic setting of loss smoothness","H. Watanabe; J. Tokuno; T. Ohashi; S. Katagiri; M. Ohsaki","MASTAR Project, National Institute of Information and Communications Technology, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289, Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The loss function smoothness embedded in the Minimum Classification Error formalization increases the number of virtual training samples, enables high robustness to unseen samples, and well approximates the ultimate, minimum classification error probability status. However, a rational method for controlling smoothness has not yet been developed. To alleviate this long-standing problem, we propose a new method that automatically sets the loss function smoothness through Parzen kernel (window) width estimation with a cross-validation maximum likelihood method. Experiments clearly show our proposed method's high utility.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064575","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064575","Cross-validation maximum likelihood method;Loss smoothness;Minimum classification error;Parzen estimation","Error probability;Kernel;Mathematical model;Maximum likelihood estimation;Prototypes;Training","error statistics;maximum likelihood estimation;pattern classification","Parzen kernel width estimation;automatic setting;cross-validation maximum likelihood method;loss function smoothness;loss smoothness;minimum classification error formalization;minimum classification error probability status;minimum classification error training;virtual training samples;window width estimation","","2","","6","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A cloud computing service for fast audio source signal separation","T. Y. Liang; T. H. Wang; Meng-Te Chou; Shiou-Wen Chen","Department of Electrical Engineering, National Kaohsiung University of Applied Sciences, No.415, Chien-Kung Road, Taiwan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this study, we propose a cloud computing service for fast audio source signal separation. To implement this service, we have developed a GPU-based ICA (Independent Component Analysis) program by using CUDA software development toolkit (SDK). This program can rapidly separate n independent components from m sources which are composed of these components mixed by a random way. On the other hand, we also have implemented a web server to provide users with the service of fast audio signal separation. Users can upload their audio files onto this web server through the browser interface. After users click the execution command button in the web page, the web server will invoke the GPU-based ICA program to fast separate the independent audio signals from the uploaded files. Finally, users can download and play the wave files of the separated audio signals from the web server by clicking the hyperlink in the website.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064556","CUDA;Cloud computing;GPU;audio source separation;independent component analysis","Graphics processing unit;Independent component analysis;Instruction sets;Kernel;Source separation;Vectors;Web servers","Web sites;audio signal processing;cloud computing;computer graphic equipment;coprocessors;independent component analysis;software engineering;source separation","GPU-based ICA program;SDK;Web server;Website;audio source signal separation;browser interface;cloud computing service;independent component analysis;software development toolkit","","0","","11","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Speaker recognition with rival penalized EM training","A. Matza; Y. Bistritz","School of Electrical Engineering, Tel-Aviv University, 69978, Israel","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The paper considers speaker recognition with Gaussian mixture models trained by a rival penalized EM (RPEM) algorithm. Although RPEM was applied successfully to several pattern recognition problems, our attempt to apply the algorithm in its original form to speaker recognition was not successful. We modified it by adding a discriminative threshold to prevent over penalty on mixture components, and using it with batches of feature vectors rather than the original incremental mode. We applied the modified RPEM to train speaker models with the number of Gaussian mixture components adapted individually to each speaker and used it to perform some basic speaker recognition experiments. The experiments are very reassuring about using the modified RPEM as a training method for GMM based speaker recognition. In settings with limited amount of training data, not only that the algorithm showed nice convergence to reduced order speaker models, but the resulting reduced models achieved better recognition rates than the initial higher order models.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064597","GMM;RPEM;speaker recognition","Convergence;Data models;Mel frequency cepstral coefficient;Speaker recognition;Testing;Training;Vectors","Gaussian processes;pattern recognition;speaker recognition","Gaussian mixture component;Gaussian mixture model;incremental mode;pattern recognition problem;recognition rate;reduced order speaker model;rival penalized EM algorithm;rival penalized EM training;speaker recognition","","0","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Watching pattern distribution via massive character recognition","S. Uchida; W. Cai; A. Yoshida; Y. Feng","Kyushu University, Faculty of Information Science and Electrical Engineering, 744 Motooka, Nishi-ku, Fukuoka-shi, 819-0395, Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The purpose of this paper is to analyze how image patterns distribute inside their feature space. For this purpose, 832,612 manually ground-truthed handwritten digit patterns are used. Use of character patterns instead of general visual object patterns is very essential for our purpose. First, since there are only 10 classes for digits, it is possible to have an enough number of patterns per class. Second, since the feature space of small binary character images is rather compact, it is easier to observe the precise pattern distribution with a fixed number of patterns. Third, the classes of character patterns can be defined far more clearly than visual objects. Through nearest neighbor analysis on 832, 612 patterns, their distribution in the 32 × 32 binary feature space is observed quantitatively and qualitatively. For example, the visual similarity of nearest neighbors and the existence of outliers, which are surrounded by patterns from different classes, are observed.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064640","character recognition;massive pattern recognition;nearest neighbor","Accuracy;Character recognition;Error analysis;Hamming distance;Prototypes;Visualization","character recognition;character sets","binary feature space;character pattern;ground-truthed handwritten digit pattern;image pattern;massive character recognition;nearest neighbor analysis;pattern distribution;visual object pattern","","0","","8","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Spontaneous facial expression recognition by using feature-level fusion of visible and thermal infrared images","Zhaoyu Wang; S. Wang","Key Lab of Computing and Communicating Software of Anhui Province, School of Computer Science and Technology, University of Science and Technology of China, Hefei, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper, we propose a spontaneous facial expression recognition method by using feature-level fusion of visible and thermal infrared facial images. Firstly, the appearance features of visible images and statistic parameters of thermal infrared difference images are extracted. Then, analysis of variance is adopted to select the optimal feature subsets from both visible and thermal ones. These selected features are combined as the input of a K-Nearest Neighbors classifier. We experimentally evaluate the effectiveness of the proposed method on USTC-NVIE database. The experimental results show that fusion of visible and thermal infrared features can improve the accuracy rate of negative expressions and reduce the discrepancy. Thus, it can improve the expression recognition performance.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064564","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064564","Spontaneous facial expression recognition;feature-level fusion;thermal infrared image;visible image","Accuracy;Active appearance model;Face recognition;Feature extraction;Image recognition;Shape;Vectors","face recognition;feature extraction;image classification;image fusion;infrared imaging","K-nearest neighbors classifier;USTC-NVIE database;feature-level fusion;spontaneous facial expression recognition;thermal infrared difference image extraction;thermal infrared images;visible infrared images","","1","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Combining object detection and brain computer interfacing: Towards a new way of subject-environment interaction","A. Robben; N. Chumerin; N. V. Manyakov; A. Combaz; M. van Vliet; M. M. Van Hulle","K.U.Leuven, Laboratorium voor Neuro- en Psychofysiologie, Campus Gasthuisberg, Herestraat 49, PO. Box 1021, B-3000, Belgium","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper, we present an application that is a synergy of two research disciplines: visual object detection (and localization) and brain-computer interfacing. The goal is to construct an alternative way for a person to select real objects in the environment, without using speech, or any other form of muscular activity. Due to the latter, our application is potentially useful for patients that suffer from severe motor impairments since it would enable them to engage in a high-level interaction process with objects.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064548","","Accuracy;Electroencephalography;Frequency estimation;Noise;Object detection;Training;Visualization","brain-computer interfaces;handicapped aids;object detection","brain computer interfacing;motor impairments;patients;subject-environment interaction;visual object detection","","0","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Stochastic kernel temporal difference for reinforcement learning","J. Bae; L. S. Giraldo; P. Chhatbar; J. Francis; J. Sanchez; J. Principe","Department of Electrical and Computer Engineering, University of Florida, Gainesville, 32611, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","This paper introduces a kernel adaptive filter using the stochastic gradient on temporal differences, kernel TD(λ), to estimate the state-action value function Q in reinforcement learning. Kernel methods are powerful for solving nonlinear problems, but the growing computational complexity and memory size limit their applicability on practical scenarios. To overcome this, the quantization approach introduced in [1] is applied. To help understand the behavior and illustrate the role of the parameters, we apply the algorithm on a 2-dimentional spatial navigation task. Eligibility traces are commonly applied in TD learning to improve data efficiency, so the relations of eligibility trace λ and step size and filter size are observed. Moreover, kernel TD (0) is applied to neural decoding of an 8 target center-out reaching task performed by a monkey. Results show the method can effectively learn the brain-state action mapping for this task.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064634","Temporal difference learning;adaptive filtering;kernel methods;reinforcement learning","Decoding;Kernel;Learning;Least squares approximation;Matched filters;Quantization;Signal processing algorithms","computational complexity;gradient methods;learning (artificial intelligence);stochastic processes","brain state action mapping;computational complexity;data efficiency;kernel adaptive filter;neural decoding;nonlinear problems;reinforcement learning;state action value function;stochastic gradient;stochastic kernel temporal difference;temporal differences","","4","","20","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Putting poses on manifold for action recognition","Xianbin Cao; Bo Ning; Pingkun Yan; Xuelong Li","Department of Computer Science and Technology, University of Science and Technology of China, Hefei, 230026, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In action recognition, bag of words based approaches have been shown to be successful, for which the quality of codebook is critical. This paper proposes a novel approach to select key poses for the codebook, which models the descriptor space utilizing manifold learning to recover the geometric structure of the descriptors on a lower dimensional manifold space. A PageRank based centrality measure is developed to select key poses on the manifold. In each step, a key pose is selected and the remaining model is modified to maximize the discriminative power of selected codebook. In classification, the ambiguity of each action couple is evaluated through cross validation. An additional subdivision will be executed for ambiguous pairs. Experiments on ut-tower dataset showed that our method is able to obtain better performance than the state-of-the-art methods.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064580","Action Recognition;Bag of Words;Centrality Measure;Key poses;Manifold Leaning","Computer vision;Histograms;Image motion analysis;Manifolds;Optical sensors;Support vector machines;Videos","gesture recognition;image classification;learning (artificial intelligence)","PageRank based centrality measure;action recognition;bag of word based approach;codebook;cross validation;descriptor space;discriminative power;geometric structure recovery;key pose selection;manifold learning;manifold space","","0","","15","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"An adaptive decoder from spike trains to micro-stimulation using kernel least-mean-squares (KLMS)","Lin Li; Il Memming Park; S. Seth; J. S. Choi; J. T. Francis; J. C. Sanchez; J. C. Príncipe","University of Florida, University of Miami, SUNY Downstate Medical Center and NYU-Poly, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","This paper proposes a nonlinear adaptive decoder for somatosensory micro-stimulation based on the kernel least mean square (KLMS) algorithm applied directly on the space of spike trains. Instead of using a binned representation of spike trains, we transform the vector of spike times into a function in reproducing kernel Hilbert space (RKHS), where the inner product of two spike time vectors is defined by a nonlinear cross intensity kernel. This representation encapsulates the statistical description of the point process that generates the spike trains, and bypasses the curse of dimensionality-resolution of the binned spike representations. We compare our method with two other methods based on binned data: GLM and KLMS, in reconstructing biphasic micro-stimulation. The results indicate that the KLMS based on RKHS for spike train is able to detect the timing, the shape and the amplitude of the biphasic stimulation with the best accuracy.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064603","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064603","Adaptive Neural decoder;KLMS;microstimulation;spike train","Decoding;Heuristic algorithms;Hilbert space;Integrated circuit modeling;Kernel;Neurons;Vectors","Hilbert spaces;adaptive decoding;least mean squares methods;medical signal processing;neurophysiology;nonlinear codes;statistical analysis","KLMS algorithm;kernel least-mean-squares;nonlinear adaptive decoder;nonlinear cross intensity kernel;reproducing kernel Hilbert space;somatosensory microstimulation;spike representation;spike time vector;spike train;statistical description","","4","","12","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"HMM-based Tianjin Dialect speech synthesis using bilateral question Set","Qiong Hu; Jianhua Tao; Shifeng Pan; Chunyu Zhao","Dept. of Electronic, Information and Electrical Engineering, Shanghai Jiaotong University, 200240, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","4","The main difference between Tianjin dialect and Mandarin is the tone change. However, because there is no pronunciation dictionary for Tianjin dialect and not all the tones follow the sandhi rules in a continuous utterance, we focus on improving the tone accuracy by using bilateral question set based on the traditional Mandarin synthesis system. By considering more contextual features in one question, we can obtain better splitting steps during clustering so that the models could be more precise. Through experiments, we select appropriate bilateral question set for both pith models and spectrum models. ABX test also shows that we could get more natural and accurate tones by using the bilateral question set than the ones using summarized rules for Tianjin Dialect.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064612","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064612","HTS;Question set;Tianjin dialect;speech synthesis","Indexes;Radio frequency;Speech synthesis","hidden Markov models;speech synthesis","HMM-based Tianjin dialect speech synthesis;Mandarin synthesis system;bilateral question set;continuous utterance;sandhi rules;summarized rules;tone change","","0","","8","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Persian language understanding using a two-step extended hidden vector state parser","a. Jabbari; o. Sameti; M. Hadi Bokaei","Speech Processing Lab, Department of Computer Engineering, Sharif University of Technology, Tehran, Iran","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The key element of a spoken dialogue system is a spoken language understanding (SLU) unit. Hidden Vector State (HVS) is one of the most popular statistical approaches employed to implement the SLU unit. This paper presents a two-step approach for Persian language understanding. First, a goal detector is used to identify the main goal of the input utterance. Second, after restricting the search space for semantic tagging, an extended hidden vector state (EHVS) parser is used to extract the remaining semantics in each subspace. This will mainly improve the performance of semantic tagger, while reducing the model complexity and training time. Moreover, the need for large amount of data will be reduced importantly due to lowering of data sparseness. Experiments are reported on a Persian corpus, the University Information Kiosk corpus. The experimental results show the effectiveness of the proposed approach compared to HVS and EHVS.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064607","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064607","Spoken language understanding;goal detector;semantic tagging;two-step approach","Accuracy;Educational institutions;Hidden Markov models;Mathematical model;Semantics;Support vector machines;Vectors","interactive systems;natural language processing;speech processing;statistical analysis","Persian language understanding;goal detector;model complexity reduction;search space;semantic tagging;spoken dialogue system;spoken language understanding unit;statistical approach;training time reduction;two-step extended hidden vector state parser;university information kiosk corpus","","0","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Approximating the predictive distribution of the beta distribution with the local variational method","Zhanyu Ma; A. Leijon","KTH - Royal Institute of Technology, Sound and Image Processing Lab, Stockholm, Sweden","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In the Bayesian framework, the predictive distribution is obtained by averaging over the posterior parameter distribution. When there is a small amount of data, the uncertainty of the parameters is high. Thus with the predictive distribution, a more reliable result can be obtained in the applications as classification, recognition, etc. In the previous works, we have utilized the variational inference framework to approximate the posterior distribution of the parameters in the beta distribution by minimizing the Kullback-Leibler divergence of the true posterior distribution from the approximating one. However, the predictive distribution of the beta distribution was approximated by a plug-in approximation with the posterior mean, regardless of the parameter uncertainty. In this paper, we carry on the factorized approximation introduced in the previous work and approximate the beta function by its first order Taylor expansion. Then the upper bound of the predictive distribution is derived by exploiting the local variational method. By minimizing the upper bound of the predictive distribution and after normalization, we approximate the predictive distribution by a probability density function in a closed form. Experimental results shows the accuracy and efficiency of the proposed approximation method.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064567","Bayesian Estimation;Beta Distribution;Local Variational Method;Predictive Distribution","Approximation algorithms;Approximation methods;Bayesian methods;Closed-form solutions;Probability density function;Training data;Upper bound","Bayes methods;approximation theory;minimisation;statistical distributions;variational techniques","Bayesian framework;Kullback-Leibler divergence minimisation;beta distribution;factorized approximation;first order Taylor expansion;local variational method;parameter uncertainty;plug-in approximation;posterior distribution approximation;posterior mean;posterior parameter distribution;predictive distribution approximation;probability density function;variational inference framework","","0","","10","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"An outlier rejection scheme for optical flow tracking","Minghao Yang; Jianhua Tao; Lihui Shi; Kaihui Mu; Jianfeng Che","National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, Institute of Equipment Technology of Artillery and Air Defense, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","4","During tracking process in optical flow, some points are normally easy to be lost or become outliers, due to the fact that the object undergoes changes of illumination or becomes partially occluded. The paper presents a novel scheme, Heterogeneity Elimination Individually (HEI), for outlier rejections from the tracking results of optical flow. HEI determines the most poisonous element by the distance between the tracked point and the projected point which is determined by its complements set from the source to the target one. Then HEI eliminates the farthest point every time from the element heterogeneous sequence until all remaining points are within the error tolerance and ensures the accuracy of the optical flow tracking results. Finally, we make an experiment by comparing our method with a popularly used method, RANSAC. The comparison results show the validity and effectiveness of our proposed method for outlier rejection.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064583","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064583","Homography;Optical flow;RANSAC","Adaptive optics;Cameras;Computer vision;Optical signal processing;Real time systems;Target tracking;Visualization","image sequences","RANSAC;element heterogeneous sequence;error tolerance;heterogeneity elimination;illumination;optical flow tracking;outlier rejection scheme;tracking process","","1","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Comparision of different classifiers in fault detection in microgrid","P. P. K. Chan; J. Zhu; Z. W. Qiu; W. W. Y. Ng; D. S. Yeung","Machine Learning and Cybernetics Research Center, School of Computer Science and Engineering, South China, University of Technology, 510006, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","3","","1210","1213","Distributed Generation (DG) has gained more attention recently due to its flexibility and efficiency. In order to manage the DG efficiently, Micro Grid was introduced by some scholars because of its potential to increase the use of DG. A micro grid is a small power system consists of some different components e.g. distribution generators, energy storage devices, energy conversion devices, several loads and monitors. Any component in micro grid may go wrong thus lead to severe damage. This paper studies on fault detection of micro grid using several well-known classification methods such as Radial Basis Function Neural Network (RBFNN), Decision Tree (DT), KNN, and Naïve Bayes (NB). Those methods are compared in term of accuracy and time complexity experimentally in noisy-free and noisy environment.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016932","DG;Decision tree;Fault classification;KNN;Micro grid;Naïve Bayes;RBFNN","Accuracy;Fault detection;Machine learning;Niobium;Noise measurement;Phase distortion;Power systems","decision trees;distributed power generation;fault diagnosis;power distribution faults;power engineering computing;radial basis function networks","DG;DT;KNN;NB;Naive Bayes;RBFNN;classification methods;decision tree;distributed generation;distribution generators;energy conversion devices;energy storage devices;fault detection;microgrid;radial basis function neural network","","0","","16","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Animating a Chinese interactive virtual character","Kaihui Mu; J. Tao; Minghao Yang","The Institute of Automation of the Chinese Academy of Science, The National Laboratory of Pattern Recognition (NLPR), China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","This paper creates a Chinese interactive virtual character based on multi-modal mapping and rules, which receives information from the input modules and generates audio and visual speech, face expressions and body animations. The audio and visual speech are synthesized from the input text by multi-modal mapping, while face expressions and body movements are rule-based driven by emotion states. All of the original animations are captured by a motion capture system and plotted into a character model, which is created by the 3D creation software. We use a skeletal open source animation engine to create the scene in which the virtual character can talk like human communicating with users. The whole expression of this virtual character is considered very natural and realistic.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064586","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064586","body movements;face animation;interactive virtual character;multi-modal;skeletal animation","Animation;Engines;Face;Markup languages;Muscles;Speech;Three dimensional displays","computer animation;face recognition;human computer interaction;knowledge based systems;public domain software;solid modelling;speech synthesis;virtual reality","3D creation software;Chinese interactive virtual character animation;character model;face expressions;motion capture system;multimodal mapping;rule-based driven body movements;skeletal open source animation engine;visual speech synthesis","","0","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Pinning the tail on the distribution: A multivariate extension to the generalised Pareto distribution","D. A. Clifton; S. Hugueny; L. Tarassenko","Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Old Road Campus Research Building, Roosevelt Drive, OX3 7DQ, UK","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Novelty detection is often used for analysis where there are insufficient examples of “abnormal” data to take a multi-class approach to classification. Models of normality are constructed from commonly-available examples of “normal” behaviour, and we then reason about the presence of abnormalities with respect to this normal model. Extreme value theory (EVT) is a branch of statistics that is concerned with modelling extremal events, and is therefore appealing for use with novelty detection. However, conventional existing EVT approaches are limited to the analysis of univariate or low-dimension data. This paper considers the peaks-over-threshold method of EVT, in which exceedances over a (typically univariate) threshold can be shown to tend towards the generalised Pareto distribution (GPD). We extend this method for use with high-dimensional data, allowing us to reason about the “extreme” data lying in the tails of the distributions of complex, real-world datasets, which are typically multivariate and multimodal. Illustrations are provided from the analysis of large clinical studies of hospital patient vital-sign data.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064572","Novelty detection;condition monitoring;extreme value theory","Data models;Frequency modulation;Hidden Markov models;Probabilistic logic;Probability density function;Shape;Training","Pareto distribution;medical administrative data processing;statistics","EVT;GPD;extreme value theory;generalised Pareto distribution;hospital patient vital-sign data;multivariate extension;novelty detection;statistics","","1","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Separation theorem and maximal margin classification for fuzzy number spaces","Q. He; H. L. Li","Key Lab. of Machine Learning and Computational Intelligence, College of Mathematics and Computer Science, Hebei, University, Baoding, 071002, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","1","","278","281","The theory of machine learning in metric space is a new research topic and has drawn much attention in recent years. The theoretical foundation of this topic is the question under which conditions two sample sets can be separated in this space. In this paper, motivated by developing a new support vector machine (SVM) in fuzzy number space, we present a necessary and sufficient condition of separating two finite classes of samples by a hyper-plane in n-dimensional fuzzy number space. We also present an attainable expression of maximal margin of the separating hyper-planes which includes some cases of the classes of infinite samples in n-dimensional fuzzy number space. These results generalize and improve the corresponding conclusions for the theory of SVM in Hilbert space to fuzzy number space.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016732","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016732","Classification;Convex Hull;Extreme Point;Fuzzy Numbers;Separating Hyper-plane","Cybernetics;Extraterrestrial measurements;Hilbert space;Learning systems;Machine learning;Support vector machines","Hilbert spaces;fuzzy set theory;learning (artificial intelligence);pattern classification;support vector machines","Hilbert space;fuzzy number spaces;hyper planes;machine learning theory;maximal margin classification;metric space;separation theorem;support vector machine","","0","","16","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Determining the number of sources in high-density EEG recordings of event-related potentials by model order selection","F. Cong; Z. He; J. Hämäläinen; A. Cichocki; T. Ristaniemi","Department of Mathematical Information Technology, University of Jyv&#x00E4;skyl&#x00E4;, 40014, Finland","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","To high-density electroencephalography (EEG) recordings, determining the number of sources to separate the signal and the noise subspace is very important. A mostly used criterion is that percentage of variance of raw data explained by the selected principal components composing the signal space should be over 90%. Recently, a model order selection method named as GAP has been proposed. We investigated the two methods by performing independent component analysis (ICA) on the estimated signal subspace, assuming the number of selected principal components composing the signal subspace is equal to the number of sources of brain activities. Through examining wavelet-filtered EEG recordings (128 electrodes) of ERPs, ICA with the reference to GAP decomposed 14 selected principal components reliably into 14 independent components, and ICA decomposition with the variance explained method was not reliable, indicating that the number of sources, as well as the signal subspace, should be well estimated through GAP.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064590","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064590","Event-related potential;independent/principal component analysis;model order selection;number of sources;reliability;wavelet filter","Brain modeling;Eigenvalues and eigenfunctions;Electrodes;Electroencephalography;Noise;Principal component analysis;Reliability","bioelectric potentials;electroencephalography;filtering theory;independent component analysis;medical signal processing;principal component analysis;wavelet transforms","ERP;GAP;ICA decomposition;brain activity;estimated signal subspace;event-related potentials;high-density EEG recordings;high-density electroencephalography recordings;independent component analysis;model order selection method;noise subspace;principal components;signal space;variance explained method;wavelet-filtered EEG recordings","","1","","24","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Cooperative data censoring for energy-efficient communications in Sensor Networks","J. Fernández-Bes; R. Arroyo-Valles; J. Cid-Sueiro","Universidad Carlos III de Madrid, Signal Theory and Communication Dept., Av. de la Universidad, 30, 28911 Legan&#x00E9;s, Spain","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Signal processing algorithms in Wireless Sensor Networks claim for energy efficiency because of node energy scarcity. Tailored to this scenario, in this paper we develop energy-efficient cooperative strategies for selective communications. Cooperation among nodes is exploited in order to optimize energy consumption while guaranteeing good overall performance. The analysis of representative scenarios reveals that cooperative selective nodes yield a good performance in both network lifetime and quality of the transmitted information under different network conditions.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064553","","Batteries;Energy consumption;Erbium;Network topology;Optimization;Topology;Wireless sensor networks","energy conservation;energy consumption;signal processing;wireless sensor networks","cooperative data censoring;energy consumption optimisation;energy-efficient communication;energy-efficient cooperative strategy;network lifetime;node energy scarcity;selective communication;sensor network;signal processing algorithm","","1","","8","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Ringing artifact reduction of JPEG images using a SGLI prior","C. Jung; L. C. Jiao","Key Lab of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","4","This paper deals with the ringing artifact problem of JPEG compressed images. The ringing artifacts occur because of loss of high frequency components and appear around sharp edges in images. They degrade the quality of picture and cause unpleasant viewing experiences to viewers. Therefore, we propose a novel Bayesian method which removes the ringing artifacts efficiently in JPEG images. The proposed method employs a Bayesian framework based on a SGLI (spatial gradient and local inhomogeneity) prior. The SGLI prior is from two discontinuity measures which have been utilized as an illumination normalization method for robust face recognition. Experimental results show that the proposed method gives an averaging 0.21 dB gain in PSNR for the JPEG compression artifact reduction.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064558","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064558","","Cameras;Filtering;Manganese;PSNR;Smoothing methods","Bayes methods;belief networks;data compression;face recognition;gradient methods;image coding","Bayesian framework;Bayesian method;JPEG compressed images;JPEG compression artifact reduction;JPEG images;PSNR;SGLI prior;discontinuity measures;high frequency components;illumination normalization method;picture quality;ringing artifact reduction;robust face recognition;sharp edges;spatial gradient and local inhomogeneity prior;unpleasant viewing experiences","","0","","12","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A sinusoidal audio and speech analysis/synthesis model based on improved EMD by adding pure tone","Xiao-ming Li; Chang-chun Bao; Mao-shen Jia","Speech and Audio Signal Processing Laboratory, School of Electronic Information and Control Engineering, Beijing University of Technology, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","A multi-resolution speech and audio sinusoidal analysis/synthesis model based on an improved Empirical Mode Decomposition (EMD) is proposed in this paper. Because of the special filtering characteristic and superiority in dealing with non-stationary signal of EMD, a preprocessing module is adopted to classify the original signal by using the energy ratio and spectrum center of each Intrinsic Mode Function (IMF). A pure tone is added into original signal to extract the noise-like high frequency components without destroying the harmonics of signal. Then a multi-resolution Perceptual Weighted Matching Pursuit (PWMP) and frequency fine search method are adopted to estimate the sinusoidal parameters. Finally, objective measurements of perceived audio quality (PEAQ) show that this model can be effective for the audio synthesis.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064614","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064614","audio analysis and synthesis;empirical mode decomposition;sinusoidal model","Adaptation models;Analytical models;Educational institutions;Encoding;Noise;Psychoacoustic models;Speech","audio signal processing;filtering theory;iterative methods;speech processing;speech synthesis","EMD;IMF;PEAQ;PWMP;audio sinusoidal analysis;audio sinusoidal synthesis;empirical mode decomposition;energy ratio;frequency fine search method;intrinsic mode function;multiresolution perceptual weighted matching pursuit;multiresolution speech analysis;perceived audio quality;pure tone;spectrum center;speech synthesis","","0","","10","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Bayesian nonparametric modeling of hierarchical topics and sentences","Y. L. Chang; Jui-Jung Hung; J. T. Chien","Department of Computer Science and Information Engineering, Cheng Kung University, Tainan, Taiwan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Automatically scoring the sentences of multiple documents plays an important role for document summarization. This study presents a new Bayesian nonparametric approach to conduct unsupervised learning of a hierarchical topic and sentence model (HTSM). This HTSM discovers an extended hierarchy in the nested Chinese restaurant process (nCRP) where each sentence is assigned by a hierarchical topic path. A tree structure with distributions ranging from broad topics to precise topics is established. The dependencies among sentences are characterized. The words in different sentences are represented by a shared hierarchical Dirichlet process (HDP). The topic mixtures in word level and sentence level are estimated according to unsupervised nonparametric processes based on HDP and nCRP, respectively. Compared with the nCRP representing a document based on a single path, the proposed HTSM is flexible with a new nCRP where multiple paths are incorporated to generate different sentences of a document. A summarization system is developed to extract semantically-rich sentences from documents. A new Gibbs sampling algorithm is developed to infer the structural parameters of HTSM. In the experiments on DUC corpus, the proposed HTSM outperforms the other methods for document summarization in terms of ROUGE measures.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064569","Bayesian nonparametrics;Topic model;document summarization;unsupervised learning","Approximation algorithms;Bayesian methods;Data models;Graphical models;Resource management;Unsupervised learning;Vocabulary","Bayes methods;document handling;learning (artificial intelligence);natural language processing;tree data structures","Bayesian nonparametric modeling;DUC corpus;Gibbs sampling algorithm;ROUGE measures;document summarization;hierarchical Dirichlet process;hierarchical topic and sentence model;nested Chinese restaurant process;tree structure;unsupervised learning","","0","","11","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Operator based multicomponent AM-FM signal separation approach","X. Hu; S. Peng; W. L. Hwang","Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The operator-based signal separation approach, which formulates the signal separation as an optimization problem, uses an adaptive operator to separate a signal into additive subcomponents. Furthermore, it is possible to design different operators to fit different signal models. In this paper, we propose a new kind of differential operator to separate multicomponent AM-FM signals. We then use the estimated operators to calculate each sub-component's envelope and instantaneous frequency. To demonstrate the efficacy of the proposed method, we compare the decomposition and AM-FM demodulation results of several signals, including real-life signals.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064592","AM-FM signals;Multicomponent;Null Space Pursuit;Operator-based;separation and demodulation","Demodulation;Equations;Frequency modulation;Mathematical model;Null space;Signal to noise ratio;Source separation","amplitude modulation;demodulation;frequency modulation;source separation","AM-FM demodulation;adaptive operator;additive subcomponents;differential operator;instantaneous frequency;operator based multicomponent AM-FM signal separation;optimization problem","","3","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Search free algorithms for DOA estimation of quasi-stationary signals","W. T. Zhang; S. T. Lou","School of Electronic Engineering, Xidian University, Xi'an 710071, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","We propose two search free algorithms for direction-of-arrival (DOA) estimation of quasi-stationary signals. The two algorithms are all based on the Khatri-Rao (KR) subspace. The first algorithm directly estimates the array manifold matrix through joint diagonalization of a set of matrices associated with signal KR subspace. By removing the redundant data in KR signal model, the second algorithm exploits the rotational invariance technique to estimate the DOAs, and it can be used in the case with more sources than sensors. Simulation results are provided to demonstrate the performance of the proposed algorithms.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064560","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064560","Direction-of-arrival;joint diagonalization;quasi-stationary signals","Arrays;Direction of arrival estimation;Estimation;Joints;Sensors;Signal processing algorithms;Signal to noise ratio","direction-of-arrival estimation;search problems;signal processing","DOA estimation;KR signal model;KR subspace;Khatri-Rao subspace;array manifold matrix;direction-of-arrival estimation;joint diagonalization;quasistationary signal;rotational invariance;search free algorithm","","0","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Efficient preference learning with pairwise continuous observations and Gaussian Processes","B. S. Jensen; J. B. Nielsen; J. Larsen","Technical University of Denmark, Department of Informatics and Mathematical Modeling, Richard Petersens Plads B321, 2800 Lyngby, Denmark","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Human preferences can effectively be elicited using pairwise comparisons and in this paper current state-of-the-art based on binary decisions is extended by a new paradigm which allows subjects to convey their degree of preference as a continuous but bounded response. For this purpose, a novel Beta-type likelihood is proposed and applied in a Bayesian regression framework using Gaussian Process priors. Posterior estimation and inference is performed using a Laplace approximation. The potential of the paradigm is demonstrated and discussed in terms of learning rates and robustness by evaluating the predictive performance under various noise conditions on a synthetic dataset. It is demonstrated that the learning rate of the novel paradigm is not only faster under ideal conditions, where continuous responses are naturally more informative than binary decisions, but also under adverse conditions where it seemingly preserves the robustness of the binary paradigm, suggesting that the new paradigm is robust to human inconsistency.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064616","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064616","Continuous Response;Gaussian Processes;Laplace Approximation;Pairwise Comparisons","Approximation methods;Gaussian processes;Humans;Noise;Predictive models;Robustness;Training","Bayes methods;Gaussian processes;approximation theory;learning (artificial intelligence);regression analysis","Bayesian regression framework;Beta type likelihood;Gaussian processes;Laplace approximation;pairwise continuous observations;preference learning","","2","","10","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A practical approach for depth estimation and image restoration using defocus cue","K. R. Ranipa; M. V. Joshi","","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Reconstruction of depth from 2D images is an important research issue in computer vision. Depth from defocus (DFD) technique uses space varying blurring of an image as a cue in reconstructing the 3D structure of a scene. In this paper we explore the regularization based approach for simultaneous estimation of depth and image restoration from defocused observations. We are given two defocused observations of a scene that are captured with different camera parameters. Our method consists of two steps. First we obtain the initial estimates for the depth as well as for the focused image. In the second step we refine the solution by using a fast optimization technique. Here we use the classic depth recovery method due to Subbarao for obtaining the initial depth map and Weiner filter approach for initial image restoration. Since the problem we are solving is ill-posed and does not yield unique solution, it is necessary to regularize the solution by imposing additional constraint to restrict the solution space. The regularization is performed by imposing smoothness constraint only. However, for preserving the depth and image intensity discontinuities, they are identified prior to the minimization process from initial estimates of the depth map and the restored image. The final solution is obtained by using computationally efficient gradient descent algorithm, thus avoiding the need for computationally taxing algorithms. The depth as well as intensity edge details of the final solution correspond to those obtained using the initial estimates. The experimental results indicate that the quality of the restored image is good even under severe space-varying blur conditions.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064594","","Approximation methods;Cameras;Cost function;Detectors;Estimation;Image edge detection;Image restoration","Wiener filters;computer vision;gradient methods;image restoration;minimisation","2D image;Wiener filter approach;computer vision;defocus cue;depth estimation;depth from defocus technique;depth map;depth reconstruction;depth recovery method;fast optimization technique;gradient descent algorithm;image restoration;minimization process;regularization based approach;space varying blurring","","1","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Program committee","","","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","3","Provides a listing of current committee members.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064544","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064544","","","","","","0","","","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A new i-vector approach and its application to irrelevant variability normalization based acoustic model training","Y. Zhang; Z. J. Yan; Q. Huo","Department of Computer Science and Engineering, Shanghai Jiao Tong University, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","This paper presents a new approach to extracting a low-dimensional i-vector from a speech segment to represent acoustic information irrelevant to phonetic classification. Compared with the traditional i-vector approach, a full factor analysis model with a residual term is used. New procedures for hyperparameter estimation and i-vector extraction are derived and presented. The proposed i-vector approach is applied to acoustic sniffing for irrelevant variability normalization based acoustic model training in large vocabulary continuous speech recognition. Its effectiveness is confirmed by experimental results on Switchboard-1 conversational telephone speech transcription task.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064637","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064637","LVCSR;acoustic model;i-vector;irrelevant variability normalization;unsupervised adaption","Acoustic measurements;Acoustics;Hidden Markov models;Speech;Training;Transforms;Vectors","speech processing;speech recognition","acoustic model training;acoustic sniffing;factor analysis model;hyperparameter estimation;i-vector extraction;irrelevant variability normalization;low-dimensional i-vector;phonetic classification;residual term;speech segment;switchboard-1 conversational telephone speech transcription task;vocabulary continuous speech recognition","","2","1","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Robust online estimation of the vanishing point for vehicle mounted cameras","N. Gupta; H. Faraji; D. He; G. Rathi","Magna Electronics Vision Center, 78, Walker Drive, Brampton, Ontario, L6T 4N6, CANADA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","For cameras mounted on a vehicle, the estimation of the vanishing point corresponding to the observed field of view is an important machine vision task necessary for a lot of applications, such as camera calibration and autonomous vehicle navigation. In this paper, a novel method for the estimation of the vanishing point corresponding to a particular camera orientation with respect to the vehicle is proposed. Robust features are first extracted and the motion of the vehicle is then used to estimate parallel trajectories by tracking these features. Thus, the proposed scheme does not rely on any man-made structures or pre-assumed gradients. The estimated trajectories are then processed to robustly estimate the vanishing point for the mounted camera for any given driving direction. Experimental results show that the proposed technique is able to robustly and accurately estimate the vanishing point for a variety of orientations of the camera mounting.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064630","Vanishing point;camera calibration;computer vision","Cameras;Feature extraction;Image edge detection;Robustness;Tracking;Trajectory;Vehicles","calibration;cameras;computer vision;traffic engineering computing","autonomous vehicle navigation;camera calibration;machine vision task;parallel trajectories;robust online vanishing point estimation;vehicle motion extraction;vehicle mounted cameras","","1","","9","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Deflation technique for neural spike sorting in multi-channel recordings","Z. Tiganj; M. Mboup","Non-A, INRIA Lille - Nord Europe, parc Scientifique de la Haute Borne 40, 59650 Villeneuve d'Ascq, France","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","We propose an ICA based algorithm for spike sorting in multi-channel neural recordings. In such context, the performance of ICA is known to be limited since the number of recording sites is much lower than the number of the neurons around. The algorithm uses an iterative application of ICA and a deflation technique in two nested loops. In each iteration of the external loop, the spiking activity of one neuron is singled out and then deflated from the recordings. The internal loop implements a sequence of ICA and spike detection for removing the noise and all the spikes that are not coming from the targeted neuron. We validate the performance of the algorithm on simulated data, but also on real simultaneous extracellular-intracellular recordings. The results show that the proposed algorithm performs significantly better than when only ICA is applied.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064619","Deflation;Iterative ICA;Spike sorting","Clustering algorithms;Electrodes;Feature extraction;Integrated circuits;Neurons;Sorting;Vectors","cellular biophysics;independent component analysis;iterative methods;neurophysiology","ICA based algorithm;deflation technique;extracellular-intracellular recordings;iterative application;multichannel neural recordings;neural spike sorting;neurons;noise;spike detection","","1","","18","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Metric measurement from street view sequences with simple operator assistance and phase correlation based frame selection","E. Ozuag; M. K. Gullu; O. Urhan; S. Erturk","Kocaeli University Laboratory of Image and Signal processing (KULIS), Electronics and Telecom. Eng. Dept., University of Kocaeli, Umuttepe Campus, 41380, Turkey","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","This paper presents a metric measurement approach from sequences of images captured from a moving spherical camera without the need of additional equipment, such as laser scanners or motion detection units. The user assists the algorithms with simple inputs to facilitate the measurement process. The operator initially selects a keyframe that contains the object of interest that is to be measured. Next, a suitable pair is selected for this keyframe, automatically, using a novel phase correlation based approach proposed in this paper. Then, correspondence matching between these two images is performed using scale-invariant feature transform (SIFT) and these features are refined using RANdom SAmple Consensus (RANSAC) and information obtained from the phase correlation stage. As a last step conversion form the image domain to the 3D domain is performed. The user selects two corresponding point pairs in both frames, corresponding to the edges of the distance that is to be measured, and the metric distance between these two points is obtained. During this process, the height information of the camera with respect to the ground is used as basic reference to obtain metric results. Experimental results show that the proposed methods can provide metric measurements with up to 10% error.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064622","","Cameras;Correlation;Feature extraction;Measurement;Three dimensional displays;Vectors;Videos","correlation theory;image motion analysis;image sequences;measurement;transforms","frame selection;image sequences;laser scanner;metric measurement;motion detection units;moving spherical camera;operator assistance;phase correlation stage;random sample consensus;scale-invariant feature transform;street view sequences","","0","","24","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Heteroscedastic Gaussian process regression using expectation propagation","L. Muñoz-González; M. Lázaro-Gredilla; A. R. Figueiras-Vidal","Signal Theory and Communications Department, Universidad Carlos III de Madrid, Spain","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Gaussian Processes (GPs) are Bayesian non-parametric models that achieve state-of-the-art performance in regression tasks. To allow for analytical tractability, noise power is usually considered constant in these models, which is unrealistic for many real world problems. In this work we consider a GP model with heteroscedastic (i.e., input dependent) noise power, and then, use Expectation Propagation (EP) to perform approximate inference on it. The proposed EP approach is much faster than Markov Chain Monte Carlo and more accurate than competing methods of similar computational cost. This superiority is illustrated in several experiments with synthetic and real-world data.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064576","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064576","","Approximation algorithms;Approximation methods;Estimation;Gold;Markov processes;Noise;Training","Bayes methods;Gaussian processes;approximation theory;regression analysis","Bayesian nonparametric model;analytical tractability;approximate inference;expectation propagation;heteroscedastic Gaussian process regression;heteroscedastic noise power;regression task","","1","","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Intelligent book positioning for library using RFID and book spine matching","W. W. Y. Ng; Y. S. Qiao; L. Lin; H. L. Ding; P. P. K. Chan; D. S. Yeung","Machine Learning and Cybernetic Research Center, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2011 International Conference on Machine Learning and Cybernetics","20110912","2011","2","","465","470","In library, the management of books is very complication and timing costing. The location of books could be altered by librarian, students, teachers and any one around the library. Therefore, allocating a book is not an easy task in big library. Indoor positioning is an important technology to help storage management and customer services providing. RFID provides a good wireless platform to facilitate indoor positioning. However, duo to the small width of each book spine, adopting positioning based RFID alone is not enough to locate books in a library. In this work, we combine image matching with L-GEM based RBFNN to enhance the accuracy and robustness of the book locating system. We apply this new method in a library environment to position the certain books. Experimental results show that the proposed method is highly accurate and robust to white noise of RFID signals.","2160-133X;2160133X","Electronic:978-1-4577-0308-9; POD:978-1-4577-0305-8","10.1109/ICMLC.2011.6016840","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6016840","Image matching;Indoor Positioning;Neural Network;RFID","Feature extraction;Image matching;Libraries;Neurons;Noise;Radiofrequency identification;Training","customer services;image matching;indoor communication;library automation;radial basis function networks;radiofrequency identification;storage management;white noise","L-GEM based RBFNN;RFID signals;book locating system;book spine matching;customer services providing;image matching;indoor positioning;intelligent book positioning;library environment;radial basis function neural network;storage management;white noise","","2","","15","","","10-13 July 2011","","IEEE","IEEE Conference Publications"
"Estimation of periodicity in non-uniformly sampled astronomical data using a 2D kernel in correntropy","B. P. Mishra; J. C. Principe; P. A. Estévez; P. Protopapas","University of Florida, Computational NeuroEngineering Laboratory, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Estimation of periodicity in non-uniformly sampled time series data is frequently a goal in astronomical data analysis. There are various problems faced: Firstly, data is sampled non-uniformly which makes it difficult to use simple Fourier transform for performing spectral analysis. Secondly, there are large gaps in data which makes it difficult to interpolate the signal for re-sampling. Thirdly, in data sets with smaller time periods the non-uniformity in sampling and noise in data pose even greater problems because of the lesser number of samples per period. Finally, recent use of CCD technology has enabled collection of vast amounts of data from various sources. In order to process this huge amount of data we also need to remove human intervention from the process of periodicity estimation to make the algorithm more efficient. In the present work we focus on correntropy and design a new spatio-temporal kernel to accurately estimate the time period of the data without any human intervention.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064635","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064635","","Accuracy;Correlation;Dynamic range;Estimation;Kernel;Time series analysis;Vectors","Fourier transforms;astronomy computing;data analysis;entropy;interpolation;signal sampling;spectral analysis;time series","2D kernel;CCD technology;Fourier transform;correntropy;nonuniformly sampled astronomical data analysis;nonuniformly sampled time series data;periodicity estimation;signal interpolation;spatio-temporal kernel;spectral analysis","","0","","14","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Acoustic surveillance based on Higher-order Local Auto-Correlation","A. Sasou","National Institute of Advanced Industrial Science and Technology, AIST, Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","The importance of video-surveillance applications has been increasing with the increase of crime and terrorism. In addition to traditional video cameras, the use of acoustic sensors in surveillance and monitoring applications is also becoming increasingly important. In this paper, we apply a High-order Local Auto-Correlation (HLAC) system, which has succeeded in video surveillance application, to extract features from acoustic signals for acoustic-surveillance systems. Experiment results confirmed that the proposed acoustic-surveillance system outperforms a cepstrum-based one under all SNR conditions.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064587","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064587","Cepstrum;HLAC;acoustic surveillance","Cepstrum;Feature extraction;Signal to noise ratio;Surveillance;Time frequency analysis;Vectors","acoustic signal processing;acoustic transducers;cepstral analysis;correlation methods;terrorism;video cameras;video surveillance","HLAC system;SNR conditions;acoustic sensors;acoustic signals;acoustic surveillance;acoustic-surveillance systems;cepstrum-based one;crime;high-order local auto-correlation system;higher-order local auto-correlation;monitoring applications;terrorism;video cameras;video-surveillance applications","","1","","7","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Patch-based Markov random fields for fast face occlusion recovery","Jeong Min Yun; Seungjin Choi","Department of Computer Science, Pohang University of Science and Technology, Korea","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper we present Markov random field (MRF) models for face occlusion detection and recovery. For occlusion detection, we use a pixel-based pair-wise MRF model (which is similar to the Ising model) where the binary mask on each pixel is inferred to decide the presence of occlusion. Then we construct a patch-based non-parametric pair-wise MRF model for occlusion recovery, which is learned using occlusion-free face images in the training set. Probabilistic inference using α-expansion leads to fast occlusion recovery, compared to the existing method. Numerical experiments confirm that our method speeds up the existing method by several orders of magnitude, while the quality of recovery is as good as the existing one.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064573","Face occlusion recovery;Markov random fields;probabilistic inference","Computational modeling;Face;Inference algorithms;Markov processes;Mouth;Nose;Training","Markov processes;face recognition;probability;random processes","α-expansion;binary mask;face occlusion detection;fast face occlusion recovery;occlusion-free face images;patch-based Markov random fields;pixel-based pair-wise MRF model;probabilistic inference","","0","","15","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Lesion detection of gastroscopic images based on cost-sensitive boosting","Kai Sun; S. Zhang; R. Yao; W. Yang; S. Cheng; S. Zhang","School of Biomedical Engineering, Shanghai Jiao Tong University, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Gastroscopy is widely used for clinical examination of gastric cancer which is one of the most serious diseases. Computer-aided detection can help physicians to identify suspicious regions to reduce false negative diagnosis which costs too much more than false positive diagnosis. Three cost-sensitive boosting algorithms are compared in this paper in the task of lesion detection of gastroscopic images. The optimal cost structure is selected for each boosting algorithm. Threshold obtained adaptively from training set is adopted to get the final result of a novel sample instead of the sign function. Classification performance becomes better after adaptive threshold is used. Experimental results show that Cost-sensitive AdaBoost performs the best for lesion detection of gastroscopic images achieving a sensitivity of 77.34% with the threshold obtained on training set at a target detection rate of 80%. Lesion detection based on cost-sensitive AdaBoost can outline the lesion area more completely and accurately than AdaBoost method.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064554","AdaBoost;adaptive threshold;cost-sensitive;lesion detection","Boosting;Feature extraction;Histograms;Image color analysis;Lesions;Sensitivity;Training","cancer;image classification;learning (artificial intelligence);medical image processing;patient diagnosis","classification performance;clinical examination;computer aided detection;cost sensitive AdaBoost;cost sensitive boosting;false negative diagnosis;false positive diagnosis;gastric cancer;gastroscopic images;lesion detection","","1","","27","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Large scale topic modeling made practical","B. Ø. Wahlgreen; L. K. Hansen","DTU Informatics, Technical University of Denmark, DK-2800 Lyngby, Denmark","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Topic models are of broad interest. They can be used for query expansion and result structuring in information retrieval and as an important component in services such as recommender systems and user adaptive advertising. In large scale applications both the size of the database (number of documents) and the size of the vocabulary can be significant challenges. Here we discuss two mechanisms that can make scalable solutions possible in the face of large document databases and large vocabularies. The first issue is addressed by a parallel distributed implementation, while the vocabulary problem is reduced by use of large and carefully curated term set. We demonstrate the performance of the proposed system and in the process break a previously claimed `world record' announced April 2010 both by speed and size of problem. We show that the use of a WordNet derived vocabulary can identify topics at par with a much larger case specific vocabulary.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064628","","Adaptation models;Computational modeling;Data models;Databases;Matrix decomposition;Mutual information;Vocabulary","information retrieval;recommender systems","WordNet;curated term set;document database;information retrieval;large scale topic modeling;process break;query expansion;recommender system;result structuring;user adaptive advertising;vocabulary","","1","","24","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Semipolynomial kernel optimization based on the fisher method","E. Taghizadeh; Z. Sadeghipoor; M. T. Manzuri","Idiap Research Institute, Martigny, Switzerland","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Kernel based methods are significantly important in the pattern classification problem, especially when different classes are not linearly separable. In this paper, we propose a new kernel, which is the modified version of the polynomial kernel. The free parameter (d) of the proposed kernel considerably affects the error rate of the classifier. Thus, we present a new algorithm based on the Fisher criterion to find the optimum value of d. Simulation results show that using the proposed kernel for classification leads to satisfactory results. In our simulation in most cases the proposed method outperforms the classification using the polynomial kernel.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064561","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064561","Pattern classification;kernel based methods;kernel learning;polynomial kernel","Cost function;Error analysis;Kernel;Polynomials;Scattering;Training","optimisation;pattern classification;polynomials","Fisher method;pattern classification;semipolynomial kernel optimization","","0","","12","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A novel method of diagnosing coronary heart disease by analysing ECG signals combined with motion activity","Linglin Yin; Yiqiang Chen; Wen Ji","Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China 100190","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","In this paper, we propose an effective method to automatically diagnose coronary heart disease by detecting ST segment episodes of ECG signals. To improve the diagnostic accuracy, we consider the motion activity of individual while monitoring ECG signals and we detect the motion activity of people through heart rate. Our method is based on clinical principle that ST segment depression is greater relative to heart rate (HR) in the recovery period compared with the exercise phase, which is stated in reference. Finally, the method is simulated by The Long-Term ST Database which has reference annotations about whether the person had coronary heart disease or not, with a diagnostic accuracy 80%.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064617","Coronary heart disease;ECG signals;ST segment","Databases;Diseases;Electrocardiography;Feature extraction;Heart rate;Testing","diseases;electrocardiography;medical signal detection","ECG signals;Long-Term ST Database;ST segment episodes detection;coronary heart disease;diagnostic accuracy;heart rate;motion activity","","1","","8","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Dimensionality reduction for EEG classification using Mutual Information and SVM","C. Guerrero-Mosquera; M. Verleysen; A. Navia Vazquez","University Carlos III of Madrid, Signal Processing and Communications Department, Avda. Universidad, 30 28911 Leganes. Spain","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Dimensionality reduction is a well known technique in signal processing oriented to improve both the computational cost and the performance of classifiers. We use an electroencephalogram (EEG) feature matrix based on three extraction methods: tracks extraction, wavelets coefficients and Fractional Fourier Transform. The dimension reduction is performed by Mutual Information (MI) and a forward-backward procedure. Our results show that feature extraction and dimension reduction could be considered as a new alternative for solving EEG classification problems.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064595","","Accuracy;Electroencephalography;Estimation;Feature extraction;Mutual information;Time frequency analysis;Wavelet transforms","Fourier transforms;electroencephalography;feature extraction;medical signal processing;pattern classification;support vector machines","EEG classification;MI;SVM;dimensionality reduction;electroencephalogram;feature extraction;fractional Fourier transform;mutual Information;signal processing;support vector machine;tracks extraction;wavelets coefficients","","0","","28","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Optimization of average precision with Maximal Figure-of-Merit Learning","Ilseo Kim; C. H. Lee","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","We propose an efficient algorithm to directly optimize class average precision (AP) with a Maximal Figure-of-Merit (MFoM) learning scheme. AP is considered as a staircase function with respect to each individual sample score after rank ordering is applied to all samples. A combination of sigmoid functions is then used to approximate AP as a continuously differentiable function of the classified parameters used to compute the sample scores. Compared to pair-wise ranking comparisons, the computational complexity of the proposed MFoM-AP learning algorithm can be substantially reduced when estimating classifier parameters with a gradient descent algorithm. Experiments on the TRECVID 2005 high-level feature extraction task showed that the proposed algorithm can effectively improve the mean average precision (MAP) over 39 concepts from a baseline performance of 0.4039 with MFoM maximizing F1 to 0.4274 with MFoM-AP, while showing significant impromvements for 12 concepts as more than 10%.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064638","MFoM;automatic image annotation;average precision;high-level image feature extraction;optimization;rank statistics","Approximation algorithms;Approximation methods;Computational modeling;Manganese;Measurement;Optimization;Training","computational complexity;feature extraction;function approximation;gradient methods;learning (artificial intelligence);optimisation;pattern classification","MFoM-AP learning algorithm;average precision optimization;computational complexity;gradient descent algorithm;high-level feature extraction;maximal figure-of-merit learning scheme;mean average precision;pair-wise ranking comparisons;sigmoid functions;staircase function","","0","","19","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Gaussian process for human motion modeling: A comparative study","G. Fan; X. Zhang; Meng Ding","School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, 74078, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","We evaluate recent Gaussian process (GP)-based manifold learning methods for human motion modeling, including our recently proposed joint gait and pose manifolds (JGPMs). Unlike most GP algorithms that involve either one latent variable or multiple independent variables in separate latent spaces, JGPMs define two variables jointly and explicitly in one latent space to represent a collection of gait data from different individuals. We develop a model validation technique to examine these GP-based algorithms in terms of their capability of motion interpolation, extrapolation, filtering, and recognition. Experimental results on both CMU Mocap and Brown HumanEva datasets show the superiority of JGPMs over existing GP algorithms for human motion modeling.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064631","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064631","","Data models;Humans;Indexes;Interpolation;Joints;Manifolds;Training","Gaussian processes;extrapolation;filtering theory;gait analysis;human factors;image motion analysis;interpolation;learning (artificial intelligence);pose estimation","CMU Mocap;GP algorithms;GP-based algorithms;GP-based manifold learning methods;Gaussian process-based manifold learning methods;JGPM;brown humanEva datasets;extrapolation;filtering;gait data;human motion modeling;joint gait and pose manifolds;latent spaces;model validation technique;motion interpolation;recognition","","3","","24","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Heterogeneous mixture models using sparse representation features for applause and laugh detection","Ziqiang Shi; Jiqing Han; Tieran Zheng","School of Computer Science and Technology, Harbin Institute of Technology, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","A novel and robust approach for applause and laugh detection is proposed based on sparse representation features and heterogeneous mixture models (hetMM). The projections of the noise robust sparse representations for audio signals computed by L<sub>1</sub> - minimization are used as feature. We consider the classifiers based on heterogeneous mixture models (hetMM) which combine multiple different kinds of distributions, since in practice the data may come from multiple sources and it is often unclear what the most suitable distribution is. Experimental results show that method with hetMM has better results than using a single distribution type and gives comparable performances with Support Vector Machines (SVMs).","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064620","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064620","EM algorithm;audio event detection;heterogeneous mixture models;multivariate logistic distribution;sparse representation features (SRF)","Data models;Dictionaries;Feature extraction;Logistics;Robustness;Support vector machines;Vectors","pattern classification;signal representation;speech processing;support vector machines","L<sub>1</sub>-minimization;applause detection;audio signals representations;classifiers;heterogeneous mixture models;laugh detection;sparse representation features;support vector machines","","1","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Top-down attentionwith features missing at random","S. G. Karadog̃an; L. Marchegiani; J. Larsen; L. K. Hansen","DTU Informatics, Technical University of Denmark, DK-2800, Kgs. Lyngby, Denmark","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper we present a top-down attention model designed for an environment in which features are missing completely at random. Following (Hansen et al., 2011) we model top-down attention as a sequential decision making process driven by a task - modeled as a classification problem - in an environment with random subsets of features missing, but where we have the possibility to gather additional features among the ones that are missing. Thus, the top-down attention problem is reduced to finding the answer to the question what to measure next? Attention is based on the top-down saliency of the missing features given as the estimated difference in classification confusion (entropy) with and without the given feature. The difference in confusion is computed conditioned on the available set of features. In this work, we make our attention model more realistic by also allowing the initial training phase to take place with incomplete data. Thus, we expand the model to include a missing data technique in the learning process. The top-down attention mechanism is implemented in a Gaussian Discrete mixture model setting where marginals and conditionals are relatively easy to compute. To illustrate the viability of expanded model, we train the mixture model with two different datasets, a synthetic data set and the well-known Yeast dataset of the UCI database. We evaluate the new algorithm in environments characterized by different amounts of incompleteness and compare the performance with a system that decides next feature to be measured at random. The proposed top-down mechanism clearly outperforms random choice of the next feature.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064577","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064577","Machine learning;attention modeling;entropy;missing data techniques","Computational modeling;Data models;Error analysis;Mathematical model;Mutual information;Signal to noise ratio;Training","Gaussian processes;data handling;decision making;entropy;learning (artificial intelligence);random processes;set theory","Gaussian discrete mixture model;UCI database;Yeast dataset;classification confusion;classification problem;entropy;learning process;missing data technique;missing feature;random subsets;sequential decision making process;synthetic data set;top-down attention model;top-down saliency","","1","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A super-resolution method for recognition of license plate character using LBP and RBF","Xiaoxuan Chen; C. Qi","School of Electronics and Information Engineering, Xi'an Jiaotong University, Shaanxi 710049, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","Character recognition is the key of three steps in license plate recognition. Although many methods have been proposed to deal with this problem, there is less work dealing with exploration of effective feature to represent license plate characters and recognize characters in low-resolution (LR) images. In this paper, we propose a method that uses the feature based on local binary pattern (LBP) to describe characters and uses radial basis function (RBF) to establish the relationship between features of HR and LR images. The experimental results show that the LBP feature is effective and our method has a good recognition performance.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064550","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064550","Character recognition;local binary pattern (LBP);radial basis function (RBF);super-resolution","Character recognition;Feature extraction;Histograms;Image recognition;Image resolution;Licenses;Training","feature extraction;image resolution;optical character recognition;radial basis function networks;traffic engineering computing","HR images;LBP;RBF;feature exploration;license plate character recognition;local binary pattern;low-resolution images;radial basis function;super-resolution method","","1","1","13","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"An excitation model based on inverse filtering for speech analysis and synthesis","Zhengqi Wen; Jianhua Tao","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","Speech Synthesized in LPC-like vocoders suffered from a typical buzz problem. It is mostly due to the fact that the excitation is either a pulse train or a white Gaussian noise. In this paper, a new excitation model is proposed to reconstruct residual signal derived from inverse filtering. A residual frame of two-pitch periods length is intercepted to do spectrum analysis in every speech frame. Amplitude spectrum of only half of pitch period length is preserved in synthesis stage and zero-phase criterion is used to synthesize the excitation frame. Then the excitation signal is constructed by pitch-synchronous overlapping method (PSOLA). Speech synthesized by this excitation model can give a CMOS of 1.56 compared to the traditional excitation model. After that Mel Generalization Cepstrum (MGC) and LBG algorithm are adopted to manipulate the amplitude spectrum of proposed excitation model. MSE distortion and listening test showed that LBG algorithm is better than MGC to compress the amplitude spectrum.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064574","LBG;MGC;PSOLA;excitation model;inverse filtering","Biological system modeling;CMOS integrated circuits;Filtering;Semiconductor device modeling;Speech;Speech synthesis;Vocoders","cepstral analysis;filtering theory;mean square error methods;signal reconstruction;speech synthesis","LBG algorithm;LPC-like vocoder;MSE distortion;PSOLA method;amplitude spectrum;excitation model;excitation signal;inverse filtering;listening test;mel generalization cepstrum;pitch-synchronous overlapping method;residual signal reconstruction;spectrum analysis;speech analysis;speech frame;speech synthesis;two-pitch periods length","","0","","15","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Semi-blind kurtosis maximization algorithm applied to complex-valued fMRI data","Q. H. Lin; Jia-Cheng Wang; Xiao-Feng Gong; Jian-Lin Wu; J. Y. Chen; V. D. Calhoun","School of Information and Communication Engineering, Dalian University of Technology, 116024, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","The complex kurtosis maximization (KM) algorithm is an efficient algorithm for separating mixtures of circular signals and noncircular signals, which are the typical characteristic in real situations. Based on the fixed-point KM algorithm, we here propose a semi-blind complex ICA algorithm by incorporating the magnitude information about a specific signal into the cost function of KM as an inequality constraint. The proposed algorithm is tested using both synthetic signals including circular and noncircular complex-valued sources and real complex-valued functional magnetic resonance imaging (fMRI) data. Performance is compared to several standard complex ICA algorithms and an additional semi-blind complex ICA algorithm based on gradient KM algorithm. The results show that the proposed semi-blind complex ICA algorithm can largely improve the performance of separation. Significant improvement is shown for the detection of task-related components from the complex-valued fMRI data, which are complete but much noisier than the magnitude-only fMRI data.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064555","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064555","ICA;complex-valued ICA;fMRI;kurtosis maximization;semi-blind ICA","Algorithm design and analysis;Correlation;Cost function;Educational institutions;Signal processing algorithms;Visualization","biomedical MRI;independent component analysis;medical image processing","complex-valued fMRI data;fixed-point KM algorithm;functional magnetic resonance imaging;noncircular signals;semiblind complex ICA algorithm;semiblind kurtosis maximization algorithm","","1","","15","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Inference in Supervised latent Dirichlet allocation","B. Lakshminarayanan; R. Raich","Yandex Labs, 299 S California Ave, Suite 200, Palo Alto, 94306, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Supervised latent Dirichlet allocation (Supervised-LDA) [1] is a probabilistic topic model that can be used for classification. One of the advantages of Supervised-LDA over unsupervised LDA is that it can potentially learn topics that are inline with the class label. The variational Bayes algorithm proposed in [1] for inference in Supervised-LDA suffers from high computational complexity. To address this issue, we develop computationally efficient inference methods for Supervised-LDA. Specifically, we present collapsed variational Bayes and MAP inference for parameter estimation in Supervised-LDA. Additionally, we present computationally efficient inference methods to determine the label of unlabeled data. We provide an empirical evaluation of the classification performance and computational complexity (training as well as classification runtime) of different inference methods for the Supervised-LDA model and a classifier based on probabilistic latent semantic analysis.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064562","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064562","Bayesian inference;Classification;Supervised Latent Dirichlet Allocation","Accuracy;Computational complexity;Computational modeling;Mathematical model;Nickel;Runtime;Training","Bayes methods;computational complexity;inference mechanisms;learning (artificial intelligence);pattern classification;probability;semantic networks;variational techniques","MAP inference;classification performance;classification runtime;collapsed variational Bayes;computational complexity;computationally efficient inference methods;parameter estimation;probabilistic latent semantic analysis;probabilistic topic model;supervised latent Dirichlet allocation;supervised-LDA;unlabeled data;unsupervised LDA;variational Bayes algorithm","","5","","22","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Representing fundamental frequency contours generated by HMM-based speech synthesis using generation process model","K. Hirose; T. Matsuda; H. Hashimoto; N. Minematsu","Department of Information and Communication Engineering, the University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Frame-by-frame representation is not appropriate for prosodic features, which are tightly related to speech units spreading a wide time span, such as words, phrases and so on. This causes an inherit problem in fundamental frequency (F<sub>0</sub>) contour generation by HMM-based speech synthesis. A method is developed to modify F<sub>0</sub> contours in the framework of a generation process model by referring to linguistic information of input text (word boundary and accent type). It takes F<sub>0</sub> variances obtained through HMM-based speech synthesis into account during the process. Through a listening experiment on synthetic speech, the method is proved to generate better quality as compared to the HMM-based speech synthesis on average. Since the generation process model can clearly relate its commands and linguistic (and para-/non- linguistic) information, the method has an additional advantage; changing speech styles, and /or adding further information (such as emphasis) can be easily done through manipulating the commands.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064596","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064596","HMM-based speech synthesis;flexible control;fundamental frequency contour;generation process model;linguistic information","Frequency synthesizers;Hidden Markov models;Mathematical model;Pragmatics;Speech;Speech synthesis","hidden Markov models;speech synthesis","HMM;accent type;command manipulation;fundamental frequency contour generation;fundamental frequency contour representation;generation process model;speech synthesis;word boundary","","0","","17","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Infinite multiple membership relational modeling for complex networks","M. Mørup; M. N. Schmidt; Lars Kai Hansen","Section for Cognitive Systems, DTU Informatics, Denmark","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Learning latent structure in complex networks has become an important problem fueled by many types of networked data originating from practically all fields of science. In this paper, we propose a new non-parametric Bayesian multiple-membership latent feature model for networks. Contrary to existing multiple-membership models that scale quadratically in the number of vertices the proposed model scales linearly in the number of links admitting multiple-membership analysis in large scale networks. We demonstrate a connection between the single membership relational model and multiple membership models and show on “real” size benchmark network data that accounting for multiple memberships improves the learning of latent structure as measured by link prediction while explicitly accounting for multiple membership result in a more compact representation of the latent structure of networks.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064546","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064546","","Analytical models;Communities;Complex networks;Computational modeling;Data models;Proposals;Stochastic processes","Bayes methods;complex networks;learning (artificial intelligence);nonparametric statistics","complex networks;large scale networks;latent structure learning;link prediction;multiple membership analysis;networked data;nonparametric Bayesian multiple membership latent feature model;single membership relational model","","5","","20","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Minimum classification error training with geometric margin enhancement for robust pattern recognition","H. Watanabe; S. Katagiri; M. Ohsaki","MASTAR Project, National Institute of Information and Communications Technology, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289, Japan","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","As a practical discriminative approach to pattern classifier design, the Minimum Classification Error (MCE) training method has been extensively used. In it, classification correctness is represented by a misclassification measure whose positive value corresponds to misclassification and whose negative value corresponds to correct classification. The amount of its negative value is considered to bring in high robustness to unseen pattern samples. However, this effect of the misclassification measure on robustness increase has been questioned in recent studies. In this paper, we clarify the cause of the measure's insufficiency and propose a solution by developing a new MCE training method using geometric margin as the misclassification measure. To maintain the high application generality of the MCE framework, we derive the geometric margin for a general class of discriminant functions and demonstrate the utility of our new MCE method by installing the newly formulated general geometric margin to widely used prototype-based discriminant functions.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064639","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064639","Discriminative training;geometric margin;minimum classification error;misclassification measure","Loss measurement;Prototypes;Robustness;Support vector machines;Training;Vectors","pattern classification;probability","MCE training method;classification correctness;geometric margin enhancement;minimum classification error training;misclassification measure;pattern classifier design;robust pattern recognition","","2","","21","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Multi-resolution inversion algorithm for the attenuated radon transform","P. E. Barbano; A. S. Fokas","Department of Applied Mathematics and Theoretical Physics, University of Cambridge, CB30WA, UK","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","We present a FAST implementation of the Inverse Attenuated Radon Transform which incorporates accurate collimator response, as well as artifact rejection due to statistical noise and data corruption. This new reconstruction procedure is performed by combining a memory-efficient implementation of the analytical inversion formula (AIF [1], [2]) with a wavelet-based version of a recently discovered regularization technique [3]. The paper introduces all the main aspects of the new AIF, as well numerical experiments on real and simulated data. Those display a substantial improvement in reconstruction quality when compared to linear or iterative algorithms.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064632","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064632","Image reconstruction;Multiresolution Analysis;Non-linear processing;Radon transform","Collimators;Image reconstruction;Positron emission tomography;Single photon emission computed tomography;Wavelet domain;Wavelet transforms","Radon transforms;collimators;image reconstruction;image resolution;medical image processing;positron emission tomography;wavelet transforms","analytical inversion formula;artifact rejection;collimator response;data corruption;inverse attenuated Radon transform;memory-efficient implementation;multiresolution inversion algorithm;positron emission tomography;reconstruction procedure;regularization technique;single photon emission computerized tomography;statistical noise;wavelet-based version","","0","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Collaborative learning of mixture models using diffusion adaptation","Z. J. Towfic; Jianshu Chen; A. H. Sayed","Department of Electrical Engineering, University of California, Los Angeles, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In large ad-hoc networks, classification tasks such as spam filtering, multi-camera surveillance, and advertising have been traditionally implemented in a centralized manner by means of fusion centers. These centers receive and process the information that is collected from across the network. In this paper, we develop a decentralized adaptive strategy for information processing and apply it to the task of estimating the parameters of a Gaussian-mixture-model (GMM). The proposed technique employs adaptive diffusion algorithms that enable adaptation, learning, and cooperation at local levels. The simulation results illustrate how the proposed technique outperforms non-collaborative learning and is competitive against centralized solutions.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064578","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064578","Expectation-Maximization;Gaussian-mixture-model;Newton's method;diffusion;distributed processing;machine learning;online-learning","Adaptation models;Approximation methods;Distributed databases;Newton method;Optimization;Probability density function;Vectors","Gaussian processes;groupware;learning (artificial intelligence);pattern classification","GMM;Gaussian mixture model;ad-hoc networks;collaborative learning;diffusion adaptation;fusion centers;information processing;mixture models;multicamera surveillance;spam filtering","","13","","16","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Decoding phase-based information from SSVEP recordings: A comparative study","N. V. Manyakov; N. Chumerin; A. Combaz; A. Robben; M. van Vliet; M. M. Van Hulle","Laboratory for Neurofysiology, K.U.Leuven, Herestraat 49, bus 1021, 3000, Belgium","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","In this paper, we report on the decoding of phase-based information, from steady-state visual evoked potential (SSVEP) recordings, by means of different classifiers. In addition to the ones reported in the literature, we also consider other types of classifiers such as the multilayer feedforward neural network based on multi-valued neurons (MLMVN), and the classifier based on fuzzy logic, which we especially tuned for phase-based SSVEP decoding. The dependency of the decoding accuracy on the number of targets and on the decoding window size are discussed. When comparing existing phase-based SSVEP decoding methods with the proposed ones, we are able to show that the latter ones perform better, for different parameter settings, but especially when having multiple targets. The necessity of optimizing the target frequencies to the individual subject is also discussed.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064563","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064563","Steady state visual evoked potential;brain signals;decoding;phase shift","Accuracy;Decoding;Electrodes;Electroencephalography;Neurons;Training;Visualization","brain-computer interfaces;feedforward neural nets;fuzzy logic;pattern classification;visual evoked potentials","SSVEP recordings;brain-computer interface;classifiers;fuzzy logic;multi valued neurons;multilayer feedforward neural network;phase-based information decoding;steady-state visual evoked potential recordings","","0","","23","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Transformation invariant sparse coding","M. Mørup; M. N. Schmidt","Section for Cognitive Systems, DTU Informatics, Technical University of Denmark, Richard Petersens Plads bld 321, 2800 Kgs. Lyngby, Denmark","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Sparse coding is a well established principle for unsupervised learning. Traditionally, features are extracted in sparse coding in specific locations, however, often we would prefer invariant representation. This paper introduces a general transformation invariant sparse coding (TISC) model. The model decomposes images into features invariant to location and general transformation by a set of specified operators as well as a sparse coding matrix indicating where and to what degree in the original image these features are present. The TISC model is in general overcomplete and we therefore invoke sparse coding to estimate its parameters. We demonstrate how the model can correctly identify components of non-trivial artificial as well as real image data. Thus, the model is capable of reducing feature redundancies in terms of pre-specified transformations improving the component identification.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064547","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064547","","Algorithm design and analysis;Encoding;Feature extraction;Image coding;Image reconstruction;Oscillators;Visualization","image coding;unsupervised learning","TISC model;component identification;invariant representation;transformation invariant sparse coding;unsupervised learning","","7","","26","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"A reproducing kernel Hilbert space formulation of the principle of relevant information","L. G. S. Giraldo; J. C. Principe","University of Florida, ECE Department, Gainesville, USA","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","6","Information theory allows one to pose problems in principled terms that very often have direct interpretation. For instance, capturing the structure based on statistical regularities of data can be thought of as a problem of relevance determination, that is, information preservation under limited resources. The principle of relevant information is an information theoretic objective function that attempts to capture the statistical regularities through entropy minimization under an information preservation constraint. Here, we employ an information theoretic reproducing kernel Hilbert space (RKHS) formulation, which can overcome some of the limitations of previous approaches based on Parzen density estimation. Results are competitive with kernel-based feature extractors such as kernel PCA. Moreover, the proposed framework goes further on the relation between information theoretic learning, kernel methods and support vector algorithms.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064633","Information theoretic learning;kernel methods;unsupervised learning","Entropy;Estimation;Hilbert space;Information theory;Kernel;Support vector machines;TV","Hilbert spaces;entropy;learning (artificial intelligence);principal component analysis;statistical analysis;support vector machines","Parzen density estimation;entropy minimization;information preservation constraint;information theoretic learning;information theoretic objective function;information theoretic reproducing kernel Hilbert space formulation;kernel PCA;kernel methods;kernel-based feature extractors;relevance determination problem;relevant information principle;statistical regularities;support vector algorithms","","0","","25","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
"Speaker segmentation and clustering based on the improved spectral clustering","Yong Ma; C. c. Bao; Jia Liu","Speech and Audio Signal Processing Lab, School of Electronic Information and Control Engineering, Beijing University of Technology, 100124, China","2011 IEEE International Workshop on Machine Learning for Signal Processing","20111031","2011","","","1","5","Efficient speaker segmentation and clustering method based on the improved spectral clustering is proposed in this paper. Traditional speaker segmentation and clustering is performed by the hierarchical clustering algorithms with Bayesian information criterion (BIC) metric and cross likelihood ratio (CLR) metric after the speakers are segmented. Since this method has high computational complexity and may result in a suboptimal solution, we use spectral clustering to overcome this problem and improve the performance of clustering algorithm. First the affinity matrix is constructed with the mean supervector feature transformed by KL kernel mapping. And then the scaling parameter is selected adaptively. The experiments performed on the NIST 1998 multi-speaker corpus show that the proposed method outperforms the baseline system.","1551-2541;15512541","Electronic:978-1-4577-1623-2; POD:978-1-4577-1621-8; USB:978-1-4577-1622-5","10.1109/MLSP.2011.6064579","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064579","Bayesian information criterion;Speaker segmentation and clustering;Spectral Clustering","Clustering algorithms;Clustering methods;Kernel;Measurement;NIST;Speech;Viterbi algorithm","Bayes methods;matrix algebra;pattern clustering;speaker recognition","BIC metric;Bayesian information criterion;CLR metric;KL kernel mapping;affinity matrix;cross likelihood ratio;hierarchical clustering algorithm;mean supervector feature;scaling parameter;speaker clustering;speaker segmentation;spectral clustering","","0","","17","","","18-21 Sept. 2011","","IEEE","IEEE Conference Publications"
