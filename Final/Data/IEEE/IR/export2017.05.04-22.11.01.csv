"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7495651,7498440,7412622,7498442,7496057,7498342,7498306,7495628,7498414,7498266,7498355,7494245,7495049,7494038,7491675,7490971,7492798,7460254,7488406,7490102,7489619,7490129,7489835,7490158,7489648,7489186,7488404,7219439,7488039,7488130,7482290,7426405,7483397,7479982,7474848,7479003,7479327,7479286,7477408,7474210,7476633,7474205,7471228,7473116,7471676,7469578,7470973,7471678,7466099,7472839,7389355,7470812,7469580,7473408,7472492,7378887,7060711,7426384,7468895,7467321,7469126,7468985,7465254,7463833,7258387,7464802,7462427,7460340,7460362,7461705,7459622,7456908,7455821,7456785,7455947,7453825,7453830,7451561,7451551,7451554,7451556,7450806,7450744,7448649,7448725,7446943,7447158,7443520,7444763,7443233,7444775,7440969,7442359,7442338,7430305,7439319,7416164,7439308,7439307,7440185",2017/05/04 22:11:01
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"The Optimization Scheme Research of Small Files Storage Based on HDFS","Q. Mu; Y. Jia; B. Luo","Comput. Sci. & Technol. Coll., Xi'an Univ. of Sci. & Technol., Xi'an, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","1","","431","434","With the rapid development of cloud storage, this paper makes a research on the problem of storing small files on HDFS. It puts forward a new storage optimization method, including improving the storage architecture before the HDFS storage, and proposing the secondary retrieval mechanism on the basis of the improvement method. Simulation results show that the new method can save the name node memory and improve the access efficiency.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.285","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468985","Cloud;HDFS;Hadoop;Storage","Cloud computing;Computer architecture;Computers;File systems;Indexes;Merging;Optimization","cloud computing;file organisation;information retrieval;optimisation;parallel processing","HDFS;Hadoop distributed file system;cloud storage;node memory;optimization scheme research;secondary retrieval mechanism;small files storage;storage architecture;storage optimization method","","","","10","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Privacy-preserving use of genomic data on mobile devices","X. Lei; X. Zhu; H. Chi; S. Jiang","National Key Laboratory of Integrated Services Networks, Xidian University, Xi'an 710071, China","2015 IEEE/CIC International Conference on Communications in China (ICCC)","20160407","2015","","","1","6","The rapid development of genomic technologies, especially the DNA sequencing progress, greatly decreases the costs in genome sequencing, which leads to a high availability of genomic data in the near future (e.g., medical test and healthcare). Meanwhile, the increasing popularity of smartphones and mobile connectivity makes it an inevitable trend to use genomic data on mobile devices. However, since one's genomic information is the ultimate identifier of an individual and contains sensitive private data (e.g., disease predispositions, ancestry information, etc.), the use of genomic data may raise serious privacy concerns. Therefore, it is necessary to find ways of using genomic data on mobile devices without disclosure and abuse of the individual's privacy. In this paper, we provide a general framework for storing and processing genomic data privately, in which dynamic symmetric searchable encryption (DSSE) is employed for users to efficiently retrieve their needed genomic data from the Cloud Storage Provider (CSP). Then, users can implement the genetic disease susceptibility test with these genomic data on their mobile devices. Our proposed framework can achieve a higher privacy preserving level at a lower computation cost. Performance evaluation shows the effectiveness and practicality of the proposed scheme.","","Electronic:978-1-5090-0243-6; POD:978-1-5090-0244-3","10.1109/ICCChina.2015.7448649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448649","Dynamic Symmetric Searchable Encryption;Genomic Data;Medical Test;Privacy Protection","Bioinformatics;Decision support systems;Diseases;Encryption;Genomics;Mobile handsets","DNA;cloud computing;cryptography;data privacy;diseases;genomics;information retrieval;medical computing;mobile computing;smart phones","CSP;DNA sequencing progress;DSSE;ancestry information;cloud storage provider;disease predispositions;dynamic symmetric searchable encryption;genetic disease susceptibility test;genome sequencing;genomic data retrieval;healthcare;medical test;mobile connectivity;mobile devices;privacy-preserving use;smartphones","","","","19","","","2-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"The IoT: Exciting Possibilities for Bettering Lives: Special application scenarios","S. M. R. Islam; M. N. Uddin; K. S. Kwak","Univ. of Dhaka, Dhaka, Bangladesh","IEEE Consumer Electronics Magazine","20160411","2016","5","2","49","57","The Internet of Things (IoT) is a Network of Recognizable Physical objects (or things). It includes anyone, anything, any service, and any network connected to the Internet used to retrieve information at any time and from anywhere. The IoT is smart enough to offer us solutions for a wide range of applications, including intelligent transportation systems, personal communications, consumer electronics, health care, organizational services, securities and monitoring, and industrial controls.","2162-2248;21622248","","10.1109/MCE.2016.2516079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450744","","Cloud computing;Google;Internet of things;Mobile communication;Sensors;Social network services;TV","Internet of Things;information retrieval","Internet of Things;IoT;consumer electronics;health care;industrial controls;intelligent transportation systems;organizational services;personal communications;recognizable physical objects","","","","","","","April 2016","","IEEE","IEEE Journals & Magazines"
"TKBG — The knowledge based grep using self-key discovery and semantic linking for online resources","C. Sekar; G. A. Poorani; M. S. Baba; E. Soundararajan","Computer Science and Engineering, Indian Institute of Information Technology, Srirangam Tiruchirapalli, Tamilnadu, India","2015 Online International Conference on Green Engineering and Technologies (IC-GET)","20160419","2015","","","1","7","The tremendous growth of information resources in the World Wide Web (WWW) made the information retrieval process inefficient and irrelevant due to poor linking of data. One of challenging issues is to find the relevant information from web. Semantic web brings solution by meaningful information retrieval through unique semantic links. In this project, we propose a Self-Key Discovery algorithm based on Sematic Linking Network which allows systematically acquire keys to link RDF(Resource Description Framework) data resources with Semantic relationships among subject Ontologies. Data published on the WWW are usually generated automatically, thus may contain enormous information, duplicates or may be incomplete. RDF is used to represent web content which is the initial stage for semantic linking. SKD algorithm used for RDF data set only, Creation of RDF data is important step to implement semantic linking of data. Proposed Self Key Discovery technique is to performing semantic Linking on knowledge domain clusters using an Ontology Guided Data Linkage (OGDL) framework. This framework allows self-organization of contributing data resources through the discovery of semantic Keys, by performing Linking data of ontological domain knowledge relating to RDF resources. The framework thus automates the discovery of Key to link data across unrelated Resources, and different RDF data set for concept clustering and cluster mapping. In this project, demonstrate the feasibility of our Self Key Discovery algorithms through semantic links to set of RDF Resources, and run on real-world datasets.","","Electronic:978-1-4673-9781-0; POD:978-1-4673-9782-7","10.1109/GET.2015.7453825","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7453825","Ontology;Person ontology;RDF;SAKey;Self Key Discovery Algorithm;Semantic web;knowledge based grep","Joining processes;OWL;Ontologies;Resource description framework;Semantics;Urban areas","Web sites;information retrieval;ontologies (artificial intelligence);semantic Web","OGDL;RDF data resources;SKD algorithm;TKBG;WWW;Web content;World Wide Web;information resources;information retrieval process;knowledge domain clusters;knowledge-based grep;online resources;ontological domain knowledge;ontology guided data linkage;resource description framework data resources;self-key discovery algorithm;semantic Web;sematic linking network","","","","29","","","27-27 Nov. 2015","","IEEE","IEEE Conference Publications"
"Manifold Learning for Multivariate Variable-Length Sequences With an Application to Similarity Search","S. S. Ho; P. Dai; F. Rudzicz","School of Computer Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Neural Networks and Learning Systems","20160516","2016","27","6","1333","1344","Multivariate variable-length sequence data are becoming ubiquitous with the technological advancement in mobile devices and sensor networks. Such data are difficult to compare, visualize, and analyze due to the nonmetric nature of data sequence similarity measures. In this paper, we propose a general manifold learning framework for arbitrary-length multivariate data sequences driven by similarity/distance (parameter) learning in both the original data sequence space and the learned manifold. Our proposed algorithm transforms the data sequences in a nonmetric data sequence space into feature vectors in a manifold that preserves the data sequence space structure. In particular, the feature vectors in the manifold representing similar data sequences remain close to one another and far from the feature points corresponding to dissimilar data sequences. To achieve this objective, we assume a semisupervised setting where we have knowledge about whether some of data sequences are similar or dissimilar, called the instance-level constraints. Using this information, one learns the similarity measure for the data sequence space and the distance measures for the manifold. Moreover, we describe an approach to handle the similarity search problem given user-defined instance level constraints in the learned manifold using a consensus voting scheme. Experimental results on both synthetic data and real tropical cyclone sequence data are presented to demonstrate the feasibility of our manifold learning framework and the robustness of performing similarity search in the learned manifold.","2162-237X;2162237X","","10.1109/TNNLS.2015.2399102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060711","Application;embedding;feature extraction;isometric feature mapping (ISOMAP);longest common subsequence (LCSS);metric learning;similarity learning;similarity search;tropical cyclone;tropical cyclone.","Manifolds;Measurement;Robustness;Time series analysis;Trajectory;Tropical cyclones;Vectors","data handling;information retrieval;learning (artificial intelligence)","arbitrary-length multivariate data sequences;consensus voting scheme;data sequence similarity measures;distance measures;feature vectors;general manifold learning framework;instance-level constraints;manifold learning;multivariate variable-length sequences;nonmetric data sequence space;real tropical cyclone sequence data;semisupervised setting;sequence space structure;similarity search;similarity/distance learning;synthetic data;user-defined instance level constraints","","1","","38","","20150313","June 2016","","IEEE","IEEE Journals & Magazines"
"Estimation of the reliability of multiple rhythm features extraction from a single descriptor","E. Quinton; M. Sandler; S. Dixon","Center for Digital Music, Queen Mary University of London","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","256","260","The design of systems for automatic audio feature extraction is a central aspect of the field of Music Information Retrieval. However, feature extraction systems often do not provide an indication of the reliability of the corresponding feature. Nevertheless, the provision of a reliability or confidence measure can be critical for the usage of a given feature in complex systems and real-world applications. In the present study we investigate the relationship between the entropy of a rhythmogram, which has been proposed as a descriptor of tempo salience in previous work, and the reliability of the extraction of multiple high level rhythm related features. The results show that this single descriptor is viable for simultaneously estimating the reliability of multiple rhythm features extraction. The results also provide quantitative insight that is consistent with qualitative observations extensively reported in the literature on a qualitative basis.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471676","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471676","MIR;beat tracking;meter;rhythm;tempo","Complex systems;Correlation;Entropy;Estimation;Feature extraction;Reliability;Rhythm","audio signal processing;entropy;feature extraction;information retrieval;music;reliability","automatic audio feature extraction;multiple rhythm features extraction;music information retrieval;reliability estimation;rhythmogram entropy","","","","16","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Data Cleaning for XML Electronic Dictionaries via Statistical Anomaly Detection","M. Bloodgood; B. Strauss","Center for Adv. Study of Language, Univ. of Maryland, College Park, MD, USA","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","79","86","Many important forms of data are stored digitally in XML format. Errors can occur in the textual content of the data in the fields of the XML. Fixing these errors manually is time-consuming and expensive, especially for large amounts of data. There is increasing interest in the research, development, and use of automated techniques for assisting with data cleaning. Electronic dictionaries are an important form of data frequently stored in XML format that frequently have errors introduced through a mixture of manual typographical entry errors and optical character recognition errors. In this paper we describe methods for flagging statistical anomalies as likely errors in electronic dictionaries stored in XML format. We describe six systems based on different sources of information. The systems detect errors using various signals in the data including uncommon characters, text length, character-based language models, word-based language models, tied-field length ratios, and tied-field transliteration models. Four of the systems detect errors based on expectations automatically inferred from content within elements of a single field type. We call these single-field systems. Two of the systems detect errors based on correspondence expectations automatically inferred from content within elements of multiple related field types. We call these tied-field systems. For each system, we provide an intuitive analysis of the type of error that it is successful at detecting. Finally, we describe two larger-scale evaluations using crowdsourcing with Amazon's Mechanical Turk platform and using the annotations of a domain expert. The evaluations consistently show that the systems are useful for improving the efficiency with which errors in XML electronic dictionaries can be detected.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439308","","Cleaning;Context;Data models;Dictionaries;Optical character recognition software;Standards;XML","XML;information retrieval;natural language processing;outsourcing;statistical analysis;text analysis","Amazon's Mechanical Turk platform;XML electronic dictionaries;annotation analysis;character-based language model;crowdsourcing;data cleaning;digitally-stored data;domain expert;efficiency improvement;larger-scale evaluation;manual-typographical entry errors;optical character recognition errors;single-field systems;statistical anomalies;statistical anomaly detection;text length;textual content;tied-field length ratios;tied-field systems;tied-field transliteration models;uncommon characters;word-based language model","","","","21","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Improvement of big data retrieval algorithm in the intelligent archives management","Wang Yong; Liu Liming; Qiu Yongsheng","Nanjing University of Posts and Telecommunications, 210003, CHINA","2015 12th IEEE International Conference on Electronic Measurement & Instruments (ICEMI)","20160620","2015","01","","487","491","Under the guidance of scientific and technological innovation concept, new technology and algorithms are applied to information retrieval and real estate registration system. These excellent algorithms and hardware technology make our file management more convenient, intelligent, and efficient. In this paper, researches on the establishment of intelligent file management system and document retrieval were done based on big data environment and with the combination of the project development experience of the Land and Resources Bureau of Nanjing. First of all, this paper focuses on the defects of Java EE framework which is proposed based on the composite Spring-Struts-Hibernate (SSH) frame system and aims to optimize the performance of SSH and promote its efficiency. Secondly, the growing number of archives is reducing the retrieval efficiency of archives management website. In this paper, the ant colony optimization algorithm is employed to classify the data mining and applied to the quick retrieval of big data. At the same time, the complexity of the optimized algorithm and retrieval efficiency are analyzed. The results show that the retrieval time and efficiency are improved in the big data environment.","","CD-ROM:978-1-4799-7618-8; Electronic:978-1-4799-7071-1; POD:978-1-4799-7072-8","10.1109/ICEMI.2015.7494245","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7494245","Ant colony optimization algorithm;Big data retrieval;SSH framework improved","Algorithm design and analysis;Ant colony optimization;Big data;Classification algorithms;Complexity theory;Heuristic algorithms;Optimization","Big Data;Java;ant colony optimisation;computational complexity;data mining;file organisation;information retrieval;information retrieval systems","Big Data retrieval algorithm;Java EE framework;Land and Resources Bureau;Nanjing;SSH frame system;ant colony optimization algorithm;archives management Website;composite Spring-Struts-Hibernate frame system;data mining;document retrieval;intelligent archives management;intelligent file management system;optimized algorithm complexity;retrieval efficiency analysis","","","","10","","","16-18 July 2015","","IEEE","IEEE Conference Publications"
"On physical web models","M. Sneps-Sneppe; D. Namiot","Ventspils International Radio Astronomy Centre, Ventspils University College, Ventspils, Latvia","2016 International Siberian Conference on Control and Communications (SIBCON)","20160616","2016","","","1","6","The Physical Web is a generic term describes interconnection of physical objects and web. The Physical Web lets to present physical objects in a web. There are different ways to do that and we will discuss them in our paper. Usually, the web presentation for a physical object could implement with the help of mobile devices. The basic idea behind the Physical Web is to navigate and control physical objects in the world surrounding mobile devices with the help of web technologies. Of course, there are different ways to identify and enumerate physical objects. In this paper, we describe the existing models as well as related challenges. In our analysis, we will target objects enumeration and navigation as well as data retrieving and programming for the Physical Web.","","CD-ROM:978-1-4673-8382-0; Electronic:978-1-4673-8383-7; POD:978-1-4673-8384-4","10.1109/SIBCON.2016.7491675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7491675","Bluetooth;Physical Web;Wi-Fi;network proximity","Bluetooth;Context;IEEE 802.11 Standard;Mobile communication;Mobile handsets;Uniform resource locators;Wireless communication","Internet;information retrieval;mobile computing","Web technologies;data retrieval;mobile devices;object enumeration;object navigation;physical Web models;physical object control;physical object-Web interconnection;programming","","","","33","","","12-14 May 2016","","IEEE","IEEE Conference Publications"
"Side-channel attacks on mobile and wearable systems","A. Nahapetian","Computer Science Department, California State University, Northridge (CSUN), Los Angeles, USA","2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC)","20160331","2016","","","243","247","This paper describes a variety of side-channel attacks on mobile and wearable computing systems, exposing vulnerabilities in their system and software architectures. Specifically addressed are malware approaches that passively leverage sensors on-board the systems to monitor user information for sensitive information retrieval. Some potential countermeasures at the system and user interface level are provided.","","Electronic:978-1-4673-9292-1; POD:978-1-4673-9293-8","10.1109/CCNC.2016.7444763","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444763","Mobile security;keystroke inference;mobile computing;side-channel attacks;wearable computing","Accelerometers;Intelligent sensors;Malware;Mobile communication;Smart phones","information retrieval;mobile computing;telecommunication security;user interfaces","information retrieval;mobile computing;side-channel attack;software architecture;user information monitoring;user interface level;wearable computing system","","","","28","","","9-12 Jan. 2016","","IEEE","IEEE Conference Publications"
"Understanding Line Plots Using Bayesian Network","R. R. Nair; N. Sankaran; I. Nwogu; V. Govindaraju","Dept. of Comput. Sci. & Eng., Univ. at Buffalo, Buffalo, NY, USA","2016 12th IAPR Workshop on Document Analysis Systems (DAS)","20160613","2016","","","108","113","Information graphics, such as bar charts, graphs, plots etc. in scientific documents primarily facilitate better understanding of information. Graphics are a key component in technical documents as they are simplified representations of complex ideas. When the traditional optical character recognition (OCR) systems is used on digitized documents, we lose the ideas conveyed in these information graphics since OCRs typically work only on text. And although in more recent times, tools have been developed to extract information graphics from pdf files, they still do not intelligently interpret the contents of the extracted graphics. We therefore propose a method for identifying the intended messages of line plots using a Bayesian network. We accomplish this by first extracting a dense set of points in from a line plot and then represent the entire line plot as a sequence of trends. We then implement a Bayesian network for reasoning about the messages conveyed by the line plots and their trends. We validate our approach by performing experiments on a dataset obtained from computer science conference publications and evaluate the performance of the network against the messages generated by human end users. The resulting intended message gives holistic information about the line plot(s) as well as lower level information about the trends that make up the plot.","","Electronic:978-1-5090-1792-8; POD:978-1-5090-1793-5","10.1109/DAS.2016.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490102","bayesian network;document analysis;graphics;line plots","Bayes methods;Computer science;Data mining;Graphics;Image color analysis;Market research;Media","belief networks;computer graphics;document image processing;inference mechanisms;information retrieval;optical character recognition","Bayesian network;OCR system;information graphics extraction;line plot;optical character recognition;reasoning;technical document","","","","16","","","11-14 April 2016","","IEEE","IEEE Conference Publications"
"Optimizing jobs' completion time in cloud systems during virtual machine placement","Y. Alharbi; K. Yang","School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK","2016 3rd MEC International Conference on Big Data and Smart City (ICBDSC)","20160428","2016","","","1","6","Cloud computing gives beneficial services to share large scale of information, storage resources, computing resources, and knowledge for research. Cloud users deploy their own applications and related data on a pay-as-you-go basis. virtual machines (VMs) usually host these data-intensive applications. The performance of these applications often depends on workload types I/O data-intensive or I/O computation, workload volume, CPU attributes on computing nodes CNs, the VMs number on the same CN and network status between storage nodes SNs and CNs. Therefore, the application jobs in the workload have different completion times based on the VM placement decision and large data retrieval. To gain high performance for the overall jobs' completion time and maximizing the throughput of cloud links, we propose VMs placement that considers both computation resources and I/O data. The aim of this algorithm is to reduce the overall jobs' completion time (computing time as well as data transferring time). The CloudSim Simulator results show that our algorithm can significantly maximize the overall application performance and reduce the average jobs' completion time compared among VMs placement approaches previously proposed in the literature.","","Electronic:978-1-4673-9584-7; POD:978-1-4673-9585-4","10.1109/ICBDSC.2016.7460362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460362","Cloud Computing;Cloudsim;Data transfer time;Data-intensive;Job Completion time;Network aware;Processing;Queuing and Data transfer time;VM placement","Bandwidth;Cloud computing;Data transfer;Mathematical model;Processor scheduling;Time factors;Virtual machining","cloud computing;digital simulation;information retrieval;storage management;virtual machines","CPU attributes;CloudSim simulator;IO computation;IO data-intensive;VM;VM placement decision;cloud computing;cloud links;cloud systems;computing resources;data retrieval;data-intensive applications;jobs completion time optimization;pay-as-you-go basis;storage resources;virtual machine placement;workload volume","","","","17","","","15-16 March 2016","","IEEE","IEEE Conference Publications"
"Ontology Construction of the Field of Tourism in Africa","X. Zhao; L. Liu; H. Wang; W. Song","Inf. & Eng. Coll., Capital Normal Univ., Beijing, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","1","","47","50","In the field of the Semantic Web, ontology plays a crucial role. In this paper, for the user's choice and retrieval needs, ontology language grammar-based content, research and construction are hot tourist areas in Africa ontology knowledge of the domain ontology, the knowledge base can not only meet the user's needs, but also scalability. In this paper, the process of constructing domain ontology, using the consistency of testing, and through reasoning and retrieval, semantic web database will be presented to the user, allowing users to get a more comprehensive and accurate retrieval of information.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468895","domain ontology;ontology reasoning;semantic retrieval","Africa;Buildings;Cognition;Ontologies;Semantic Web;Semantics;Urban areas","inference mechanisms;information retrieval;ontologies (artificial intelligence);semantic Web;travel industry","Africa;domain ontology;information retrieval;knowledge base;ontology construction;ontology knowledge;ontology language grammar-based content;reasoning;semantic Web database;testing consistency;tourism;user choice;user retrieval needs","","","","10","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Deep web performance enhance on search engine","D. Kumar; R. Mishra","School of Information and Communication Technology, Gautam Buddha University, Greater Noida, India","2015 International Conference on Soft Computing Techniques and Implementations (ICSCTI)","20160613","2015","","","137","140","Due to digital preservation and new generation technology Deep Web increasing faster than Surface Web, it's necessary to public accessible content also retrieving on general search engine. Huge amounts of data like documents, unstructured, distributed, multi-media available on HTML forms or hidden or invisible or difficult to access known as Deep Web has becoming one of the most valuable resources. Surface Web and Deep Web are two types of Web. The traditional or general search engines like - Google, Yahoo, MSN, Bing etc. better crawling Surface Web only whose pages are directly indexed by general search engines. In this paper proposed on Deep Web public access content that hidden data indexing enhance by general search engine crawler. Sitemap, search engine crawler's Robot.txt and meta data (data about data) technique implemented on a particular developed website. Where all documents data store in databases that access by HTML forms. For the result comparing purpose developed similar Deep Web website which has not implements aforesaid technique. Google webmaster tool used for result analysis. Quicker result found on which have technique implemented that is indexed by Google crawler.","","CD-ROM:978-1-4673-6790-5; Electronic:978-1-4673-6792-9; POD:978-1-4673-6793-6","10.1109/ICSCTI.2015.7489619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7489619","Crawler Robot;Deep Web;Hidden Web;Mata data;Search engine;Sitemap;World Wide Web","Crawlers;Databases;Google;HTML;Metadata;Robots;Search engines","Web sites;hypermedia markup languages;indexing;information retrieval;meta data;search engines","Deep Web performance enhancement;Deep Web public access;Deep Web website;Google crawler;Google webmaster tool;HTML forms;Sitemap;Surface Web;hidden data indexing;meta data technique;search engine;search engine crawler Robot.txt","","","","24","","","8-10 Oct. 2015","","IEEE","IEEE Conference Publications"
"Automatic algorithm to classify and locate research papers using natural language","E. A. Calvillo Moreno; R. Mendoza Gonzalez; J. Munoz Arteaga; J. C. Martinez Romo; M. Vargas Martin; L. C. Rodriguez Martinez","Inst. Tecnol. de Aguascalientes, Aguascalientes, Mexico","IEEE Latin America Transactions","20160426","2016","14","3","1367","1371","The objective of this paper was to provide an automatic engine to classify and locate information using natural language. The proposal integrates a set of two algorithms to extract information from different repositories using their own open APIs and creates a knowledge database using a natural language approach using a Bayesian algorithm to classify and a second algorithm to clean the paper. Putting said techniques together derived in a strong alternative which reach common gaps in classification and location of information including avoid the use of the whole paper to get information and not only the information introduced at the moment of upload the paper in the digital library. The proposal was oriented to classify and locate research papers in order to better describe this contribution, however, findings could be applicable to a vast range of scenarios. An adaptation of the popular methodology Crisp-DM was used to evaluate the performance of the algorithm obtaining good results in classifying, searching, and feeding the knowledge base.","1548-0992;15480992","","10.1109/TLA.2016.7459622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459622","Knowledge DB;Search-Engine;Web-Searching","Classification algorithms;Crawlers;Data mining;Engines;Libraries;Natural languages;Proposals","information retrieval;natural language processing;pattern classification;search engines","API;Bayesian algorithm;Crisp-DM methodology;application program interfaces;information extraction;knowledge database;natural language approach;research papers classification;research papers location;search engine","","","","","","","March 2016","","IEEE","IEEE Journals & Magazines"
"Towards Cleaning-Up Open Data Portals: A Metadata Reconciliation Approach","A. Tygel; S. Auer; J. Debattista; F. Orlandi; M. L. M. Campos","Grad. Program on Inf. - PPGI, UFRJ, Brazil","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","71","78","This paper presents an approach for metadata reconciliation, curation and linking for Open Governamental Data Portals (ODPs). ODPs have been lately the standard solution for governments willing to put their public data available for the society. Portal managers use several types of metadata to organize the datasets, one of the most important ones being the tags. However, the tagging process is subject to many problems, such as synonyms, ambiguity or incoherence, among others. As our empiric analysis of ODPs shows, these issues are currently prevalent in most ODPs and effectively hinders the reuse of Open Data. In order to address these problems, we develop and implement an approach for tag reconciliation in Open Data Portals, encompassing local actions related to individual portals, and global actions for adding a semantic metadata layer above individual portals. The local part aims to enhance the quality of tags in a single portal, and the global part is meant to interlink ODPs by establishing relations between tags.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439307","open data portal;semantic web;tag","Measurement;Metadata;Organizations;Portals;Semantics;Standards organizations;Tagging","data handling;government data processing;information retrieval;meta data;portals","metadata curation;metadata linking;metadata reconciliation approach;open governamental data portal;public data;semantic metadata layer;tag reconciliation;tagging process","","","","25","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Understanding and Predicting Question Subjectivity in Social Question and Answering","Z. Liu; B. J. Jansen","IBM Almaden Research Laboratory, San Jose, CA, USA","IEEE Transactions on Computational Social Systems","20160620","2016","3","1","32","41","The explosive popularity of social networking sites has provided an additional venue for online information seeking. By posting questions in their status updates, more and more people are turning to social networks to fulfill their information needs. Given that understanding individuals' information needs could improve the performance of question answering, in this paper, we model the task of intent detection as a binary classification problem, and thus for each question, two classes are defined: subjective and objective. We use a comprehensive set of lexical, syntactical, and contextual features to build the classifier and the experimental results show satisfactory classification performance. By applying the classifier on a larger dataset, we then present in-depth analyses to compare subjective and objective questions, in terms of the way they are being asked and answered. We find that the two types of questions exhibited very different characteristics, and further validate the expected benefits of differentiating questions according to their subjectivity orientations.","2329-924X;2329924X","","10.1109/TCSS.2016.2564400","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495049","Information seeking;Twitter;social question and answering (social Q&A);social search;subjectivity analysis social network","Context;Feature extraction;Predictive models;Tagging;Training data;Twitter","information needs;pattern classification;question answering (information retrieval);social networking (online)","binary classification problem;classifier;contextual features;information needs;intent detection;lexical features;objective class;online information seeking;question subjectivity prediction;question subjectivity understanding;social networking sites;social question and answering;subjective class;subjectivity orientations;syntactical features","","","","37","","","March 2016","","IEEE","IEEE Journals & Magazines"
"Why is Stack Overflow Failing? Preserving Sustainability in Community Question Answering","I. Srba; M. Bielikova","Slovak University of Technology in Bratislava","IEEE Software","20160623","2016","33","4","80","89","Enormous amounts of knowledge sharing occur every day in community question answering (CQA) sites, some of which (for example, Stack Overflow or Ask Ubuntu) have become popular with software developers and users. In spite of these systems' overall success, problems are emerging in some of them - increased failure and churn rates. To investigate this trend, researchers conducted a case study of Stack Overflow. First, they evaluated the community perception that the emerging problems are heavily related to the growing amount of low-quality content created by undesired groups of users (help vampires, noobs, and reputation collectors). Reproducible data analyses of content and community evolution supported these findings. Suggestions to deal with the emerging problems include providing users with responder-oriented adaptive support that involves a whole community in QA. Such approaches represent an eminent attitude change regarding QA support, with the aim to preserve CQA ecosystems' long-term sustainability.","0740-7459;07407459","","10.1109/MS.2016.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412622","community question answering;computer-supported cooperative work;knowledge sharing;question-answering systems;software development;software engineering","Data analysis;Ecosystems;Information exchange;Knowledge discovery;Linear regression;Market research;Software","data analysis;question answering (information retrieval);social networking (online);software engineering","CQA ecosystem long-term sustainability;CQA sites;churn rates;community question answering sites;failure rates;knowledge sharing;low-quality content;reproducible data analysis;responder-oriented adaptive support;stack overflow","","2","","13","","20160218","July-Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Human-Based Video Browsing - Investigating Interface Design for Fast Video Browsing","W. Hürst; R. v. d. Werken","Inf. & Comput. Sci., Utrecht Univ., Utrecht, Netherlands","2015 IEEE International Symposium on Multimedia (ISM)","20160328","2015","","","363","368","The Video Browser Showdown (VBS) is an annual event where researchers evaluate their video search systems in a competitive setting. Searching in videos is often a two-step process: first some sort of pre-filtering is done, where, for example, users query an indexed archive of files, followed by a human-based browsing, where users skim the returned result set in search for the relevant file or portion of it. The VBS aims at this whole search process, focusing in particular on its interactive aspects. Encouraged by previous years' results, we created a system that purely addresses the latter issue, i.e., interface and interaction design. By eliminating all kind of video indexing and query processing, we were aiming to demonstrate the importance of good interface design for video search and that its relevance is often underestimated by today's systems. This claim is clearly proven by the results our system achieved in the VBS 2015 competition, where our approach was on a par with the top performing ones. In this paper, we will describe our system along with related design decisions, present our results from the VBS event, and discuss them in further detail.","","Electronic:978-1-5090-0379-2; POD:978-1-5090-0380-8; USB:978-1-5090-0378-5","10.1109/ISM.2015.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442359","Video browsing;interaction design;video search interfaces","Browsers;Layout;Multimedia communication;Navigation;Query processing;Streaming media;Visualization","information retrieval;online front-ends;video signal processing","VBS;human-based browsing;indexed archive;interactive aspects;interface design;prefiltering;query processing;video browser showdown;video indexing;video search systems","","1","","13","","","14-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Toward better keywords extraction","Shihua Xu; Fang Kong","School of Computer Science & Technology, Soochow university, Suzhou, Jiangsu Province, China","2015 International Conference on Asian Language Processing (IALP)","20160414","2015","","","181","184","Automatic keyword extraction is the task to identify a small set of keywords from a given document that can describe the meaning of the document. It plays an important role in information retrieval. In this paper, a clustering-based approach to do this task is proposed. And the impacts of keyword length, the window size of centroid on the performance of AKE system are discussed. Then by introducing keyword length constraint and extending the number of centroid of every cluster, the performance of our AKE system is improved by 7.5% in F-score.","","CD-ROM:978-1-4673-9594-6; Electronic:978-1-4673-9596-0; POD:978-1-4673-9597-7","10.1109/IALP.2015.7451561","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451561","Affinity propagation clustering;Keywords extraction;Machine learning","Sun","information retrieval;pattern clustering","AKE system;automatic keyword extraction;centroid;clustering-based approach;information retrieval;keyword length constraint","","","","14","","","24-25 Oct. 2015","","IEEE","IEEE Conference Publications"
"Indonesian medical question classification with pattern matching","W. Suwarningsih; A. Purwarianti; I. Supriana","School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Jl. Ganesa 10 Bandung, Indonesia","2015 International Conference on Automation, Cognitive Science, Optics, Micro Electro-Mechanical System, and Information Technology (ICACOMIT)","20160324","2015","","","106","109","Indonesian medical question answering system requires the extraction of named entity recognition process. This research aims to propose and evaluate a systematic approach to classify Problem, Intervention, Comparison and Outcome (PICO) from the Indonesian medical sentences. We here declare that the extraction using the PICO frames for Indonesian medical sentences is the first. The advantage of PICO frame is to accelerate the classification process based on Problem Intervention, Comparison, and Outcome criteria. Our strategy here was to build a combining question term with multiple classifiers and repetition. The training and test data were generated automatically from Indonesia medical literature with 200 sentences by the exact pattern match of head words of P-I-C-O categories. This approach achieved F-measure values of 0.90 for Problem and Intervention; 0.89 for Problem, Intervention, and Comparison; 0.91 for Problem, Comparison and Outcome. It then can be concluded that by the pattern in matching criteria of the training set and the classification of PICO elements is reproducible with minimal expert intervention.","","CD-ROM:978-1-4673-7407-1; Electronic:978-1-4673-7408-8; POD:978-1-4673-7409-5","10.1109/ICACOMIT.2015.7440185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7440185","PICO frame;pattern matching;question answering;semantic feature","Feature extraction;Informatics;Information technology;Knowledge discovery;Pattern matching;Semantics;Training","medical information systems;pattern classification;pattern matching;question answering (information retrieval);text analysis","F-measure values;Indonesia medical literature;Indonesian medical question answering system;Indonesian medical question classification;Indonesian medical sentences;PICO frame;head words;multiple classifiers;named entity recognition process extraction;pattern matching;problem-intervention-comparison-and-outcome criteria;question term;sentence repetition;test data;training data","","","","13","","","29-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"AWS: Automatic webpage segmentation","M. M. Yadollahi; M. Asadpour","Social Networks Lab., Faculty of Electrical and Computer Engineering, University of Tehran, Tehran, Iran","2016 Second International Conference on Web Research (ICWR)","20160623","2016","","","25","30","A webpage contains many blocks of data, which can be informative or non-informative. In content extraction methods, informative data such as page title, headlines, news article and post body are distinguished from non-informative data such as advertisement, sidebar and navigational menus. The content extraction tasks have many difficulties because of the variety structure of webpages. In this paper, we proposed a content extraction method named Automatic Webpage Segmentation, AWS, which classifies the main content of a given webpage using a feature set consisting of structural and shallow text features. We benefit DOM tree of webpages for feature extraction. The obtained results are promising due to the effectiveness of proposed method to classify individual text elements of a webpage. Besides, feature selection methods such as wrapper and filter are utilized to improve performance of AWS.","","Electronic:978-1-5090-2166-6; POD:978-1-5090-2167-3","10.1109/ICWR.2016.7498442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498442","Content Extraction;Full-text Extraction;Web Document Modeling;Web Information Extraction","Computers;Data mining;Feature extraction;HTML;Histograms;Navigation;Social network services","Web sites;feature extraction;information retrieval","AWS;DOM tree;automatic Web page segmentation;content extraction;data blocks;feature set;informative data;text features","","","","21","","","27-28 April 2016","","IEEE","IEEE Conference Publications"
"Research on the Service Platform to Realize Unified Retrieval and Revelation of Digital Cultural Resources","X. Liu","Res. Inst., Nat. Libr., Beijing, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","20160512","2015","2","","250","253","In order to realize the combination of traditional culture industry with digital technology, network technology and information technology. We design a distributed, scalable, interoperable service platform to realize unified retrieval and revelation of digital cultural resources. The platform can realize the unified retrieval and revelation of books, periodicals, pictures, audio, video, drama, dance, tourism and other more than ten kinds of digital cultural resources and has formed a distributed seamless cross database service system includes ten million metadata and one million object data.","","Electronic:978-1-4673-9587-8; POD:978-1-4673-9588-5","10.1109/ISCID.2015.239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469126","cultural resources;metadata;search engine;unified platform","Authentication;Cultural differences;Dynamic scheduling;Metadata;Search engines;Search problems;Servers","history;information retrieval;meta data","digital cultural resources retrieval;digital cultural resources revelation;distributed seamless cross database service system;metadata;object data;service platform","","","","8","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Chinese text paraphrase detection method based on dependency tree","Y. Jiang; Y. Hao; X. Zhu","Tsinghua National Laboratory of Intelligent Technology and Systems (LITS), Department of Computer Science and Technology, Tsinghua University, Beijing, China","2016 IEEE 13th International Conference on Networking, Sensing, and Control (ICNSC)","20160526","2016","","","1","5","Paraphrase detection is regarded as an important subtask in lots of natural language processing tasks. For example, in question answering, finding similar relations between questions needs paraphrase detection, also it is widely used in information retrieval, machine translation, document clustering, etc. Traditional solutions are mainly divided to two types. One is based on bag of words, which only considers the words in the sentences and similarity degrees between words. The other type is based on word embedding and deep neural networks, which learns word vectors to sentence vectors in deep models, in these models, deep layers may represent deep information in a sentence like phrase information and syntactic information, but these models may also lose some sentence information. We proposed a new method that considers word similarity and also directly uses dependency relations in sentences. We train our model in a Chinese text corpus. By working out dependency relation similarities and word similarities, we decide whether a sentence is a paraphrase of another one.","","Electronic:978-1-4673-9975-3; POD:978-1-4673-9976-0; USB:978-1-4673-9974-6","10.1109/ICNSC.2016.7479003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479003","dependency tree;lexical similarity;paraphrase detection;semantic similarity","Feature extraction;Knowledge based systems;Knowledge discovery;Semantics;Standards;Syntactics;Training","natural language processing;neural nets;question answering (information retrieval);text analysis;trees (mathematics);vectors","Chinese text paraphrase detection method;bag of words;deep neural networks;dependency relation similarities;dependency tree;natural language processing tasks;phrase information;question answering;sentence vectors;syntactic information;word embedding;word similarities;word vectors","","","","14","","","28-30 April 2016","","IEEE","IEEE Conference Publications"
"Fast video search on recurring segments","E. Esen; S. Özkan; İ. Atıl","G&#246;r&#252;nt&#252; &#304;&#351;leme Grubu, T&#220;B&#304;TAK UZAY, Ankara, T&#252;rkiye","2016 24th Signal Processing and Communication Application Conference (SIU)","20160623","2016","","","1585","1588","In this paper, we present a novel visual content search approach that can query quite fast, have low memory need and achieve successful results particularly for the instances with minor content changes. For this purpose, first, the content of a video is represented with sparsely sampled edge energy variations among video frames. Then, these high dimensional features are converted into simple signatures using an approach presented in [1]. During a query, these signatures are compared with a novel data structure model which needs low memory burden, and thus similar videos and their overlapping time intervals are estimated. 11 commercial videos downloaded from YouTube are utilized for the test. Furthermore, these videos are augmented with different compression parameters. Reference video archive consists of 11 new videos composed of the original query videos in different time orders and additional 150 hours video dataset that contains none of the query videos. The results validate that the proposed method is fully effective in computation speed and memory requirements.","","Electronic:978-1-5090-1679-2; POD:978-1-5090-1680-8; USB:978-1-5090-1678-5","10.1109/SIU.2016.7496057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7496057","Indexing;Video Content Search","Art;Data models;Data structures;Indexing;Memory management;Visualization;YouTube","data compression;data structures;information retrieval systems;query processing;social networking (online);video retrieval;video signal processing","YouTube;compression parameters;computation memory requirement;computation speed requirement;data structure model;fast video search;overlapping time intervals;recurring segments;reference video archive;sparsely sampled edge energy variations;video dataset;video frames;visual content search approach","","","","","","","16-19 May 2016","","IEEE","IEEE Conference Publications"
"Leveraging Co-authorship and Biographical Information for Author Ambiguity Resolution in DBLP","H. Hazimeh; I. Youness; J. Makki; H. Noureddine; J. Tscherrig; E. Mugellini; O. A. Khaled","HES-SO/FR, Fribourg, Switzerland","2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)","20160523","2016","","","1080","1084","Many authors can share the same name and this constitutes a serious problem that affects the relevancy of retrieval results and constitutes our motivation of finding such approach to cover this issue at the author names entity level. Solving such a problem may return with positive gain at the level of document retrieval, web search and the quality of data. This entity resolution task can be tackled as an unsupervised problem, where there are set of features that can be employed for the resolution job, or as supervised problem to compute the similarities among two citations and then classify if they are the same or not. Recent approaches usually utilize features such as: co-author, venue, topic similarity, affiliations and title of publications to deal with author ambiguity. In this paper, three attributes are used to treat this problem sequentially. The co-authorship firstly which is a well-known attribute, and then the topic and affiliation extracted from biographies, which can be found inside the publication, and this is our novelty frame in this paper.","1550-445X;1550445X","Electronic:978-1-5090-1858-1; POD:978-1-5090-1859-8","10.1109/AINA.2016.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474210","Clustering;Entity Resolution;Name Disambiguation","Biographies;Classification algorithms;Data mining;Feature extraction;History;Libraries;Supervised learning","citation analysis;information retrieval;publishing","Web search;affiliation extraction;author ambiguity resolution;biographical information;biographies;citations;co-authorship leveraging;data quality;document retrieval;publications;resolution job;topic extraction;unsupervised problem","","","","16","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Document level semantic context for retrieving OOV proper names","I. Sheikh; I. Ulina; D. Fohr; G. Linarès","MultiSpeech Group, LORIA-INRIA, 54500 Villers-l&#x00E8;s-Nancy, France","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","6050","6054","Recognition of Proper Names (PNs) in speech is important for content based indexing and browsing of audio-video data. However, many PNs are Out-Of-Vocabulary (OOV) words for LVCSR systems used in these applications due to the diachronic nature of data. By exploiting semantic context of the audio, relevant OOV PNs can be retrieved and then the target PNs can be recovered. To retrieve OOV PNs, we propose to represent their context with document level semantic vectors; and show that this approach is able to handle less frequent OOV PNs in the training data. We study different representations, including Random Projections, LSA, LDA, Skip-gram, CBOW and GloVe. A further evaluation of recovery of target OOV PNs using a phonetic search shows that document level semantic context is reliable for recovery of OOV PNs.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472839","OOV;indexing;proper names;semantic","Context;Context modeling;Semantics;Speech recognition;Training;Videos;Vocabulary","document handling;indexing;information retrieval;speech recognition;vectors","CBOW;GloVe;LDA;LSA;LVCSR systems;OOV proper name retrieval;OOV words;PN recognition;audio-video data browsing;content based indexing;document level semantic context;document level semantic vectors;out-of-vocabulary words;phonetic search;proper name recognition;random projections;skip-gram;speech","","","","28","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Optimal Web Page Download Scheduling Policies for Green Web Crawling","V. Hatzi; B. B. Cambazoglu; I. Koutsopoulos","University of Thessaly, Volos, Greece","IEEE Journal on Selected Areas in Communications","20160519","2016","34","5","1378","1388","A web crawler is responsible for discovering and downloading new pages on the Web as well as refreshing previously downloaded pages. During these operations, the crawler issues a large number of HTTP requests to web servers. These requests increase the energy consumption and carbon footprint of the web servers since computational resources are used while serving the requests. In this work, we introduce the problem of green web crawling, where the objective is to devise a page refresh policy that minimizes the total staleness of pages in the repository of a web crawler, subject to a constraint on the amount of carbon emissions due to the processing on web servers. For the case of one web server and one crawling thread, the optimal policy turns out to be a greedy one. At each iteration, the page to be refreshed is selected based on a metric that considers the page's staleness, its size, and the greenness of the energy consumed at the web server premises. We then extend the optimal policy to the cases of 1) many servers; 2) multiple threads; and 3) pages with variable freshness requirements. We conduct simulations on a real data set that involves a large web server collection hosting around two billion pages. We present experimental results for the optimal page refresh policy as well as for various heuristics, in an effort to study the effect of different factors on performance.","0733-8716;07338716","","10.1109/JSAC.2016.2520246","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7389355","Crawling;carbon footprint;greenness;staleness","Carbon;Carbon dioxide;Crawlers;Energy consumption;Green products;Web pages;Web servers","energy consumption;green computing;information retrieval;search engines","HTTP request;Web page download;Web server;carbon footprint;computational resources;energy consumption;green Web crawling;hypertext transfer protocol;page refresh policy;scheduling policy;variable freshness requirements","","","","34","","20160121","May 2016","","IEEE","IEEE Journals & Magazines"
"Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval","A. A. Liu; W. Z. Nie; Y. Gao; Y. T. Su","School of Electronic Information Engineering, Tianjin University, Tianjin, China","IEEE Transactions on Image Processing","20160325","2016","25","5","2103","2116","Multi-view matching is an important but a challenging task in view-based 3D model retrieval. To address this challenge, we propose an original multi-modal clique graph (MCG) matching method in this paper. We systematically present a method for MCG generation that is composed of cliques, which consist of neighbor nodes in multi-modal feature space and hyper-edges that link pairwise cliques. Moreover, we propose an image set-based clique/edgewise similarity measure to address the issue of the set-to-set distance measure, which is the core problem in MCG matching. The proposed MCG provides the following benefits: 1) preserves the local and global attributes of a graph with the designed structure; 2) eliminates redundant and noisy information by strengthening inliers while suppressing outliers; and 3) avoids the difficulty of defining high-order attributes and solving hyper-graph matching. We validate the MCG-based 3D model retrieval using three popular single-modal data sets and one novel multi-modal data set. Extensive experiments show the superiority of the proposed method through comparisons. Moreover, we contribute a novel real-world 3D object data set, the multi-view RGB-D object data set. To the best of our knowledge, it is the largest real-world 3D object data set containing multi-modal and multi-view information.","1057-7149;10577149","","10.1109/TIP.2016.2540802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7430305","3D Model Retrieval;3D model retrieval;Graph Matching;Image Set;Multi-modal;graph matching;image set;multi-modal","Computational modeling;Context modeling;Data models;Image reconstruction;Shape;Solid modeling;Three-dimensional displays","computer graphics;graph theory;information retrieval;pattern matching","3D model retrieval;MCG matching;MCG matching method;hyper edges;link pairwise cliques;multimodal clique-graph matching;multiview matching;noisy information;set-to-set distance measure","","8","","65","","20160310","May 2016","","IEEE","IEEE Journals & Magazines"
"Learning from the past: Improving news summarization with past news articles","Feng Li; Yan Chen; Zhoujun Li","State Key Laboratory of Software Development Environment, Beihang University, China","2015 International Conference on Asian Language Processing (IALP)","20160414","2015","","","140","143","One common approach to single-document news summarization involves scoring and ranking individual sentences within an input story. We demonstrate that the accuracy of this scoring process can be improved by looking beyond the text found within each input news story. Leveraging on an external corpus of past news articles, we show that summarization performance can be greatly enhanced if we also consider signals and cues from other related news stories. Working on top of a basic keyword-based summarization system, we expanded the set of keywords we have from the original news stories with related stories retrieved from the external corpus. With this enhancement, we are able to get significant improvements of at least 10% and 16% in ROUGE-1 and ROUGE-2 respectively.","","CD-ROM:978-1-4673-9594-6; Electronic:978-1-4673-9596-0; POD:978-1-4673-9597-7","10.1109/IALP.2015.7451551","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451551","keyword discovery;single document summarization","Face","information resources;information retrieval;text analysis","ROUGE-1;ROUGE-2;individual sentence ranking;individual sentence scoring;keyword discovery;keyword-based summarization system;news stories;news story;past news articles;single-document news summarization improvement","","","","15","","","24-25 Oct. 2015","","IEEE","IEEE Conference Publications"
"Triple-based analysis of music alignments without the need of ground-truth annotations","T. Prätzlich; M. Müller","International Audio Laboratories Erlangen","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","266","270","The goal of music alignment methods is to temporally align different versions of the same piece of music. These methods are typically evaluated by comparing the computed alignments to given ground-truth annotations. Creating such annotations is usually very labor intensive. For many musical pieces, especially in classical music, there exists a multitude of different recordings. In this work, we investigate whether an evaluation of music alignment algorithms can be performed without ground-truth annotations when at least a triplet of recordings of the same piece of music is available. The main idea is to align the time points of a fixed reference version, in a circular way, back through a second and third version by using their pairwise alignments. A triple error is then computed by comparing these time points with their circularly aligned version. In this paper, we formalize the idea of the triple error and discuss its potential and limitations. We present typical examples for the triple error and compare it to the pairwise alignment error based on ground-truth. Furthermore, we present a case study to indicate the potential of the triple error to analyze alignments and to compare different alignment methods without the need of ground-truth annotations.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7471678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471678","evaluation;ground-truth;music alignment;music synchronization","Indexes;Instruments;Laboratories;Measurement uncertainty;Multiple signal classification;Position measurement;Time measurement","information retrieval;music","fixed reference version;music alignment methods;music information retrieval;pairwise alignment error;triple-based analysis","","","","15","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Spectral-spatial information extraction and classification of mangrove species using joint sparse representation","Jie Geng; Jianchao Fan; Xiu Su; Xiaorui Ma; Hongyu Wang","School of Information and Communication Engineering, Dalian University of Technology, China 116024","2015 4th International Conference on Computer Science and Network Technology (ICCSNT)","20160616","2015","01","","1311","1315","Classification of mangrove species is very important for monitoring and protecting the coastal ecosystem. In this paper, we present a new spectral-spatial classifier that uses multi-spectral image captured by the ZY-3 satellite to distinguish seven mangrove species in the Beihai ecological monitoring area, Guangxi, China. In order to extract the spatial information, a correlative filter is designed to incorporate neighborhood correlative information before classification. Moreover, a feature optimization algorithm based on dictionary learning is applied to reduce the noise and improve the discrimination of sample features. Finally, a classification method using joint sparse representation is proposed to extract the mangrove region and recognize seven mangrove species. The classification results show that the major species in the study area are Aegiceras corniculatum and Avicenna marina that conform to field investigations. The overall accuracy reaches 95.62% and the kappa coefficient achieves the value of 0.9380. Hence, the accuracy and efficiency of our proposed method are demonstrated in mangrove species classification.","","CD-ROM:978-1-4673-8172-7; Electronic:978-1-4673-8173-4; POD:978-1-4673-8174-1","10.1109/ICCSNT.2015.7490971","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490971","joint sparse representation;mangrove species classification;multispectral image;spectral-spatial classification","Atmospheric modeling;Dictionaries;Feature extraction;Matching pursuit algorithms;Optimization;Remote sensing;Training","ecology;geophysical image processing;image classification;image denoising;image filtering;image representation;information retrieval;vegetation;vegetation mapping","Aegiceras corniculatum;Avicenna marina;Beihai ecological monitoring area;China;Guangxi;ZY-3 satellite;correlative filter;dictionary learning;feature optimization algorithm;joint sparse representation;kappa coefficient;mangrove species classification;mangrove species recognition;multispectral image;neighborhood correlative information;noise reduction;spectral-spatial classifier;spectral-spatial information extraction","","","","13","","","19-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"SEED: A system for entity exploration and debugging in large-scale knowledge graphs","J. Chen; Y. Chen; X. Du; X. Zhang; X. Zhou","School of Information, Renmin University of China, Beijing, China","2016 IEEE 32nd International Conference on Data Engineering (ICDE)","20160623","2016","","","1350","1353","Large-scale knowledge graphs (KGs) contain massive entities and abundant relations among the entities. Data exploration over KGs allows users to browse the attributes of entities as well as the relations among entities. It therefore provides a good way of learning the structure and coverage of KGs. In this paper, we introduce a system called SEED that is designed to support entity-oriented exploration in large-scale KGs, based on retrieving similar entities of some seed entities as well as their semantic relations that show how entities are similar to each other. A by-product of entity exploration in SEED is to facilitate discovering the deficiency of KGs, so that the detected bugs can be easily fixed by users as they explore the KGs.","","Electronic:978-1-5090-2020-1","10.1109/ICDE.2016.7498342","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498342","","Debugging;Generators;Itemsets;Knowledge engineering;Semantics;User interfaces;Visualization","graph theory;information retrieval;learning (artificial intelligence)","SEED;System for Entity Exploration and Debugging;bug detection;coverage learning;data exploration;entity attribute browsing;entity relations;entity-oriented exploration;large-scale knowledge graphs;semantic relations;similar entity retrieval;structure learning","","","","9","","","16-20 May 2016","","IEEE","IEEE Conference Publications"
"Correlation analysis of audio and video contents: A metadata based approach","S. P. Algur; B. A. Goudannavar; P. Bhat","Dept. of Computer Science, Rani Channamma University, Belagavi, Karnataka, India","2015 International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)","20160421","2015","","","351","356","The study of the associations between audio and video contents has numerous important applications in the fields of multimedia mining and information retrieval. Many works are implemented to correlate audio and video contents based on signal processing. This work represents audio visual correlation using metadata of audio and video as a leading role. The proposed method focuses on the web videos which exhibit a broad range of structural and semantic relationships between audio and video contents. To identify such relationships, it is necessary to undergo correlation analysis of audio and video contents. In this work, attempts are made to correlate audio and video contents of Entertainments, Sports and News categories web videos effectively and efficiently, and also correlation coefficient are calculated. The experimental procedures and results on the correlation of audio-video sequences by considering audio spectrogram frequency value to corresponding video bitrate value is described using different methods.","","Electronic:978-1-4673-9223-5; POD:978-1-4673-9224-2; USB:978-1-4673-9222-8","10.1109/ICATCCT.2015.7456908","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456908","Audio and Video Processing;Correlation;Metadata;Multimedia","Bit rate;Correlation;Correlation coefficient;Frequency measurement;Spectrogram;Streaming media;Visualization","information retrieval;meta data;video signal processing","audio contents;audio visual correlation;correlation analysis;correlation coefficient;information retrieval;multimedia mining;signal processing;video contents","","","","10","","","29-31 Oct. 2015","","IEEE","IEEE Conference Publications"
"A semantic-based technique for question lassification in question answering systems — A hybrid approach","M. M. Hoque; P. Quaresma","Department of Informatics, University of Evora, Evora, Portugal","2015 18th International Conference on Computer and Information Technology (ICCIT)","20160609","2015","","","38","43","Question classification plays a substantial role in Question Answering systems. To obtain a semantically rich and syntactically sound question classifier, we present in this paper a semantic-based hybrid approach that explores the meaning underlying the question and seeks to understand the linguistic denotation of the question by constructing a lexically minimalistic syntactic labelled graph from it Questions are classified into one of the six major and fifty finer classes. The system proposes a training method that learns a set of graph traversal rules to detect a question's focus. A standard set containing diverse classes of benchmark questions is used for the training purpose. The system proposes using a semantic memory to store a set of commonly used and unambiguous words that often occur with specific graph traversal rules. A modified technique of the Word Sense Disambiguation using WordNet detects the contextual meaning of a question's focus and maps it to a finer class. A substantial improvement achieved using the approach over other similar systems using similar benchmark data shows that the current approach can be used as a syntactically and semantically rich model in the area of question answering systems.","","Electronic:978-1-4673-9930-2; POD:978-1-4673-9931-9","10.1109/ICCITechn.2015.7488039","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7488039","","","graph theory;natural language processing;pattern classification;question answering (information retrieval)","WordNet;finer-classes;graph traversal rules;lexically minimalistic syntactic labelled graph;linguistic denotation;major-classes;question answering systems;question classification;semantic memory;semantic-based hybrid approach;word sense disambiguation","","","","23","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"An Interactive Approach with Off-Line and On-Line Handwritten Text Recognition Combination for Transcribing Historical Documents","E. Granell; V. Romero; C. D. Martínez-Hinarejos","PRHLT Res. Centre, Univ. Politec. de Valencia, Valencia, Spain","2016 12th IAPR Workshop on Document Analysis Systems (DAS)","20160613","2016","","","269","274","Automatic transcription of historical documents is becoming an important research topic, specially because of the increasing number of digitised historical documents that libraries and archives are publishing. However, state-of-the-art handwritten text recognition systems are far from being perfect. Therefore, to have perfect transcriptions, human expert revision is required to really produce a transcription of standard quality. In this context, an interactive assistive scenario, where the automatic system and the human transcriber cooperate to generate the perfect transcription, would allow for a more effective approach. In this paper we present a multimodal interactive transcription system where user feedback is provided by means of touchscreen pen strokes, traditional keyboard and mouse operations. The combination of both the main and the feedback data stream is based on the use of Confusion Networks derived from the output of the on-line and off-line handwritten text recognition systems. The use of the proposed combination help to optimise overall performance and usability.","","Electronic:978-1-5090-1792-8; POD:978-1-5090-1793-5","10.1109/DAS.2016.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490129","Historical handwritten text transcription;confusion networks;interactive framework;multimodal combination;on-line handwritten text recognition","Context;Decoding;Ergonomics;Hidden Markov models;Keyboards;Mice;Text recognition","digital libraries;feedback;handwriting recognition;history;information retrieval systems;interactive systems;text analysis;user interfaces","archives;automatic transcription;confusion networks;feedback data stream;historical documents;human transcriber;interactive assistive scenario;libraries;multimodal interactive transcription system;offline handwritten text recognition;online handwritten text recognition;publishing;user feedback","","","","18","","","11-14 April 2016","","IEEE","IEEE Conference Publications"
"Robust Cross-view Hashing for Multimedia Retrieval","X. Shen; F. Shen; Q. S. Sun; Y. H. Yuan; H. T. Shen","School of Computer and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Signal Processing Letters","20160518","2016","23","6","893","897","Hashing techniques have been widely applied to large-scale cross-view retrieval tasks due to the significant advantage of binary codes in computation and storage efficiency. However, most existing cross-view hashing methods learn binary codes with continuous relaxations, which cause large quantization loss across views. To address this problem, in this letter, we propose a novel cross-view hashing method, where a common Hamming space is learned such that binary codes from different views are consistent and comparable. The quantization loss across views is explicitly reduced by two carefully designed regression terms from original spaces to the Hamming space. In our method, the l<sub>2,1</sub>-norm regularization is further exploited for discriminative feature selection. To obtain high-quality binary codes, we propose to jointly learn the codes and hash functions, for which an efficient iterative algorithm is presented. We evaluate the proposed method, dubbed Robust Cross-view Hashing (RCH), on two benchmark datasets and the results demonstrate the superiority of RCH over many other state-of-the-art methods in terms of retrieval performance and cross-view consistency.","1070-9908;10709908","","10.1109/LSP.2016.2517093","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378887","Cross-view;Hashing;Multimedia retrieval;hashing;multimedia retrieval","Binary codes;Electronic mail;Multimedia communication;Optimization;Quantization (signal);Robustness;Yttrium","binary codes;feature selection;file organisation;information retrieval;learning (artificial intelligence);multimedia computing","RCH method;binary codes;common Hamming space;cross-view consistency;discriminative feature selection;dubbed robust cross-view hashing method;l<sub>2,1</sub>-norm regularization;large-scale cross-view retrieval tasks;multimedia retrieval;quantization loss;regression terms","","2","","27","","20160112","June 2016","","IEEE","IEEE Journals & Magazines"
"Automatic user identification method across heterogeneous mobility data sources","W. Cao; Z. Wu; D. Wang; J. Li; H. Wu","Institute for Interdisciplinary Information Sciences, Tsinghua University, China","2016 IEEE 32nd International Conference on Data Engineering (ICDE)","20160623","2016","","","978","989","With the ubiquity of location based services and applications, large volume of mobility data has been generated routinely, usually from heterogeneous data sources, such as different GPS-embedded devices, mobile apps or location based service providers. In this paper, we investigate efficient ways of identifying users across such heterogeneous data sources. We present a MapReduce-based framework called Automatic User Identification (AUI) which is easy to deploy and can scale to very large data set. Our framework is based on a novel similarity measure called the signal based similarity (SIG) which measures the similarity of users' trajectories gathered from different data sources, typically with very different sampling rates and noise patterns. We conduct extensive experimental evaluations, which show that our framework outperforms the existing methods significantly. Our study on one hand provides an effective approach for the mobility data integration problem on large scale data sets, i.e., combining the mobility data sets from different sources in order to enhance the data quality. On the other hand, our study provides an in-depth investigation for the widely studied human mobility uniqueness problem under heterogeneous data sources.","","Electronic:978-1-5090-2020-1","10.1109/ICDE.2016.7498306","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498306","","Buildings;Education;Mobile communication;Navigation;Noise measurement;Trajectory;Urban areas","data integration;information retrieval;mobile computing","AUI;MapReduce-based framework;SIG measure;automatic user identification method;data quality;heterogeneous mobility data sources;location based services;mobility data integration problem;mobility data volume;signal based similarity measure","","","","39","","","16-20 May 2016","","IEEE","IEEE Conference Publications"
"Localizing components on printed circuit boards using 2D information","W. Li; C. Jiang; M. Breier; D. Merhof","Institute of Imaging and Computer Vision, RWTH Aachen University, 52056 Aachen, Germany","2016 IEEE International Conference on Industrial Technology (ICIT)","20160526","2016","","","769","774","Information retrieval based re-configurable recycling is crucial for solving the environmental and social problems raised by the dramatically increasing amount of waste printed circuit boards. However, the indispensable localization of mounted components for the desired information retrieval is an unsolved problem for state-of-the-art techniques so far. In this paper, for the first time, a feasible solution addressing this problem by using general 2D information is proposed. In the form of a sophisticated modular analysis pipeline, complementary information sources are combined appropriately for capturing the sought objects. With a novel background removal algorithm and an additional candidate validation step, the proposed approach significantly outperforms state-of-the-art localization approaches in case of PCB images. Moreover, with respect to the intended trade-off between complexity and performance, it is quite straightforward to re-construct the deployed workflow accordingly by considering the knowledge obtained in a comprehensive evaluation of diverse combination possibilities.","","Electronic:978-1-4673-8075-1; POD:978-1-4673-8076-8","10.1109/ICIT.2016.7474848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474848","","Electronic waste;Feature extraction;Image color analysis;Image edge detection;Merging;Proposals;Recycling","information retrieval;printed circuits;production engineering computing;recycling","2D information;PCB images;component localization;information retrieval;information sources;modular analysis pipeline;printed circuit boards;re-configurable recycling","","","","33","","","14-17 March 2016","","IEEE","IEEE Conference Publications"
"Density based clustering for Cricket World Cup tweets using Cosine similarity and time parameter","N. Pandey","LJ Institute of Engineering and Technology, PG CE Department, Ahmedabad, India","2015 Annual IEEE India Conference (INDICON)","20160331","2015","","","1","6","The rapid spread of location-based devices and cheap storage mechanisms, as well as fast development of Internet technology, allowed collection and distribution of huge amounts of user-generated data. These user generated data sometimes are known as georeferenced documents, they have their location information and time of posting embedded with them. These parameters help to retrieve the location information and the time of posting. We need to retrieve the topic from those geo-referenced documents and determine the local topics and events for a particular region. All these clusters are geospatial in arbitrary shape hence density based clustering is the most appropriate clustering algorithm. Here we used tweets from Twitter, while the DBSCAN method is used for generating clusters. Here for finding similarity between tweets cosine similarity is used, but because of its low value we increase its value by adding weight to it by matching the keywords in tweets. Also another parameter of time is used for separating clusters temporally. Results have shown that weighted keyword based method gives more specific clusters than DBSCAN method, while using the time parameter in it we get clusters time separated. Hence for purpose of information retrieval or building marketing strategy by tweets we can use this method.","","Electronic:978-1-4673-7399-9; POD:978-1-4673-7400-2","10.1109/INDICON.2015.7443520","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443520","Density based clustering;geo-referenced documents;location detection;spatial clusters;spatio-temporal clusters;topic retrieval","Buildings;Clustering algorithms;Clustering methods;Internet;Mobile handsets;Shape;Twitter","Internet;information retrieval;mobile computing;pattern clustering;pattern matching;social networking (online);sport","Cricket World Cup tweet;DBSCAN method;Internet technology;Twitter;cosine similarity;density-based clustering;information retrieval;keyword matching;location-based device;time parameter","","","","12","","","17-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"Study on classification of domain-oriented user exploration process for exploratory search","Pengfei Li; Yin Zhang; Kening Gao; Bin Zhang","College of Information Science and Engineering/Key Laboratory of Medical Image Computing, Northeastern University/Ministry of Education, Shenyang, China","2015 IEEE International Conference on Progress in Informatics and Computing (PIC)","20160613","2015","","","191","195","In the study of exploratory search, different supporting methods have already been proposed to meet users' different information needs. However, these methods are mostly targeted at different domains of user exploration process. In this paper, we study on a classification method of domain-oriented user exploration process for exploratory search to support determine user's search domains for search engines who will well-directed help users to complete exploratory tasks. First, we seek to define and built exploration process model base on tree structure. Second, we study on domain-oriented classification method based on user exploration process model and design a parameter training method based on ListNet. In the experimental stage, we compare the abilities between our method and two `baseline' methods. Results show that the precision, recall and F1-measure of our method is found to increase by 7 percent to 15 percent over these previous methods.","","CD-ROM:978-1-4673-8085-0; Electronic:978-1-4673-9088-0; POD:978-1-4673-9089-7","10.1109/PIC.2015.7489835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7489835","Exploratory search;ListNet;tree structure model;user exploration process","Computers;Economics;Engines;Entropy;Integrated circuits","information retrieval;pattern classification;search engines;search problems;trees (mathematics)","domain-oriented user exploration process classification;exploratory search;parameter training method;search engine;tree structure","","","","15","","","18-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"Searchable encryption through obfuscation and multi-cloud search","S. Chatterjee; S. Bhattacharjee; K. Chandrasekaran","Dept. of Computer Science and Engineering, NIT, Karnataka, Surathkal, Mangalore, India","2015 Annual IEEE India Conference (INDICON)","20160331","2015","","","1","6","In this paper different searchable encryption techniques are studied along with some implementation of searchable encryption in a cloud environment. Symmetric searchable encryption is implemented through trapdoor function to selectively expose keyword for search. A new method of achieving searchable encryption in the random oracle model is proposed through one way indistinguishability obfuscation. Indistinguishability obfuscation is achievable through mimicry function and one way cryptographic hash function. Security of the model is also analyzed with non adaptable indistinguishability security. Using this method an efficient idea of multi-cloud search environment is also proposed. In multi cloud searchable encryption several independent data providers collaborate in a federated way to provide search in their data through different independent cloud service provider revealing only keywords associated with the data.","","Electronic:978-1-4673-7399-9; POD:978-1-4673-7400-2","10.1109/INDICON.2015.7443233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443233","","Cloud computing;Databases;Encryption;Probabilistic logic;Servers","cloud computing;cryptography;data privacy;information retrieval","cryptographic hash function;indistinguishability obfuscation;information retrieval privacy;mimicry function;multicloud search environment;random oracle model;searchable encryption technique;trapdoor function","","","","23","","","17-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"Supervised Matrix Factorization Hashing for Cross-Modal Retrieval","J. Tang; K. Wang; L. Shao","Key Laboratory of Intelligent Computing and Signal Processing, Ministry of Education, Anhui University, Hefei, China","IEEE Transactions on Image Processing","20160519","2016","25","7","3157","3166","The target of cross-modal hashing is to embed heterogeneous multimedia data into a common low-dimensional Hamming space, which plays a pivotal part in multimedia retrieval due to the emergence of big multimodal data. Recently, matrix factorization has achieved great success in cross-modal hashing. However, how to effectively use label information and local geometric structure is still a challenging problem for these approaches. To address this issue, we propose a cross-modal hashing method based on collective matrix factorization, which considers both the label consistency across different modalities and the local geometric consistency in each modality. These two elements are formulated as a graph Laplacian term in the objective function, leading to a substantial improvement on the discriminative power of latent semantic features obtained by collective matrix factorization. Moreover, the proposed method learns unified hash codes for different modalities of an instance to facilitate cross-modal search, and the objective function is solved using an iterative strategy. The experimental results on two benchmark data sets show the effectiveness of the proposed method and its superiority over state-of-the-art cross-modal hashing methods.","1057-7149;10577149","","10.1109/TIP.2016.2564638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7466099","Cross-modal hashing;collective matrix factorization;cross-modal hashing;label consistency;local geometric consistency;multimedia retrieval","Image coding;Laplace equations;Linear programming;Manifolds;Multimedia communication;Semantics;Sparse matrices","computational complexity;geometry;graph theory;information retrieval;matrix decomposition","collective matrix factorization;cross-modal hashing;cross-modal retrieval;graph Laplacian;heterogeneous multimedia data;iterative strategy;label information;local geometric structure;low-dimensional Hamming space;supervised matrix factorization hashing","","2","","49","","20160506","July 2016","","IEEE","IEEE Journals & Magazines"
"Data security and privacy management in healthcare applications and clinical data warehouse environment","M. Puppala; T. He; X. Yu; S. Chen; R. Ogunti; S. T. C. Wong","Systems Medicine and Bioengineering Department of Houston Methodist Research Institute and Informatics Development Department of Houston Methodist Hospital, Houston, TX 77030 USA","2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)","20160421","2016","","","5","8","Health Information is considered the most sensitive information associated to an individual. Even though numerous suitable policies, guidelines, and compliance requirements are in place to safeguard health information, privacy and security breach remains key issues for electronic healthcare systems. In this paper we focus on these issues and propose a security and privacy model implemented in Methodist Environment for Translational and Outcomes Research (METEOR). METEOR was developed at Houston Methodist Hospital and consists of two components: the enterprise data warehouse (EDW) and a software intelligence and analytics (SIA) layer. This model indicates that patient privacy is best protected by implementing a systematic mix of technologies and best practices such as technical de-identification of data, restrictive data access, and security measures in the underlying technical platforms. Our results suggest that the proposed security model make data security compromise and unauthorized access of protected patient health information extremely improbable.","","Electronic:978-1-5090-2455-1; POD:978-1-5090-2456-8","10.1109/BHI.2016.7455821","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7455821","","Data privacy;Data warehouses;Databases;Medical services;Privacy;Security;Servers","data privacy;data warehouses;information retrieval;medical information systems;security of data","Methodist Environment for Translational and Outcomes Research;SIA layer;clinical data warehouse environment;data privacy management;data security;electronic healthcare system;enterprise data warehouse;healthcare application;patient health information;patient privacy;restrictive data access;software intelligence and analytics;technical data deidentification","","","","16","","","24-27 Feb. 2016","","IEEE","IEEE Conference Publications"
"K-Word Proximity Search on Encrypted Data","M. Gall; G. Brost","Fraunhofer AISEC, Garching, Germany","2016 30th International Conference on Advanced Information Networking and Applications Workshops (WAINA)","20160519","2016","","","365","372","Current Symmetric Searchable Encryption schemes do not fulfill the expectations of users that are used to web search engines. Although users are now able to search for multiple keywords, Boolean retrieval returns all results to a client regardless of how relevant the results are for the user. For searches in large data sets when also result sets are expected to be large, Boolean retrieval is not appropriate for users of modern information retrieval systems. In this paper, we present a SSE scheme that allows ranked retrieval on encrypted data, more specifically we enhanced highly-scalable Boolean retrieval with k-word proximity ranking. Additionally, we introduce an access control in our search engine, such that clients searching the data set will not learn anything about parts of the data set, for which they are not eligible. To achieve this, we rely on attribute-based authentication. Users of modern full text search engines (most of all internet search engines) are used to comfortable proximity search. The applicability of our scheme was shown in a prototypical implementation.","","Electronic:978-1-5090-2461-2; POD:978-1-5090-2462-9","10.1109/WAINA.2016.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471228","attribute-based encryption;proximity search;proxy re-encryption;searchable encryption","Encryption;Games;Indexes;Protocols;Servers","Internet;cryptography;information retrieval systems;search engines","Boolean retrieval;K-word proximity search;SSE scheme;Web search engines;attribute-based authentication;encrypted data;information retrieval systems;prototypical implementation;symmetric searchable encryption schemes","","","","24","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Using analogy computing for ontology development","V. Nejkovic; M. Tosic","Intelligent Information Systems Laboratory, Faculty of Electronic Engineering, University of Nis, Serbia","2016 IEEE 32nd International Conference on Data Engineering Workshops (ICDEW)","20160623","2016","","","115","120","In this paper, we address the problem of ontology development by exploiting analogy between different but related knowledge domains. We define analogy model and use it in combination with question-answering approach for ontology development and validation processes. The proposed approach was practically evaluated in the use case of developing ontology for a wireless networking interface software module based on existing ontology of another different but analogous module.","","Electronic:978-1-5090-2109-3; POD:978-1-5090-2110-9","10.1109/ICDEW.2016.7495628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495628","analogy computing;ontology;wireless networking","Cognition;Knowledge acquisition;Ontologies;Semantics;Software;Wireless communication;Wireless sensor networks","ontologies (artificial intelligence);question answering (information retrieval);radio networks;telecommunication computing","analogous module;analogy computing;ontology development;question-answering approach;wireless networking interface software module","","","","26","","","16-20 May 2016","","IEEE","IEEE Conference Publications"
"Efficient search engine approach for measuring similarity between words: Using page count and snippets","P. Murugesan; K. Malathi","PG student computer science and engineering, Indian Institute of Information Technology, Srirangam Tiruchirappalli","2015 Online International Conference on Green Engineering and Technologies (IC-GET)","20160419","2015","","","1","5","Web mining involve activities such as document clustering, community mining etc., to be performed on web. Such tasks need measuring semantic similarity between word. This helps in performing web mining activities easily in many applications. The accurate measures of semantic similarity between any two words is the difficult task. A new approach to measure similarity between words is based on text snippets and page count. These two measures are taken from the results of a search engine like Google. The lexical patterns are extracted from text snippets and word co-occurrence measures are defined using page count. The results of these two are combined. Moreover, the pattern clustering and pattern extraction algorithm are used to find various relationships between any two given words. Support Vector Machines is used to optimize the result. The empirical results reveal that the techniques are finding the best results that can be compared with human ratings and accuracy in web mining activity. Semantic similarity refers to the concept by which a set of document or words within the document are assigned a weight based on their meaning. The accurate measurement of such similarity plays an important role in Natural language Processing.","","Electronic:978-1-4673-9781-0; POD:978-1-4673-9782-7","10.1109/GET.2015.7453830","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7453830","Community mining;page count;pattern clustering;text snippets","Clustering algorithms;Engines;Mutual information;Pattern clustering;Search engines;Semantics;Web search","data mining;information retrieval;natural language processing;pattern clustering;search engines;string matching;support vector machines;word processing","Google;Web mining activities;document clustering;natural language processing;page count;pattern clustering algorithm;pattern extraction algorithm;search engine;search engine approach;semantic similarity;support vector machines;text snippets;word cooccurrence measures;word similarity measurement","","","","11","","","27-27 Nov. 2015","","IEEE","IEEE Conference Publications"
"An improved matrix factorization model under multidimensional context situation","J. Liu; Y. Wang; H. Tao","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, P.R. China","2015 IEEE/CIC International Conference on Communications in China (ICCC)","20160407","2015","","","1","6","Traditional recommender systems have won great success on electronic commerce. However, when the user-item rating record matrix is sparse, traditional recommendation algorithms perform poor, which is known as the cold-start problem. Recently, more and more contextual features have been proven to be valuable information for improving the accuracy of recommendation, and newly formed context-aware recommendation systems (CARS) provide a way to solve the cold-start problem by using some certain features such as users location, mood and social relationship. In order to handle multidimensional context, this paper first extracts relevant contextual information by calculating the information entropy, then divides the contextual information into three categories - user context, item context and interaction context. Finally, we extend the matrix factorization (MF) model to integrate the context information. Experimental results on LDOS-CoMoDa dataset have shown that our approach provides improvement in terms of recommendation accuracy.","","Electronic:978-1-5090-0243-6; POD:978-1-5090-0244-3","10.1109/ICCChina.2015.7448725","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448725","","Automobiles;Context;Context modeling;Mood;Motion pictures;Prediction algorithms;Sparse matrices","entropy;information retrieval;matrix decomposition;recommender systems","CARS;LDOS-CoMoDa dataset;cold-start problem;context-aware recommendation systems;contextual features;contextual information extraction;information entropy;interaction context;item context;matrix factorization model;multidimensional context situation;recommendation accuracy;user context;user-item rating record matrix","","2","","18","","","2-4 Nov. 2015","","IEEE","IEEE Conference Publications"
"Interactive browsing of large image databases","G. Schaefer","Department of Computer Science, Loughborough University, U.K.","2016 Sixth International Conference on Digital Information Processing and Communications (ICDIPC)","20160519","2016","","","168","170","With image databases expanding at a rapid rate, effective and efficient methods of managing and querying these collections are highly sought after. In this paper, we present image browsing as an alternative to retrieval based systems. Image browsers provide a visualisation of a complete image database together with tools for interactive and intuitive exploration of the dataset. As examples we give an introduction to our Hue Sphere Image Browser system which provides an intuitive hierarchical approach to navigating large image repositories, while we also present ports to mobile devices and large multi-touch screens.","","CD-ROM:978-1-4673-7503-0; Electronic:978-1-4673-7504-7; POD:978-1-4673-7505-4","10.1109/ICDIPC.2016.7470812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470812","","Browsers;Image color analysis;Image retrieval;Mobile handsets;Navigation;Visualization","data visualisation;image colour analysis;image retrieval;information retrieval systems;interactive systems;mobile computing;touch sensitive screens;visual databases","hue sphere image browser system;interactive dataset exploration;interactive large image database browsing;intuitive dataset exploration;large image repositories;large multitouch screens;mobile devices;retrieval based systems","","","","15","","","21-23 April 2016","","IEEE","IEEE Conference Publications"
"Software-Specific Named Entity Recognition in Software Engineering Social Content","D. Ye; Z. Xing; C. Y. Foo; Z. Q. Ang; J. Li; N. Kapre","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)","20160523","2016","1","","90","101","Software engineering social content, such as Q&A discussions on Stack Overflow, has become a wealth of information on software engineering. This textual content is centered around software-specific entities, and their usage patterns, issues-solutions, and alternatives. However, existing approaches to analyzing software engineering texts treat software-specific entities in the same way as other content, and thus cannot support the recent advance of entity-centric applications, such as direct answers and knowledge graph. The first step towards enabling these entity-centric applications for software engineering is to recognize and classify software-specific entities, which is referred to as Named Entity Recognition (NER) in the literature. Existing NER methods are designed for recognizing person, location and organization in formal and social texts, which are not applicable to NER in software engineering. Existing information extraction methods for software engineering are limited to API identification and linking of a particular programming language. In this paper, we formulate the research problem of NER in software engineering. We identify the challenges in designing a software-specific NER system and propose a machine learning based approach applied on software engineering social content. Our NER system, called S-NER, is general for software engineering in that it can recognize a broad category of software entities for a wide range of popular programming languages, platform, and library. We conduct systematic experiments to evaluate our machine learning based S-NER against a well-designed, and to study the effectiveness of widely-adopted NER techniques and features in the face of the unique characteristics of software engineering social content.","","Electronic:978-1-5090-1855-0; POD:978-1-5090-1856-7","10.1109/SANER.2016.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476633","Mining software repositories;named entity recognition","Androids;Computer languages;Libraries;Organizations;Software;Software engineering;Software standards","information retrieval;knowledge based systems;learning (artificial intelligence);software engineering;text analysis","API identification;S-NER;entity-centric applications;information extraction methods;issues-solutions;machine learning based approach;programming language;rule-based baseline system;software engineering social content;software engineering text analysis;software-specific NER system;software-specific entities;software-specific named entity recognition;usage patterns","","","","48","","","14-18 March 2016","","IEEE","IEEE Conference Publications"
"An abstract architecture design for medical information exchange","A. Ibrahim; M. Singhal","Computer Science Department, University of Kentucky, Lexington, KY","2016 International Conference on Industrial Informatics and Computer Systems (CIICS)","20160502","2016","","","1","6","Electronic Health Record (EHR) systems are being widely used by various healthcare providers due to the benefits these systems offer. As the exchange of medical information among different healthcare providers has become a point of interest, it poses serious integration, security, and privacy concerns. Previous work proposed to offer medical information exchange has been partially insecure, simple, and sometimes requires special hardware like smart cards. In this paper we present an abstract architecture design that allows on-demand reliable retrieval of medical information from remote providers regardless of geographic location, time difference or working hours. Also, it does not require any special hardware to operate.","","Electronic:978-1-4673-8743-9; POD:978-1-4673-8744-6","10.1109/ICCSII.2016.7462427","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7462427","Architecture Design;EHRs Exchange;HIPAA;Healthcare","Biomedical imaging;Contracts;Cryptography;Information exchange;Medical services;Privacy","data privacy;electronic data interchange;electronic health records;health care;information retrieval;software architecture","EHR systems;abstract architecture design;electronic health record;healthcare providers;integration;medical information exchange;on-demand reliable retrieval;privacy;remote providers;security","","1","","15","","","13-15 March 2016","","IEEE","IEEE Conference Publications"
"Hardware Covert Attacks and Countermeasures","J. Phukan; K. F. Li; F. Gebali","Dept. of Electr. & Comput. Eng., Univ. of Victoria, Victoria, BC, Canada","2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)","20160523","2016","","","1051","1054","Computing platforms deployed in many critical infrastructures, such as smart grid, financial systems, governmental organizations etc., are subjected to security attacks and potentially devastating consequences. Computing platforms often get attacked 'physically' by an intruder accessing stored information, studying the internal structure of the hardware or injecting a fault. Even if the attackers fail to gain sensitive information stored in hardware, they may be able to disrupt the hardware or deny service leading to other kinds of security failures in the system. Hardware attacks could be covert or overt, based on the awareness of the intended system. This work classifies existing hardware attacks. Focusing mainly on covert attacks, they are quantified using a proposed schema. Different countermeasure techniques are proposed to prevent such attacks.","1550-445X;1550445X","Electronic:978-1-5090-1858-1; POD:978-1-5090-1859-8","10.1109/AINA.2016.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474205","attack classification;computer security;covert attack;covert attack countermeasure;hardware attack","Encryption;Hardware;Read only memory;Subspace constraints;Timing","critical infrastructures;information retrieval;security of data","computing platforms;countermeasures;critical infrastructures;hardware covert attacks;security attacks;security failures;stored information access","","","","19","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Neural potential learning for tweets classification and interpretation","R. Kitajima; R. Kamimura; O. Uchida; F. Toriumi","Graduate School of Science and Technology, Tokai University Kanagawa, Japan","2015 7th International Conference of Soft Computing and Pattern Recognition (SoCPaR)","20160616","2015","","","141","148","The present paper aims to apply a new neural learning method called ""Neural Potential Learning, NPL"" to the classification and interpretation of tweets. It has been well known that social media such as the Twitter play crucial roles in transmitting important information at the time of natural disasters. In particular, since the Great East Japan Earthquake in 2011, the Twitter has been considered as one of the most efficient and convenient communication tools. However, because much redundant information is contained in the tweets, it is usually difficult to obtain important information from the flows of the tweets. Thus, it is urgently needed to develop some methods to extract the important and useful information from redundant tweets. To cope with complex and redundant data, a new neural potential learning has been developed to extract the important information. The method aims to find some highly potential neurons and enhance those neurons as much as possible to reduce redundant information and to focus on important information. The method was applied to the real tweets data collected in the earthquake and it was found that the method could classify the tweets as important and unimportant ones more accurately than the other conventional machine learning methods. In addition, the method made it possible to interpret how the tweets could be classified, based on the examination of highly potential neurons.","","Electronic:978-1-4673-9360-7; POD:978-1-4673-9361-4","10.1109/SOCPAR.2015.7492798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7492798","Twitter;classification;interpretation;neural network;potentiality","Biological neural networks;Earthquakes;Electronic mail;Neurons;Supervised learning;Training","emergency services;information retrieval;learning (artificial intelligence);neural nets;pattern classification;redundancy;social networking (online)","Great East Japan Earthquake;NPL method;communication tools;complex data;natural disasters;neural potential learning;redundant data;redundant information reduction;social media;tweets classification;tweets interpretation;twitter;useful information extraction","","1","","24","","","13-15 Nov. 2015","","IEEE","IEEE Conference Publications"
"App relationship calculation: An iterative process","M. Liu; C. Wu; X. N. Zhao; C. Y. Lin; X. L. Wang","School of Computer Science and Technology, Harbin Institute of Technology, China","2016 IEEE 32nd International Conference on Data Engineering (ICDE)","20160623","2016","","","1540","1541","Today, plenty of apps are released to help users make the best use of their mobile phones. Facing the large amount of apps, app retrieval and app recommendation are extensively adopted to help users obtain their favorite apps. To acquire the high-quality retrieval or recommending results, it needs to obtain the accurate app relationship calculating results in advance. Unfortunately, recent methods are conducted mostly depending on user's log or app's contexts, which can only detect whether two apps are downloaded, installed meanwhile or provide similar functions or not. In fact, apps contain many deep relationships other than similarity, e.g., one app needs another app to cooperate to fulfill its work. Obviously, app's reviews contain user's viewpoint. They are useful to help dig deep relationship between apps. Therefore, to calculate relationship between apps via reviews, we propose an iterative process by combining review similarity calculation and app relationship calculation together.","","Electronic:978-1-5090-2020-1","10.1109/ICDE.2016.7498414","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498414","","Computer science;Context;Correlation;Dictionaries;Iterative methods;Semantics;Thesauri","information retrieval;iterative methods;mobile computing;recommender systems","App relationship calculation;app recommendation;app retrieval;high-quality retrieval;iterative process;mobile phones","","","","6","","","16-20 May 2016","","IEEE","IEEE Conference Publications"
"A framework for focused linked data crawler using context graphs","S. Bai; S. Hussain; S. Khoja","Faculty of Computer Science, Institute of Business Administration, Karachi, Pakistan","2015 International Conference on Information and Communication Technologies (ICICT)","20160519","2015","","","1","6","In this paper, we propose a framework for focused Linked Data (LD) crawler based on context graphs. A focused crawler searches for a specific subset of web, in our case it targets interlinked RDF data stores. The proposed crawler constructs set of context graphs for the given seed URIs by back crawling the web, and classifiers are trained to detect and assign documents to different categories based on the content type. These classifier help crawler in search and updating of context graphs automatically. The crawler are trained using supervised learning. Additionally, an extensive overview of existing LD crawlers is also provided along with its basic requirements, architecture, issues and challenges.","","Electronic:978-1-4673-8907-5; POD:978-1-4673-8908-2","10.1109/ICICT.2015.7469580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469580","Classifiers;Context Graphs;Crawler;Linked Data","Bandwidth;Context;Crawlers;HTML;Indexing;Resource description framework;Search engines","Internet;data mining;graph theory;information retrieval;learning (artificial intelligence);pattern classification;text analysis","URI;Web crawling;classifier training;content type;context graph;document assignment;document detection;focused linked data crawler;interlinked RDF data stores;supervised learning","","","","29","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Efficient unsteady flow visualization with high-order access dependencies","J. Zhang; H. Guo; X. Yuan","Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University","2016 IEEE Pacific Visualization Symposium (PacificVis)","20160505","2016","","","80","87","We present a novel high-order access dependencies-based model for efficient pathline computation in unsteady flow visualization. By taking longer access sequences into account to model more sophisticated data access patterns in particle tracing, our method greatly improves the accuracy and reliability in data access prediction. In our work, high-order access dependencies are calculated by tracing uniformly seeded pathlines in both forward and backward directions in a preprocessing stage. The effectiveness of our approach is demonstrated through a parallel particle tracing framework with high-order data prefetching. Results show that our method achieves higher data locality and hence improves the efficiency of pathline computation.","","Electronic:978-1-5090-1451-4; POD:978-1-5090-1452-1","10.1109/PACIFICVIS.2016.7465254","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7465254","","Computational modeling;Data models;Data visualization;Markov processes;Mathematical model;Prefetching;Reliability","data flow computing;data visualisation;information retrieval;ray tracing;storage management","data access prediction;data locality;high-order access dependencies;high-order data prefetching;parallel particle tracing framework;pathline computation;sophisticated data access patterns;uniformly seeded pathline tracing;unsteady flow visualization","","","","28","","","19-22 April 2016","","IEEE","IEEE Conference Publications"
"Friend recommendation framework for social networking sites using user's online behavior","M. M. Hasan; N. H. Shaon; A. A. Marouf; M. K. Hasan; H. Mahmud; M. M. Khan","Systems and Software Lab (SSL), Department of Computer Science and Engineering (CSE) Islamic University of Technology (IUT), Gazipur, Bangladesh","2015 18th International Conference on Computer and Information Technology (ICCIT)","20160609","2015","","","539","543","Social network sites (SNS's) have connected millions of users creating the social revolution. Users' social behavior influences them to connect with others with same mentality. Social networks are constituted because of its user or organizations common interest in some social emerging issues. The popular social networking sites are Facebook, Twitter, MySpace, Orkut, LinkedIn, Google plus etc. which are actually online social networking (OSN) sites. However, the large amount of online users and their diverse and dynamic interests possess great challenges to support recommendation of friends on SNS's for each of the users. In this paper, we proposed a novel friend recommendation framework (FRF) based on the behavior of users on particular SNS's. The proposed method is consisted of the following stages: measuring the frequency of the activities done by the users and updating the dataset according to the activities, applying FP-Growth algorithm to classify the user behavior with some criteria, then apply multilayer thresholding for friend recommendation. The proposed framework shows good accuracy for social graphs used as model dataset.","","Electronic:978-1-4673-9930-2; POD:978-1-4673-9931-9","10.1109/ICCITechn.2015.7488130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7488130","FP-Growth Algorithm;Friend Recommendation Framework (FRF);Multilayer Thresholding;Social Entities;Social Networking Sites (SNS's)","Facebook;Games;MySpace;Nonhomogeneous media;Postal services;Twitter","behavioural sciences computing;information retrieval;recommender systems;social networking (online)","FP-growth algorithm;FRF;Facebook;Google plus;LinkedIn;MySpace;OSN sites;Orkut;SNS;Twitter;dataset update;friend recommendation framework;multilayer thresholding;online social networking sites;online users;user behavior;user online behavior;user social behavior;users activity frequency measurement","","","","18","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Cross-Modal Retrieval via Deep and Bidirectional Representation Learning","Y. He; S. Xiang; C. Kang; J. Wang; C. Pan","National Laboratory of Pattern Recognition, Institute of Automation, Beijing, China","IEEE Transactions on Multimedia","20160615","2016","18","7","1363","1377","Cross-modal retrieval emphasizes understanding inter-modality semantic correlations, which is often achieved by designing a similarity function. Generally, one of the most important things considered by the similarity function is how to make the cross-modal similarity computable. In this paper, a deep and bidirectional representation learning model is proposed to address the issue of image-text cross-modal retrieval. Owing to the solid progress of deep learning in computer vision and natural language processing, it is reliable to extract semantic representations from both raw image and text data by using deep neural networks. Therefore, in the proposed model, two convolution-based networks are adopted to accomplish representation learning for images and texts. By passing the networks, images and texts are mapped to a common space, in which the cross-modal similarity is measured by cosine distance. Subsequently, a bidirectional network architecture is designed to capture the property of the cross-modal retrieval-the bidirectional search. Such architecture is characterized by simultaneously involving the matched and unmatched image-text pairs for training. Accordingly, a learning framework with maximum likelihood criterion is finally developed. The network parameters are optimized via backpropagation and stochastic gradient descent. A great deal of experiments are conducted to sufficiently evaluate the proposed method on three publicly released datasets: IAPRTC-12, Flickr30k, and Flickr8k. The overall results definitely show that the proposed architecture is effective and the learned representations have good semantics to achieve superior cross-modal retrieval performance.","1520-9210;15209210","","10.1109/TMM.2016.2558463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460254","Bidirectional Modeling;Bidirectional modeling;Convolutional Neural Network;Cross-Modal Retrieval;Representation Learning;Word Embedding;convolutional neural network;cross-modal retrieval;representation learning;word embedding","Computational modeling;Convolution;Correlation;Feature extraction;Neural networks;Semantics;Training","backpropagation;computer vision;convolution;gradient methods;information retrieval;knowledge representation;maximum likelihood estimation;natural language processing;neural nets;optimisation;stochastic processes;text analysis","backpropagation;bidirectional network architecture;bidirectional representation learning;computer vision;convolution-based network;cosine distance;deep neural network;image-text cross-modal retrieval;maximum likelihood criterion;natural language processing;network parameter optimization;similarity function;stochastic gradient descent","","1","","61","","20160427","July 2016","","IEEE","IEEE Journals & Magazines"
"Smart semantic-based approach for mobile applications in pervasive environments","A. Alti; M. Achouri; M. Derdour; P. Roose","LRSD, University of Setif-1, S&#233;tif - Algeria","2016 International Conference on Information Technology for Organizations Development (IT4OD)","20160526","2016","","","1","6","Today, the field of smart-* (Home, City, Health, Tourism, etc.) is oriented multimedia by nature, highly heterogeneous and now lacks of intelligent way to able to manage various modalities according to the current users needs, usage situations and execution context. In consequence, mobile applications are certainly existing but often inadequate according to users' expectations and more precisely the instant expectations. The inclusion in our daily life, connected objects can retrieve information directly related to the immediate physical environment and the user. The use of different services from devices according to evolutionary scenarios affects both the nature and presentation of information and the different interactions that the user can and must have. The main idea is to design new way to make relevant semantic connected objects, multi-devices and many more agility and to use the cloud as a way to insure the service continuity on mobile devices. This paper presents an autonomic smart semantic based context-aware service and controller that will enhance users experience through the use of optimized semantic multimodal detection services. The originality of the dedicated cloud and context-aware of quality service composition paths is that it relies on smart multimodal inputs and multimodal user preferences. We propose real case study in order to validate our proposal.","","Electronic:978-1-4673-7689-1; POD:978-1-4673-7690-7","10.1109/IT4OD.2016.7479327","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479327","Context-aware;ambiant services;autonomic reconfiguration;cloud;multi-modality","Clouds;Context;Mobile communication;Mobile handsets;Semantics;Temperature sensors","cloud computing;ergonomics;information retrieval;mobile computing;quality of service","autonomic smart semantic based context-aware service;evolutionary scenarios;information retrieval;mobile applications;mobile devices;multimodal user preferences;optimized semantic multimodal detection services;pervasive environments;physical environment;quality service composition paths;semantic connected objects;service continuity;smart multimodal inputs;users experience","","","","18","","","March 30 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Privacy-preserving multi-keyword ranked search over encrypted big data","Yanzhu Liu; Zhi Li; Wang Guo; Wu Chaoxia","School of Computer and Communication Engineering, University of Science and Technology Beijing(USTB), 100083, China","Third International Conference on Cyberspace Technology (CCT 2015)","20160407","2015","","","1","3","Common data is become more meaningful after dealing with, so it makes hacker get the private information, after dealing with the data, more easier. To the Sensitive Data, the data must be encrypted before outsourced, through encryption to protect user's and company's privacy, but the encrypted data can't be searched over traditional search scheme. In this paper, we solve the problem of privacy-preserving multi-keyword ranked search over encrypted data in big data, called BDES. It can feedback the best search result to users. BDES can solve the problem of traditional Search, such as, inefficient, lack privacy protection, single keyword, multi-users and so on.","","Electronic|Paper:978-1-78561-090-5|978-1-78561-089-9","10.1049/cp.2015.0851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7446943","Big Data","","Big Data;cryptography;data privacy;information retrieval","BDES;company privacy protection;encrypted big data;privacy-preserving multikeyword ranked search;private information;sensitive data;user privacy protection","","","","","","","17-18 Oct. 2015","","IET","IET Conference Publications"
"Research on Semantic Retrieval for Communication Ontology","F. Wenting; L. Yunqing; X. Yanlong; C. Jing; Y. Xiaopeng","Jiangxi Normal Univ., Nanchang, China","2015 8th International Conference on Intelligent Computation Technology and Automation (ICICTA)","20160519","2015","","","756","760","Seven-step method is used to build the communication domain ontology, and the system uses Jena stored the ontology to the relational database. It Uses ICTCLAS Chinese word segmentation machine to deal with retrieval request submitted by users and converted to specification format which the system can identify. Using distance-based semantic similarity algorithm which adds edge type for quantizing semantic distance between concepts, this algorithm improve the accuracy of quantitative the semantic similarity between concepts, and building a semantic retrieval for communication ontology system.","","Electronic:978-1-4673-7644-0; POD:978-1-4673-7645-7","10.1109/ICICTA.2015.192","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7473408","Communications;Ontology;Semantic Retrieval","Classification algorithms;Communication networks;Databases;OWL;Ontologies;Semantics;Thesauri","information retrieval;natural language processing;ontologies (artificial intelligence);relational databases;word processing","ICTCLAS Chinese word segmentation machine;communication domain ontology;distance-based semantic similarity algorithm;relational database;semantic distance;semantic retrieval;specification format","","","","8","","","14-15 June 2015","","IEEE","IEEE Conference Publications"
"An End-to-End Neural Network for Polyphonic Piano Music Transcription","S. Sigtia; E. Benetos; S. Dixon","Centre for Digital Music, School of Electronic Engineering, and Computer Science, Queen Mary University of London, London, U.K.","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20160324","2016","24","5","927","939","We present a supervised neural network model for polyphonic piano music transcription. The architecture of the proposed model is analogous to speech recognition systems and comprises an acoustic model and a music language model. The acoustic model is a neural network used for estimating the probabilities of pitches in a frame of audio. The language model is a recurrent neural network that models the correlations between pitch combinations over time. The proposed model is general and can be used to transcribe polyphonic music without imposing any constraints on the polyphony. The acoustic and language model predictions are combined using a probabilistic graphical model. Inference over the output variables is performed using the beam search algorithm. We perform two sets of experiments. We investigate various neural network architectures for the acoustic models and also investigate the effect of combining acoustic and music language model predictions using the proposed architecture. We compare performance of the neural network-based acoustic models with two popular unsupervised acoustic models. Results show that convolutional neural network acoustic models yield the best performance across all evaluation metrics. We also observe improved performance with the application of the music language models. Finally, we present an efficient variant of beam search that improves performance and reduces run-times by an order of magnitude, making the model suitable for real-time applications.","2329-9290;23299290","","10.1109/TASLP.2016.2533858","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416164","Automatic Music Transcription,;Automatic music transcription;Deep Learning;Music Language Models;Recurrent Neural Networks;deep learning;music language models;recurrent neural networks","Acoustics;Computational modeling;Feature extraction;Hidden Markov models;Recurrent neural networks;Spectrogram","information retrieval;learning (artificial intelligence);music;musical instruments;recurrent neural nets;search problems;speech recognition","MIR;acoustic model;acoustic models;audio frame;beam search algorithm;end-to-end neural network;evaluation metrics;language model predictions;music information retrieval;music language model;music language model predictions;music language models;polyphonic music;polyphonic piano music transcription;probabilistic graphical model;recurrent neural network;speech recognition systems;supervised neural network model;unsupervised acoustic models","","1","","52","","20160223","May 2016","","IEEE","IEEE Journals & Magazines"
"Document summarization based on semantic representations","Hui Zhang; Xueliang Zhang; Guanglai Gao","Department of Computer Science, Inner Mongolia University, Hohhot, China, 010021","2015 International Conference on Asian Language Processing (IALP)","20160414","2015","","","152","155","We present a novel extractive summarization method based on semantic vector representation. The new representation extends the word embedding, and represents words, phrases, sentences, paragraphs and documents in same vector space, which is used to measure the semantic similarity between sentences and document. Then we use greedy search algorithm to extract the summary sentences. The proposed method is evaluated on DUC01 dataset and employ F1-measure and ROUGE-N as metrics. The results show the proposed method outperforms comparison methods. The ROUGE-N is much higher than others.","","CD-ROM:978-1-4673-9594-6; Electronic:978-1-4673-9596-0; POD:978-1-4673-9597-7","10.1109/IALP.2015.7451554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451554","automatic summarization;bag of word vectors (BOWV);semantic vector representation","Pragmatics;Semantics","document handling;greedy algorithms;information retrieval;search problems","DUC01 dataset;F1-measure;ROUGE-N;document representation;document summarization;extractive summarization method;greedy search algorithm;paragraph representation;phrase representation;semantic similarity measurement;semantic vector representation;sentence representation;summary sentence extraction;word embedding;word representation","","","","26","","","24-25 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Deep and Autoregressive Approach for Topic Modeling of Multimodal Data","Y. Zheng; Y. J. Zhang; H. Larochelle","Department of Electronic Engineering, Tsinghua University, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","20160504","2016","38","6","1056","1069","Topic modeling based on latent Dirichlet allocation (LDA) has been a framework of choice to deal with multimodal data, such as in image annotation tasks. Another popular approach to model the multimodal data is through deep neural networks, such as the deep Boltzmann machine (DBM). Recently, a new type of topic model called the Document Neural Autoregressive Distribution Estimator (DocNADE) was proposed and demonstrated state-of-the-art performance for text document modeling. In this work, we show how to successfully apply and extend this model to multimodal data, such as simultaneous image classification and annotation. First, we propose SupDocNADE, a supervised extension of DocNADE, that increases the discriminative power of the learned hidden topic features and show how to employ it to learn a joint representation from image visual words, annotation words and class label information. We test our model on the LabelMe and UIUC-Sports data sets and show that it compares favorably to other topic models. Second, we propose a deep extension of our model and provide an efficient way of training the deep model. Experimental results show that our deep model outperforms its shallow version and reaches state-of-the-art performance on the Multimedia Information Retrieval (MIR) Flickr data set.","0162-8828;01628828","","10.1109/TPAMI.2015.2476802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7258387","Deep neural network;Multimodal data modeling;Neural autoregressive model;Topic model;deep neural network;neural autoregressive model;topic model","Computational modeling;Data models;Joints;Mathematical model;Neural networks;Training;Visualization","Boltzmann machines;autoregressive processes;document image processing;image representation;information retrieval;multimedia systems;text analysis","DBM;DocNADE;Flickr data set;LDA;LabelMe;MIR;UIUC-Sports data sets;annotation words;class label information;deep Boltzmann machine;deep neural networks;document neural autoregressive distribution estimator;image annotation tasks;image visual words;joint representation;latent Dirichlet allocation;multimedia information retrieval;multimodal data;text document modeling;topic modeling","","1","","35","","20150911","June 1 2016","","IEEE","IEEE Journals & Magazines"
"A New Glowworm Swarm Optimization Based Clustering Algorithm for Multimedia Documents","K. Pushpalatha; V. S. Ananthanarayana","Dept. of Inf. Technol., Nat. Inst. of Technol. Karnataka, Surathkal, India","2015 IEEE International Symposium on Multimedia (ISM)","20160328","2015","","","262","265","Due to the explosion of multimedia data, the demand for the sophisticated multimedia knowledge discovery systems has been increased. The multimodal nature of multimedia data is the big barrier for knowledge extraction. The representation of multimodal data in a unimodal space will be more advantageous for any mining task. We initially represent the multimodal multimedia documents in a unimodal space by converting the multimedia objects into signal objects. The dynamic nature of the glowworms motivated us to propose the Glowworm Swarm Optimization based Multimedia Document Clustering (GSOMDC) algorithm to group the multimedia documents into topics. The better purity and entropy values indicates that the GSOMDC algorithm successfully clusters the multimedia documents into topics. The goodness of the clustering is evaluated by performing the cluster based retrieval of multimedia documents with better precision values.","","Electronic:978-1-5090-0379-2; POD:978-1-5090-0380-8; USB:978-1-5090-0378-5","10.1109/ISM.2015.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442338","Clustering;Glowworm Swarm Optimization;Multimedia Document;Multimodal;Unified Representation","Algorithm design and analysis;Clustering algorithms;Entropy;Heuristic algorithms;Media;Multimedia communication;Particle swarm optimization","data mining;document handling;information retrieval;multimedia computing;pattern clustering","GSOMDC algorithm;cluster based retrieval;glowworm swarm optimization based clustering algorithm;knowledge extraction;multimedia knowledge discovery systems;multimodal multimedia documents","","","","17","","","14-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"An enhanced LSA-based approach for update summarization","Guo-Hua Wu; Yu-Tian Guo","Department of computing science, Hangzhou Dianzi University, 310000, China","2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20160620","2015","","","493","497","Update summarization is a challenge in automatic text summarization. The task aims to distill evolved messages from a collection of new articles, under the assumption that the reader has already browsed the previous articles. In this paper, we reviewed some state-of-the-art approaches for extracting update summarization and then focused on a LSA-based one. After the analysis of LSA-based approach's framework, we improved the approach by enhancing the approach's performance in accuracy. First, we utilized TOPIC SIGNATURE algorithm to extract the terms' novel information and incorporated the information to the process of evaluating topic's novelty score, which makes the evaluation more accuracy. Second, we excluded the least novel and important topics when generating summary, which helps improving the quality of the summary. The evaluation result on the update summarization task of Text Analysis Conference (TAC) 2008 indicates the validity of our modification.","","Electronic:978-1-4673-8266-3; POD:978-1-4673-8267-0","10.1109/ICCWAMTIP.2015.7494038","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7494038","LSA;Update summarization;topic signature","Algorithm design and analysis;Mathematical model;Matrix decomposition;Resource management;Semantics;Text analysis","abstracting;information retrieval;text analysis","TAC 2008;Text Analysis Conference 2008;automatic text summarization;enhanced LSA-based approach;term information extraction;topic novelty score evaluation;topic signature algorithm;update summarization","","","","12","","","18-20 Dec. 2015","","IEEE","IEEE Conference Publications"
"Finding similar patents through semantic expansion","P. Sharma; R. Tripathi; R. C. Tripathi","Indian Institute of Information, Technology-Allahabad, India","2016 International Conference on Computer Communication and Informatics (ICCCI)","20160530","2016","","","1","5","Semantic information retrieval technique is widely applied in various research areas. However the key consideration is about selecting the most extensive external source which can be used for augmenting the query. In this research paper we have employed WordNet and Wiktionary as two external sources for expanding the query and finding the effect of it over the similarity models. We found that a combination of two external sources gives much improved result in comparison to single source expansion. We have further selected wu-palmer model to measure the efficiency of these combined models of expansion to find the effect on similarity in comparison to the tradition similarity cosine model.","","CD-ROM:978-1-4673-6678-6; Electronic:978-1-4673-6680-9; POD:978-1-4673-6681-6","10.1109/ICCCI.2016.7479982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479982","Cosine similarity;Patent search;Semantic similarity;Wiktionary;WordNet;Wu-Palmer","Computational modeling;Computers;Databases;Patents;Semantics;Taxonomy","information retrieval","Wiktionary;WordNet;semantic expansion;semantic information retrieval technique;wu-palmer model","","","","8","","","7-9 Jan. 2016","","IEEE","IEEE Conference Publications"
"Information system at the Moroccan University: A business intelligence tool for management and communication of scientific research","Y. Elhissi; A. Haqiq","Computer, Networks, Mobility and Modeling laboratory, Department of Mathematics and Computer, FST, Hassan 1st University, Settat, Morocco","2016 International Conference on Information Technology for Organizations Development (IT4OD)","20160526","2016","","","1","5","In a context of E-Governance and modernization of higher education, the Moroccan University is facing new challenges, such as: - Orientation, development and promotion of scientific research that meets the needs of the socio-economic environment and therefore affects the lives of citizens. - Developing the culture of communication and information by ending practices that limit the dissemination of information. Moroccan strategy for the development of higher education has focused all its projects on the use of new technologies for the management and structuring of research, and the promotion and enhancement of its activities. To this end, the establishment of an information system for the management and communication of research in the university can organize all the research activities, structure research units on an administrative and financial sides it can also communicate its work to enhance the sharing and open a window of partnership with its socio-economic environment. This work aims to develop an information system for management, information security and communication research in the Moroccan university. This system will allow collecting, classification, processing and disseminating information related to scientific research at the university in order to organize and structure all its activities. It will also enable all university's actors to use a digital workspace to access and share information, and therefore interact and get involved in the promotion of scientific research at the university.","","Electronic:978-1-4673-7689-1; POD:978-1-4673-7690-7","10.1109/IT4OD.2016.7479286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7479286","Communication;Information Security;Information System;Management;Moroccan University;Scientific Research","Collaboration;Computers;Context;Education;Information systems;Organizations;Stakeholders","classification;competitive intelligence;educational administrative data processing;further education;information dissemination;information retrieval;scientific information systems;security of data","Moroccan University;Moroccan strategy;business intelligence tool;digital workspace;e-governance;higher education;information access;information classification;information collection;information dissemination;information processing;information security;information sharing;information system;scientific research communication;scientific research management;socio-economic environment","","","","10","","","March 30 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Data archiving system implementation in ITER's CODAC CORE SYSTEM","R. Castro; L. Abadie; Y. Makushok; P. Makijarvi; J. Vega; M. Ruiz; D. Sanz; S. Simrock; J. Faig; G. Román-Pérez","CIEMAT Fusion program, Avda. Complutense 40, Madrid, Spain","2015 IEEE 26th Symposium on Fusion Engineering (SOFE)","20160602","2015","","","1","4","A new data archiving implementation developed by the CIEMAT-INDRA-SGENIA-UPM Consortium (in alphabetical order) has been fully integrated into ITER's CODAC CORE SYSTEM at the beginning of year 2015. This software includes components on the client and server sides that are responsible for the distribution and archiving of acquired or process-generated data, with important restrictions. On the one side, ITER's high pulse length requires that any data archiving implementation include a steady state archiving mechanism with continuous storage of the data acquired and processed throughout the experiment. On the other side, all these data must be safely archived and continuously available for read systems on the client side in a short time from their acquisition. On the side of client systems, a new software library has been developed with two main goals. The first one is to provide simple and complete data archiving functionality, while the second pursues to implement a continuous and efficient data distribution engine including different data sources as well as a diversity of potential consumer systems. From the server-based perspective, a complete solution has been implemented using the HDF5 files as the underlying data storage technology, while adapting the metadata structures and data access protocols to meet ITER's CODAC requirements.","","Electronic:978-1-4799-8264-6; POD:978-1-4799-8265-3","10.1109/SOFE.2015.7482290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482290","archiving;fusion;iter","Control systems;Data acquisition;Libraries;Metadata;Servers;Software","client-server systems;data acquisition;fusion reactor design;information retrieval;information retrieval systems;meta data;nuclear engineering computing;software libraries;storage management","CIEMAT-INDRA-SGENIA-UPM Consortium;HDF5 files;ITER CODAC CORE SYSTEM;ITER high pulse length;alphabetical order;client system;consumer systems;data access protocols;data archiving implementation;data distribution engine;data sources;data storage;data storage technology;metadata structures;process-generated data;read system;server system;server-based perspective;software library;steady state archiving mechanism","","","","3","","","May 31 2015-June 4 2015","","IEEE","IEEE Conference Publications"
"Iteratively reweighted tensor SVD for robust multi-dimensional harmonic retrieval","W. Sun; X. Lin; H. C. So; L. Huang; Q. Li","Key Lab of Multidimensional Signal Processing, Shenzhen University, China","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20160519","2016","","","4318","4322","In this paper, parameter estimation for multi-dimensional sinusoids in additive impulsive noise is addressed. Our underlying idea is to minimize the ℓ<sub>p</sub>-norm of the residual error tensor, where 1 <; p <; 2, and transform this problem to an iterative ℓ<sub>2</sub>-norm minimization. In doing so, we can utilize the tensorial structure of the received data and then apply iteratively reweighted tensor singular value decomposition, referred to as IR-t-SVD, to recover the subspace or the signal tensor. After the recovery step, standard subspace techniques can be applied for parameter estimation. Based on the numerical results, IR-t-SVD outperforms several state-of-the-art methods in terms of mean square frequency error under α-stable noise.","","Electronic:978-1-4799-9988-0; POD:978-1-4799-9989-7; USB:978-1-4799-9987-3","10.1109/ICASSP.2016.7472492","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472492","ℓ<inf>p</inf>-norm;Harmonic Retrieval;Parameter Estimation;tensor Singular Value Decomposition","Estimation;Harmonic analysis;Matrix decomposition;Minimization;Multiple signal classification;Robustness;Tensile stress","information retrieval;iterative methods;minimisation;parameter estimation;singular value decomposition;tensors","IR-t-SVD;additive impulsive noise;iterative ℓ<sub>2</sub>-norm minimization;iteratively reweighted tensor SVD;mean square frequency error;multidimensional sinusoids;parameter estimation;reweighted tensor singular value decomposition;robust multidimensional harmonic retrieval;signal tensor;standard subspace techniques;tensorial structure","","","","25","","","20-25 March 2016","","IEEE","IEEE Conference Publications"
"Efficient File Search in Delay Tolerant Networks with Social Content and Contact Awareness","K. Chen; H. Shen; L. Yan","Department of Electrical and Computer Engineering, Carbondale, IL","IEEE Transactions on Parallel and Distributed Systems","20160610","2016","27","7","1982","1995","Distributed file searching in delay tolerant networks formed by mobile devices can potentially support various useful applications. In such networks, nodes often present certain social network properties of their holders in terms of contents (i.e., interests) and contacts. However, current methods in DTNs only consider either content or contact for file searching or dissemination, which limits the file sharing efficiency. In this paper, we first analyze real traces to confirm the importance and necessity of considering both content and contact in file search. We then propose Cont<sup>2</sup>, a social-aware file search method that exploits both node contents and contact patterns. First, considering people with common interests tend to share files and gather together, Cont<sup>2</sup> virtually groups common-interest nodes into a community to direct file search. Second, considering human mobility follows a certain pattern, Cont<sup>2</sup> exploits nodes' contact frequencies with a community to expedite file searching. To further improve the searching efficiency, Cont<sup>2</sup> also integrates sub-communities and parallel forwarding as optional components for file searching. Trace-driven experiments on the GENI testbed and NS-2 simulator show that Cont<sup>2</sup> can effectively improve the search efficiency compared to current methods.","1045-9219;10459219","","10.1109/TPDS.2015.2472005","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219439","Delay Tolerant Networks;File Search;Social-Aware;Social-aware;delay tolerant networks;file search","Delays;Mobile handsets;Nickel;Peer-to-peer computing;Routing;Servers;Social network services","delay tolerant networks;distributed databases;information retrieval;search engines;social networking (online)","Cont<sup>2</sup>;DTN;GENI testbed;NS-2 simulator;common-interest node groups;contact awareness;contact patterns;delay tolerant networks;distributed file search;file dissemination;file sharing efficiency;mobile devices;network nodes;node contact frequencies;node contents;parallel forwarding;search efficiency improvement;social content;social network properties;social-aware file search method","","0","","36","","20150824","July 1 2016","","IEEE","IEEE Journals & Magazines"
"Extracting semantic information without linguistic cues from generic sentences","M. Madiman; A. Deo","Department of Mathematical Sciences, University of Delaware, Newark, 19716, USA","2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)","20160407","2015","","","1302","1307","A probabilistic approach is adopted to propose a novel solution to a perplexing puzzle from semantic theory involving the interpretation of generic sentences.","","Electronic:978-1-5090-1824-6; POD:978-1-5090-1825-3","10.1109/ALLERTON.2015.7447158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447158","","Encoding;Mathematical model;Noise measurement;Pragmatics;Probabilistic logic;Semantics","information retrieval;linguistics;probability","generic sentence interpretation;probabilistic approach;semantic information extraction;semantic theory","","","","15","","","Sept. 29 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Goal-aware data management for retrieval and recommendations","D. Papadimitriou","DISI, University of Trento, Italy","2016 IEEE 32nd International Conference on Data Engineering Workshops (ICDEW)","20160623","2016","","","216","220","Human activity is almost always intentional. By understanding why user-generated events are happening and what purposes they serve, a system can offer a significantly improved and more engaging experience. Analyzing user actions such as clicks can reveal patterns and behaviors. However, understanding the goals behind these actions is a more challenging issue since goals cannot be easily captured. In this thesis, we present a unified, multi-disciplinary viewpoint for goal management that covers many different cases where goals can be used and techniques with which they can be exploited. We are dealing with the problem of selecting and recommending items that will fulfill, or contribute towards the fulfillment of user goals. Specifically, we suggest a goal-aware solution for the problem of finding related forum posts to a post at-hand within a user-community. Our solution is based on the detection of intention shifts captured through text features. Furthermore, we suggest a general purpose solution for recommending items of any kind by leveraging knowledge about goals that users managed to fulfill in the past through interactions with these items. The items to be recommended are selected considering whether and how they will contribute towards the fulfillment of a number of goals.","","Electronic:978-1-5090-2109-3; POD:978-1-5090-2110-9","10.1109/ICDEW.2016.7495651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495651","","Adaptation models;Conferences;Context;Data models;Information systems;Lead;Linux","data handling;information retrieval;recommender systems","goal-aware data management;human activity;information recommendation;information retrieval;user action;user-generated event","","","","13","","","16-20 May 2016","","IEEE","IEEE Conference Publications"
"Automating Web Tasks by Simulating Browser Behaviors","C. H. Tseng; Y. H. Chen; Y. R. Jiang; P. Y. Su; F. C. Tsai","","2016 International Conference on Platform Technology and Service (PlatCon)","20160421","2016","","","1","5","In most scenarios, people rely on Web browsers to access online Web-based systems. To make automation of Web tasks useful, integration is usually required, but, the current Web infrastructure imposes huge limitations on this. In this research, the goal is to develop a framework that makes automation involving heterogeneous Web-based systems easier. With the proposed framework, users simply provide a set of configuration files and our tool will ""execute"" Web pages according to the specified configurations. In such a way, integrating Web-based systems becomes much easier.","","Electronic:978-1-4673-8685-2; POD:978-1-4673-8686-9","10.1109/PlatCon.2016.7456785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456785","","Automation;Browsers;Data mining;HTML;Mashups;Web pages","Web sites;information retrieval;online front-ends","Web browser behavior simulation;Web infrastructure;Web pages;Web task automation;Web-based system integration;configuration files;heterogeneous Web-based systems;online Web-based system access","","","","15","","","15-17 Feb. 2016","","IEEE","IEEE Conference Publications"
"Searching Corrupted Document Collections","J. Soo; O. Frieder","Inf. Retrieval Lab., Georgetown Univ., Washington, DC, USA","2016 12th IAPR Workshop on Document Analysis Systems (DAS)","20160613","2016","","","440","445","Historical documents are typically digitized using optical Character Recognition. While effective, the results may not always be accurate and are highly dependent on the input. Consequently, degraded documents are often corrupted. Our focus is finding flexible, reliable methods to correct for such degradation, in the face of limited resources. We extend upon our substring and context fusion based retrieval system known as Segments, to consider metadata. By extracting topics from documents, and supplementing and weighting our lexicon with co-occurring terms found in documents with those topics, we achieve a statistically significant improvement over the state-of-the-art in all but one test configuration. Our mean reciprocal rank measured on two free, publicly available, independently judged datasets is 0.7657 and 0.5382.","","Electronic:978-1-5090-1792-8; POD:978-1-5090-1793-5","10.1109/DAS.2016.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490158","OCR;known item retrieval","Context;Dictionaries;Internet;Optical character recognition software;Search engines;Target tracking;Text analysis","document handling;history;information retrieval;optical character recognition;sensor fusion;statistics","context fusion;corrupted document collections searching;historical documents;lexicon;optical character recognition;retrieval system;statistics;substring","","","","27","","","11-14 April 2016","","IEEE","IEEE Conference Publications"
"Semantically similar document retrieval framework for language model speaker adaptation","J. Staš; D. Zlacký; D. Hládek","Department of Electronics and Multimedia Communications, Faculty of Electrical Engineering and Informatics, Technical University of Ko&#353;ice, Park Komensk&#233;ho 13, 041 20, Slovak Republic","2016 26th International Conference Radioelektronika (RADIOELEKTRONIKA)","20160526","2016","","","403","407","The paper deals with semantically similar document retrieval framework for language model adaptation in Slovak to a specific speaker speaking style. This research extends our previous study oriented on language model speaker adaptation for transcription of Slovak parliament proceedings with available speaker-specific text data. We used a large corpora for retrieving semantically similar subset of text documents for each speaker to adjust parameters of an existing well-trained language model to a specific speaker speaking style. The same large corpora was used to build original topic-specific model of the Slovak language deployed in our automatic subtitling system. In the proposed framework, the latent semantic indexing was implemented to retrieve the subset of semantically similar documents. The output hypotheses from the first step of speech recognition were used to identify patterns between terms and concepts contained in an unstructured collection of text documents. Preliminary results show a slight improvement in speech recognition accuracy for individual speaker in fully automatic subtitling of parliament speech, broadcast news TV shows and TEDx talks.","","Electronic:978-1-5090-1674-7; POD:978-1-5090-1675-4; USB:978-1-5090-1673-0","10.1109/RADIOELEK.2016.7477408","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7477408","automatic speech recognition;document retrieval;language modeling;latent Dirichlet allocation;latent semantic indexing;speaker adaptation","Adaptation models;Hidden Markov models;Large scale integration;Matrix decomposition;Semantics;Speech;Speech recognition","indexing;information retrieval;speaker recognition;text analysis","Slovak parliament proceedings;TEDx;TV shows;automatic subtitling system;corpora;document retrieval framework;language model speaker adaptation;latent semantic indexing;speaker-specific text data;specific speaker speaking style;speech recognition;text documents","","","","17","","","19-20 April 2016","","IEEE","IEEE Conference Publications"
"GeoSentiment: A tool for analyzing geographically distributed event-related sentiments","C. Pino; I. Kavasidis; C. Spampinato","Department of Electrical, Electronics and Computer Engineering, University of Catania, 95125, Italy","2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC)","20160331","2016","","","270","271","In this demo paper we present GeoSentiment, a tool for effective assessment and visualization of event-related sentiments in geographically confined populations. GeoSentiment is developed as a web tool application and provides to stakeholders an easy-to-use and powerful means to investigate how events are perceived by people and which factors may influence such perception. GeoSentiment relies on different services for a) retrieving and mining official statistical information as well as the most-common social networks and b) performing sentiment analysis. It is provided with an interactive interface, which enables rendering and deep exploration of all the processed data and results.","","Electronic:978-1-4673-9292-1; POD:978-1-4673-9293-8","10.1109/CCNC.2016.7444775","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444775","","Conferences;Data mining;Data visualization;Monitoring;Sentiment analysis;Social network services","Internet;data mining;information retrieval;sentiment analysis;social networking (online)","GeoSentiment;Web tool application;geographically distributed event-related sentiments;interactive interface;official statistical information mining;official statistical information retrieval;sentiment analysis;sentiment visualization;social networks","","","","2","","","9-12 Jan. 2016","","IEEE","IEEE Conference Publications"
"Toward Semantic Enhancement of Monitoring Data Repository","S. Zhang; I. L. Yen; F. B. Bastani","Dept. of Comput. Sci., Univ. of Texas at Dallas, Richardson, TX, USA","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","140","147","Most existing monitoring systems do not provide semantic information for their monitoring data. Thus, monitoring data in the repository can only be understood by the system that has generated the data. Round Robin Database (RRD) is an important effort toward building monitoring data semantics. However, the RRD model has missing semantic information, such as what QoS metric or which system entity a monitoring data stream is for. Our goal is to enhance the semantics in RRD to facilitate semantic based monitoring data retrieval and to improve the interoperability of monitoring systems and analysis software. We leverage the RRD data semantics and develop the new SE-RRD (Semantic Enhanced RRD) model. We also develop the SE-RRDtool to provide semantic-based accesses to monitoring data. With SE-RRDtool, it is also possible to reason and automatically perform data alignment between the data requests and the monitoring data streams available in the repository. SE-RRDtool greatly enhances the capability of RRDtool and cloud monitoring systems can use it for semantic-rich monitoring data repository.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439319","Monitoring systems;Round Robin Database;SLA to monitoring data mapping;semantic based retrieval;semantics of monitoring data","Cloud computing;Cognition;Data models;Measurement;Monitoring;Quality of service;Semantics","cloud computing;data handling;information retrieval;ontologies (artificial intelligence)","QoS metric;RRD data semantics;cloud monitoring systems;data alignment;data requests;monitoring data semantics;monitoring data stream;round robin database;semantic based monitoring data retrieval;semantic enhanced RRD model;semantic enhancement;semantic-rich monitoring data repository","","","","22","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Spellchecker for Malayalam using finite state transition models","N. Manohar; P. T. Lekshmipriya; V. Jayan; V. K. Bhadran","Language Technology Section, CDAC -Thiruvananthapuram","2015 IEEE Recent Advances in Intelligent Computational Systems (RAICS)","20160613","2015","","","157","161","Finite-state machine is used as a core technology in many fields of natural language processing. The applications include speech recognition and generation, spelling correction, fact extraction, information retrieval and approaches to translation. This paper describes the design of finite state machine in development of a Malayalam spellchecker. Conventional spell checkers has the disadvantage of large dictionary size which can be reduced using finite state models. Morphological factors like word categories and their inflections evolve automatically during training of these models if we train the model with an appropriate training set.","","CD-ROM:978-1-4673-6669-4; Electronic:978-1-4673-6670-0; POD:978-1-4673-6671-7","10.1109/RAICS.2015.7488406","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7488406","Malayalam;automata;morphology;spellchecker","Automata;Computational modeling;Dictionaries;Mathematical model;Morphology;Training","finite state machines;information retrieval;natural language processing;speech recognition","Malayalam;fact extraction;finite state machine;finite state transition models;information retrieval;natural language processing;speech generation;speech recognition;spellchecker;spelling correction","","","","6","","","10-12 Dec. 2015","","IEEE","IEEE Conference Publications"
"Context-aware advertisement recommendation for high-speed social news feeding","Y. Li; D. Zhang; Z. Lan; K. L. Tan","NUS Graduate School of Integrative Science and Engineering, National University of Singapore, Singapore","2016 IEEE 32nd International Conference on Data Engineering (ICDE)","20160623","2016","","","505","516","Social media advertising is a multi-billion dollar market and has become the major revenue source for Facebook and Twitter. To deliver ads to potentially interested users, these social network platforms learn a prediction model for each user based on their personal interests. However, as user interests often evolve slowly, the user may end up receiving repetitive ads. In this paper, we propose a context-aware advertising framework that takes into account the relatively static personal interests as well as the dynamic news feed from friends to drive growth in the ad click-through rate. To meet the real-time requirement, we first propose an online retrieval strategy that finds k most relevant ads matching the dynamic context when a read operation is triggered. To avoid frequent retrieval when the context varies little, we propose a safe region method to quickly determine whether the top-k ads of a user are changed. Finally, we propose a hybrid model to combine the merits of both methods by analyzing the dynamism of news feed to determine an appropriate retrieval strategy. Extensive experiments conducted on multiple real social networks and ad datasets verified the efficiency and robustness of our hybrid model.","","Electronic:978-1-5090-2020-1","10.1109/ICDE.2016.7498266","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498266","","Advertising;Context;Databases;Facebook;Feeds;Twitter","advertising data processing;information retrieval;recommender systems;social networking (online);ubiquitous computing","ad click-through rate;context-aware advertisement recommendation;high-speed social news feeding;online retrieval strategy;relevant ads matching;static personal interests","","1","","27","","","16-20 May 2016","","IEEE","IEEE Conference Publications"
"Routing the social graphs for the large-scale heterogeneous information accessing","B. Li","Xi'An Technological University, Xi'An, China","2016 Sixth International Conference on Information Science and Technology (ICIST)","20160602","2016","","","122","131","The paper proposes a series of novel routing algorithms to the issue of accessing the large-scale heterogeneous information over the Internet. Different from traditional ones, the perspectives of the routing are updated in terms of the quality of information accessing, the types of resources, the dominant driver and the expected consequences. The human capital is connected to form the social capital to resolve the routing problems. Although the human capital dominates the particular information system, it is difficult to capture it to fulfill requirements of users. For that, the social capital, which is shaped in the three graphs, i.e., the data, the channel and the human, is leveraged to perform the primary tasks since the human capital is difficult to be exploited directly. Those graphs represent the comprehensive perspectives to the environment and they are constructed in accordance with users' information accessing behaviors. In the early phase, the seed graphs are constructed to initialize the system. The routing does not expect to find their exactly required information resources. Instead, it aims to provide users with relevant consequences through exploring the nearby human capital.","","CD-ROM:978-1-5090-1220-6; Electronic:978-1-5090-1224-4; POD:978-1-5090-1225-1","10.1109/ICIST.2016.7483397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7483397","channels;data;human capital;humans;large-scale heterogeneous information systems;routing;social capital","Distributed databases;Information systems;Internet;Navigation;Routing;Search engines;Web sites","Internet;graph theory;information retrieval;network routing","Internet;heterogeneous information access;human capital;information accessing quality;information system;resource types;seed graphs;social capital;social graph routing","","","","35","","","6-8 May 2016","","IEEE","IEEE Conference Publications"
"Model-to-model transformation in approach by modeling: From UML model to Model-View-Presenter and Dependency Injection patterns","R. Esbai; M. Erramdani","MATSI Laboratory, ESTO, Mohammed First University, Oujda, Morocco","2015 5th World Congress on Information and Communication Technologies (WICT)","20160613","2015","","","1","6","The continuing evolution of business needs and technology makes Web applications more demanding in terms of development, usability and interactivity of their user interfaces. The complexity and diversity of these applications emerges the need of flexibility and combining operations with existing models to create other new, more complex models. As more complex models are used, the importance of transformations between models grows. This paper presents the application of the MDA (Model Driven Architecture) to generate, from the UML model, the code following the MVP (Model-View-Presenter), DI (Dependency Injection) and DAO (Data Access Object) patterns for a RIA (Rich Internet Application) using the standard MOF 2.0 QVT (Meta-Object Facility 2.0 Query-View-Transformation) as a transformation language. We adopt GWT (Google web Toolkit), Spring and Hibernate as a Frameworks for creating a target meta-model to generate an entire GWT-based N-tiers web application. That is why we have developed two meta-models handling UML class diagrams and N-tiers Web applications, then we have to set up transformation rules. The transformation rules defined in this paper can generate, from the class diagram, an XML file containing the Presentation, the Business, and the Data Access package. This file can be used to generate the necessary code of a RIA N-tiers web application.","","Electronic:978-1-4673-8712-5; POD:978-1-4673-8713-2","10.1109/WICT.2015.7489648","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7489648","GWT;MOF 2.0 QVT;Model Transformation;Model View Presenter;dependency Injection;transformation rules","Business;Computational modeling;Data models;Java;Standards;Unified modeling language;User interfaces","Internet;Unified Modeling Language;XML;information retrieval","DAO patterns;DI;GWT-based N-tiers Web application;Google Web toolkit;Hibernate;MDA;MVP;RIA N-tiers Web application;Spring;UML model;Web applications;XML file;application complexity;application diversity;data access object;data access package;dependency injection;meta-models handling UML class diagrams;meta-object facility 2.0 query-view-transformation;model driven architecture;model-to-model transformation;model-view-presenter;rich internet application;standard MOF 2.0 QVT;transformation language;user interfaces","","","","49","","","14-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"Pattern matching for extraction of core contents from news web pages","S. Sirsat; V. Chavan","Department of Computer Science, Shri Shivaji Science & Arts College, Chikhali, Maharashtra, India","2016 Second International Conference on Web Research (ICWR)","20160623","2016","","","13","18","Web pages, besides core contents, consist of other elements, such as banners, navigational elements, copyright information, external links, etc. This noisy content covers more area of web pages and is typically not related to the main subjects of the web pages. Most of the information available on web pages is either represented in XML, or HTML, or XHTML format that mostly contains semi-structured text documents, which lacks formatted document structure. This document does not discriminate between the text and the schema, and the amount of structure used to represent the text depends on the purpose. No semantic is applied to semi-structured documents. This requires extracting core contents of text document to analyse words or sentences for retrieving relevant information. Although there are many existing methods that formulate the actual content identification problem as a DOM tree node selection problem, each one has some sort of lacunae. Here we proposed an approach based on pattern matching technique. This technique uses simple heuristic for extraction of core contents from web pages which are mostly semi-structured in nature. It requires visiting the appropriate news web site using their URL, accessing the links related to each news page of specified category, extracting the data including metadata from each of these news web pages. The approach uses devised algorithm that applies regular expressions (regexes) to identify the correct pattern for extracting the actual text contents from these news documents. Proposed approach deals with news web pages of any size and extracts core contents with efficiency and high accuracy.","","Electronic:978-1-5090-2166-6; POD:978-1-5090-2167-3","10.1109/ICWR.2016.7498440","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498440","Document Object Module;Information extraction;Pattern matching;tags","Data mining;Feature extraction;HTML;Pattern matching;Uniform resource locators;Visualization;Web pages","Web sites;information retrieval;pattern matching;text analysis","URL;banners;content identification;copyright information;core contents extraction;data extraction;external links;information retrieval;metadata;navigational elements;news Web pages;news Web site;noisy content;pattern matching;regexes;regular expressions;text document","","","","15","","","27-28 April 2016","","IEEE","IEEE Conference Publications"
"Semantic indexing for XML documents using RDBMS","I. Ihsan; M. A. Qadir; F. F. Kiyani; M. ur Rehman","Department of Computer Science, Air University, Islamabad, Pakistan","2015 International Conference on Information and Communication Technologies (ICICT)","20160519","2015","","","1","5","Indexing is a common technique used by search engines for a fast and efficient search and retrieval process. XML search engines are no different. But the search engines consider XML file as single unit completely ignoring the fact that XML document contains records in the form of semi-structured data. This hierarchal structure of XML inherits a parent/child relationship. This relationship make two tags semantically related, if they share same parent. Indexing document as a whole, result in low precision. This paper proposes an indexing scheme that preserves the parent/child relation information using document structure. The information is then used to identify the semantic relation between items. Semantic based search and retrieval on XML documents can provide more accurate results. The paper uses RDBMS to store these indices in the form of table. To check the accuracy of the proposed scheme, a case study is also performed using two queries on a sample XML file that share semantically related data.","","Electronic:978-1-4673-8907-5; POD:978-1-4673-8908-2","10.1109/ICICT.2015.7469578","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7469578","Indexing;RDBMS;Semantics;XML","Indexing;Search engines;Semantics;Standards;XML","XML;document handling;indexing;information retrieval;relational databases;search engines","RDBMS;XML documents;XML search engines;document indexing;parent-child relationship;retrieval process;search engines;search process;semantic indexing;semantically related data;semistructured data","","","","27","","","12-13 Dec. 2015","","IEEE","IEEE Conference Publications"
"Ontology-based approach to provide personalized search results for handicraft woman","E. Rekik; M. Maalej; A. Mtibaa; F. Gargouri","Higher Institute of Computer Science and Multimedia, University of Sfax, Tunisia","2015 15th International Conference on Intelligent Systems Design and Applications (ISDA)","20160613","2015","","","604","609","Nowadays, Internet users are actually bombarded with huge amounts of data, which makes it impossible at times to reach what they exactly look for and what they need. That is astounding, so it's no wonder that we're now dealing with the issue of information overload. Personalization and recommender systems are now available to help users enhance their experience in trying to search and process relevant information easily and quickly. Web personalization techniques and services are very promising when it comes to alleviating the problem of information overload. We aim to propose, in this paper, an ontology-based approach to provide personalized search results for handicraft woman in which we extract knowledge about her such as personal information, preferences and interests then we represent the user profile model. Added to that, we enrich our contribution by exposing some implementation figures that present the applicability of our approach.","","Electronic:978-1-4673-8709-5; POD:978-1-4673-8710-1","10.1109/ISDA.2015.7489186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7489186","Google Custom Search;Handicraft Woman;Ontology;Personalization;User Model","Ceramics;Context;Electronic mail;Ions;Ontologies;Painting;Paints","Internet;data mining;information retrieval;ontologies (artificial intelligence);recommender systems","Internet;Web personalization technique;handicraft woman;information overload;information search;knowledge extraction;ontology-based approach;personal information;personalized search result;recommender system;user profile model","","","","8","","","14-16 Dec. 2015","","IEEE","IEEE Conference Publications"
"DebEAQ - debugging empty-answer queries on large data graphs","E. Vasilyeva; T. Heinze; M. Thiele; W. Lehner","SAP SE, Walldorf, 69190 Germany","2016 IEEE 32nd International Conference on Data Engineering (ICDE)","20160623","2016","","","1402","1405","The large volume of freely available graph data sets impedes the users in analyzing them. For this purpose, they usually pose plenty of pattern matching queries and study their answers. Without deep knowledge about the data graph, users can create `failing' queries, which deliver empty answers. Analyzing the causes of these empty answers is a time-consuming and complicated task especially for graph queries. To help users in debugging these `failing' queries, there are two common approaches: one is focusing on discovering missing subgraphs of a data graph, the other one tries to rewrite the queries such that they deliver some results. In this demonstration, we will combine both approaches and give the users an opportunity to discover why empty results were delivered by the requested queries. Therefore, we propose DebEAQ, a debugging tool for pattern matching queries, which allows to compare both approaches and also provides functionality to debug queries manually.","","Electronic:978-1-5090-2020-1","10.1109/ICDE.2016.7498355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498355","","Data models;Databases;Debugging;Engines;Pattern matching;Topology;Urban areas","data handling;graph theory;pattern matching;program debugging;query processing;question answering (information retrieval)","DebEAQ;data graph missing subgraphs;empty-answer query debugging;failing query debugging;large data graphs;pattern matching queries","","","","11","","","16-20 May 2016","","IEEE","IEEE Conference Publications"
"Privacy Preserving Search Schemes over Encrypted Cloud Data: A Comparative Survey","J. Shen; D. Liu; J. Shen; H. Tan; D. He","Jiangsu Eng. Center of Network Monitoring, Nanjing, China","2015 First International Conference on Computational Intelligence Theory, Systems and Applications (CCITSA)","20160519","2015","","","197","202","Due to the development of the network and the growth big data, data owner prefer to remotely outsource their data to cloud, which can avoid the local data management and decrease the local hardware cost. But some sensitive data, such as personal healthcare information and personal property information, must be encrypted firstly and then outsourced to the cloud. This can protect sensitive information. But the outsource encrypted data to cloud can increase the difficulty of the data retrieval, because data owner or unauthorized users can't search correctly the data they need, and also it is impractical to download all of the data to local side from the cloud, which will result in huge communication an computation overhead. Hence, some cloud data retrieval schemes has been proposed to solve this problem, these schemes not only can search the data they need correctly, but also can prevent sensitive data leaked out. In this paper, we survey the privacy preserving cloud data retrieval schemes and give a comparison of them with respect to the key principles of search and privacy assured.","","Electronic:978-1-4673-8600-5; POD:978-1-4673-8601-2","10.1109/CCITSA.2015.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7473116","cloud;data retrieval;privacy preserving;sensitive data","Cloud computing;Computational modeling;Cryptography;Data models;Data privacy;Organizations","Big Data;cloud computing;data privacy;information retrieval","big data;encrypted cloud data;personal healthcare information;personal property information;privacy preserving cloud data retrieval schemes;privacy preserving search schemes;sensitive data","","","","20","","","10-12 Dec. 2015","","IEEE","IEEE Conference Publications"
"Retrieving relevant time-course experiments: a study on Arabidopsis microarrays","D. D. Şener; H. Oğul","Ba&#351;kent University, Turkey","IET Systems Biology","20160519","2016","10","3","87","93","Understanding time-course regulation of genes in response to a stimulus is a major concern in current systems biology. The problem is usually approached by computational methods to model the gene behaviour or its networked interactions with the others by a set of latent parameters. The model parameters can be estimated through a meta-analysis of available data obtained from other relevant experiments. The key question here is how to find the relevant experiments which are potentially useful in analysing current data. In this study, the authors address this problem in the context of time-course gene expression experiments from an information retrieval perspective. To this end, they introduce a computational framework that takes a time-course experiment as a query and reports a list of relevant experiments retrieved from a given repository. These retrieved experiments can then be used to associate the environmental factors of query experiment with the findings previously reported. The model is tested using a set of time-course Arabidopsis microarrays. The experimental results show that relevant experiments can be successfully retrieved based on content similarity.","1751-8849;17518849","","10.1049/iet-syb.2015.0042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470973","","","associative processing;bioinformatics;botany;data analysis;data mining;genetics;information retrieval;lab-on-a-chip","computational framework;computational method;data analysis;environmental factor;experimental content similarity;gene behaviour model;gene networked interaction;information retrieval;latent parameter;meta-analysis;model parameter estimation;query experiment;relevant experiment list;relevant time-course experiment retrieval;repository;stimulus response;systems biology;time-course Arabidopsis microarray;time-course experiment query;time-course gene expression experiment;time-course gene regulation","","","","","","","6 2016","","IET","IET Journals & Magazines"
"Multimodal Web Aesthetics Assessment Based on Structural SVM and Multitask Fusion Learning","O. Wu; H. Zuo; W. Hu; B. Li","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","20160513","2016","18","6","1062","1076","The overall visual attributes (e.g., aesthetics) of Web pages significantly influence user experience. A beautiful and well laid out Web page greatly facilitates user access and enhances the browsing experience. In this paper, a new method is proposed to learn an assessment model for the (visual) aesthetics of Web pages. First, multimodal features (structural, local visual, global visual, and functional) of a Web page that are known to significantly affect the aesthetics of a Web page are extracted to construct a feature vector. Second, the interuser disagreement of aesthetics is analyzed and novel aesthetic representations are obtained from the multiuser ratings of a page. A structural learning algorithm is proposed for the new aesthetic representations. Third, as a Web page's functional purpose also affects the perceived aesthetics, we divide Web pages into different types using functional features, and a soft multitask fusion learning strategy is introduced to train assessment models for pages with functional purposes. Experimental results show the effectiveness of our method: 1) the combination of structural, local, and global visual features outperforms existing state-of-the-art Web aesthetic features; 2) the proposed structural learning algorithm achieves good results for the new aesthetic representations; and 3) the proposed soft multitask fusion learning strategy improves the performances of aesthetics assessment models.","1520-9210;15209210","","10.1109/TMM.2016.2538722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426384","Aesthetic features;Visual aesthetics;Web pages;fusion;local features;multi-task learning;visual aesthetics;web pages","Feature extraction;Human computer interaction;Image color analysis;Measurement;Usability;Visualization;Web pages","Internet;human computer interaction;information retrieval;learning (artificial intelligence);sensor fusion;support vector machines;user interfaces;vectors","SVM;Web page aesthetic assessment;Web page extraction;feature vector;human-computer interaction;multitask fusion learning;structural learning algorithm;support vector machine;user experience","","","","71","","20160304","June 2016","","IEEE","IEEE Journals & Magazines"
"K-Subspaces Quantization for Approximate Nearest Neighbor Search","E. C. Ozan; S. Kiranyaz; M. Gabbouj","Department of Signal Processing, Tampere University of Technology, Tampere, Finland","IEEE Transactions on Knowledge and Data Engineering","20160602","2016","28","7","1722","1733","Approximate Nearest Neighbor (ANN) search has become a popular approach for performing fast and efficient retrieval on very large-scale datasets in recent years, as the size and dimension of data grow continuously. In this paper, we propose a novel vector quantization method for ANN search which enables faster and more accurate retrieval on publicly available datasets. We define vector quantization as a multiple affine subspace learning problem and explore the quantization centroids on multiple affine subspaces. We propose an iterative approach to minimize the quantization error in order to create a novel quantization scheme, which outperforms the state-of-the-art algorithms. The computational cost of our method is also comparable to that of the competing methods.","1041-4347;10414347","","10.1109/TKDE.2016.2535287","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426405","Approximate Nearest Neighbor Search;Approximate nearest neighbor search;Binary Codes;Large-Scale Retrieval;Subspace Clustering;Vector Quantization;binary codes;large-scale retrieval;subspace clustering;vector quantization","Artificial neural networks;Encoding;Iterative methods;Nearest neighbor searches;Principal component analysis;Vector quantization","approximation theory;information retrieval;learning (artificial intelligence);search problems;vector quantisation;very large databases","ANN search;approximate nearest neighbor search;computational cost;data dimension;data size;information retrieval;iterative approach;k-subspace quantization;multiple affine subspace learning problem;publicly available datasets;quantization centroids;quantization error minimization;vector quantization method;very-large-scale datasets","","1","","31","","20160304","July 1 2016","","IEEE","IEEE Journals & Magazines"
"Improving person name recognition quality in Chinese text with reinforced processing of ambiguities","Shuangyong Song; Zhongguang Zheng; Yao Meng","Information Technology Laboratory, Fujitsu R&D Center CO., LTD, No.2A Gong Ti Bei Lu, Chaoyang District, Beijing, China","2015 International Conference on Asian Language Processing (IALP)","20160414","2015","","","160","163","In this paper, we focus on the task of person name recognition (PNR) in Chinese text, which is an important part of Named entity recognition (NER). Chinese word segmentation makes the sequence tagging of PNR more accurate than character-based PNR, but it also brings more word-level ambiguities. For reducing the negative effect of word segmentation for PNR, we reinforce the analysis of ambiguities and propose a model to deal with them. Experimental results on People's Daily corpus show that the proposed model is effective in PNR.","","CD-ROM:978-1-4673-9594-6; Electronic:978-1-4673-9596-0; POD:978-1-4673-9597-7","10.1109/IALP.2015.7451556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451556","Person name recognition;conditional random field;unambiguous name-related word list","Biological system modeling;Hidden Markov models","information retrieval;natural language processing;text analysis","Chinese text;Chinese word segmentation;NER;PNR sequence tagging;named entity recognition;person name recognition quality;reinforced ambiguities processing;word-level ambiguities","","","","12","","","24-25 Oct. 2015","","IEEE","IEEE Conference Publications"
"A BigData approach for classification and prediction of student result using MapReduce","M. G. M. Mohan; S. K. Augustin; V. S. K. Roshni","Cyber Forensics and Information Security, Centre for Development of Advanced Computing (CDAC) Trivandrum, Kerala, India","2015 IEEE Recent Advances in Intelligent Computational Systems (RAICS)","20160613","2015","","","145","150","In recent years the amount of data stored in educational database is growing rapidly. The stored database contains hidden information which if used aids improvement of student's performance and behaviour. In this paper predictive modelling approach is used for extracting this hidden information. Data is collected, a predictive model is formulated, predictions are made, and the model is validated as additional data becomes available. The predictive models will help the instructor to understand how well or how poorly the students in his/her class will perform, and hence the instructor can choose proper pedagogical and instructional interventions to enhance student learning outcomes. The implementation is done in Hadoop framework with MapReduce and Revolutionary R Enterprise RRE.","","CD-ROM:978-1-4673-6669-4; Electronic:978-1-4673-6670-0; POD:978-1-4673-6671-7","10.1109/RAICS.2015.7488404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7488404","big data analytics;clustering;educational data mining;hadoop;hortonworks sandbox;learning analytics;predictive modeling;regression;revolution r enterprise","Big data;Clustering algorithms;Data mining;Data models;Education;Prediction algorithms;Predictive models","Big Data;educational administrative data processing;information retrieval;parallel processing;pattern classification","Hadoop framework;MapReduce;RRE;big data approach;educational database;hidden information extraction;instructional intervention;pedagogical intervention;predictive modelling approach;revolutionary R enterprise;student learning outcome enhancement;student result classification;student result prediction","","1","","8","","","10-12 Dec. 2015","","IEEE","IEEE Conference Publications"
"Informatics-based challenges of building collaborative healthcare research and analysis networks from rural community health centers","D. R. Harris; T. J. Harper; D. W. Henderson; K. W. Henry; J. C. Talbert","Center for Clinical and Translational Sciences, University of Kentucky, Lexington, Kentucky 40506","2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)","20160421","2016","","","513","516","We discuss informatics-based challenges of constructing large-scale collaborative networks for healthcare research and analysis from rural community health centers. These types of networks provide data access and analytic insights across multiple heterogeneous health centers for both healthcare professionals and biomedical researchers. Challenges fall into three general categories: data access, data integration, and technical infrastructure. Data access issues arise in balancing patient privacy, security, and utility; data integration issues persist from each site independently operating its desired electronic medical record; technical infrastructure challenges include creating an analysis and reporting hub capable of scaling across a large collaborative network. Other challenges, such as the difficulty of site recruitment, are important to discuss, but cannot be solved directly through informatics alone. We discuss these challenges and their potential solutions in the context of our implementation of the Kentucky Diabetes and Obesity Collaborative (KDOC). KDOC is a network of Federally-Qualified Community Health Centers (FQHCs) that established a collaborative infrastructure for research and analysis of obesity and diabetes in rural and under-served communities.","","Electronic:978-1-5090-2455-1; POD:978-1-5090-2456-8","10.1109/BHI.2016.7455947","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7455947","","Collaboration;Collaborative work;Data integration;Diabetes;Obesity;Recruitment","data integration;data privacy;diseases;electronic health records;health care;information retrieval;security of data","Kentucky Diabetes and Obesity Collaborative;analysis network;collaborative healthcare research;data access;data integration;diabetes;electronic medical record;federally-qualified community health centers;heterogeneous health center;informatics-based challenge;obesity analysis;patient privacy;patient security;rural community health center;technical infrastructure","","1","","15","","","24-27 Feb. 2016","","IEEE","IEEE Conference Publications"
"Exploring performance models of Hadoop applications on cloud architecture","X. Wu; Y. Liu; I. Gorton","Department of Electrical and Computer Engineering, Concordia University, Montreal, Quebec, Canada","2015 11th International ACM SIGSOFT Conference on Quality of Software Architectures (QoSA)","20160414","2015","","","93","101","Hadoop is an open source implementation of the MapReduce programming model, and provides the runtime infrastructure for map and reduce functions programmed in individual applications. Commercial clouds such as Amazon Elastic MapReduce provides the Hadoop architecture with IaaS support. In this architecture, the map and reduce functions are major determinants of end-to-end application latency, along with the framework components responsible for data access and exchange. In this paper, we aim to explore modeling methods that capture the performance characteristic and the semantics of a Hadoop architecture. We present our early results for modeling the performance of a Hadoop application given the design of map and reduce functions using Layered Queueing Network (LQN). We build two different LQN models to represent the data parallel computing of these functions and calibrate both models using monitored performance data. The output of both models produces converging results that are within ~10% of observed performance. From our modeling experience, we further discuss the issues of modeling Hadoop architecture using LQN in general and describe our future work.","","Electronic:978-1-4503-3470-9; POD:978-1-5090-1464-4","10.1145/2737182.2737197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450806","Layered queueing network;MapReduce;Performance modeling","Analytical models;Computational modeling;Computer architecture;Data models;Optimization;Predictive models;Programming","cloud computing;electronic data interchange;information retrieval;parallel processing;public domain software;queueing theory","Hadoop applications;Hadoop architecture;IaaS support;LQN models;MapReduce programming model;cloud architecture;data access;data exchange;data parallel computing;end-to-end application latency;layered queueing network;map function;open source implementation;performance model exploration;reduce function;runtime infrastructure","","1","","35","","","4-8 May 2015","","IEEE","IEEE Conference Publications"
"Labeling Feature-Oriented Software Clusters for Software Visualization Application","K. Yano; A. Matsuo","Inf. Syst. Technol. Lab., Fujitsu Labs., Kawasaki, Japan","2015 Asia-Pacific Software Engineering Conference (APSEC)","20160512","2015","","","354","361","Software clustering techniques have been used to analyze the reality of software structure. The visualization of the detected clusters has also been studied. However, the features implemented by the detected clusters are not obvious and understanding them is a crucial part of the industrial use of software clustering. In this study, we examined the existing information retrieval method and found three major issues it has. We developed technical solutions for each of them: using hierarchical labeling, weighing the words likely representing the feature by considering an architectural convention, and modifying the idf score by the scale of the cluster. The effectiveness of our approach is validated through case studies using actual software products including a COBOL business application. Also, we faced two additional practical problems: effectiveness of the method words and plural and conjugated forms of the words. We found the method name words were less useful than the class name words, and lemmatization was successfully used to normalize the form of the words even in the case of program identifiers.","","Electronic:978-1-4673-9644-8; POD:978-1-4673-9645-5","10.1109/APSEC.2015.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7467321","program comprehension;software clustering;software maintenance;software visualization","Business;Feature extraction;Labeling;Software systems;Urban areas;Visualization","COBOL;feature extraction;information retrieval;pattern clustering;program visualisation;software engineering;software maintenance","COBOL business application;architectural convention;class name words;conjugated forms;feature-oriented software cluster labeling;hierarchical labeling;hierarchical weighing;idf score;information retrieval method;program identifiers;software clustering techniques;software products;software structure reality;software visualization application","","","","16","","","1-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"Multimedia Memory Cues for Augmenting Human Memory","T. Dingler; P. E. Agroudy; H. V. Le; A. Schmidt; E. Niforatos; A. Bexheti; M. Langheinrich","University of Stuttgart, Germany","IEEE MultiMedia","20160504","2016","23","2","4","11","Technology has always had a direct impact on what humans remember. In the era of smartphones and wearable devices, people easily capture information, such as pictures and videos, on a daily basis. The so-called ""quantified self"" movement focuses on using such captured multimedia information, often in combination with additional contextual data (such as GPS traces or social media posts), with the goal of extracting and providing better insights into people's everyday actions (for example, fitness tracking, work productivity, and dieting). However, a more interesting use of such captured data might be to directly support human memory. Here, the authors describe their efforts in the EU Recall project to extract memory cues from multimedia records to augment human memory beyond simple memory prosthetics.","1070-986X;1070986X","","10.1109/MMUL.2016.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7464802","Recall project;big data;bioinformatics;data analysis;healthcare;memory;memory augmentation;memory cues;multimedia;pervasive computing;quantified self;security","Cameras;Memory management;Multimedia communication;Prototypes;Smart phones;Streaming media;Videos","information retrieval;mobile computing;multimedia computing;smart phones","human memory augmentation;multimedia information extraction;multimedia memory cue;smart phone;wearable device","","1","","13","","","Apr.-June 2016","","IEEE","IEEE Journals & Magazines"
"Possible application domains for the knowledge carrier finder system","A. Denzler; M. Wehrle","Department of Informatics, University of Fribourg, Fribourg, Switzerland","2016 Third International Conference on eDemocracy & eGovernment (ICEDEG)","20160428","2016","","","104","111","The ability to share knowledge among members of a community, has always been of great importance. Web-based technologies have facilitated this endeavour by offering tools that are specifically designed for this task. Throughout this paper, the authors will present a novel type of platform, which is designed to support users in their quest to share knowledge. It consists of a question and answer platform, with a built in recommendation system for knowledge carriers. The hybrid design ensures that questions be answered in a timely manner and by most suitable users. The developed prototype and an evaluation of application domains are presented in the final section of this paper.","","Electronic:978-3-9075-8912-0; POD:978-1-5090-2090-4","10.1109/ICEDEG.2016.7461705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7461705","Q&A platform;granular computing;knowledge assessment;knowledge profiling","Companies;Databases;Engines;Graphical user interfaces;Knowledge based systems;Periodic structures;Search engines","question answering (information retrieval);recommender systems","knowledge carrier finder system;question and answer platform;recommendation system","","","","16","","","March 30 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Proposed application of big data analytics in healthcare at Maharaja Yeshwantrao Hospital","M. Ojha; K. Mathur","International Institute of Professional Studies, Devi Ahilya University, Indore, India","2016 3rd MEC International Conference on Big Data and Smart City (ICBDSC)","20160428","2016","","","1","7","This paper gives an insight of how we can store healthcare data digitally like patient's records as an Electronic Health Record (EHR) and how we can generate useful information from these records by using analytics techniques and tools which will help in saving time and money of patients as well as the doctors. This paper is fully focused towards the Maharaja Yeshwantrao Hospital (M.Y.) located in Indore, Madhya Pradesh, India. M.Y hospital is the central India's largest government hospital. It generates large amount of heterogeneous data from different sources like patients health records, laboratory test result, electronic medical equipment, health insurance data, social media, drug research, genome research, clinical outcome, transaction and from Mahatma Gandhi Memorial medical college which is under MY hospital. To manage this data, data analytics may be used to make it useful for retrieval. Hence the concept of ""big data"" can be applied. Big data is characterized as extremely large data sets that can be analysed computationally to find patterns, trends, and associations, visualization, querying, information privacy and predictive analytics on large wide spread collection of data. Big data analytics can be done using Hadoop which plays an effective role in performing meaningful real-time analysis on the large volume of this data to predict the emergency situations before it happens. This paper also discusses about the EHR and the big data usage and its analytics at M.Y. hospital.","","Electronic:978-1-4673-9584-7; POD:978-1-4673-9585-4","10.1109/ICBDSC.2016.7460340","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460340","Analytics;Big data;EHR;Hadoop;Healthcare","Big data;Government;Hospitals;Insurance;Medical diagnostic imaging;Smart cities","Big Data;electronic health records;health care;information retrieval","EHR;Hadoop;Maharaja Yeshwantrao Hospital;big data analytics;clinical outcome;drug research;electronic health record;electronic medical equipment;genome research;government hospital;health insurance data;healthcare;laboratory test result;patient health record;social media","","","","18","","","15-16 March 2016","","IEEE","IEEE Conference Publications"
"Issues arising from the specification of an information acquisition and analysis toolkit for policy makers in governmental and legislative institutions","S. Taylor; R. Uzdavinyte; T. Wandhoefer; R. Fox","University of Southampton IT Innovation Centre, UK","eChallenges e-2015 Conference","20160328","2015","","","1","10","We describe the issues arising from the initial specification of a web-based toolkit that comprises different types of information retrieval and analysis tools. It is specifically intended for policy makers in governmental and legislative institutions, to help them research subjects of a policy in question, but the tool is general in its nature and could be applied to other domains. The major focus of this paper concerns issues arising from the initial requirements gathering for the toolkit, by consultation with its target user community. Sifting through a deluge of information available in the Internet and whether search results can be trusted are key important themes. There is also the challenge of ""unknown unknowns"" - relevant information exists that the policy maker simply does not know about, so there is no way of even beginning to search for it. The paper discusses how these challenges can be met.","","Electronic:978-1-9058-2453-3; POD:978-1-5090-2331-8","10.1109/eCHALLENGES.2015.7440969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7440969","","Databases;Electronic publishing;Encyclopedias;Government;Internet;Media","Internet;government data processing;government policies;information analysis;information retrieval;legislation","Internet;Web-based toolkit;governmental institutions;information acquisition and analysis toolkit;information analysis tools;information retrieval tools;legislative institutions;policy makers;target user community","","","","15","","","25-27 Nov. 2015","","IEEE","IEEE Conference Publications"
"Trends, Self-Similarity, and Forecasting of News Events in the Information Domain, Its Structure and Director","S. A. Lesko; D. O. Zhukov","Fed. State Budget Educ. Establ. of Higher Educ., Moscow State Univ. of Inf. Technol., Radioeng. & Electron., Moscow, Russia","2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)","20160505","2015","","","870","873","To describe the structure of news information domain, we introduce the concept of a director, that is a conditional axis, the position of which is defined by averaging the directions of vectors that set the location of all news clusters centroids. To characterise the dynamics of reaching the news event, we introduce the concepts of decreasing and increasing trends of domain varying. The analysis of self-similarity in behaviour of directors and trends on the basis of the proposed model can allow detecting the periodicity of domain approaching or moving away from the point of the predicted event.","","Electronic:978-1-5090-1893-2; POD:978-1-5090-1894-9","10.1109/SmartCity.2015.178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463833","domain director;information domain;news cluster;self-similarity of processes in information domains","Arrays;Clustering algorithms;Data models;Feeds;Forecasting;Market research;Predictive models","data mining;forecasting theory;information retrieval;vectors","information domain;news clusters centroids;news events forecasting;self-similarity;vectors","","","","8","","","19-21 Dec. 2015","","IEEE","IEEE Conference Publications"
