"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=4976463,4959234,4959521,4958895,4976558,4958389,4959811,4960494,4976330,4959997,4960644,4960432,4959687,4959917,4959902,4960399,4960699,4958894,4968149,4959972,4959895,4960449,4960434,4968037,4960391,4960702,4956615,4956633,4939516,4956610,4939640,4938677,4937885,4937406,4925106,4925651,4925093,4938650,4938678,4937794,4938630,4927506,4937886,4938640,4917879,4919645,4911213,4912747,4911580,4911198,4912771,4913291,4912886,4909246,4906770,4906768,4906771,4906814,4906746,4906754,4906794,4907196,4906781,4906758,4906755,4906808,4906752,4906803,4906749,4906756,4906809,4906750,4906783,4906751,4895559,4895453,4897437,4839783,4839627,4839440,4839087,4839825,4839848,4839442,4839815,4850290,4839817,4839665,4839343,4839057,4839033,4814441,4760150,4775904,4814205,4813381,4812431,4812500,4812577,4812463",2017/05/04 21:02:23
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A state of the art opinion mining and its application domains","H. Binali; V. Potdar; C. Wu","Digital Ecosystems and Business Intelligence Institute, Curtin University of Technology, Australia","2009 IEEE International Conference on Industrial Technology","20090519","2009","","","1","6","This paper critically evaluates existing work, presents an opinion mining framework and exposes new areas of research in opinion mining. Individuals, businesses and government can now easily know the general opinion prevailing on a product, company or public policy. At the core of this field is semantic orientation of subjective terms in documents or reviews which seeks to establish their contextual connotation through opinion mining. Overall item sentiment can be expressed based on its sentiment words in general or by specifically identifying its features and the opinions being expressed about them. This leads us to the motivation of the framework for opinion mining and categorizing current literature in such a manner as to make clear, research opportunities. The freedom offered by the Web as a platform for presenting opinions on any subject brings with it many new opportunities.","","POD:978-1-4244-3506-7","10.1109/ICIT.2009.4939640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4939640","Opinion mining;data mining;supervised learning;unsupervised learning","Artificial intelligence;Data mining;Ecosystems;Humans;Information retrieval;Machine learning;Manufacturing industries;Supervised learning;Unsupervised learning;Visual databases","Internet;data mining;learning (artificial intelligence)","Internet;contextual connotation;data mining;opinion mining;semantic orientation;supervised learning;unsupervised learning","","15","1","35","","","10-13 Feb. 2009","","IEEE","IEEE Conference Publications"
"Chinese Named Entity Recognition with new contextual features","Y. Qin; T. Zhang; X. Wang","National Research Center for Foreign Language Education, Beijing Foreign Studies University, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","6","Chinese named entity recognition (NER) is studied in two directions: inner structure and outer surroundings. Inner structural analyses induce constitutions of person, location and organization name from the point of linguistics. However inner structural rules for named entities only provide necessary conditions for a sequence of Chinese characters being an entity name but not sufficient. Whether a string being a proper name or not is also determined by its contextual information or sometimes common sense. We build Chinese NER system based on supervised machine learning using features induced from simple inner structure and contextual information. We compare some NER approaches. The experimental results indicate complicated cases of various NER strategies. Then this paper turns to explore contextual features of named entities on large scale corpus, seeking for contextual evidence for different strategies of NER and mark words giving clues to the occurrence of NE. Finally, we apply some conclusions to improve NER system by enriching features in model and enhance the performance distinctly.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906794","Named entity recognition;conditional random fields;contextual features;recognition model","Constitution;Context modeling;Data mining;Feature extraction;Hidden Markov models;Information retrieval;Large-scale systems;Machine learning;Natural languages;Predictive models","learning (artificial intelligence);linguistics;natural language processing;text analysis","Chinese NER system;Chinese character;Chinese named entity recognition;inner structural analysis;linguistics;supervised machine learning","","0","","10","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Extending OSSE beyond numerical weather prediction to new areas in Earth observing science","C. D. Norton; A. Eldering; M. Turmon; J. Parker","Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Drive, Pasadena, 91109-8099, USA","2009 IEEE Aerospace conference","20090424","2009","","","1","10","An observing system simulation experiment (OSSE), briefly stated, is a computational system designed to quantitatively assess the impact of proposed scientific observations. OSSEs allow one to examine how well specific science objectives can be met within a controlled environment where one can simulate the quality of data expected based on observation characteristics, instrument parameters, data retrieval methods, associated uncertainties, errors, and trades among design constraints. The numerical weather prediction community (NWP) has developed and utilized OSSEs to understand the impact of instrument designs and new measurements on numerical forecasts over the last 40 years. Now, there is a growing interest in applying OSSEs as a mechanism for systematic analysis and science evaluation for future observations of interest to the Earth science community. Examples include precise measurements of earth surface deformation, ice dynamics, ecosystem structure, and atmospheric chemistry. In this paper we introduce OSSE and describe the benefits and impact of the approach along with current work and future plans to apply OSSE for science analysis in various Earth science disciplines.","1095-323X;1095323X","POD:978-1-4244-2621-8","10.1109/AERO.2009.4839627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839627","","Atmospheric measurements;Computational modeling;Earth;Ecosystems;Error correction;Geoscience;Ice surface;Information retrieval;Instruments;Weather forecasting","geophysics computing;weather forecasting","Earth observing science;atmospheric chemistry;data quality;earth surface deformation;ecosystem structure;ice dynamics;numerical weather prediction;observing system simulation experiment","","0","","10","","","7-14 March 2009","","IEEE","IEEE Conference Publications"
"Effective XML Keyword Search with Relevance Oriented Ranking","Z. Bao; T. W. Ling; B. Chen; J. Lu","Sch. of Comput., Nat. Univ. of Singapore, Singapore","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","517","528","Inspired by the great success of information retrieval (IR) style keyword search on the Web, keyword search on XML has emerged recently. The difference between text database and XML database results in three new challenges: (1) Identify the user search intention, i.e. identify the XML node types that user wants to search for and search via. (2) Resolve keyword ambiguity problems: a keyword can appear as both a tag name and a text value of some node; a keyword can appear as the text values of different XML node types and carry different meanings. (3) As the search results are sub-trees of the XML document, new scoring function is needed to estimate its relevance to a given query. However, existing methods cannot resolve these challenges, thus return low result quality in term of query relevance. In this paper, we propose an IR-style approach which basically utilizes the statistics of underlying XML data to address these challenges. We first propose specific guidelines that a search engine should meet in both search intention identification and relevance oriented ranking for search results. Then based on these guidelines, we design novel formulae to identify the search for nodes and search via nodes of a query, and present a novel XML TF*IDF ranking strategy to rank the individual matches of all possible search intentions. Lastly, the proposed techniques are implemented in an XML keyword search engine called XReal, and extensive experiments show the effectiveness of our approach.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812431","XML;keyword;ranking;search","Data engineering;Databases;Guidelines;Information retrieval;Keyword search;Optical computing;Search engines;Statistics;Web search;XML","XML;database management systems;search engines","XML database;XML document;XReal;effective XML keyword search engine;information retrieval style keyword search;keyword ambiguity problems;relevance oriented ranking;scoring function;search intention identification;text database;user search intention","","35","1","25","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"A new shape descriptor using sliced image histogram for 3D model retrieval","Y. s. Park; Y. i. Yun; J. s. Choi","Chung-Ang University, South Korea","IEEE Transactions on Consumer Electronics","20090417","2009","55","1","240","247","3-dimensional (3D) model retrieval is one of emerging research fields to find the matching shape of a given query from 3D database. This paper proposes a new shape descriptor for 3D model retrieval. A shape descriptor of 3D model requires a model normalization in order to be invariant to translation, rotation, and scale for its model. Our method is based on principal component analysis (PCA) for normalizing all the models. The shape descriptor is using a histogram of 2D images sliced along the x-, y-, and z-coordinates for measuring the similarity in 3D models. Sliced shapes for a 3D model involve a hundred planes to orthogonalize with the x-y-, and z-coordinates, respectively. Therefore, sliced shape is the 2D plane images created by intersecting at between 3D model and the planes. Our approach is to compute the slices of 3D model for the x-y-, and z-coordinates, respectively and to set by the principal axis based on principal component analysis (PCA) in order to match the 3D model between the given query and the database. Experimental results show that the proposed approach outperforms the previous approaches. We demonstrate the proposed 3D retrieval system with an intermediate example at each step.","0098-3063;00983063","","10.1109/TCE.2009.4814441","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814441","3D model retrieval;A query;a descriptor;sliced shape image","Animation;Design automation;Histograms;Image databases;Image retrieval;Indexes;Information retrieval;MPEG 7 Standard;Principal component analysis;Shape measurement","image matching;image retrieval;principal component analysis","2D plane images;3D database;3D model retrieval;matching shape;model normalization;principal component analysis;shape descriptor;sliced image histogram","","5","","16","","","February 2009","","IEEE","IEEE Journals & Magazines"
"Document space dimension reduction by nonlinear Hebbian neural network","L. Skovajsova; I. Mokris","","2009 7th International Symposium on Applied Machine Intelligence and Informatics","20090519","2009","","","89","91","This paper deals with information retrieval of text documents, and their clustering into some other feature space. The aim of this paper is to reduce the dimension of the document space by the nonlinear Hebbian neural network. As can be seen from the results, not only dimension reduction of document space is made, but also clustering of these documents into clusters. We used here the nonlinear Hebbian neural network, which is feed-forward neural network with unsupervised learning.","","POD:978-1-4244-3801-3","10.1109/SAMI.2009.4956615","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4956615","","Feedforward neural networks;Feedforward systems;Indexing;Information retrieval;Matrix decomposition;Neural networks;Principal component analysis;Sparse matrices;Strontium;Unsupervised learning","Hebbian learning;feedforward neural nets;information retrieval;text analysis;unsupervised learning","document space dimension reduction;feedforward neural network;information retrieval;nonlinear Hebbian neural network;text documents;unsupervised learning","","0","","20","","","30-31 Jan. 2009","","IEEE","IEEE Conference Publications"
"The effects of high quality translations of named entities in cross-language information exploration","D. Wu; D. He; H. Ji; R. Grishman","School of Information Management, Wuhan University, Hubei, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","8","Named entities (NEs) are the expressions in human languages that explicitly link notations in languages to the entities in the real world. They play important role in cross-language information retrieval (CLIR) because most users' requests have been found to have NEs, and majority of out-of-vocabulary terms are NEs. Therefore, missing their translations has a significant impact to the retrieval effectiveness. In this paper, we examined the effect of high quality translations of NEs in event driven information exploration, where the existence of NEs is even more common. With the focus on the effect of NE translations obtained by using information extraction (IE) techniques, we conducted several experiments using TDT test collections. Our results demonstrate that NEs and their translations play critical roles in improving CLIR effectiveness, and it makes positive impact in CLIR to use high quality translations of NEs obtained by IE techniques.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906770","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906770","Named entity;cross-language information exploration","Data mining;Dictionaries;Helium;Humans;Information analysis;Information management;Information retrieval;Radiofrequency interference;Testing;USA Councils","information retrieval;language translation;natural language processing","TDT test collections;cross-language information exploration;cross-language information retrieval;human languages;information extraction techniques;named entities translations","","2","","19","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Scalable Keyword Search on Large Data Streams","L. Qin; J. X. Yu; L. Chang; Y. Tao","Chinese Univ. of Hong Kong, Hong Kong","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1199","1202","It is widely realized that the integration of information retrieval (IR) and database (DB) techniques provides users with a broad range of high quality services. A new challenging issue along the same direction is IR-styled m-keyword query processing in a RDBMS framework over an open-ended relational data stream. The capability of supporting m-keyword queries over a relational data stream makes it possible for users to monitor events, that are implicitly interrelated, over a relational data stream in a timely manner. In brief, the problem is to find all connected trees whose size is less than or equal to a user-given threshold in terms of number of nodes for a m-keyword query, {k<sub>1</sub>, k<sub>2</sub>, middot middot middot , k<sub>m</sub>}, over a relational data stream on a database schema GS. The difficulty of the problem is related to the number of costly joins to be processed over time, which is affected by the parameters such as the number of keywords (m), the maximum size of connected trees (Tmax), as well as the complexity of the database schema when it is viewed as a schema graph (G<sub>S</sub>). In this paper, we propose a new demand-driven approach to process such a query over a high speed data stream. We show that we can significantly reduce the number of intermediate results when processing joins over a data stream, and therefore can achieve high efficiency.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812500","relational database stream","Costs;Data engineering;Information retrieval;Keyword search;Monitoring;Product design;Query processing;Relational databases;Tree graphs","computational complexity;graph theory;query processing;relational databases","IR-styled m-keyword query processing;RDBMS framework;database techniques;information retrieval;open-ended relational data stream;scalable keyword search;schema graph","","2","","18","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"An efficient query matching algorithm for relational data semantic cache","M. Ahmad; M. A. Qadir; M. Sanaullah; M. F. Bashir","Centre for Distributed and Semantic Computing, Mohammad Ali Jinnah University, Islamabad, Pakistan","2009 2nd International Conference on Computer, Control and Communication","20090505","2009","","","1","6","Data access latency can be reduced for databases by using caching. Semantic caching enhances the performance of normal caching by locally answering the partially overlapped queries. Query processing (generation of probe and remainder query from the incoming queries) and cache management need to be addressed in its totality to really enjoy these benefits. That is, there is a need of correct, complete and efficient algorithms to process incoming queries and to manage semantic and data cache. In this paper, we address this issue in the context of query processing. We have observed that the algorithm proposed by Q. Ren and his colleagues has some inefficiencies and redundancies. To overcome these inefficiencies and redundancies, we have proposed an algorithm for query matching with hierarchal stored query semantics. Proposed algorithm performs matching of stored semantics in cache with semantics of incoming query. It also has capability to generate amending query efficiently and rejects incorrect queries at initial level. Comparison of proposed algorithm is made with existing algorithm. Complexity of proposed query matching algorithm is O(n) which is smaller then the existing which have O(2n-1), n is number of attributes in a relation. Also, the proposed algorithm is capable to stop the useless processing as was done in the previous algorithms.","","POD:978-1-4244-3313-1","10.1109/IC4.2009.4909246","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4909246","Algorithms;Query matching;Query processing;Relational Databases;Semantic Caching","Database systems;Delay;Distributed computing;Distributed databases;Information retrieval;Probes;Query processing;Relational databases;XML","cache storage;query processing;relational databases","cache management;data access latency;hierarchal stored query semantics;query matching algorithm;query processing;relational data semantic cache","","2","","18","","","17-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Aerosol Optical Thickness data retrieval over Penang Island, Malaysia","H. S. Lim; M. Z. MatJafri; K. Abdullah; C. J. Wong; N. M. Saleh","School of Physics, Universiti Sains Malaysia, 11800 Penang, Malaysia","2009 IEEE Aerospace conference","20090424","2009","","","1","6","In this study, we propose a new cost effective approach to retrieve aerosol optical thickness (AOT) data in the visible spectrum by using sky transmittance measurements measured by a handheld spectroradiometer. The transmittance values were measured in spectral region from 350 nm to 1050 nm at the earth's surface. The well known Beer-Lambert law was used in this study to retrieve AOT values from the measured transmittance value. The concentrations of particulate matter of less than 2.5 micron (PM2.5) were measured simultaneously with the measurements of the transmittance data. The station locations of the PM2.5 measurements were detemined using a handheld GPS. Three interpolation techniques, namely Kriging Interpolation, Inverse Distance Interpolation and Natural Neighbour Interpolation, were used for mapping the PM2.5 concentration in this study. The accuracies of the three interpolation techniques were determined in this study in order to select the most suitable technique for mapping the air pollution concentration over Penang Island, Malaysia. The results of the analysis indicated that the AOT values were linearly correlated with the PM2.5 readings. AOT and PM10 maps were generated using an interpolation technique (Kriging) based on the measured data. Basically, both PM2.5 and AOT maps agree reasonably well over Penang Island, Malaysia. The highest PM2.5 concentrations were found in densely populated and industrialized areas.","1095-323X;1095323X","POD:978-1-4244-2621-8","10.1109/AERO.2009.4839440","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839440","","Aerosols;Atmospheric measurements;Costs;Earth;Information retrieval;Interpolation;Particle measurements;Pollution measurement;Spectroradiometers;Thickness measurement","Global Positioning System;aerosols;air pollution;atmospheric chemistry;atmospheric composition;atmospheric techniques;environmental factors;radiometers;remote sensing;statistical analysis","AOT data;Beer-Lambert law;Earth surface;GPS;Global Positioning System;Malaysia;Penang Island;aerosol optical thickness;air pollution concentration;air quality mapping;atmospheric transmittance measurement;environmental pollution;industrialized area;inverse distance interpolation technique;kriging interpolation technique;natural neighbour interpolation technique;particulate matter concentration;particulate matter mapping;sky transmittance measurement;spectroradiometer;visible spectrum;wavelength 350 nm to 1050 nm","","1","","5","","","7-14 March 2009","","IEEE","IEEE Conference Publications"
"Context-Based Privacy Protection for Location-Based Mobile Services using Pseudonyms","J. Zeiss; O. Jorns","Telecommun. Reseach Center, Vienna","2008 Ninth International Conference on Mobile Data Management Workshops, MDMW","20090424","2008","","","81","87","This paper discusses the combination of a nifty pseudonym generation mechanism that is used to veil the real world identity of users with semantic user context descriptions and policy reasoning to express decisions of users and thus protects their sensitive location information. The expected development of a new class of mobile applications is further fostered by the underlying service architecture that makes use of the privacy protection means and allows the implementation of the highly postulated pay-as-you-go model. Means for privacy protection are not only an ultimate requirement for the development of successful location-based services and applications. It further means an incentive for network service operators to enrich location-based services by making available their localization capabilities to at the same time to open new sources of revenue.","","CD-ROM:978-0-7695-3721-4; POD:978-1-4244-4484-7","10.1109/MDMW.2008.5","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839087","","Context-aware services;Data privacy;Europe;Government;Information retrieval;Large-scale systems;Navigation;Network interfaces;Protection;Telephony","mobile radio;telecommunication security","context-based privacy protection;location-based mobile services;network service operators;nifty pseudonym generation mechanism;semantic user context descriptions;service architecture","","1","","23","","","27-30 April 2008","","IEEE","IEEE Conference Publications"
"SAW RFID spread spectrum OFC and TDM technology","J. M. Pavlina; N. Kozlovski; B. Santos; D. C. Malocha","School of Electrical Engineering and Computer Science University of Central Florida, Orlando, 32826, USA","2009 IEEE International Conference on RFID","20090508","2009","","","110","116","SAW based RFID sensors can offer wireless, passive operation over harsh environments, and various device embodiments are used for retrieval of the sensed data. SAW has many unique advantages over possible competing technologies, including the following characteristics: passive, radiation hard, operable over wide temperature ranges, small, rugged, inexpensive, and identifiable. In a multi-sensory environment, it is necessary both to identify the sensor and to retrieve the sensed information. The OFC SAW technology approach has been funded by NASA for possible inclusion in ground, space flight, and space exploration sensor applications. The purpose of this paper is to present the concept of encoding SAW-based sensors for use in a multiple-sensor environment. The emphasis will be on orthogonal frequency coded (OFC) devices overlaid with a form of time division multiplexing (TDM). It will be shown that in addition to the benefits of OFC such as enhanced processing gain and lower interrogation power spectral density (PSD), the TDM allows for a decrease in overlapping energy and therefore a decrease in intersensory collisions which are shown to cause peak ambiguity. This approach should be applicable to many different SAW-based sensors (such as temperature, pressure, liquid, gas, etc.), as well as allow for proper IDing. Measured device results are presented and compared with coupling of modes (COM) model predictions to demonstrate performance. This paper will discuss the use of SAW OFC in a temperature sensor application. Devices are then used in computer-simulated transceiver design, and the results of a prototype sensor system are discussed.","2374-0221;23740221","POD:978-1-4244-3337-7","10.1109/RFID.2009.4911213","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4911213","","Information retrieval;Land surface temperature;Radiofrequency identification;Sensor phenomena and characterization;Space technology;Spread spectrum communication;Surface acoustic waves;Temperature sensors;Time division multiplexing;Wireless sensor networks","orthogonal codes;radiofrequency identification;spread spectrum communication;surface acoustic wave sensors;temperature sensors;time division multiplexing;transceivers","SAW based RFID sensors;computer-simulated transceiver design;coupling of modes model;ground applications;multi-sensory environment;orthogonal frequency coded devices;power spectral density;space exploration sensor applications;space flight applications;spread spectrum OFC technology;spread spectrum TDM technology;surface acoustic wave sensors;temperature sensor application;time division multiplexing","","12","","16","","","27-28 April 2009","","IEEE","IEEE Conference Publications"
"Edge detection and filtering of images corrupted by nonstationary noise using robust statistics","N. Ponomarenko; D. Fevralev; A. Roenko; S. Krivenko; V. Lukin; I. Djurovic","Dept of Transmitters, Receivers and Signal Processing, National Aerospace University, 17, Chkalova Str., Kharkiv, 61070, UKRAINE","2009 10th International Conference - The Experience of Designing and Application of CAD Systems in Microelectronics","20090424","2009","","","129","136","Images are a type of data widely used, processed and analyzed in CAD and telecommunication systems. To retrieve useful information from images, they are often subject to different kinds of preprocessing that commonly include edge detection and filtering. These operations can be performed by standard means if noise type and statistics are known in advance. In this paper we address situations when such a priori information is not available. Two local operators based on robust statistics calculated in spatial and spectral domains are proposed and analyzed for edge detection application. Then we show how the obtained edge maps can be exploited in locally adaptive filtering based on discrete cosine transform (DCT).","","POD:978-966-2191-05-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839783","Visual quality;lossy compression;noise-free and noisy images","Discrete cosine transforms;Image analysis;Image edge detection;Image retrieval;Information filtering;Information filters;Information retrieval;Noise robustness;Statistical analysis;Statistics","adaptive filters;discrete cosine transforms;edge detection;image retrieval;statistical analysis","CAD;a priori information;adaptive filtering;discrete cosine transform;edge detection;image filtering;information retrieval;nonstationary noise;robust statistics;telecommunication systems","","1","","38","","","24-28 Feb. 2009","","IEEE","IEEE Conference Publications"
"Advanced emotion categorization and tagging","P. Jiang; F. Ren; N. Zheng","Faculty of Engineering, The Univ. of Tokushima, Japan","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","6","Affective computing is attracting attentions as a popular growing field with many applications such as Kansei engineering, information retrieval and HCI. But until now the study of fine-grained theory of emotion is still a challenge. In this paper, a novel method to analyze emotion category is proposed according to the statistics of affective property in Dictionary of contemporary Chinese. These emotion categories are called complex emotion. Firstly, over 3,700 common affective words and their detailed explanations had been collected for an affective lexicon, then we analyze the consistent relationship in the affective lexicon and consequently 52 salient complex emotion states are categorized and tagged by a straightforward clustering algorithm. The complex emotions are compared to the traditional definitions of basic emotions in psychology and have been evaluated to be valid in the experiment. Moreover we also have tagged the semantic orientation for the collected words.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906814","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906814","Complex emotion;affective clustering;affective word lexicon;emotion category","Artificial intelligence;Human computer interaction;Information retrieval;Natural languages;Psychology;Robots;Speech analysis;Statistical analysis;Tagging;Telecommunication computing","emotion recognition;natural language processing;pattern classification","advanced emotion categorization;advanced emotion tagging;contemporary Chinese dictionary;emotion category;straightforward clustering algorithm","","1","","8","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"3D Model Retrieval Using Probability Density-Based Shape Descriptors","C. B. Akg√ºl; B. Sankur; Y. Yemez; F. Schmitt","Philips Research Europe, High Tech Campus, The Netherlands","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090417","2009","31","6","1117","1133","We address content-based retrieval of complete 3D object models by a probabilistic generative description of local shape properties. The proposed shape description framework characterizes a 3D object with sampled multivariate probability density functions of its local surface features. This density-based descriptor can be efficiently computed via kernel density estimation (KDE) coupled with fast Gauss transform. The non-parametric KDE technique allows reliable characterization of a diverse set of shapes and yields descriptors which remain relatively insensitive to small shape perturbations and mesh resolution. Density-based characterization also induces a permutation property which can be used to guarantee invariance at the shape matching stage. As proven by extensive retrieval experiments on several 3D databases, our framework provides state-of-the-art discrimination over a broad and heterogeneous set of shape categories.","0162-8828;01628828","","10.1109/TPAMI.2009.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4760150","Curve;Feature evaluation and selection;Feature representation;Invariants;Nonparametric statistics;Retrieval models;Shape;and object representations;solid;surface","Application software;Content based retrieval;Design automation;Gaussian processes;Information retrieval;Kernel;Probability density function;Shape;Spatial databases;Statistics","Gaussian processes;edge detection;image matching;image retrieval;transforms","3D databases;3D model retrieval;Gauss transform;content-based retrieval;kernel density estimation;sampled multivariate probability density functions;shape descriptors;shape matching","1","54","","44","","20090123","June 2009","","IEEE","IEEE Journals & Magazines"
"Distance-Based Representative Skyline","Y. Tao; L. Ding; X. Lin; J. Pei","Chinese Univ. of Hong Kong, Hong Kong","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","892","903","Given an integer k, a representative skyline contains the k skyline points that best describe the tradeoffs among different dimensions offered by the full skyline. Although this topic has been previously studied, the existing solution may sometimes produce k points that appear in an arbitrarily tiny cluster, and therefore, fail to be representative. Motivated by this, we propose a new definition of representative skyline that minimizes the distance between a non-representative skyline point and its nearest representative. We also study algorithms for computing distance-based representative skylines. In 2D space, there is a dynamic programming algorithm that guarantees the optimal solution. For dimensionality at least 3, we prove that the problem is NP-hard, and give a 2-approximate polynomial time algorithm. Using a multidimensional access method, our algorithm can directly report the representative skyline, without retrieving the full skyline. We show that our representative skyline not only better captures the contour of the entire skyline than the previous method, but also can be computed much faster.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812463","","Clustering algorithms;Data engineering;Databases;Dynamic programming;Heuristic algorithms;Information retrieval;Multidimensional systems;Polynomials;Web server","computational complexity;dynamic programming;information retrieval;minimisation","NP-hard problem;arbitrarily tiny cluster;distance minimization;distance-based representative skyline computing;dynamic programming algorithm;multidimensional access method;polynomial time algorithm;skyline retrieval","","40","","27","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"A unified audio and image steganography by spectrum modification","K. Gopalan","Department of Electrical and Computer Engineering, Purdue University Calumet, Hammond, IN 46323, U.S.A.","2009 IEEE International Conference on Industrial Technology","20090519","2009","","","1","5","A method of embedding information in the spectral domain of a cover audio and a cover image that can be extended to video frames is proposed. The technique exploits the imperceptibility of human auditory and visual systems at low levels of spectral changes. By selectively altering the spectrum at a pair of one-dimensional frequencies by a small percentage of the average power of a segment of audio or image, the psychoacoustical or psychovisual masking property enables unnoticeable embedding with a large payload. Initial studies on the effect of Gaussian noise added to the stego demonstrate the robustness of the technique to noise in both the stego audio and image. The imperceptibility of the technique combined with high payload, robustness of embedded data and accurate data retrieval renders the proposed steganography suitable for covert communication and secure data transmission applications.","","POD:978-1-4244-3506-7","10.1109/ICIT.2009.4939516","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4939516","","Frequency;Gaussian noise;Humans;Image segmentation;Information retrieval;Noise robustness;Payloads;Psychology;Steganography;Visual system","Gaussian noise;audio coding;image coding;steganography","Gaussian noise effect;audio steganography;image steganography;one-dimensional frequencies;spectrum modification","","11","","8","","","10-13 Feb. 2009","","IEEE","IEEE Conference Publications"
"Asymptotic evaluation of distance measure on high dimensional vector spaces in text mining","M. Goto; T. Ishida; M. Suzuki; S. Hirasawa","Faculty of Environmental and Information Studies, Musashi Institute of Technology, Tsuzuki-ku, Yokohama, Kanagawa, 224-0015 Japan","2008 International Symposium on Information Theory and Its Applications","20090428","2008","","","1","6","This paper discusses the document classification problems in text mining from the viewpoint of asymptotic statistical analysis. In the problem of text mining, the several heuristics are applied to practical analysis because of its experimental effectiveness in many case studies. The theoretical explanation about the performance of text mining techniques is required and such thinking will give us very clear idea. In this paper, the performances of distance measures used to classify the documents are analyzed from the new viewpoint of asymptotic analysis. We also discuss the asymptotic performance of IDF measure used in the information retrieval field.","","CD-ROM:978-1-4244-2069-8; POD:978-1-4244-2068-1","10.1109/ISITA.2008.4895453","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4895453","","Electronic mail;Extraterrestrial measurements;Frequency measurement;Information retrieval;Information theory;Performance analysis;Space technology;Statistics;Text categorization;Text mining","classification;data mining;information retrieval;statistical analysis;text analysis","asymptotic distance measure evaluation;asymptotic statistical analysis;document classification problem;high dimensional vector space;information retrieval;text mining","","1","","8","","","7-10 Dec. 2008","","IEEE","IEEE Conference Publications"
"Using of n-ary taxonomic trees for saving and searching knowledge in the management process of technical systems","L. Sikora; Y. Miyushkovych","","2009 10th International Conference - The Experience of Designing and Application of CAD Systems in Microelectronics","20090424","2009","","","261","262","One of the main problems in the knowledge representation is the problem of saving and handling the information with the formal approach in the information systems so, that the machines can use it to achieve the system goal. In this article we have examined availability of N-ary taxonomic tree with limited tree depth for saving and searching knowledge.","","POD:978-966-2191-05-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839825","binary taxonomic tree;n-ary taxonomic tree","Binary trees;Classification tree analysis;Data mining;Information retrieval;Knowledge management;Knowledge representation;Management information systems;Mathematics;Taxonomy;Tree data structures","knowledge representation;trees (mathematics)","N-ary taxonomic trees;formal approach;knowledge representation;knowledge searching;limited tree depth;management process;technical systems","","0","","4","","","24-28 Feb. 2009","","IEEE","IEEE Conference Publications"
"Estimation of volatility in temporal rows at prognostication of technique - economic information","B. Shamsha; V. Ayvazov; N. Kuklin","Kharkiv National University of Radio Electronics, 14 Lenina Str., 61166, UKRAINE","2009 10th International Conference - The Experience of Designing and Application of CAD Systems in Microelectronics","20090424","2009","","","349","351","At the choice of method of prognostication on the stage of the preliminary data processing is necessary to check up the row of hypotheses, and in particular, presence of the troop landing, stationary, heteroskedastic and etc Basic attention in work is spared to the problem of verification of hypotheses about the presence of heteroskedastic in the conditions when conditional middle unsteadily by reason of changeability of statistical descriptions, that results in erroneous conclusions at interpretation ARCH models. Procedure of correction of changeability of conditional middle is considered.","","POD:978-966-2191-05-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839848","","Data processing;Education;Fuzzy logic;Information retrieval;Libraries;Mathematical model;Neurons;Packaging;Probability;Strontium","econometrics","data processing;economic information;heteroskedastic;prognostication;volatility","","0","","3","","","24-28 Feb. 2009","","IEEE","IEEE Conference Publications"
"Application of the preference learning model to a human resources selection task","F. Aiolli; M. De Filippo; A. Sperduti","Department of Pure and Applied Mathematics, Padua University, Italy","2009 IEEE Symposium on Computational Intelligence and Data Mining","20090515","2009","","","203","210","In many applicative settings there is the interest in ranking a list of items arriving from a data stream. In a human resource application, for example, to help selecting people for a given job role, the person in charge of the selection may want to get a list of candidates sorted according to their profiles and how much they are suited for the target job role. Historical data about past decisions can be analyzed to try to discover rules to help in defining such ranking. Moreover, samples have a temporal dynamics. To exploit this possibly useful information, here we propose a method that incrementally builds a committee of classifiers (experts), each one trained on the newer chunks of samples. The prediction of the committee is obtained as a combination of the rankings proposed by the experts which are ldquocloserrdquo to the data to rank. The experts of the committee are generated using the preference learning model, a recent method which can directly exploit supervision in the form of preferences (partial orders between instances) and thus particularly suitable for rankings. We test our approach on a large dataset coming from many years of human resource selections in a bank.","","POD:978-1-4244-2765-9","10.1109/CIDM.2009.4938650","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4938650","","Companies;Computer science;Data mining;Data warehouses;Human resource management;Information management;Information retrieval;Machine learning;Mathematics;Testing","human resource management;learning (artificial intelligence)","data stream;human resources selection task;preference learning model;temporal dynamics","","4","","13","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"An approximation algorithm for finding skeletal points for density based clustering approaches","S. H. Yeganeh; J. Habibi; H. Abolhassani; M. A. Tehrani; J. Esmaelnezhad","Computer Engineering Department, Sharif University of Techonology, Azadi Ave, Tehran, Iran","2009 IEEE Symposium on Computational Intelligence and Data Mining","20090515","2009","","","403","410","Clustering is the problem of finding relations in a data set in an supervised manner. These relations can be extracted using the density of a data set, where density of a data point is defined as the number of data points around it. To find the number of data points around another point, region queries are adopted. Region queries are the most expensive construct in density based algorithm, so it should be optimized to enhance the performance of density based clustering algorithms specially on large data sets. Finding the optimum set of region queries to cover all the data points has been proven to be NP-complete. This optimum set is called the skeletal points of a data set. In this paper, we proposed a generic algorithms which fires region queries at most 6 times the optimum number of region queries (has 6 as approximation factor). Also, we have extend this generic algorithm to create a DBSCAN (the most wellknown density based algorithm) derivative, named ADBSCAN. Presented experimental results show that ADBSCAN has a better approximation to DBSCAN than the DBRS-H (the most well-known randomized density based algorithm) in terms of performance and quality of clustering, specially for large data sets.","","POD:978-1-4244-2765-9","10.1109/CIDM.2009.4938678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4938678","Approximation Algorithms;Clustering;Data Mining;Spatial Clustering","Approximation algorithms;Clustering algorithms;Databases;Euclidean distance;Extraterrestrial measurements;Impedance;Information retrieval;Information systems;Logic;Web sites","computational complexity;optimisation;pattern clustering","ADBSCAN;DBRS-H;DBSCAN;NP-complete;approximation algorithm;data points;data set;density based clustering approaches;generic algorithms;randomized density based algorithm;region queries;skeletal points","","2","","17","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"The effect of wind speed on SST retrieval","H. G. Ng; M. Z. MatJafri; K. Abdullah; C. J. Wong","School of Physics, Universiti Sains Malaysia, 11800 USM, Penang, Malaysia","2009 IEEE Aerospace conference","20090424","2009","","","1","8","Many studies have been performed to retrieve the sea surface temperature (SST). However, the researchers studied only the effect of brightness temperature difference, observation angle and water vapor content. The sea surface emissivity (SSE) is normally considered as unity or constant. However, in a real case, the sea surface emissivity changes with the wind speed. In this study, we would like to check whether the wind speed had only minimal effect on the sea surface temperature, as was assumed in the prior literature. A new algorithm which included the term of SSE in the function of wind speed was established. The new algorithm was compared with the day split multichannel (MCSST) algorithm. The coefficients of the new algorithm were retrieved by the new derived equation with includes the term of emissivity. The algorithm coefficients of MCSST were retrieved by regression analysis with large amount of SST in-situ data. The SST data simulated by the new algorithm were compared with the SST data simulated with MCSST algorithm. The scatter plot of new derived SST algorithm coefficients was generated. The regression analysis was performed to study the effect of wind speed. The result showed that only the high wind speed had significant effect on SST retrieval.","1095-323X;1095323X","POD:978-1-4244-2621-8","10.1109/AERO.2009.4839442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839442","","Brightness temperature;Equations;Information retrieval;Ocean temperature;Regression analysis;Scattering;Sea surface;Space vehicles;Temperature sensors;Wind speed","ocean temperature;oceanographic techniques;remote sensing;wind","SST retrieval;brightness temperature difference;day split multichannel algorithm;observation angle;sea surface emissivity;sea surface temperature;water vapor content;wind speed","","0","","11","","","7-14 March 2009","","IEEE","IEEE Conference Publications"
"Linear Suffix Array Construction by Almost Pure Induced-Sorting","G. Nong; S. Zhang; W. H. Chan","Comput. Sci. Dept., Sun Yat-Sen Univ., Guangzhou","2009 Data Compression Conference","20090526","2009","","","193","202","We present a linear time and space suffix array (SA) construction algorithm called the SA-IS algorithm.The SA-IS algorithm is novel because of the LMS-substrings used for the problem reduction and the pure induced-sorting (specially coined for this algorithm)used to propagate the order of suffixes as well as that of LMS-substrings, which makes the algorithm almost purely relying on induced sorting at both its crucial steps.The pure induced-sorting renders the algorithm an elegant design and in turn a surprisingly compact implementation which consists of less than 100 lines of C code.The experimental results demonstrate that this newly proposed algorithm yields noticeably better time and space efficiencies than all the currently published linear time algorithms for SA construction.","1068-0314;10680314","POD:978-0-7695-3592-0","10.1109/DCC.2009.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4976463","Suffix array;algorithm design;divide-and-conquer;linear time","Algorithm design and analysis;Computer science;Data compression;Data structures;Educational institutions;Indexing;Information retrieval;Mathematics;Sorting;Sun","data handling;data structures","C code;LMS-substrings;SA-IS algorithm;linear suffix array construction algorithm;linear time algorithms;problem reduction;pure induced sorting","","16","","7","","","16-18 March 2009","","IEEE","IEEE Conference Publications"
"Large scale learning and recognition of faces in web videos","Ming Zhao; J. Yagnik; H. Adam; D. Bau","Google Inc., USA","2008 8th IEEE International Conference on Automatic Face & Gesture Recognition","20090410","2008","","","1","7","The phenomenal growth of video on the Web and the increasing sparseness of meta information associated with it forces us to look for signals from the video content for search/information retrieval and browsing based corpus exploration. A large chunk of users' searching/browsing patterns are centered around people present in the video. Doing it at scale in videos remains hard due to a) the absence of labeled data for such a large set of people and b) the large variation of pose/illumination/expression/age/occlusion/quality etc in the target corpus. We propose a system that can learn and recognize faces by combining signals from large scale weakly labeled text, image, and video corpora. First, consistency learning is proposed to create face models for popular persons. We use the text-image co-occurrence on the web as a weak signal of relevance and learn the set of consistent face models from this very large and noisy training set. Second, efficient and accurate face detection and face tracking is applied. Last, the key faces in each face track is select by clustering to get compact and robust representation. The face tracks are further clustered to get more representative key faces and remove duplicate key faces. For each cluster of face tracks, a combination of majority voting and probabilistic voting is done with the automatically learned models. The effectiveness of our framework is demonstrated by results on image and video corpora, in which we can achieve 92.68% in 37 million images and 80% top-5-precision in 1500 hours videos.","","CD-ROM:978-1-4244-2154-1; POD:978-1-4244-2153-4","10.1109/AFGR.2008.4813381","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813381","","Content based retrieval;Face detection;Face recognition;Image recognition;Information retrieval;Large-scale systems;Lighting;Text recognition;Videos;Voting","Internet;face recognition;information retrieval;object detection;probability;target tracking;video signal processing","Web videos;face detection;face models;face recognition;face tracking;information retrieval;large scale learning;probabilistic voting;text-image co-occurrence;video content","","10","9","17","","","17-19 Sept. 2008","","IEEE","IEEE Conference Publications"
"JigDFS: A secure distributed file system","J. Bian; R. Seker","Computer Science, University of Arkansas at Little Rock, 72204, USA","2009 IEEE Symposium on Computational Intelligence in Cyber Security","20090515","2009","","","76","82","Ubiquitous connectivity and availability of P2P resources creates opportunities for building new services. This paper describes Jigsaw Distributed File System (JigDFS) which can be used to securely store and retrieve files on a P2P network anonymously. JigDFS is designed to provide strong encryption and a certain level of plausible deniability. Files in JigDFS are sliced into small segments using an information dispersal algorithm (IDA) and distributed onto different nodes recursively to increase fault tolerance against node failures. Moreover, layered encryption is applied to each file with keys produced by a hashed-key chain algorithm, so that data (file segments) and keys reside on different hosts. In such a scheme, if an attacker compromises a host and retrieves the data, the attacker will still need the correct key to decipher the data. Furthermore, recursive IDA and layered encryption ensure users' anonymity. It is difficult for an adversary to identify who owns a file, even who has retrieved a file in JigDFS. Often, a strong adversary may have the power to monitor the network or even force a user to give up the password. Design of JigDFS provides users with plausible deniability which enhances privacy. When being questioned, a JigDFS user can simply argue that he/she is merely a relaying node, rather than the file owner. Moreover, a user, when forced, can give up a valid, however, incorrect encryption key. There is no way for an adversary to verify either correctness of a key or the identity of file owner. JigDFS is developed using platform independent Java technologies and is envisioned to utilize mobile computing elements such as PDAs and smart phones.","","POD:978-1-4244-2769-7","10.1109/CICYBS.2009.4925093","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4925093","","Availability;Buildings;Cryptography;Fault tolerance;File systems;Information retrieval;Monitoring;Personal digital assistants;Privacy;Relays","Java;cryptography;data privacy;information retrieval;mobile computing;peer-to-peer computing;software fault tolerance;ubiquitous computing","P2P network;fault tolerance;files retrieval;hashed-key chain algorithm;independent Java technologies platfrom;information dispersal algorithm;jigsaw distributed file system;layered encryption;mobile computing elements;node failures;secure distributed file system;ubiquitous connectivity","","14","2","30","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"PADRE: Modulated Backscattering-Based PAssive Data REtrieval in Wireless Sensor Networks","M. T. Isik; O. B. Akan","Dept. of Electr. & Electron. Eng., Middle East Tech. Univ., Ankara","2009 IEEE Wireless Communications and Networking Conference","20090512","2009","","","1","6","The most difficult challenge for the design of wireless sensor networks (WSN) is to maintain long network lifetimes since the sensor nodes are severely energy-constrained. Traditional WSN assumes employment of conventional RF transmitters which consume most of the stored power on the sensor node. In this regard, modulated backscattering (MB) emerges as a promising communication technique alternative, in which the sensor nodes reflect the incident signal of an RF source and modulate their data on the reflected signal. With the use of MB, the power consumption of the nodes reduce drastically since it replaces the most power consuming component of a typical sensor node, i.e., the RF transmitter. In addition, the nodes acquire relatively long-range communication ability through MB. Furthermore, the incident RF power can be converted into DC power in order to drive the sensing and processing circuitries. This, in turn,i leads to the design of battery-free wireless passive sensor networks (WPSN), which stands as a radically distinct solution approach for the energy problems of WSN. The objective of this paper is to revisit the main design challenge of WSN from entirely different perspective. To this end, the fundamental principles of WPSN are first introduced. In addition, in order to realize the potential benefits of WPSN, a new clustering-based energy-efficient communication protocol, i.e., PADRE (PAssive Data REtrieval), is presented for WPSN operating via MB technique. Simulations show that PADRE protocol achieves high performance in terms communication reliability and network lifetime.","1525-3511;15253511","POD:978-1-4244-2947-9","10.1109/WCNC.2009.4917879","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4917879","","Backscatter;Circuits;Employment;Energy consumption;Information retrieval;Protocols;RF signals;Radio frequency;Transmitters;Wireless sensor networks","backscatter;protocols;telecommunication network reliability;wireless sensor networks","battery-free wireless sensor network design;clustering-based energy-efficient communication protocol;modulated backscattering;network lifetime reliability;passive data retrieval protocol;power consumption","","4","","11","","","5-8 April 2009","","IEEE","IEEE Conference Publications"
"The Study of Mobile Learning Based on Information Push Technology","Z. Wang; X. Xiong; Y. Hou","Dept. of Inf. Technol., HuaZhong Normal Univ., Wuhan","2009 First International Workshop on Education Technology and Computer Science","20090526","2009","2","","1140","1142","Mobile learning is developing rapidly with the development of mobile communication technology. Mobile Internet brings a mount of resources in mobile learning, the explosion of information causes a lot of inconveniences to mobile learner. This paper introduces the conception of the information push technology and mobile learning at the beginning, and tries to analyze the necessity and possibility of combination the both, finally, set an example to expound the way how to apply push technology to the mobile learning.","","POD:978-0-7695-3557-9","10.1109/ETCS.2009.522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959234","Information Technology;Mobile learning;RSS","Communications technology;Computer science education;Educational technology;Explosions;IP networks;Information retrieval;Information technology;Internet;Mobile communication;Throughput","Internet;computer aided instruction;mobile communication;mobile computing","information push technology;mobile Internet;mobile communication;mobile learning","","0","","4","","","7-8 March 2009","","IEEE","IEEE Conference Publications"
"Novel similarity measure for document clustering based on topic phrases","A. E. ELdesoky; M. Saleh; N. A. Sakr","Dept. of Computer and System, Mansoura University, Egypt","2009 International Conference on Networking and Media Convergence","20090502","2009","","","92","96","Document clustering is a subset of the data clustering field which categorizes large set of documents into similar and related groups. In the traditional vector space model (VSM) researchers have considered the unique word which occurs in the document set as the candidate feature. Recently a new trend which considered the phrase to be a more informative feature has taken place; the matter which contributes in improving the document clustering accuracy and effectiveness. This paper proposes a new approach for computing the similarity measure of the traditional VSM by considering the topic phrases of the document as the constituting terms for the VSM instead of the traditional term ldquowordrdquo and applying the new approach to the Buckshot method, which is a mix of the Hierarchical Agglomerative Clustering (HAC) algorithm and the K-means partitioning algorithm. Such a mechanism may raise the effectiveness of the clustering by increasing the evaluation metrics values.","","POD:978-1-4244-3776-4","10.1109/ICNM.2009.4907196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4907196","","Clustering algorithms;Clustering methods;Frequency;Humans;Information retrieval;Natural language processing;Organizing;Partitioning algorithms;Taxonomy;Text mining","document handling;pattern clustering","Buckshot method;document clustering;hierarchical agglomerative clustering algorithm;k-means partitioning algorithm;similarity measure;topic phrases;vector space model","","3","1","17","","","24-25 March 2009","","IEEE","IEEE Conference Publications"
"Weighted Superimposed Codes and Constrained Integer Compressed Sensing","W. Dai; O. Milenkovic","Dept. of Electr. & Comput. Eng., Univ. of Illinois at Urbana-Champaign, Urbana, IL","IEEE Transactions on Information Theory","20090421","2009","55","5","2215","2229","We introduce a new family of codes, termed weighted superimposed codes (WSCs). This family generalizes the class of Euclidean superimposed codes (ESCs), used in multiuser identification systems. WSCs allow for discriminating all bounded, integer-valued linear combinations of real-valued codewords that satisfy prescribed norm and nonnegativity constraints. By design, WSCs are inherently noise tolerant. Therefore, these codes can be seen as special instances of robust compressed sensing schemes. The main results of the paper are lower and upper bounds on the largest achievable code rates of several classes of WSCs. These bounds suggest that, with the codeword and weighting vector constraints at hand, one can improve the code rates achievable by standard compressive sensing techniques.","0018-9448;00189448","","10.1109/TIT.2009.2016024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839057","Code exponent;compressive sensing;random coding bound;sphere-packing bound;superimposed codes","Code standards;Compressed sensing;Databases;Euclidean distance;Information retrieval;Noise robustness;Signal processing;Testing;Upper bound;Vectors","linear codes","Euclidean superimposed codes;constrained integer compressed sensing;integer-valued linear combinations;real-valued codewords;robust compressed sensing schemes;weighted superimposed codes","","15","","24","","","May 2009","","IEEE","IEEE Journals & Magazines"
"A dimensional approach to emotion recognition of speech from movies","T. Giannakopoulos; A. Pikrakis; S. Theodoridis","Dept. of Informatics and Telecommunications, University of Athens, Greece","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","65","68","In this paper we present a novel method for extracting affective information from movies, based on speech data. The method is based on a 2D representation of speech emotions (Emotion Wheel). The goal is twofold. First, to investigate whether the Emotion Wheel offers a good representation for emotions associated with speech signals. To this end, several humans have manually annotated speech data from movies using the Emotion Wheel and the level of disagreement has been computed as a measure of representation quality. The results indicate that the emotion wheel is a good representation of emotions in speech data. Second, a regression approach is adopted, in order to predict the location of an unknown speech segment in the Emotion Wheel. Each speech segment is represented by a vector of ten audio features. The results indicate that the resulting architecture can estimate emotion states of speech from movies, with sufficient accuracy.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959521","Emotion Recognition;Multimedia analysis;Regression","Content based retrieval;Data mining;Emotion recognition;Humans;Informatics;Motion pictures;Music information retrieval;Psychology;Speech;Wheels","emotion recognition;feature extraction;prediction theory;regression analysis;signal representation;speech recognition","audio feature;emotion wheel;movie information extraction;multimedia analysis;regression approach;signal representation;speech emotion recognition","","9","","11","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Improving Latent Semantic Indexing with concepts mapping based on domain ontology","J. Hao; L. Liao; X. Dong","Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, 100081, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","6","ldquoCurse of dimensionalityrdquo is a common problem in the area of information retrieval. It was verified that points in a vector space are projected to a random subspace of suitably high dimension, and then the distances between the points are approximately preserved. Although such a random projection can be used to reduce the dimension of the document space, it does not bring together semantically related documents. Latent Semantic Indexing (LSI) projects documents to lower dimensional LSI space from higher dimensional term space with singular-value decomposition (SVD) for the purpose of reducing the dimensions of the document space and bringing together semantically related documents. But the computation time of SVD is a bottleneck because of the higher dimensions of documents. In this paper, a novel method of dimension reduction for improving LSI is provided. A term-to-concept projection matrix based on domain ontology was created in this method. This way documents were projected to lower dimensional concept space by the projection matrix. LSI pre-computation was performed not on the original term by document matrix, but on the lower dimensional concept by document matrix at great computational savings. Experiments indicate that this method improves the efficiency of LSI. And the similarity judgment between documents is not disturbed.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906768","LSI;Latent Semantic Indexing;dimension reduction;domain ontology","Computer science;Data mining;Indexing;Information retrieval;Information technology;Laboratories;Large scale integration;Ontologies;Partial response channels;Space technology","information retrieval;ontologies (artificial intelligence);singular value decomposition","concepts mapping;domain ontology;information retrieval;latent semantic indexing;singular-value decomposition;vector space","","0","","18","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Research of Active Information Service System Based on Intelligent Agent","H. Jinzhu; Z. Xing; S. Jiangbo; X. Chunxiu; Z. Jun","Dept. of Comput. Sci., HuaZhong Normal Univ., Wuhan","2009 First International Workshop on Education Technology and Computer Science","20090526","2009","1","","837","841","The current active information service system focuses too much on the study of personalized modeling, and there is less research on artificial participation, automatic information analysis and automatic information update. According to the requirement of active information service to topical Web, the article integrate agent technology, information filtering technology, crawling technology on Heritrix and the technology of Web information extraction on HtmlParser, based on which a model that describes active information service system based on intelligent agent is presented. The model embeds the intelligent agent technology, on one hand, it could accomplish four active functions, they are active information collection, active Web page parsing, active information filtering, active information publishing, on the other hand, it has intelligence to a certain degree and has some learning abilities in parsing module. The characteristic of the model is its flexibility and adaptive capability.","","POD:978-0-7695-3557-9","10.1109/ETCS.2009.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4958895","active information service;information update;intelligent Agent","Computer science;Computer science education;Data mining;Educational technology;Information analysis;Information filtering;Information filters;Information retrieval;Intelligent agent;Search engines","Internet;Web sites;information filtering;learning (artificial intelligence);multi-agent systems","Heritrix crawling technology;HtmlParser Web information extraction technology;Web site;active Web page parsing;active information collection;active information filtering technology;active information publishing;active information service system;automatic information analysis;automatic information update;intelligent agent technology;learning ability;personalized modeling;topical Web","","0","","8","","","7-8 March 2009","","IEEE","IEEE Conference Publications"
"Integrity Assurance Technique Using Determinant Approach","J. A. Ghaeb","Dept. of Electr. & Comput. Eng., Hashemite Univ., Zarqa","2009 Workshops at the Grid and Pervasive Computing Conference","20090526","2009","","","160","164","Data integrity is an important aspect of storage security and reliability which are prerequisite for most computer systems and network applications. This paper proposes a new technique for improving the detection of data integrity violations. The method is based on check determinant approach. Simulation results show that the new method outperforms the traditional methods such as Hamming code method and RAID method.","","POD:978-0-7695-3677-4","10.1109/GPC.2009.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4976558","Data integrity;Error detection;Security;Storage integrity.","Computer crashes;Cryptography;Data security;Disk drives;File systems;Hardware;Information retrieval;Pervasive computing;Protection;Secure storage","data integrity;determinants;security of data","check determinant approach;computer system;data integrity;network application;storage reliability;storage security","","0","","16","","","4-8 May 2009","","IEEE","IEEE Conference Publications"
"A bandwidth-efficient scheme for distributed storage systems","N. S. Bathaee; M. R. Pakravan","Department of Electrical Engineering, Sharif University of Technology, Iran","2008 2nd International Symposium on Advanced Networks and Telecommunication Systems","20090515","2008","","","1","3","In this paper, utilizing the benefits of network coding, we introduce a scheme for uncoordinated dynamic distributed storage systems in which nodes can randomly join and leave the storage network. The proposed scheme can reduce the bandwidth requirement of the storage network.","2153-1676;21531676","POD:978-1-4244-3600-2","10.1109/ANTS.2008.4937794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4937794","","Bandwidth;Encoding;File servers;Flow graphs;Information retrieval;Joining processes;Maintenance;Network coding;Redundancy","block codes;encoding;redundancy;storage area networks","bandwidth;distributed storage systems;network coding","","0","","3","","","15-17 Dec. 2008","","IEEE","IEEE Conference Publications"
"An experiment of word sense disambiguation in a machine translation system","H. Faili","Department of ECE, University of Tehran, Iran","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","In this paper, we demonstrate an experiment of a machine translation (MT) system for two different languages, English and Persian. We also describe a model for word sense disambiguation (WSD) task inside the MT system, which uses decision trees automatically learned from a training data set, as its disambiguation formalism. Our evaluations can be divided into two different categories: evaluation on the whole MT system and evaluation on the WSD component. The experiments on the whole MT, shows that this system gets 16% with respect to NIST measure, while the evaluation on WSD using a corpus contains 860 aligned sentences shows that this component disambiguates 81.4% of ambiguous word correctly.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906781","Machine Translation;Persian Language;Word Sense Disambiguation","Computational linguistics;Data mining;Decision trees;Information retrieval;Machine learning;NIST;Natural language processing;Natural languages;Statistics;Training data","language translation;natural language processing","different languages;machine translation system;word sense disambiguation","","3","","29","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Radio Frequency Identification systems--present status, design challenges and future outlook","R. Mittra","Penn State University, USA","2008 Asia-Pacific Microwave Conference","20090526","2008","","","1","2","RFID systems are composed of three major components, namely, readers, transponders and antennas. A majority of the transponders are passive or batteryless, and are powered by the energy transmitted by the reader antenna, although active transponders are finding limited applications in some high-end applications, where security, reliability, and automatic operation capability are of the utmost importance, and can thus justify the use of more costly tags than the passive ones. The design of RFID systems is very challenging indeed because of demanding specifications coupled with restrictions on the available size cost, and platform tolerance of tags that may be mounted on a diverse array of products. To meet these challenges, it is necessary to combine the expertise on signal processing, antenna technology and system design. This review talk will identify the challenges and describe some of the proposed solutions for addressing them.","2165-4727;21654727","CD-ROM:978-1-4244-2642-3; POD:978-1-4244-2641-6","10.1109/APMC.2008.4958389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4958389","","Animals;Antenna accessories;Encoding;Frequency;Information retrieval;Inventory control;Pharmaceutical technology;Plastics;Radiofrequency identification;Transponders","radiofrequency identification;telecommunication network reliability;transponders","RFID system design;RFID system reliability;active transponder;antenna technology;automatic operation;batteryless transponder;passive transponder;radio frequency identification system;reader antenna;signal processing","","1","","","","","16-20 Dec. 2008","","IEEE","IEEE Conference Publications"
"An improved approach for image segmentation based on color and local homogeneity features","C. S. Ouyang; C. T. Chou; C. F. Jhan; J. Y. Huang","Department of Information Engineering, I-Shou University, Kaohsiung County 840, Taiwan, R.O.C.","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","1225","1228","In this paper, we propose an improved approach for image segmentation based on color and local homogeneity features. A given image is transformed into a quantized image by a self-constructing fuzzy clustering. Then, a color-based region image and an initial seeded region image are obtained from the quantized image by color-based and homogeneity-based region growing methods, respectively. After that, we combine these two images to generate a refined seeded region image and obtain an initial segmented image by a region-based region growing. Finally, merging based on color similarities and sizes of regions is performed for avoiding the problem of over-segmentation. Compared with the other method, experimental results show that the segmented regions obtained by our approach are more reasonable and precise.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959811","color quantization;fuzzy clustering;image segmentation;local homogeneity;seeded region growing","Application software;Computer vision;Image generation;Image retrieval;Image segmentation;Image texture analysis;Information retrieval;Merging;Pattern recognition;Quantization","fuzzy set theory;image coding;image colour analysis;image segmentation;pattern clustering","color homogeneity features;image merging;image segmentation;local homogeneity features;quantized image;self-constructing fuzzy clustering","","3","","5","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Resources for Nepali Word Sense Disambiguation","N. Shrestha; P. A. V. Hall; S. K. BISTA","Information and Language, Processing Research Lab, Kathmandu University, Dhulikel, Kavre, NEPAL","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","5","Word sense disambiguation (WSD) is a process of identifying proper meaning of words that may have multiple meanings. It is regarded as one of the most challenging problems in the field of natural language processing (NLP). Nepali Language also has words that have multiple meanings, thus giving rise to the problem of WSD in it. In this paper, we investigate the impact of NLP resources like morphology analyzer (MA) and machine readable dictionary (MRD) in ambiguity resolution. Our results show that the accuracy in WSD is better with the availability of NLP resources like morph analyzer, MRD etc. Lesk algorithm has been used to solve WSD problem using a sample Nepali WordNet containing few sets of Nepali nouns and the system is able to disambiguate these nouns only. The system was tested on a small set of data with limited number of nouns. The accuracy reading was between 50% - 70% depending on the sample data provided. When the same data was tested through manual morph analysis, the accuracy was seen to be considerably high (80%).","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906758","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906758","Language;Lesk Algorithm;Nepali WordNet;WSD","Availability;Computer science;Dictionaries;Information retrieval;Morphology;Natural language processing;Natural languages;Software systems;Speech processing;System testing","dictionaries;natural language processing;word processing","Lesk algorithm;Nepali word sense disambiguation;machine readable dictionary;morphology analyzer;natural language processing","","2","","17","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Semantic similarity computation based on HowNet2008","K. Jia; J. Fu; X. Jiang; J. Mao","School of Computer Science and Technology, Beijing Institute of Technology, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","5","Semantic similarity is a fundamental concept and widely researched and used in the fields of natural language processing. By analyzing the definition of the concept in HowNet2008, this paper proposes a new method of semantic similarity calculation. The concepts are classified into three classes: simple concept; complex concept and combined concept. To different concept, we design different method and then transform the similarity calculation of concept into the similarity calculation of the sememe. The similarity of the smeme is computed by the hyponymy of the sememe in the sememe tree. Experiments show the new approach is effective to the similarity calculation and out-performs the conventional computed approaches.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906755","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906755","HowNet2008;natural language processing;semantic similarity computation","Clothing;Computer science;Data mining;Design methodology;Frequency;Information management;Information retrieval;Natural language processing;Ontologies;Statistics","natural language processing","HowNet2008;hyponymy;natural language processing;semantic similarity computation;sememe tree","","2","","10","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Staff Detection with Stable Paths","J. dos Santos Cardoso; A. Capela; A. Rebelo; C. Guedes; J. Pinto da Costa","INESC Porto, Universidade do Porto, Porto","IEEE Transactions on Pattern Analysis and Machine Intelligence","20090417","2009","31","6","1134","1139","The preservation of musical works produced in the past requires their digitalization and transformation into a machine-readable format. The processing of handwritten musical scores by computers remains far from ideal. One of the fundamental stages to carry out this task is the staff line detection. We investigate a general-purpose, knowledge-free method for the automatic detection of music staff lines based on a stable path approach. Lines affected by curvature, discontinuities, and inclination are robustly detected. Experimental results show that the proposed technique consistently outperforms well-established algorithms.","0162-8828;01628828","","10.1109/TPAMI.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4775904","document image processing;image analysis;optical character recognition;optical music recognition","Character recognition;Degradation;Design methodology;Document image processing;Image analysis;Music information retrieval;Optical character recognition software;Ordinary magnetoresistance;Robustness;Writing","document image processing;handwritten character recognition;music","automatic detection;digitalization;handwritten musical scores processing;machine-readable format;music staff lines;stable path approach;staff line detection","0","37","","16","","20090206","June 2009","","IEEE","IEEE Journals & Magazines"
"Divergence-based feature selection for na√Øve Bayes text classification","H. Wang; J. Zhu; K. Y. Su","Natural Language Processing Laboratory, Northeastern University, Shenyang, Liaoning, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","A new divergence-based approach to feature selection for naive Bayes text classification is proposed in this paper. In this approach, the discrimination power of each feature is directly used for ranking various features through a criterion named overall-divergence, which is based on the divergence measures evaluated between various class density function pairs. Compared with other state-of-the-art algorithms (e.g. IG and CHI), the proposed approach shows more discrimination power for classifying confusing classes, and achieves better or comparable performance on evaluation data sets.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906808","Divergence-based;feature selection;overall-divergence;text classification","Density functional theory;Density measurement;Indexing;Information retrieval;Laboratories;Natural language processing;Power measurement;Testing;Text categorization;Text processing","Bayes methods;classification;text analysis","divergence measure;divergence-based feature selection;feature ranking;naive Bayes text classification;overall-divergence","","1","","25","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Effect of pronounciations on OOV queries in spoken term detection","D. Can; E. Cooper; A. Sethy; C. White; B. Ramabhadran; M. Saraclar","Bogazici University, Turkey","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","3957","3960","The spoken term detection (STD) task aims to return relevant segments from a spoken archive that contain the query terms whether or not they are in the system vocabulary. This paper focuses on pronunciation modeling for out-of-vocabulary (OOV) terms which frequently occur in STD queries. The STD system described in this paper indexes word-level and sub-word level lattices or confusion networks produced by an LVCSR system using weighted finite state transducers (WFST).We investigate the inclusion of n-best pronunciation variants for OOV terms (obtained from letter-to-sound rules) into the search and present the results obtained by indexing confusion networks as well as lattices. The following observations are worth mentioning: phone indexes generated from sub-words represent OOVs well and too many variants for the OOV terms degrade performance if pronunciations are not weighted.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960494","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960494","Speech Indexing and Retrieval;Speech Recognition;Spoken Term Detection;Weighted Finite State Transducers","Automatic speech recognition;Decoding;Dictionaries;Indexing;Information retrieval;Lattices;NIST;Speech recognition;Transducers;Vocabulary","query processing;speech recognition","out-of-vocabulary term;speech recognition;spoken term detection queries;weighted finite state transducers","","17","2","17","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Recognizing location names from Chinese texts based on Max-Margin Markov Network","L. Li; Z. Ding; D. Huang","Dalian University of Technology, Liaoning, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","This paper presents a novel method of recognizing location names from Chinese texts based on max-margin Markov <sub>N</sub>etwork (M<sup>3</sup>Net) owing to its ability to exploit very high dimensional feature spaces (using the kernel trick) while at the same time dealing with structured data compared with Support Vector Machine (SVM) and conditional random fields (CRFs). In our model, the character itself, character-based part-of-speech (POS) tag, the information whether a character appears in the location name characteristic word table and context information are extracted as the features. The F-measure is up to 90.57% based on 1-order M<sup>3</sup>Net which is better than that based on either SVM or CRFs in open test on MSRA dataset.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906752","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906752","CRFs;M<sup>3</sup>Net;SVM;named entity recognition","Information retrieval;Libraries;Markov random fields;Natural languages;Optical computing;Performance evaluation;Relational databases;Spatial databases;Testing;Text recognition","Markov processes;character recognition;support vector machines;text analysis","Chinese text;F-measure;character-based part-of-speech tag;conditional random field;context information extraction;location name characteristic word table;location names recognition;max-margin Markov network;structured data;support vector machine","","1","","21","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Significant term extraction by Higher Order SVD","S. Manna; Z. Petres; T. Gedeon","Department of Computer Science, The Australian National University, ACT 0200, Australia","2009 7th International Symposium on Applied Machine Intelligence and Informatics","20090519","2009","","","63","68","In this paper, we present a novel method for term importance, called tensor term indexing (TTI). This extracts significant terms from a document as well as a coherent collection of document set. The basic idea of this approach is to represent the whole document collection in a term-sentence-document tensor and employs higher-order singular value decomposition (HOSVD) for important term extraction. TTI uses the lower rank approximation technique to reduce noise by eliminating anecdotal terms, to mitigate synonymy by merging the dimensions associated with terms that have similar meanings, and to mitigates polysemy, since components of polysemous words that point in the ldquorightrdquo direction are added to the components of words that share a similar meaning. Our evaluation shows that that TTI model can extract significant terms relevant to a topic from a small number of documents which term frequency and inverse document frequency (tfidf) cannot.","","POD:978-1-4244-3801-3","10.1109/SAMI.2009.4956610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4956610","","Automation;Computer science;Data mining;Databases;Frequency;Indexing;Information retrieval;Law;Singular value decomposition;Tensile stress","approximation theory;document handling;indexing;information retrieval;singular value decomposition","higher order singular value decomposition;inverse document frequency;rank approximation technique;significant term extraction;tensor term indexing;term frequency;term sentence document tensor","","1","1","24","","","30-31 Jan. 2009","","IEEE","IEEE Conference Publications"
"Programmable presence virtualization for next-generation context-based applications","A. Acharya; N. Banerjee; D. Chakraborty; K. Dasgupta; A. Misra; S. Sharma; X. Wang; C. P. Wright","IBM Research, T. J. Watson Research Center, Hawthorne, NY, USA","2009 IEEE International Conference on Pervasive Computing and Communications","20090508","2009","","","1","10","Presence, broadly defined as an event publish-notification infrastructure for converged applications, has emerged as a key mechanism for collecting and disseminating context attributes for next-generation services in both enterprise and provider domains. Current presence-based solutions and products lack in the ability to a) support flexible user-defined queries over dynamic presence data and b) derive composite presence from multiple provider domains. Accordingly, current uses of context are limited to individual domains/organizations and do not provide a programmable mechanism for rapid creation of context-aware services. This paper describes a presence virtualization architecture, where a virtualized presence server receives customizable queries from multiple presence clients, retrieves the necessary data from the base presence servers, applies the required virtualization logic and notifies the presence clients. To support both query expressiveness and computational efficiency, virtualization queries are structured to separately identify both the XSLT-based transformation primitives and the presence sources over which the transformation occurs. For improved scalability, the proposed architecture offloads the XSLT-related processing to a high-performance XML processing engine. We describe our current implementation and present performance results that attest to the promise of this virtualization approach.","","CD-ROM:978-1-4244-3304-9","10.1109/PERCOM.2009.4912747","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4912747","Presence;context;federation;scalability;virtualization","Application virtualization;Computational efficiency;Computer architecture;Context-aware services;Information retrieval;Logic;Protocols;Scalability;Subscriptions;XML","query processing;ubiquitous computing","XML processing engine;XSLT-based transformation primitives;converged applications;event publish-notification infrastructure;flexible user-defined queries;next-generation context-based applications;programmable presence virtualization;virtualization logic;virtualization queries;virtualized presence server","","9","3","21","","","9-13 March 2009","","IEEE","IEEE Conference Publications"
"Sahayika: A framework for participatory authoring of knowledge structures for education domain","P. K. Bhowmick; S. Bhowmick; D. Roy; S. Sarkar; A. Basu","Department of Computer Science and Engineering, Indian Institute of Technology Kharagpur, India-721302","2007 International Conference on Information and Communication Technologies and Development","20090515","2007","","","1","11","In countries like India, a great deal of diversity exists in language, culture and socio-economic conditions. In order to deliver computer aided education, efforts have to be put for proper management of concerned domain and learning materials keeping in mind this diversity. Participatory authoring of domain knowledge structure is of immense importance in this regard. In this paper, we describe a knowledge structure which is effective in capturing the structure of the learning materials of school level subjects. Ontologies have gained importance in representing the knowledge of the domain in a formal and machine understandable form in areas like intelligent information processing. Thus it can provide the platform for effective extraction of information and many other applications. We describe different aspects of manual ontology engineering in developing application specific domain ontology. The domain of our interest is the education domain where we are interested in retrieving relevant Web documents for the curriculum related requirements of school students. We identify an effective way of structuring the knowledge about these domains, which allows us to clearly demarcate the roles of topics, concepts, and actual words. We also describe applications in the area of information retrieval and in indexing document repositories in connection with e-learning where our ontology plays an important role. In this paper, we have provided a framework, Sahayika, for building knowledge structures in education domain.","","CD-ROM:978-1-4244-1991-3; POD:978-1-4244-1990-6","10.1109/ICTD.2007.4937406","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4937406","Computer aided education;e-learning;knowledge management;ontology building tool;participatory authoring","Computer science education;Cultural differences;Data mining;Educational institutions;Electronic learning;Indexing;Information processing;Information retrieval;Learning systems;Ontologies","Internet;authoring systems;computer aided instruction;indexing;information retrieval;ontologies (artificial intelligence)","Sahayika framework;Web document retrieval;application specific domain ontology;computer aided education;document repository indexing;e-learning;education domain;knowledge representation;learning material;participatory knowledge structure authoring;school level subject","","0","","20","","","15-16 Dec. 2007","","IEEE","IEEE Conference Publications"
"Assessing - Learning - Improving, an Integrated Approach for Self Assessment and Process Improvement Systems","D. Malzahn","OrgaTech GmbH, Lunen","2009 Fourth International Conference on Systems","20090526","2009","","","126","130","Delivering successful projects and system in a sustaining way becomes more and more the focus of systems and software developing organizations. New approaches in the field of assessment and standardization application led to an increase of assessment and self assessment systems. But these systems are only the first step on a long way. If the assessment system itself is not supported by a learning and improvement approach, the organization will have a system to identify the status but does not have any support for improvement. This gap can be closed by an approach combining assessment tools, wiki-based knowledge platforms and self-learning expert systems (based on ontologies and semantic wikis). Result is a system environment which provides status assessment, learning and continuous improvement services based on different standards and approaches. This approach is already being implemented for the field of project management. In this article we explained the basics and show the application of a combined system.","","POD:978-1-4244-3469-5","10.1109/ICONS.2009.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4976330","Assessment;CMMI;Mappings;Ontology;SPICE;Semantic WIKI;Semantics;WIKI","Continuous improvement;ISO standards;Information retrieval;Ontologies;Project management;Quality assurance;SPICE;Software systems;Standards development;Standards organizations","continuous improvement;ontologies (artificial intelligence);project management;semantic Web;software development management;software standards","combined system;continuous improvement services;ontologies;process improvement system;project management;selfassessment system;selflearning expert systems;semantic wikis;software developing organizations;standardization application;wiki-based knowledge platforms","","3","","4","","","1-6 March 2009","","IEEE","IEEE Conference Publications"
"Latent semantic retrieval of personal photos with sparse user annotation by fused image/speech/text features","Yi-sheng Fu; Chia-yu Wan; Lin-shan Lee","Graduate Institute of Computer Science and Information Engineering, National Taiwan University, Taiwan","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","1969","1972","While users prefer high-level semantic photo descriptions (e.g., who, what, when, where), we wish to minimize the need to annotate photos using such descriptions by the user. We propose a latent semantic personal photo retrieval approach using fused image/speech/text features. We use low-level image features to derive relationships among sparsely annotated photos, and probabilistic latent semantic analysis (PLSA) models based on fused image/speech/text features to analyze photo ldquotopicsrdquo. We then retrieve the photos using text or speech queries of simple high-level semantic words only. In preliminary experiments, while only 10% of the photos were manually annotated, the photos could be well retrieved with very encouraging results.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959997","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959997","fused features;image retrieval;latent topics;semantic analysis","Computer science;Content based retrieval;Digital cameras;Image analysis;Image retrieval;Indexing;Information retrieval;Labeling;Large scale integration;Speech analysis","content-based retrieval;image retrieval;text analysis","fused image/speech/text features;image features;latent semantic personal photo retrieval;latent semantic retrieval;personal photos;probabilistic latent semantic analysis models;semantic photo descriptions;sparse user annotation;sparsely annotated photos;speech query;text query","","1","","12","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Automatic named identification of speakers using diarization and ASR systems","V. Jousse; S. Petit-Renaud; S. Meignier; Y. Esteve; C. Jacquin","LIUM (Le Mans), France - LINA (Nantes), France","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","4557","4560","In this paper, we consider the extraction of speaker identity from audio records of broadcast news without a priori acoustic information about speakers. Using an automatic speech recognition system and an automatic speaker diarization system, we present improvements for a method which allows to extract speaker identities from automatic transcripts and to assign them to speech segments. Experiments are carried out on French broadcast news records from the ESTER 1 evaluation campaign. Experimental results using outputs of automatic speech recognition and automatic diarization are presented.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960644","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960644","Automatic transcription;Named identification;Speaker diarization","Automatic speech recognition;Broadcasting;Contracts;Costs;Data mining;Indexing;Information retrieval;Loudspeakers;Multimedia communication;Training data","audio signal processing;information resources;natural language processing;speaker recognition","ASR systems;French broadcast news;audio records;automatic named identification;automatic speaker diarization system;automatic speech recognition system;broadcast news;speaker identity","","7","","10","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Relevance weighting of multi-term queries for Vector Space Model","L. S. Wang","International School of Minnesota, Eden Prairie, MN 55344 USA","2009 IEEE Symposium on Computational Intelligence and Data Mining","20090515","2009","","","396","402","The vector space model is one of the most common information retrieval (IR) methods for text document search. The cosine of the angle or the Euclidean distance between the query vector and each document vector is commonly used to measure similarity for query matching. Even though the vector space model starts with a term-by-document matrix, it inevitably loses the information of relations between query terms in the document in the first place. This paper presents a modified vector space model for measuring similarity between the query and the document when responding to a multi-term query. More weight is assigned to the keywords based on the adjacency between the terms in the documents. Thus, when a document contains the adjacency terms, its vector will typically move closer to the query vector to show stronger relevancy between query and the document.","","POD:978-1-4244-2765-9","10.1109/CIDM.2009.4938677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4938677","","Databases;Euclidean distance;Extraterrestrial measurements;Impedance;Indexing;Information retrieval;Information systems;Logic;Mathematical model;Web sites","information retrieval;matrix algebra;text analysis;vectors","Euclidean distance;document vector;information retrieval;multiterm queries;query matching;query vector;term-by-document matrix;text document search;vector space model","","1","","17","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Relevance tuning in content-based retrieval of structurally-modeled images using Particle Swarm Optimization","N. Oka; K. Kameyama","Graduate School of Systems and Information Engineering, 1-1-1, Tennodai, Tsukuba, Ibaraki 305-8573, Japan","2009 IEEE Symposium on Computational Intelligence for Multimedia Signal and Vision Processing","20090515","2009","","","75","82","Similarity of images in content-based image retrieval (CBIR) is a subjective measure varying by the user, and requires tuning according to the user's preference. Another issue in CBIR is the need of partial image matching. Structural modeling of the images can be promising in finding a small query image within a large database image. In this work, a graph-based image modeling which assigns image regions to labeled nodes and their adjacency to weighted edges is used. Also, the image similarity measure is tuned according to the user's evaluation, by way of parameter selection using Particle Swarm Optimization (PSO)[1][2]. In the experiments, a small-scale CBIR system based on graph modeling of images was developed. Using the system, it was confirmed that images including the query image of different size and rotation angle could be successfully retrieved. Also, the user's preference in weighting the different aspects of similarity in the feedback information was found to be successfully incorporated in the retrieval after parameter optimization using PSO.","","POD:978-1-4244-2771-0","10.1109/CIMSVP.2009.4925651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4925651","","Content based retrieval;Digital images;Feedback;Image databases;Image matching;Image retrieval;Information retrieval;Particle measurements;Particle swarm optimization;Search engines","content-based retrieval;image retrieval;particle swarm optimisation;very large databases;visual databases","content-based retrieval;graph-based image modeling;image retrieval;large database image;parameter selection;partial image matching;particle swarm optimization;query image;relevance tuning;structurally-modeled images","","5","","14","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Discovering human routines from cell phone data with topic models","K. Farrahi; D. Gatica-Perez","IDIAP Research Institute, Martigny, Switzerland","2008 12th IEEE International Symposium on Wearable Computers","20090508","2008","","","29","32","We present a framework to automatically discover people's routines from information extracted by cell phones. The framework is built from a probabilistic topic model learned on novel bag type representations of activity-related cues (location, proximity and their temporal variations over a day) of peoples' daily routines. Using real-life data from the Reality Mining dataset, covering 68 000+ hours of human activities, we can successfully discover location-driven (from cell tower connections) and proximity-driven (from Bluetooth information) routines in an unsupervised manner. The resulting topics meaningfully characterize some of the underlying co-occurrence structure of the activities in the dataset, including ldquogoing to work early/laterdquo, ldquobeing home all dayrdquo, ldquoworking constantlyrdquo, ldquoworking sporadicallyrdquo and ldquomeeting at lunch timerdquo.","1550-4816;15504816","POD:978-1-4244-2637-9","10.1109/ISWC.2008.4911580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4911580","","Bluetooth;Cellular phones;Data mining;Genetics;Histograms;Humans;Image retrieval;Information retrieval;Poles and towers;Training data","behavioural sciences computing;data mining;mobile computing;probability","activity-related cues;bag type representations;cell phone data;human routines;information extraction;location-driven routines;probabilistic topic model;proximity-driven routines;reality mining dataset","","9","","6","","","Sept. 28 2008-Oct. 1 2008","","IEEE","IEEE Conference Publications"
"Large scale natural image classification by sparsity exploration","C. Wang; Shuicheng Yan; H. J. Zhang","MOE-MS Key Lab of MCC, University of Science and Technology of China, China","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","3709","3712","We consider in this paper the problem of large scale natural image classification. As the explosion and popularity of images in the Internet, there are increasing attentions to utilize millions of or even billions of these images for helping image related research. Beyond the opportunities brought by unlimited data, a great challenge is how to design more effective classification methods under these large scale scenarios. Most of existing attempts are based on k-nearest-neighbor method. However, in spite of the optimistic performance in some tasks, this strategy still suffers from that, one single fixed global parameter k is not robust for different object classes from different semantic levels. In this paper, we propose an alternative method, called lscr<sup>1</sup>-nearest-neighbor, based on a sparse representation computed by lscr<sup>1</sup>-minimization. We first treat a testing sample as a sparse linear combination of all training samples, and then consider the related samples as the nearest neighbors of the testing sample. Finally, we classify the testing sample based on the majority of these neighbors' classes. We conduct extensive experiments on a 1.6 million natural image database on different semantic levels defined based on WordNet, which demonstrate that the proposed lscr<sup>1</sup>-nearest-neighbor algorithm outperforms k-nearest-neighbor in two aspects: 1) the robustness of parameter selection for different semantic levels, and 2) the discriminative capability for large scale image classification task.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960432","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960432","‚Ñì<sup>1</sup>-nearest-neighbor;Image classification;WordNet;k-nearest-neighbor;sparsity","Computer vision;Image classification;Image recognition;Information retrieval;Large-scale systems;Layout;Robustness;Signal processing;Signal processing algorithms;Testing","image classification;visual databases","Internet;k-nearest-neighbor method;large scale natural image classification;natural image database","","7","","16","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"A novel pattern identification scheme using distributed video coding concepts","M. Paul; M. Murshed","Gippsland School of Information Technology, Monash University, Churchill, Vic-3842, Australia","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","729","732","Pattern-based video coding focusing on moving region in a macroblock has already established its superiority over recent H.264 video coding standard at very low bit rate. Obviously, a large number of pattern templates approximate the moving regions better however, after a certain limit no coding gain is observed due to the increase number of pattern identification bits. Recently, distributed video coding schemes used syndrome coding to predict the original information in decoder using side information. In this paper a novel pattern identification scheme is proposed which predicts the pattern from the syndrome codes and side information in decoder so that actual pattern identification number is not needed in the bitstream. The experimental results confirm that this new scheme successfully improves the rate-distortion performance compared to the existing pattern-based video coding as well as H.264 standard. This new scheme will also open another window of syndrome coding application.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959687","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959687","H.264;Video coding;distributed video coding;low bit rate;pattern recognition;side information","Bit rate;Decoding;Information retrieval;Information technology;Pattern recognition;Rate-distortion;Redundancy;Shape;Video coding;Videoconference","pattern recognition;video coding","bitstream;distributed video coding;pattern identification;pattern recognition;side information;syndrome codes;syndrome coding","","0","","13","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"A pillar algorithm for K-means optimization by distance maximization for initial centroid designation","A. R. Barakbah; Y. Kiyoki","Graduate School of Media and Governance, Keio University, Japan","2009 IEEE Symposium on Computational Intelligence and Data Mining","20090515","2009","","","61","68","Clustering performance of the K-means greatly relies upon the correctness of the initial centroids. Usually the initial centroids for the K-means clustering are determined randomly so that the determined centroids may reach the nearest local minima, not the global optimum. This paper proposes a new approach to optimizing the designation of initial centroids for K-means clustering. This approach is inspired by the thought process of determining a set of pillars' locations in order to make a stable house or building. We consider the pillars' placement which should be located as far as possible from each other to withstand against the pressure distribution of a roof, as identical to the number of centroids amongst the data distribution. Therefore, our proposed approach in this paper designates positions of initial centroids by using the farthest accumulated distance between them. First, the accumulated distance metric between all data points and their grand mean is created. The first initial centroid which has maximum accumulated distance metric is selected from the data points. The next initial centroids are designated by modifying the accumulated distance metric between each data point and all previous initial centroids, and then, a data point which has the maximum distance is selected as a new initial centroid. This iterative process is needed so that all the initial centroids are designated. This approach also has a mechanism to avoid outlier data being chosen as the initial centroids. The experimental results show effectiveness of the proposed algorithm for improving the clustering results of K-means clustering.","","POD:978-1-4244-2765-9","10.1109/CIDM.2009.4938630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4938630","","Algorithm design and analysis;Biology;Clustering algorithms;Data mining;Design optimization;Image classification;Information retrieval;Iterative algorithms;Partitioning algorithms;Pattern recognition","iterative methods;optimisation;pattern clustering","K-means optimization;clustering method;distance maximization;distance metric;initial centroid designation;iterative process;pillar algorithm","","10","","18","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"TE4AV: Textual Entailment for Answer Validation","O. Ferrandez; R. Munoz; M. Palomar","University of Alicante, Spain","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","8","The textual entailment (TE) task consists of discovering unidirectional semantic inferences between the meanings of two text snippets. Taking advantage of this, in this paper we propose using the TE system as an answer validation (AV) engine to improve the performance of question answering (QA) systems and help humans in the assessment of QA systems' outputs. To achieve these aims and in order to assess the overall performance of our TE system and its application in QA tasks, two evaluation environments are presented: pure entailment and QA-response evaluation. The former uses the corpus and methodology of the PASCAL recognizing textual entailment challenges, whereas for the latter we use the data provided by the answer validation exercise competition within the cross-language evaluation forum. The system, the evaluations environments and the experiments developed are discussed throughout the paper.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906746","Answer Validation;Question Answering;Recognizing Textual Entailment","Computational linguistics;Concrete;Data mining;Engines;Humans;Information filtering;Information filters;Information retrieval;Natural language processing;Tellurium","information retrieval;natural language processing;text analysis","QA-response evaluation;TE system;TE4AV;answer validation;cross-language evaluation;natural language processing;pure entailment;question answering system;text snippet;textual entailment;unidirectional semantic inferences","","0","","40","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Exploiting syntactic and semantic information in coarse chinese question classification","Xin Kang; X. Wang; Fuji Ren","Beijing University of Posts and Telecommunications, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","Recent years have seen great process in studying English question classification. In our research, we learn Chinese question classification by exploiting the result of lexical, syntactic and semantic parsing on question sentences. Support vector machines are adopted to train a classifier on 6 coarse categories using single and combination of different parsing results as features. We find that even the surface information such as words and parts of speech could lead to a satisfying result, while augmenting the classifier with syntactic and semantic features could give even higher precision. However, the lack of words and incomplete syntactic structures among most questions cause combination of features even sparser than single features in the feature space, with much side effect brought to the performance of Chinese question classification.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906803","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906803","","Classification tree analysis;Data mining;Filters;Information retrieval;Learning systems;Natural languages;Search engines;Speech;Support vector machine classification;Support vector machines","classification;grammars;natural language processing;support vector machines;text analysis","Chinese question classification;lexical parsing;parts of speech;question sentence;semantic information;semantic parsing;support vector machine;syntactic information;syntactic parsing","","3","","16","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"The data-centricity of Web 2.0 workloads and its impact on server performance","Moriyoshi Ohara; P. Nagpurkar; Yohei Ueda; Kazuaki Ishizaki","IBM Research, Japan","2009 IEEE International Symposium on Performance Analysis of Systems and Software","20090512","2009","","","133","142","Advances in network performance and browser technologies, coupled with the ubiquity of internet access and proliferation of users, have lead to the emergence of a new class of Web applications, called Web 2.0. Web 2.0 technologies enable easy collaboration and sharing by allowing users to contribute, modify, and aggregate content using applications like Wikis, Blogs, Social Networking communities, and Mashups. Web 2.0 applications also make heavy use of Ajax, which allows asynchronous communication between client and server, to provide a richer user experience. In this paper, we analyze the effect of these new features on the infrastructure that hosts these workloads. In particular, we focus on the data-centricity, inherent in many Web 2.0 applications, and study its impact on the persistence layer in an application server context. Our experimental results reveal some important performance characteristics; we show that frequent Ajax requests, and other requests arising from the participatory nature of Web 2.0, often retrieve and update persistent data. This can lead to frequent database accesses, lock contention, and reduced performance. We also show that problems in the persistence layer, arising from the data-intensive nature of Web 2.0 applications, can lead to poor scalability that can inhibit us from exploiting current and future multicore architectures.","","POD:978-1-4244-4184-6","10.1109/ISPASS.2009.4919645","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4919645","","Aggregates;Asynchronous communication;Blogs;Collaborative work;IP networks;Information retrieval;Mashups;Network servers;Social network services;Web server","Internet;Java;XML;client-server systems;groupware","Ajax;Asynchronous Java script;Internet;Web 2.0 technology;XML;asynchronous communication;client-server system;data-centricity","","3","","24","","","26-28 April 2009","","IEEE","IEEE Conference Publications"
"Dimensionality reduction for text using LLE","C. He; Z. Dong; R. Li; Y. Zhong","School of Information Engineering, Beijing University of Posts and Telecommunications, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","Dimensionality reduction is a necessary preprocessing step in many fields of information processing such as information retrieval, pattern recognition and data compression. Its goal is to discover the representative or the discriminative information residing in raw data. Locally linear embedding (LLE), one of effective manifold learning algorithms, addresses this problem by computing low-dimensional, neighborhood preserving embeddings of high-dimensional data. The embedding is derived from the symmetries for locally linear reconstructions. And the computation of this embedding is related to an eigen-problem in the implement. Since LLE was proposed, it has been being applied to deal with image data only because it originated from facial recognition. However, the problem of curse of dimensionality is very prevalent. Therefore, we here try to apply this algorithm for text processing. In this paper, we introduce the LLE briefly and analyze its advantage and latent disadvantages, and the relationship between LSI and LLE in the graph embedding framework is then discussed from a theoretic view. Finally, the experimental results are show with the datasets of Reuters21578 and TDT2.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906771","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906771","","Covariance matrix;Data compression;Embedded computing;Feature extraction;Image reconstruction;Information retrieval;Large scale integration;Pattern recognition;Principal component analysis;Text processing","text analysis","data compression;dimensionality reduction;discriminative information;eigen-problem;facial recognition;graph embedding framework;image data;information processing;information retrieval;locally linear embedding;locally linear reconstruction;manifold learning algorithm;pattern recognition;raw data;text processing","","0","","23","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Comparison of large object storage methods in Oracle database version 11g","P. Mazur; J. Murlewski; M. Kaminski; B. Sakowicz; D. Makowski","Department of Microelectronics and Computer Science, Technical University of Lodz, Poland","2009 10th International Conference - The Experience of Designing and Application of CAD Systems in Microelectronics","20090424","2009","","","233","236","The article presents comparison between different large object (LOB) storage methods currently supported by the Oracle database including Secure Files present in Oracle 11. Article focuses on performance of reading and writing large objects to the database.","","POD:978-966-2191-05-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839815","BFILE Secure File;LOB;Oracle;Performance","Buffer storage;Containers;Database systems;Drives;Indexing;Information retrieval;Secure storage;Spatial databases;Testing;Writing","object-oriented programming;security of data;visual databases","Oracle database;file security;large object storage methods","","1","","5","","","24-28 Feb. 2009","","IEEE","IEEE Conference Publications"
"Improving the Effectiveness of XML Retrieval with User Navigation Models","M. S. Ali; M. P. Consens; B. Helou","Dept. of Mech. & Ind. Eng., Univ. of Toronto Bahen Center for Inf. Technol., Toronto, ON","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1584","1587","Structured documents (predominantly encoded in XML) utilize markup dialects for several purposes, such as conveying logical structure, or providing rendering instructions. XML structure can also help users to navigate within documents to satisfy their information needs. However, including the user's structural preferences in the ranking of retrieved elements remains a key challenge in XML retrieval. In this paper, we propose an approach for including structural preferences in the ranking of XML elements by improving the structural relevance (SR) of results. SR is an evaluation measure which relies on graphical navigation models to capture the structural preferences of users. We propose several algorithms to post-process search engine output to improve the SR of the output. Experimental results (using data, assessments, and search engines from INEX 2007 and 2008) demonstrate the effect of different combinations of post-processing algorithms and navigation models on the effectiveness of systems.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812577","","Content based retrieval;Data engineering;Industrial engineering;Information retrieval;Information technology;Navigation;Search engines;Strontium;Wikipedia;XML","XML;information retrieval","XML retrieval;graphical user navigation models;structural relevance;structured documents","","0","","9","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Blind estimation of signal in periodic long-code DSSS communications","S. Daneshmand; H. Aghaeinia; M. Tohidian; A. Jafarnia Jahromi","Electrical Engineering Department Amirkabir University of Technology, Tehran, Iran","2009 IEEE Sarnoff Symposium","20090424","2009","","","1","6","This paper discusses blind estimation of periodic long-code (PLC) direct sequence spread spectrum (DSSS) signal. We model a PLC DSSS signal as equivalent to a multiuser short-code DSSS system. This enables us to exploit second-order statistics (SOS) to estimate users' spreading codes up to an inherent ambiguity matrix. Using the structure of the spreading codes of these virtual users and without further restricting assumptions, we will show that the ambiguity matrix can be estimated which would lead us to the extraction of spreading codes. Exploiting similar ideas, we will extend the proposed algorithm to blind estimation of the PLC DSSS signal in multipath environment. Finally, simulations are presented to demonstrate the superior performance of the proposed algorithm.","","POD:978-1-4244-3381-0","10.1109/SARNOF.2009.4850290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4850290","Blind estimation;direct sequence spread spectrum;periodic long code","AWGN channels;Bandwidth;Information retrieval;MIMO;Military communication;Paper technology;Programmable control;Spread spectrum communication;Statistics;Transmitters","codes;multipath channels;spread spectrum communication;statistical analysis","ambiguity matrix;blind estimation;direct sequence spread spectrum;multiuser short-code DSSS system;periodic long-code DSSS communications;second-order statistics","","0","","11","","","March 30 2009-April 1 2009","","IEEE","IEEE Conference Publications"
"Extracting information from tag collisions","R. S. Khasgiwale; R. U. Adyanthaya; D. W. Engels","Department of Electrical Engineering, University of Texas at Arlington, USA","2009 IEEE International Conference on RFID","20090508","2009","","","131","138","In this paper, we develop techniques to extract information from communication collisions involving passive UHF RFID tags. Our goal is to extract information that can enhance the performance of existing anti-collision protocols. Present RFID anti-collision protocols detect a collision at the medium access control (MAC) layer; however, the physical layer signal received during collisions is discarded. This signal contains valuable information, such as the number of tags communicating, that can be used in the anti-collision algorithms. Collecting and utilizing this currently discarded information would provide performance improvements to existing protocols and provide insights that can be used to guide the development of future protocols.We analyzed communication collisions from ISO 18000-6C compliant tags in their response to a Query command. Our techniques enabled us to reliably identify the exact number of tags in the collided slot for up to 4 tags communicating in that slot and the existence of at least 5 tags communicating in a slot with more than 4 tags communicating in that slot.","2374-0221;23740221","POD:978-1-4244-3337-7","10.1109/RFID.2009.4911198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4911198","","Access protocols;Data mining;ISO standards;Information retrieval;Media Access Protocol;Passive RFID tags;Physical layer;Radio communication;Radio frequency;Radiofrequency identification","access protocols;radiofrequency identification","ISO 18000-6C compliant tags;anti-collision protocols;information extraction;medium access control protocols;passive UHF RFID tags;passive ultra high frequency radio-frequency identification technology;query command;tag collisions","","28","2","23","","","27-28 April 2009","","IEEE","IEEE Conference Publications"
"Effective dimensionality reduction in multimedia applications","S. Jeong; S. W. Kim; W. Y. Kim; B. U. Choi","Department of Electronics and Computer Engineering, Hanyang University, Seoul, South Korea","2009 IEEE Symposium on Computational Intelligence for Image Processing","20090515","2009","","","82","87","In multimedia information retrieval, multimedia data such as images and videos are represented as vectors in high-dimensional space. To search these vectors efficiently, a variety of indexing methods have been proposed. However, the performance of these indexing methods degrades dramatically with increasing dimensionality, which is known as the dimensionality curse. To resolve the dimensionality curse, dimensionality reduction methods have been proposed. They map feature vectors in high-dimensional space into vectors in low-dimensional space before the data are indexed. This paper proposes an improvement for the previously proposed dimensionality reduction. The previous method uses the norm and the approximated angle for every subvector. However, more storage space and a number of cosine computations are required because of multiple angle components. In this paper, we propose an alternative method employing a single angle component instead of respective angles for all the subvectors. Because only one angle for every subvector is considered, though the loss of information regarding the original data vector increases, which degrades the performance slightly, we can successfully reduce storage space as well as a number of cosine computations. Finally, we verify the superiority of the proposed approach via extensive experiments with synthetic and real-life data sets.","","POD:978-1-4244-2760-4","10.1109/CIIP.2009.4937885","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4937885","","Degradation;Equations;Euclidean distance;Filtering;Image retrieval;Indexing;Information retrieval;Multimedia databases;Query processing;Videos","database indexing;information retrieval;multimedia databases","approximated angle;cosine computation;dimensionality reduction;indexing method;multimedia database;multimedia information retrieval;single angle component","","0","","14","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Ensembles of landmark multidimensional scalings","Seunghak Lee; Seungjin Choi","Department of Computer Science, University of Toronto, Canada","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","1649","1652","Landmark multidimensional scaling (LMDS) uses a subset of data (landmark points) to solve classical MDS, where the scalability is increased but the approximation is noise-sensitive. In this paper we present an ensemble of LMDSs, referred to as landmark MDS ensemble (LMDSE), where we use a portion of the input in a piecewise manner to solve classical MDS, combining individual LMDS solutions which operate on different partitions of the input. Ground control points (GCPs) that are shared by partitions considered in the ensemble, allow us to align individual LMDS solutions in a common coordinate system through affine transformations. LMDSE solution is determined by averaging aligned LMDS solutions. We show that LMDSE is less noise-sensitive while maintaining the scalability as well as the speed of LMDS. Experiments on synthetic data (noisy grid) and real-world data (similar image retrieval) confirm the high performance of the proposed LMDSE.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959917","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959917","Dimensionality reduction;embedding;multidimensional scaling (MDS);unsupervised learning","Computer science;Control systems;Costs;Extraterrestrial measurements;Geometry;Image retrieval;Information retrieval;Multidimensional systems;Scalability;Unsupervised learning","affine transforms;data handling;grid computing;image retrieval","affine transformations;ground control points;landmark MDS ensemble;landmark multidimensional scaling;landmark points;noisy grid;similar image retrieval","","0","","8","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"A bi-clustering agent-based approach for map segmentation","A. Bouchachia; M. Prossegger","Department of Informatics, University of Klagenfurt, Austria","2009 IEEE Symposium on Intelligent Agents","20090515","2009","","","99","105","The present paper introduces an agent-based approach for clustering geographical data. In this approach, a multi-agent architecture is proposed. It consists of three competence levels: specialized gatherers (G-Agents), breakers (B-Agents), mappers (M-Agents). Each of these agents have particular role in the process of segmentation. Using biclustering, the approach combines the different views of the data (according to the land-use classes) to obtain a useful segmentation which serves as an instrument of decision making. Illustrative simulation of the multi-agent architecture on realworld data is reported.","","POD:978-1-4244-2767-3","10.1109/IA.2009.4927506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4927506","","Coherence;Collaboration;Computational modeling;Computer architecture;Constraint optimization;Decision making;Humans;Informatics;Information retrieval;Instruments","geographic information systems;image segmentation;multi-agent systems;pattern clustering","bi-clustering agent-based approach;decision making;map segmentation;multiagent architecture","","1","","22","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Dynamic texture models of music","L. Barrington; A. B. Chan; G. Lanckriet","Electrical and Computer Engineering Department, University of California, San Diego, USA","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","1589","1592","In this paper, we consider representing a musical signal as a dynamic texture, a model for both the timbral and rhythmical qualities of sound. We apply the new representation to the task of automatic song segmentation. In particular, we cluster sequences of audio feature-vectors, extracted from the song, using a dynamic texture mixture model (DTM). We show that the DTM model can both detect transition boundaries and accurately cluster coherent segments. The similarities between the dynamic textures which define these segments are based on both timbral and rhythmic qualities of the music, indicating that the DTM model simultaneously captures two of the important aspects required for automatic music analysis.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959902","Music modeling;automatic segmentation;dynamic texture model;music similarity","Cepstral analysis;Clustering algorithms;Computer vision;Data mining;Feature extraction;Hidden Markov models;Multiple signal classification;Music information retrieval;Timbre;Video sequences","audio signal processing;music","audio feature-vectors;automatic music analysis;automatic song segmentation;dynamic texture;dynamic texture mixture model;musical signal;rhythmical quality;timbral quality","","2","","23","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"To extract Ontology attribute value automatically based on WWW","Q. Zhao; Z. Sui","Institute of Computational Linguistics, Peking University, Beijing, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","Attribute value is among the most important information to describe ontology. However, few researches have been done about attribute values extraction so far. This paper proposes a method of extracting ontology attribute values automatically based on WWW. Firstly, a method based on a seeds set is described about interaction between relevant sentences selection including attribute values and attribute values extraction, so that we can extract and expand the target attribute value set by the redundancy of WWW. Secondly, we construct the seeds set with an automatic method instead of by hand. Finally, we build hierarchical clusters of the candidate attribute values to gain more accurate and complete results. Experiments have been done to compute the precision and recall. Also automatically enriched ontology information is used in Webpage content extraction to show its usage.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906749","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906749","Attribute value extraction;Ontology;Search Engine;WWW;interactive method","Information retrieval;Libraries;Natural languages;Ontologies;Optical computing;Performance evaluation;Relational databases;Spatial databases;Testing;World Wide Web","Internet;ontologies (artificial intelligence)","WWW;Webpage content extraction;automatically enriched ontology information;ontology attribute value extraction;relevant sentences selection;seeds set;target attribute value set","","2","","11","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Searching for content in mobile DTNs","M. Pitkanen; T. Karkkainen; J. Greifenberg; J. Ott","Helsinki Institute of Physics, Technology Programme, Finland","2009 IEEE International Conference on Pervasive Computing and Communications","20090508","2009","","","1","10","Delay-tolerant networking (DTN) provides a platform for applications in environments where end-to-end paths may be highly unreliable or do not exist at all. In many applications such as distributed wikis or photo sharing, users need to be able to find content even when they do not know an unambiguous identifier. In order do bring these applications to the domain of DTNs, a search scheme is required that works despite the unreliable network conditions. In this paper, we introduce a search scheme that makes no assumptions about the underlying routing protocols and the format of search requests. We evaluate different algorithms for forwarding and terminating search queries, using simulations with different classes of DTN routing protocols for different mobility scenarios.","","CD-ROM:978-1-4244-3304-9","10.1109/PERCOM.2009.4912771","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4912771","","Communications technology;Content based retrieval;Disruption tolerant networking;Information retrieval;Mobile communication;Network servers;Peer to peer computing;Physics;Routing protocols;Search engines","Web sites;computer networks;distributed processing;mobile communication;query processing;routing protocols","DTN routing protocols;delay-tolerant networking;distributed wikis;mobile DTN;photo sharing;search query;search requests;unambiguous identifier","","10","","26","","","9-13 March 2009","","IEEE","IEEE Conference Publications"
"Multidimensional Unitary Tensor-ESPRIT for non-circular sources","F. Roemer; M. Haardt","Ilmenau University of Technology, Communications Research Laboratory, P.O. Box 100565, D-98684, Germany","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","3577","3580","Recently, many authors have shown that high-resolution parameter estimation schemes can be significantly improved if the sources are non-circular. For example, enhanced versions of root MUSIC and standard ESPRIT for non-circular sources as well as the entirely real-valued NC unitary ESPRIT algorithm have been proposed. We can achieve further enhancements in the R-dimensional (R-D) case by using tensor algebra to express and manipulate multidimensional signals in their natural R-D structure. This has led to tensor-based parameter estimation algorithms with enhanced estimation accuracy such as R-D unitary tensor- ESPRIT. In this paper we demonstrate how to achieve both benefits at the same time. This is not straightforward since the usual method to exploit non-circular sources destroys the tensor structure and therefore a new approach had to be found. This approach allows us to derive the NC R-D unitary tensor-ESPRIT algorithm which exploits the non-circularity of the sources and the R-D structure of the measured signals jointly. Numerical computer simulations demonstrate the benefit in terms of a significantly improved accuracy compared to state of the art algorithms.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960399","Array signal processing;Direction of arrival estimation;Multidimensional signal processing;Parameter estimation","Array signal processing;Computer simulation;Multidimensional signal processing;Multidimensional systems;Multiple signal classification;Music information retrieval;Parameter estimation;Radar signal processing;Signal processing algorithms;Tensile stress","array signal processing;direction-of-arrival estimation;multidimensional signal processing;signal classification;signal resolution;tensors","ESPRIT algorithm;direction-of-arrival estimation;high-resolution parameter estimation;multidimensional unitary tensor algebra;noncircular source;root MUSIC","","2","","13","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Answer extraction based on query expansion in Chinese question answering system","K. Jia; Y. Sun; Z. Li","School of Information Management, Shandong Economic University, Jinan, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","4","When using natural language question to retrieval document, query expansion are the key factors that affect its retrieval performance. By analyzing the traditional query expansion method, this paper puts forward a query expansion method based on set theory for answering document retrieval. In order to verify the validity of the method, a similarity calculation method for question and candidate answer sentences is proposed to extract the answer. The major query expansion terms and the minor query expansion terms are taken into consideration with different weight in the similarity calculation. The experiment results show that the performance makes substantial improvement.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906756","Chinese question answering system;answer extracting;query expansion;similarity calculation","Computer science;Data mining;Feedback;Information management;Information retrieval;Natural languages;Set theory;Statistical analysis;Text analysis;Thesauri","natural language processing;query processing;set theory","Chinese question answering system;answer extraction;document retrieval;natural language question;query expansion;set theory","","0","","12","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Answering definitional question by dependency-based knowledge","J. Cao; X. Huang","Dept of Computer Science, Fudan University, Shanghai, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","6","Most current systems apply flat pattern and flat centroid words, which are extracted only by relative position to question target, to identify definition sentences. In contrast to the flat knowledge, we propose dependency-based knowledge, including dependency pattern and dependency centroid word, which are extracted by dependency relation to question target. Specifically, we use the improved ultraconservative online algorithm, binary margin infused relaxed algorithm (MIRA), to estimate the weight of each dependency knowledge for the task of candidate sentences ranking. We demonstrate that the dependency-based knowledge is more effective than the flat knowledge. Meanwhile, we also show that our definitional question answering system outperforms the state-of-the-art systems on recent TREC data.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906809","MIRA;definitional question answering;dependency relation","Computer science;Data mining;Feeds;Filtering;Information retrieval;Pattern matching","query processing","TREC data;binary margin infused relaxed algorithm;candidate sentence ranking;definitional question answering system;dependency centroid word;dependency pattern;dependency relation;dependency-based knowledge;flat centroid words;flat pattern;ultraconservative online algorithm","","0","","25","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Adams re-trace","A. De Lucia; R. Oliveto; G. Tortora","University of Salerno, Fisciano (SA, Italy","2008 ACM/IEEE 30th International Conference on Software Engineering","20090414","2008","","","839","842","In this demonstration we present the traceability recovery tool developed in ADAMS, a fine-grained artefact management system. The tool is based on an information retrieval technique, namely latent semantic indexing, and aims at supporting the software engineer in the identification of traceability links between artefacts of different types. The tool has also been integrated in the Eclipse-based client of ADAMS.","0270-5257;02705257","Electronic:978-1-60558-079-1; POD:978-1-4244-4486-1","10.1145/1368088.1368216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814205","ir-based traceability recovery;latent semantic indexing","Documentation;Engineering management;Indexing;Informatics;Information retrieval;Mathematics;Software development management;Software engineering;Software maintenance;Software tools","information retrieval;program diagnostics;programming environments;software maintenance;software tools;system recovery","ADAMS re-trace;Eclipse-based client;fine-grained software artefact management system;information retrieval technique;latent semantic indexing;software engineer;software maintenance;traceability link recovery tool","","9","","16","","","10-18 May 2008","","IEEE","IEEE Conference Publications"
"Distributed task-based execution engine for support of text-mining processes","P. Butka; P. Bednar; F. Babic; K. Furdik; J. Paralic","Centre for Information Technologies, Faculty of Electrical Engineering and Informatics, Technical University of Kosice, Bo&#191;eny N&#191;mcovej 3, Slovakia","2009 7th International Symposium on Applied Machine Intelligence and Informatics","20090519","2009","","","29","34","This paper describes design and implementation aspects for extension of our original software system developed in Java for support of information retrieval and text mining with specialized execution engine for different type of tasks. Some of our experiences and specific requirements of the real applications lead us to idea give the system possibility to run the tasks in distributive way. The result of the idea is task-based execution engine, which represents middleware-like transparent layer (mostly for programmers who want to re-use functionality of our package) for running of different tasks in multi-thread environment. The original system is being developed as open source with the intention to provide an easy extensible, modular framework for pre-processing, indexing and further exploration of large text collections. This specialized execution engine has been implemented within APVV project called PoZnaT (Support for knowledge creation processes) in order to extend proposed text-mining platform for educational and experimental purposes. Conceptual architecture of the system is provided as well as details regarding our extension of library like usage of content repository paradigm, representation and encapsulation of tasks, implementation of the engine itself and its role within PoZnaT platform.","","POD:978-1-4244-3801-3","10.1109/SAMI.2009.4956633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4956633","","Application software;Engines;Indexing;Information retrieval;Java;Libraries;Packaging;Programming profession;Software systems;Text mining","Java;data mining;information retrieval;middleware;multi-threading;text analysis","Java;PoZnaT;distributed task-based execution engine;information retrieval;knowledge creation processes;middleware-like transparent layer;multi thread environment;software system;text mining processes","","0","","9","","","30-31 Jan. 2009","","IEEE","IEEE Conference Publications"
"Query parsing for voice-enabled mobile local search","J. Feng; S. Bangalore","AT&T Labs-Research, 180 Park Avenue, Florham Park, NJ 07932, USA","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","4777","4780","With the exponential growth in the number of mobile devices, voice enabled local search is emerging as one of the most popular applications. Although the application is essentially an integration of automatic speech recognition (ASR) and text or database search, the potential usefulness of this application has been widely acknowledged. In this paper, we present a data-driven approach to voice query parsing, that segments the input query into several fields that are necessary for high-precision local search. We also demonstrate the robustness of our approach to ASR errors. We present an approach for exploiting multiple hypotheses from ASR, in the form of word confusion networks, in order to achieve tighter coupling between ASR and query parsing. A confusion-network based query parsing outperforms ASR 1-best based query-parsing by 2.6% absolute.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960699","Robustness to ASR errors;Voice Search","Automatic speech recognition;Cities and towns;Databases;Frequency;Hidden Markov models;Information retrieval;Natural languages;Robustness;Search engines;Yarn","query processing;speech recognition","automatic speech recognition;database search;mobile devices;query parsing;text search;voice query parsing;voice-enabled mobile local search","","1","1","8","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Challenges to the New Network Management Protocol: NETCONF","H. Ji; B. Zhang; G. Li; X. Gao; Y. Li","Pattern Recognition & Intell. Syst. Lab., Beijing Univ. of Posts & Telecommun. (BUPT), Beijing","2009 First International Workshop on Education Technology and Computer Science","20090526","2009","1","","832","836","In 2006, the IETF released its latest effort, NETCONF, a brand new network management protocol, which is based on the XML encoding method. The NETCONF protocol is thought to be able to meet the requirement of configuration management which SNMP fails to do well. The NETCONF protocol also performs better in other fields such as the efficiency, more flexible operations, etc. But, as a new protocol, NETCONF is not perfect either and it also has some shortcomings in several aspects. In this paper, some common problems and challenges in the field of network management which NETCONF has not efficiently solved are reviewed and a few pieces of suggestion will be given out.","","POD:978-0-7695-3557-9","10.1109/ETCS.2009.189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4958894","challenges;management;netconf;network","Computer network management;Encoding;Information retrieval;Monitoring;Network servers;Technology management;Telecommunication network management;Transport protocols;Transportation;XML","XML;authorisation;computer network management;protocols","NETCONF network management protocol;XML encoding method;access control mechanism;computer network management;configuration management","","3","","16","","","7-8 March 2009","","IEEE","IEEE Conference Publications"
"Sentence similarity computation based on feature set","Y. Liu; Q. Liu","School of Software, Tsinghua University, Beijing 100084, China","2009 13th International Conference on Computer Supported Cooperative Work in Design","20090526","2009","","","751","756","Sentence similarity computation has been used widely in the field of information processing. Many methods have been proposed to measure the similarity of sentences, but they focus mainly on one or two features, e.g. words, structure or semantic information and so on. The accuracy of these methods is usually lower. In this paper, we present a new approach to compute the similarity of sentences based on feature set. This method defines the key features in similarity computation and then combines their contribution to obtain the sentence similarity. Experiments show that this method has higher accuracy in sentence similarity computation.","","POD:978-1-4244-3534-0","10.1109/CSCWD.2009.4968149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4968149","Dependency tree;Feature set;HowNet;Semantic feature;Sentence Similarity;Structure feature","Collaborative work;Databases;Design methodology;Frequency measurement;Information processing;Information retrieval;Length measurement;Natural languages;Text categorization;Text mining","information analysis;natural language processing;set theory","feature set;information processing;sentence similarity computation","","0","","16","","","22-24 April 2009","","IEEE","IEEE Conference Publications"
"High resolution audio synchronization using chroma onset features","S. Ewert; M. Muller; P. Grosche","Universit&#228;t Bonn, Informatik III, R&#246;merstr. 164, D-53117, Germany","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","1869","1872","The general goal of music synchronization is to automatically align the multiple information sources such as audio recordings, MIDI files, or digitized sheet music related to a given musical work. In computing such alignments, one typically has to face a delicate tradeoff between robustness and accuracy. In this paper, we introduce novel audio features that combine the high temporal accuracy of onset features with the robustness of chroma features. We show how previous synchronization methods can be extended to make use of these new features. We report on experiments based on polyphonic Western music demonstrating the improvements of our proposed synchronization framework.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959972","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959972","Music synchronization;audio alignment;chroma features;onset features","Algorithm design and analysis;Audio recording;Music information retrieval;Organizing;Robustness;Software libraries","audio recording;audio signal processing;music;signal resolution;synchronisation","MIDI files;audio recordings;chroma onset features;digitized sheet music;high resolution audio synchronization;multiple information sources;music synchronization;polyphonic Western music;temporal accuracy","","34","","7","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Discovering topics from dark websites","L. Yang; F. Liu; J. M. Kizza; R. K. Ege","","2009 IEEE Symposium on Computational Intelligence in Cyber Security","20090515","2009","","","175","179","Analysis of dark Websites is important for developing effective combating strategies against terrorism or extremists when more and more scattered terrorist cells use the ubiquity of the Internet to form communities in virtual space with fairly low costs. Terrorists or extremists anonymously set up various Web sites embedded in the public Internet, exchanging ideology, spreading propaganda, and recruiting new members. In this paper, we propose a framework to discover latent topics via analyzing contents of dark Websites. The content and data from dark Websites are gathered and extracted by crawlers and exported to documents. Latent Dirichlet allocation (LDA) algorithm is used to analyze the extracted documents so as to discover latent topics from web sites of terrorists or extremists. In contrast to the traditional information retrieval (IR) schemes, LDA-based analysis assigns a probability to a document and captures exchangeability of both words and documents. Our work helps to gain insights into the structure and communities of terrorists and extremists.","","POD:978-1-4244-2769-7","10.1109/CICYBS.2009.4925106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4925106","","Algorithm design and analysis;Costs;Crawlers;Data mining;Information retrieval;Internet;Linear discriminant analysis;Recruitment;Scattering;Terrorism","Internet;security of data","Internet;dark Websites;information retrieval schemes;latent Dirichlet allocation","","6","","19","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Using dependencies to pair samples for multi-view learning","A. Tripathi; A. Klami; S. Kaski","University of Helsinki, Department of Computer Science, P.O.Box 68, 00014 UH, Finland","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","1561","1564","Several data analysis tools such as (kernel) canonical correlation analysis and various multi-view learning methods require paired observations in two data sets. We study the problem of inferring such pairing for data sets with no known one-to-one pairing. The pairing is found by an iterative algorithm that alternates between searching for feature representations that reveal statistical dependencies between the data sets, and finding the best pairs for the samples. The method is applied on pairing probe sets of two different microarray platforms.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4959895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4959895","canonical correlation;co-occurrence data;dependency;multi-view learning","Computer science;Data analysis;Information retrieval;Iterative algorithms;Kernel;Learning systems;Machine learning;Probes;Semiconductor device measurement;Text mining","data analysis;iterative methods;learning (artificial intelligence);statistical analysis","data analysis tools;feature representations;iterative algorithm;kernel canonical correlation analysis;microarray platforms;multiview learning;one-to-one pairing;pairing probe sets;statistical dependency","","1","","10","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"A dual belief propagation method for shape recognition","P. Tipwai; S. Madarasmi","Department of Computer Engineering, Rajamangala University of Technology Lanna, Chiang Mai 50300, THAILAND","2009 IEEE Symposium on Computational Intelligence for Image Processing","20090515","2009","","","88","95","We present a shape recognition framework which includes two steps: shape searching and shape matching by deformation. First, the user can draw a contour shape descriptor as a search template. The first Bayesian belief propagation (BP I) algorithm is used to find possible targets allowing for translation, scale, and rotation transformations to all contours in a cluttered image. The contour segments with common transformation values are grouped and hypothesized as belonging to the contour in the search template. The search template is then transformed for each possible transformation value. A second belief propagation (BP II) is applied to perform a deformable contour matching. The matching score or cost function determines whether there is an actual match. The algorithm overcomes the weaknesses of the other approaches since it does not require any pre-processing to detect feature points, it can match targets at any position, scale, or rotation transformations, and it does not use any accumulation space that my have peak clustering problems such as in the Hough transform.","","POD:978-1-4244-2760-4","10.1109/CIIP.2009.4937886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4937886","","Belief propagation;Degradation;Equations;Euclidean distance;Filtering;Indexing;Information retrieval;Multimedia databases;Query processing;Shape","belief networks;image matching;image recognition","Hough transform;cluttered image;deformable contour matching;dual belief propagation method;second belief propagation;shape matching;shape recognition;shape searching","","0","","16","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Capacity/Storage Tradeoff in High-Dimensional Identification Systems","E. Tuncel","Dept. of Electr. Eng., Univ. of California, Riverside, CA","IEEE Transactions on Information Theory","20090421","2009","55","5","2097","2106","The asymptotic tradeoff between the number of distinguishable objects and the necessary storage space (or equivalently, the search complexity) in an identification system is investigated. In the discussed scenario, high-dimensional (and noisy) feature vectors extracted from objects are first compressed and then enrolled in the database. When the user submits a random query object, the extracted noisy feature vector is compared against the compressed entries, one of which is output as the identified object. The first result this paper presents is a complete single-letter characterization of achievable storage and identification rates (measured in bits per feature dimension) subject to vanishing probability of identification error as the dimensionality of feature vectors becomes very large. This single-letter characterization is then extended for a multistage system whereby depending on the number of entries, the identification is performed by utilizing part or all of the recorded bits in the database. Finally, it is shown that a necessary and sufficient condition for a two-stage system to achieve single-stage capacities at each stage is Markovity of the optimal test channels.","0018-9448;00189448","","10.1109/TIT.2009.2016057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839033","Capacity;databases;identification systems;successive refinement","Feature extraction;Impedance;Indexing;Information retrieval;Information theory;Random access memory;Spatial databases;Statistics;Sufficient conditions;System testing","Markov processes;storage management;visual databases","Markovity;capacity-storage tradeoff;database;extracted noisy feature vector;high-dimensional identification systems;multistage system;random query object;single-letter characterization;storage space","","11","","16","","","May 2009","","IEEE","IEEE Journals & Magazines"
"Bootstrapping word alignment by automatically generated bilingual dictionary","D. Zhu; B. Chang","Institute of Computational Linguistics, Peking University, Beijing, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","This paper presents a new approach to improve the word alignment. Building a bilingual dictionary is one of the main applications for word alignment. However, the research of using the bilingual dictionary to improve the word alignment is not enough. There are two bottlenecks. The first is that large bilingual dictionary is hard to get. The second is that the normal approach of using bilingual dictionary does not make full use of the dictionary. We designed a bootstrapping algorithm to conquer the bottlenecks, achieving a good result.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906750","Bootstrapping;Machine Learning;Word Alignment","Data engineering;Dictionaries;Information retrieval;Libraries;Natural languages;Optical computing;Performance evaluation;Relational databases;Spatial databases;Testing","dictionaries;language translation;natural language processing","automatically generated bilingual dictionary;bootstrapping algorithm;word alignment","","1","","13","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Home healthcare via wireless biomedical sensor network","R. A. Rashid; S. H. S. Arifin; M. R. A. Rahim; M. A. Sarijari; N. H. Mahalin","Telematic and Optic Department, Faculty of Electrical Engineering, University of Technology Malaysia, Malaysia","2008 IEEE International RF and Microwave Conference","20090428","2008","","","511","514","Fast information retrieval is pivot of medical breakthrough to provide quality medical services. There were a number of attempts to develop clinical information system (CIS) which is reliable, affordable and accessible over the entire hospital and beyond. Today's home healthcare progression is becoming a predominant form of healthcare delivery. Although there have been many recent advances in biomedical sensors, low-power radio communication and embedded computation, there does not yet exist a flexible, robust communication infrastructure to integrate these devices into an emergency care setting. An efficient wireless communication substrate for medical devices that addresses ad hoc or fixed network formation, naming and discovery, security and authentication, as well as filtration and aggregation of vital sign data need to be studied. The potential applications will save lives, create valuable data for medical research, and cut the cost of medical services. In this paper, we focus on home healthcare via wireless sensor network (WSN) platform. WSN composed of a large number of sensor nodes and multi-hop networking capability that are densely deployed for a wide variety of applicants such as smart buildings, interactive user interfaces, environment control and highly suitable for monitoring in military and biomedical applications. We describe our experiences in developing and implement both hardware and software platform for medical sensor network, provides protocol for device discovery and multi-hop routing, as well as a simple query interface that is tailored for medical monitoring.","","CD-ROM:978-1-4244-2867-0; POD:978-1-4244-2866-3","10.1109/RFM.2008.4897437","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4897437","Home Healthcare;biomedical sensor;multi-hop routing;wireless sensor network","Biomedical monitoring;Biosensors;Clinical diagnosis;Computational Intelligence Society;Information retrieval;Intelligent sensors;Medical services;Spread spectrum communication;Telecommunication network reliability;Wireless sensor networks","ad hoc networks;biomedical communication;health care;home computing;message authentication;patient monitoring;telecommunication network routing;wireless sensor networks","biomedical application;clinical information system;data aggregation;data authentication;data discovery;data filtration;data security;device discovery;environment control;home healthcare;information retrieval;interactive user interfaces;medical monitoring;medical services;military application;multihop networking capability;multihop routing;query interface;smart buildings;wireless biomedical sensor network;wireless sensor network","","4","","10","","","2-4 Dec. 2008","","IEEE","IEEE Conference Publications"
"Probabilistic neural network based text summarization","M. Abdel Fattah; F. Ren","Faculty of Engineering, University of Tokushima, 2-1 Minamijosanjima, Japan 770-8506","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","6","This work proposes an approach to address the problem of improving content selection in automatic text summarization by using probabilistic neural network (PNN). This approach is a trainable summarizer, which takes into account several features, including sentence position, positive keyword, negative keyword, sentence centrality, sentence resemblance to the title, sentence inclusion of name entity, sentence inclusion of numerical data, sentence relative length, Bushy path of the sentence and aggregated similarity for each sentence to generate summaries. First we investigate the effect of each sentence feature on the summarization task. Then we use all features in combination to train the probabilistic neural network (PNN) in order to construct a text summarizer model.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906783","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906783","Automatic Summarization;probabilistic neural network;statistical model","Artificial intelligence;Artificial neural networks;Data mining;Inference mechanisms;Information retrieval;Knowledge representation;Neural networks;Packaging;Predictive models;Testing","neural nets;probability;text analysis","automatic text summarization;content selection;name entity;negative keyword;numerical data;positive keyword;probabilistic neural network;sentence centrality;sentence feature;sentence inclusion;sentence position;sentence relative length;sentence resemblance","","0","","27","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"Enhanced depth estimation by using object placement relation","N. Futragoon; P. Kanongchaiyos","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand","2008 IEEE International Conference on Robotics and Biomimetics","20090508","2009","","","1899","1904","Depth estimation from a scene is an important task in computer vision and 3-d image reconstruction. Normally, human being has an amazing ability to understand a scene quickly by extracting visual information such as object shape, stereo vision cue, size, placement and etc. However, in computer vision, finding 3-d position from an image is still a challenging task, though many researches have been proposed for decades. Many methods have been presented some efficient solutions using image acquisition from both one and several images. Nevertheless, there is no generic solution to recover precise depth from a single image without any prior knowledge. Object placement is one of vision cues usually used to identify 3-d position efficiently, while extraction of such information is not so trivial. Our approach presents an adaptive algorithm defining placement information as a constraint to estimate depth from a single scene image having many arbitrary objects. Our experimental result shows that our algorithm can estimate precise depth from a wide range of image scenes.","","POD:978-1-4244-2678-2","10.1109/ROBIO.2009.4913291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4913291","Computational Photography;Depth estimation;Object Relation","Biomimetics;Computer vision;Data mining;Humans;Image reconstruction;Image retrieval;Information retrieval;Layout;Robot vision systems;Shape","computer vision;image reconstruction;object detection","3D image reconstruction;computer vision;depth estimation;image acquisition;object placement relation","","1","","11","","","22-25 Feb. 2009","","IEEE","IEEE Conference Publications"
"Recent improvements of Probability Based Prosody Models for Unit Selection in concatenative Text-to-Speech","W. Zhang; L. Gu; Y. Gao","IBM T. J. Watson Research Center, Yorktown Heights, NY 10598 USA","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","3777","3780","The work presented in this paper is subsequent to the paper ldquoProbability Based Prosody Model for Unit Selectionrdquo which was published in ICASSP'2004. In the improved probability prosody model for corpus based concatenative Text-to-Speech (TTS), likelihood is replaced with posterior probability in the cost functions which conduct the following step, unit selection. Objective and subjective experiments show that posterior probability has obvious advantages over likelihood on robustness, flexibility and overall quality.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960449","Posterior probability;Text-to-Speech (TTS);prosody model;unit selection","Context modeling;Cost function;Databases;Decision trees;Information retrieval;Predictive models;Robustness;Runtime;Speech synthesis;Statistics","natural language processing;probability;speech synthesis","concatenative text-to-speech;posterior probability;probability based prosody model;unit selection","","2","2","10","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Toward a Robust data fusion for document retrieval","Daqing He; D. Wu","School of Information Sciences, University of Pittsburgh, PA, USA","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","8","This paper describes an investigation of signal boosting techniques for post-search data fusion, where the quality of the retrieval results involved in fusion may be low or diverse. The effectiveness of data fusion techniques in such situation depends on the ability of the fusion techniques to be able to boost the signals from relevant documents and reduce the effect of noise that often comes from low quality retrieval results. Our studies on Malach spoken document collection and HARD collection have demonstrated that CombMNZ, the most widely used data fusion method, does not have such ability. We, therefore, developed two versions of signal boosting mechanisms on top of CombMNZ, which result in two new fusion methods called WCombMNZ and WCombMWW. To examine the effectiveness of the two new methods, we conducted experiments on Malach and HARD document collections. Our results show that the new methods can significantly outperform CombMNZ in combining retrieval results that are low and diverse. When the tasks are to combine retrieval results that are in similar quality, which have been the scenarios that CombMNZ are applied often, the two new methods still can obtain often better, sometimes significantly, fusion results.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906754","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906754","CombMNZ;Data fusion;Malach;Spoken document retrieval;TREC HARD","Boosting;Diversity reception;Fusion power generation;Helium;Information management;Information resources;Information retrieval;Noise reduction;Robustness;Thesauri","information retrieval;sensor fusion","HARD collection;Malach spoken document collection;WCombMNZ;WCombMWW;document retrieval;post-search data fusion;signal boosting techniques","","0","","16","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"The practicality of the keyword search using PIR","R. Yoshida; Y. Cui; R. Shigetomi; H. Imai","Graduate School of Science and Engineering, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan","2008 International Symposium on Information Theory and Its Applications","20090428","2008","","","1","6","Nowadays, there are more and more use of storage-provider through the Internet, such as Google and Hotmail e-mail accounts, which are convenient to store and transfer electronic files and medias. Though the storage-provider offers users the capability to collect, retrieve and search on the emails, however, there is no protection of the users' privacy. For example, it is unknown how to prevent some honest-but-curious storage-provider from learning the private information of the user, such as, searching criterion and access pattern, etc. In CRYPTO'07, Boneh et al. put forward a privacy-preserving solution to solve this open problem, under the public key infrastructure. They made use of PIR (private information retrieval) and several other techniques, which are theoretically interesting and likely to be the best approach in the underlying setting. In this paper, we investigate the practicality of the proposed scheme by Boneh et al. Surprisingly, our evaluation result shows that their proposal seems unlikely to be implementable with the latest technology, due to a large amount of computational cost involved. Note that it is the first time to analyze and examine the practicality of this public key encryption based keyword search protocol using PIR.","","CD-ROM:978-1-4244-2069-8; POD:978-1-4244-2068-1","10.1109/ISITA.2008.4895559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4895559","","Computational efficiency;Electronic mail;Information retrieval;Internet;Keyword search;Privacy;Protection;Protocols;Public key;Public key cryptography","Internet;information retrieval;public key cryptography","Google;Hotmail email accounts;Internet;PIR;access pattern;electronic files;keyword search protocol;open problem;privacy-preserving solution;private information retrieval;public key encryption;public key infrastructure;searching criterion;storage-provider","","3","","11","","","7-10 Dec. 2008","","IEEE","IEEE Conference Publications"
"Annotating images by harnessing worldwide user-tagged photos","Xirong Li; C. G. M. Snoek; M. Worring","ISLA, Informatics Institute, University of Amsterdam, Science Park 107, 1098 XG, The Netherlands","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","3717","3720","Automatic image tagging is important yet challenging due to the semantic gap and the lack of learning examples to model a tag's visual diversity. Meanwhile, social user tagging is creating rich multimedia content on the Web. In this paper, we propose to combine the two tagging approaches in a search-based framework. For an unlabeled image, we first retrieve its visual neighbors from a large user-tagged image database. We then select relevant tags from the result images to annotate the unlabeled image. To tackle the unreliability and sparsity of user tagging, we introduce a joint-modality tag relevance estimation method which efficiently addresses both textual and visual clues. Experiments on 1.5 million Flickr photos and 10 000 Corel images verify the proposed method.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960434","Automatic image tagging;User tagging","Cultural differences;Image databases;Image retrieval;Informatics;Information retrieval;Multimedia databases;Multimedia systems;Tagging;Video sharing;Visual databases","image retrieval;relevance feedback","automatic image tagging;image annotation;image retrieval;joint-modality tag relevance estimation method;multimedia Web content;search-based framework;social user tagging;user-tagged image database;worldwide user-tagged photo","","4","1","11","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Explaining for developing a shared context in collaborative design","P. J. Brezillon","Laboratoire d'Informatique de Paris 6, University Pierre et Marie Curie, France","2009 13th International Conference on Computer Supported Cooperative Work in Design","20090526","2009","","","72","77","Collaborative design often meets together experts of different domains. Such groups need to share a context but often limited this one is often limited to few elements as common language, common tools and a same goal (the design process). Our goal is to developing a shared context to make compatible different experts' viewpoints. Making context explicit and shared supposes some explanatory capability. In this paper, we point out how context and explanation are intertwined, and the need of a uniform representation of elements of reasoning and of contexts for offering a larger spectrum of explanation in a collaborative design.","","POD:978-1-4244-3534-0","10.1109/CSCWD.2009.4968037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4968037","Explanation generation;collaborative design;contextual graphs;shared context","Artificial intelligence;Collaborative software;Collaborative work;Content based retrieval;Expert systems;Humans;Information retrieval;International collaboration;Knowledge engineering;Process design","graph theory;groupware;inference mechanisms;knowledge representation","collaborative design;contextual graphs;e-collaboration","","3","","14","","","22-24 April 2009","","IEEE","IEEE Conference Publications"
"View-invariant tensor null-space representation for multiple motion trajectory retrieval and classification","Xu Chen; D. Schonfeld; A. Khokhar","Department of Electrical and Computer Engineering, University of Illinois at Chicago, USA","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","3545","3548","In this paper, we propose a novel general framework for tensor based null space affine invariants, namely, tensor null space invariants (TNSI) with a linear classifier for high order data classification and retrieval. We first derive TNSI, which is perfectly invariant to multidimensional affine transformations due to camera motions for multiple motion trajectories in consecutive motion events. We subsequently propose an efficient classification and retrieval system relying on TNSI for archiving and searching motion events consisting of multiple motion trajectories. The simulation results demonstrate superior performance of the proposed systems.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960391","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960391","Classification;multilinear;null space;retrieval;tensor;trajectory","Algebra;Australia;Cameras;Handicapped aids;Information retrieval;Motion analysis;Multidimensional systems;Null space;Robustness;Tensile stress","image classification;image motion analysis;image representation;image retrieval;tensors","camera motions;high order data classification;high order data retrieval;linear classifier;motion trajectory classification;multidimensional affine transformations;multiple motion trajectory retrieval;tensor-based null space affine invariants;view-invariant tensor null-space representation","","1","","4","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"Hierarchically classifying documents with multiple labels","A. Mayne; R. Perry","Oxford University, UK","2009 IEEE Symposium on Computational Intelligence and Data Mining","20090515","2009","","","133","139","This paper describes the evaluation of a hierarchical classifier for classifying multi-labeled documents organized in a two-level taxonomy. The hierarchical classifier consists of a tree of independent naive Bayes classifiers, with output probabilities from parent classifiers propagated to child classifiers as additional features. Each classifier uses Bi-Normal Feature Separation for word feature selection. Experiments were performed using the Weka Toolkit adapted to deal with multi-labeled documents. The hierarchical classifier accuracy marginally out-performed a set of independent binary classifiers trained to classify documents for each class in the taxonomy.","","POD:978-1-4244-2765-9","10.1109/CIDM.2009.4938640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4938640","","Classification tree analysis;Feature extraction;Feedback;Feeds;Information retrieval;Information technology;Search engines;Taxonomy;User interfaces;Wikipedia","Bayes methods;document handling;feature extraction;pattern classification;probability;trees (mathematics)","bi-normal feature separation;hierarchical document classification;independent naive Bayes classifier tree;multi labeled document;output probability;word feature selection","","0","","10","","","March 30 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Organization and application of the programmable ordered access memory","A. Melnyk; D. a. Ravashdech; M. a. Hababsach","","2009 10th International Conference - The Experience of Designing and Application of CAD Systems in Microelectronics","20090424","2009","","","240","241","In this paper the requirements to memory of advanced computer are defined. The advantages and disadvantages of memory with random, serial and associative access in comparison with programmable ordered access memory are justified. The approaches to build of programmable ordered access memory is considered and the advantages of this memory use are estimated.","","POD:978-966-2191-05-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839817","Memory;memory organization;programmable ordered access memory;types of memory","Application software;Associative memory;Clocks;Content based retrieval;Hardware;Information retrieval;Processor scheduling;Random access memory;Telecommunication computing;Writing","programmable circuits;random-access storage","memory organization;programmable ordered access memory","","0","","10","","","24-28 Feb. 2009","","IEEE","IEEE Conference Publications"
"Semantic keywords-based duplicated web pages removing","Yunhe Weng; Lei Li; Yixin Zhong","School of Information, Engineering, Beijing University of Posts and Tele-communications, China","2008 International Conference on Natural Language Processing and Knowledge Engineering","20090502","2008","","","1","7","Because of many duplicated web pages existing on the web, search engines need to find and remove them, not only for saving process time and hardware resource, but also for ensuring that users can get the result information without many replicas. In this paper, we propose a method to find and remove duplicated Chinese Web pages for search engine. First we describe a scheme based on semantic keywords combined with sentence overlapping, and then show an implemented prototype, with the experimental results that suggest the prototype work well under a proper setting.","","CD-ROM:978-1-4244-2780-2; POD:978-1-4244-2779-6","10.1109/NLPKE.2008.4906751","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4906751","Duplicated web pages;IR;semantic keywords","Data engineering;Information retrieval;Libraries;Natural languages;Optical computing;Performance evaluation;Relational databases;Spatial databases;Testing;Web pages","Web sites;natural language processing;search engines","Chinese Web pages;duplicated Web pages;search engines;semantic keywords","","0","1","16","","","19-22 Oct. 2008","","IEEE","IEEE Conference Publications"
"A new efficient method for system structural analysis and generating Analytical Redundancy Relations","A. Fijany; F. Vatan","Italian Institute of Technology, Via Morego, 30, 16163 Genoa, Italy","2009 IEEE Aerospace conference","20090424","2009","","","1","12","In this paper we present a new efficient algorithmic method for generating the analytical redundancy relations (ARRs). ARRs are one of the crucial tools for model-based diagnosis as well as for optimizing, analyzing, and validating the system of sensors. However, despite the importance of the ARRs for both system diagnosis and sensor optimization, it seems that less attention has been paid to the development of systematic and efficient approaches for their generation. In this paper we discuss the complexity in derivation of ARRs and present a new efficient algorithm for their derivation. Given a system with a set of L ARRs, our algorithm achieves a complexity of O(L<sup>4</sup>) for generating the ARRs. To our knowledge, this is the first algorithm with a polynomial complexity for derivation of ARRs. We also present the results of application of our algorithms, for generating the complete set of ARRs, to both synthetic and industrial examples.","1095-323X;1095323X","POD:978-1-4244-2621-8","10.1109/AERO.2009.4839665","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839665","","Algorithm design and analysis;Costs;Equations;Fault detection;Information retrieval;Laboratories;Linear programming;Propulsion;Redundancy;Sensor systems","condition monitoring;fault diagnosis;optimisation;polynomial approximation;structural engineering","analytical redundancy relations;model-based diagnosis;polynomial complexity;sensor optimization;system diagnosis;system structural analysis","","5","3","9","","","7-14 March 2009","","IEEE","IEEE Conference Publications"
"Towards the combination of statistical and symbolic techniques for activity recognition","D. Riboni","EveryWare Lab., D.I.Co., University of Milano, via Comelico 39, I-20135, Italy","2009 IEEE International Conference on Pervasive Computing and Communications","20090508","2009","","","1","2","Techniques for activity recognition are fundamental components of any context-aware system. Indeed, precise knowledge of the user's current activity is necessary in order to thoroughly tailor services to the user's context. To this aim, in the last years many research efforts have been devoted to devise statistical techniques for recognizing basic physical activities based on data retrieved from body- worn sensors. An intriguing research issue is how to integrate those statistical techniques with symbolic ones in order to i) refine statistical predictions, and ii) derive more complex activities. The intuition behind this research direction is that the current user's context (e.g., artifacts and persons in the user's surrounding environment) may give useful hints about the possible activities performed by the user herself. Given an ontology that models the addressed scenario, those hints can be automatically derived through ontological reasoning and used to refine the prediction of the statistical classifier. Moreover, ontological reasoning can be performed to derive complex activities described in terms of simpler activities and symbolic constraints about the user's context.","","CD-ROM:978-1-4244-3304-9","10.1109/PERCOM.2009.4912886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4912886","","Accelerometers;Context-aware services;Geographic Information Systems;Global Positioning System;Information retrieval;Mobile communication;Network servers;Ontologies;Pervasive computing;Sensor fusion","inference mechanisms;ontologies (artificial intelligence);pattern classification;statistical analysis;ubiquitous computing","activity recognition;body-worn sensors;complex activities;context-aware system;ontological reasoning;physical activities;statistical classifier;statistical prediction;statistical techniques;symbolic constraints;symbolic techniques","","0","","5","","","9-13 March 2009","","IEEE","IEEE Conference Publications"
"A Bayesian NETWORKS approach for dialog modeling: The fusion BN","F. F. Martinez; J. Ferreiros; R. Cordoba; J. M. Montero; R. San-Segundo; J. M. Pardo","Speech Technology Group, Universidad Polit&#233;cnica de Madrid, Spain","2009 IEEE International Conference on Acoustics, Speech and Signal Processing","20090526","2009","","","4789","4792","Bayesian networks, BNs, are suitable for mixed-initiative dialog modeling allowing a more flexible and natural spoken interaction. This solution can be applied to identify the intention of the user considering the concepts extracted from the last utterance and the dialog context. Subsequently, in order to make a correct decision regarding how the dialog should continue, unnecessary, missing, wrong, optional and required concepts have to be detected according to the inferred goals. This information is useful to properly drive the dialog prompting for missing concepts, clarifying for wrong concepts, ignoring unnecessary concepts and retrieving those required and optional. This paper presents a novel BNs approach where a single BN is obtained from N goal-specific BNs through a fusion process. The new fusion BN enables a single concept analysis which is more consistent with the whole dialog context.","1520-6149;15206149","POD:978-1-4244-2353-8","10.1109/ICASSP.2009.4960702","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4960702","bayesian networks;dialog modeling","Bayesian methods;Computational efficiency;Control systems;Data mining;Databases;Delta modulation;Dictionaries;Information retrieval;Speech;Topology","belief networks;human computer interaction;interactive systems;natural language interfaces;sensor fusion;speech-based user interfaces","Bayesian network approach;concept analysis;fusion BN process;mixed-initiative dialog modeling;natural language sentence;natural spoken interaction;speech interface;spoken dialog system","","0","","5","","","19-24 April 2009","","IEEE","IEEE Conference Publications"
"In quest of global Radio Occultation Mission for meteorology beyond 2011","C. J. Fong; N. L. Yen; C. H. Chu; C. C. Hsiao; S. K. Yang; Y. C. Lin; S. S. Chen; Y. A. Liou; S. Chi","National Space Organization (NSPO), Hsin-Chu, Taiwan 30077","2009 IEEE Aerospace conference","20090424","2009","","","1","8","The FORMOSAT-3/COSMIC mission consisting of six satellites is the world's first demonstration of near real-time operational GPS Radio Occultation (RO) constellation mission. The success of the mission expected to operate through 2011 has initiated a new era for operational GPS RO soundings. The World Meteorological Organization had recommended continuing RO observations operationally and urges planning for a complementary follow-on mission. The follow-on mission will be a new constellation of 12 to 18 satellites equipped with the GNSS RO payload and collect over 9000 soundings per day. This higher density of sounding profiles will be useful for global and mesoscale models, and also severe weather forecasting. The follow-on mission will establish international standards so that future RO missions deployed by any country can be used together for operations and research. In this paper, we present the state-of-the-art achievements and the results of the current mission; as well as the follow-on mission planning progress.","1095-323X;1095323X","POD:978-1-4244-2621-8","10.1109/AERO.2009.4839343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4839343","","Global Positioning System;Information retrieval;Meteorology;Predictive models;Remote sensing;Satellite broadcasting;Space missions;Space vehicles;Terrestrial atmosphere;Weather forecasting","Global Positioning System;remote sensing;weather forecasting","AD 2011;FORMOSAT-3/COSMIC mission;GNSS RO payload;GPS Radio Occultation constellation mission;World Meteorological Organization;global-mesoscale models;operational Global Positioning System RO soundings;weather forecasting","","1","","15","","","7-14 March 2009","","IEEE","IEEE Conference Publications"
