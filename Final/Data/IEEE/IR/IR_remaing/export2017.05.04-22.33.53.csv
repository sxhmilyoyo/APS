"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5687995,5662587,5662302,5685899,5686025,5662790,5687442,5662779,5664692,5687969,5687859,5663513,5662320,5662703,5684896,5684842,5684480,5685500,5685524,5683297,5685521,5648462,5679953,5681602,5681950,5681335,5681488,5681623,5681608,5681904,5679916,5681283,5679643,5679616,5679726,5680027,5681607,5678554,5676978,5678207,5677058,5676486,5678457,5677052,5678408,5677743,5678112,5678583,5676788,5673157,5675809,5673822,5676167,5675810,5674850,5673368,5671408,5672300,5670833,5670474,5670931,5670731,5670948,5669016,5669065,5670923,5667105,5666756,5666786,5666008,5667981,5666252,5666637,5666231,5666006,5661917,5668053,5662114,5666766,5665447,5661593,5664634,5665350,5665359,5661531,5652885,5664891,5650251,5663312,5661565,5660873,5664235,5663220,5665461,5664303,5664305,5664873,5652467,5663251,5661561",2017/05/04 22:33:53
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Singing Melody Extraction from Pop Songs Using a Novel Feature and Viterbi Search","M. Li; J. Li; J. Han; Z. Shi","Sch. of Comput. Sci. & Technol., Harbin Inst. of Technol., Harbin, China","2010 International Conference on Computational Intelligence and Software Engineering","20101230","2010","","","1","4","Extracting singing melody from audio signals is one essential component for musical information retrieval. One can identify melody of different types of music easily even without professional training, but it is difficult for computer to achieve this goal. In this paper, we present a new feature which provides not only a convenient way to observe music but also a tool to extract singing melody. Also, we propose pitch likelihood, note and energy transition probabilities to perform Viterbi search. The experimental results show that our method can extract singing melody accurately.","","Electronic:978-1-4244-5392-4; POD:978-1-4244-5391-7","10.1109/CISE.2010.5676978","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676978","","Band pass filters;Feature extraction;Frequency domain analysis;Gaussian distribution;Spectrogram;Viterbi algorithm","audio signal processing;information retrieval;music","Viterbi search;audio signals;feature search;musical information retrieval;pop songs;singing melody extraction","","0","","7","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Web Service Based Enterprise Mobile Information System","J. Tao; X. Chen","E-Commerce Dept., Nanjing Univ., Nanjing, China","2010 International Conference on Multimedia Information Networking and Security","20101217","2010","","","320","323","Mobile applications are changing the behavior of individuals and also of organizations. Instant access to information is beneficial for us in many business situations. More and more enterprises have recognized the potential importance and transformative impact of them and are planning to build their own mobile information system. This paper first discusses some architectural considerations for mobile applications, and then provides a web service based architecture for the mobile system, which is better in function customization, internal systems integration and dynamic cooperation with trading partners in mobile environment.","2162-8998;21628998","Electronic:978-1-5090-5632-3; POD:978-1-4244-8626-7; USB:978-0-7695-4258-4","10.1109/MINES.2010.216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670833","","Information systems;Mobile communication;Mobile handsets;Organizations;Real time systems;Web services","Web services;information retrieval;management information systems;mobile computing","Web services;enterprise mobile information system;information access","","0","","10","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"Simple Blog Searching framework based on social network analysis","I. Dolińska","University of Economics and Computer Science in Warsaw, Stok&#x0142;osy 3, 02-787, Poland","Proceedings of the International Multiconference on Computer Science and Information Technology","20110106","2010","","","611","617","Blogs are very popular Internet communication tools. The process of knowledge sharing is a very important activity in the contemporary information era. Blogs are used for knowledge sharing on any subject all over the world. Knowledge gathered on blogs can be used in personal e-learning, which is a more informal and personal way of learning than the one offered by traditional e-learning courses. However, it is not easy to find valuable knowledge in the huge amount of invalid information. In this study the Simple Blog Searching framework is proposed to improve the blog searching process. The social network analysis methods of centrality measuring help to choose more easily the best results form the long list of hits, received from a blog search tool. To incorporate social network analysis methods, the blog searching have to be expanded with the blog links searching.","2157-5525;21575525","Electronic:978-83-60810-27-9; POD:978-1-4244-6432-6","10.1109/IMCSIT.2010.5679953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5679953","","Computer science;Information services;Information technology;Internet;Iron;Social network services;Web sites","Internet;computer aided instruction;information retrieval;knowledge management;social networking (online)","Blog searching framework;Internet communication tool;knowledge sharing;personal e-learning;social network analysis","","0","","21","","","18-20 Oct. 2010","","IEEE","IEEE Conference Publications"
"Adaptive segment model for spoken document retrieval","C. H. Chueh; J. T. Chien","Dept. of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan","2010 7th International Symposium on Chinese Spoken Language Processing","20110110","2010","","","261","264","In a robust information retrieval system, the documents should be represented by considering the variations of word distributions in different paragraphs or segments. A nonstationary latent Dirichlet allocation (NLDA) was established by incorporating a Markov chain to detect the stylistic segments in a heterogeneous document. Each segment corresponds to a particular style and is generated by different word distributions. However, such NLDA is constrained by a fixed number of segments for different lengths of documents. This paper presents a new adaptive segment model (ASM) by adaptively building the topic-based document model with different segment numbers. By incorporating a multinomial hidden variable with Dirichlet prior, the inference procedure of ASM parameters is built through a variational Bayes EM algorithm. In the experiments, the proposed ASM is evaluated for spoken document retrieval using TDT2 corpus. ASM achieves better performance than LDA and NLDA.","","Electronic:978-1-4244-6246-9; POD:978-1-4244-6244-5","10.1109/ISCSLP.2010.5684896","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5684896","segment model;spoken document retrieval;topic model;variational Bayes","Adaptation model;Biological system modeling;Hidden Markov models;Markov processes;Probability;Speech recognition;Viterbi algorithm","computational linguistics;hidden Markov models;information retrieval;speech recognition","Dirichlet prior;Markov chain;TDT2 corpus;adaptive segment model;information retrieval system;nonstationary latent Dirichlet allocation;paragraphs;spoken document retrieval;topic-based document model;variational Bayes EM algorithm;word distributions","","1","","10","","","Nov. 29 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Design and Implementation of Embedded TCM System Based on Android Platform","C. l. Cheng; J. q. Du; C. h. Liao; X. l. Liu","Sch. of Comput. Sci., Jiangxi Univ. of Traditional Chinese Med., Nangchang, China","2010 International Conference on E-Product E-Service and E-Entertainment","20101210","2010","","","1","4","TCM (Traditional Chinese Medicine) prescriptions are too complicated and numerous for most learners to remember, so the dialectic classification and the choice of TCM prescriptions are usually out of joint in clinic and teaching nowadays. The embedded system, described in this paper, is designed as a TCM prescription information system based on Android platform, in which the emphasis is placed on the standardization of TCM information and the promotion of the TCM traditional spreading approach. And it is implemented with the techniques regarding the Android platform and embedded database, to provide functions such as retrieval of recipes, herbs and syndromes, assisted prescribing and TCM information synchronization in Android device. Moreover, the system has established the integrated relationship of TCM entities relying on our TCM research to overcome the above obstacle in TCM development.","","Electronic:978-1-4244-7161-4; POD:978-1-4244-7159-1","10.1109/ICEEE.2010.5661593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661593","","Java;Medical information systems;Mobile communication;Protocols;Servers;Synchronization","embedded systems;information retrieval;medical information systems;operating systems (computers);pattern classification","Android platform;dialectic classification;embedded TCM system;embedded database;information retrieval;information synchronization;prescription information system;traditional Chinese medicine","","0","","11","","","7-9 Nov. 2010","","IEEE","IEEE Conference Publications"
"Aggregating Web Service matchmaking variants using web search engine and machine learning","I. Paik; E. Fujikawa; S. Kim","School of Computer Science and Engineering, University of Aizu, Aizu-Wakamatsu, Fukushima, Japan","2010 2nd International Symposium on Aware Computing","20101217","2010","","","191","195","Variety of Web Service discovery algorithms had been investigated for improvement of the retrieval quality. Combining the several algorithms according to their strong points, is proposed as enabling more refined discovery consequence. Now, many researches as OWL-Mx are sited as examples, had already shown the method that join together and conclude for the specific domain. However, there are no way to conclude multi-algorithms results. Klusch shows the brand-new way that leads the conclusion by using machine-learning algorithm Support Vector Machine (SVM). In this research, we attempted to apply the SVM aggregation and several new discovery algorithm using similarity based on search engine, shown on Trip Domain service discovery. And, 88 percent over score of precision, were gotten as the result from specifically prepared queries for Trip Domain. This experiment also had shown 10 percent missing which occurred by using web page count based similarity computation. In future work, we will conduct some comparison for getting more reliability of this proposed method.","","Electronic:978-1-4244-8314-3; POD:978-1-4244-8313-6","10.1109/ISAC.2010.5670474","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670474","Machine learning;Match making;Semantic similarity;Service discovery","Humans;Indexes","Web services;information retrieval;knowledge representation languages;learning (artificial intelligence);search engines;software reliability;support vector machines","OWL-Mx;SVM;Trip Domain service discovery;Web service matchmaking variants aggregation;machine-learning algorithm;retrieval quality;search engine;similarity computation;support vector machine;web page count","","0","","10","","","1-4 Nov. 2010","","IEEE","IEEE Conference Publications"
"Information Technology Risk Measurement Using NIST (Case Study at Pt. Pintraco)","A. Gui; R. Kristanto; H. Haron; E. Adrian","Computerized Accounting Dept., Bina Nusantara Univ., Jakarta, Indonesia","2010 Second International Conference on Advances in Computing, Control, and Telecommunication Technologies","20101223","2010","","","191","194","The purpose of this study is to measure how big the risk level associated existing information technology at PT. Phintraco and how to minimize the risk of information technology. The research methodology used involves library research, documentation studies and interviews, collected data were analyzed using the NIST method. Results from this study indicate there are 13 types of risks that might occur, one of them at high risk (Malicious code) and there are two risks with a medium risk level (Information theft, server hangs). The conclusion was that risk controls has been applied quite good but still there are some weaknesses in it, among others: the password is not changed periodically, there is no documentation about the system, the right of access to the IT division is too free, antivirus programs inadequate.","","Electronic:978-0-7695-4269-0; POD:978-1-4244-8746-2","10.1109/ACT.2010.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5675809","Information Technology;Measurement;NIST;Risk","Companies;Hardware;Information technology;NIST;Risk management;Security;Servers","document handling;information retrieval;information technology;risk analysis","NIST method;antivirus programs inadequate;documentation studies;information technology;library research;risk measurement","","0","","10","","","2-3 Dec. 2010","","IEEE","IEEE Conference Publications"
"A secure and privacy protection digital goods trading scheme in cloud computing","W. S. Juang; Y. Y. Shue","Department of Information Management, National Kaohsiung First University of Science and Technology, Kaohsiung 824, Taiwan","2010 International Computer Symposium (ICS2010)","20110110","2010","","","288","293","In a cloud computing environment, a seller can store her/his digital goods in a cloud server, and then sell them when a buyer needs. In order to protect the digital content's privacy, the seller should store her/his digital goods in an encrypted form before being stored in a cloud. However, the method of directly encrypting digital goods maybe not work well if buyers and sellers trade with the digital goods in this environment. The reason is that the cloud server could not decide which digital goods contain certain keywords requested by a buyer if the meta data of the encrypted digital goods is not searchable. In this paper, we propose a secure digital goods trading scheme in the cloud computing. Our scheme can efficiently protect keywords privacy for buyers, and make the cloud server to search the keywords on the encrypted digital content to protect the privacy of sellers' digital content. We also provide an efficient trading method to let buyers and sellers trade with the matched digital goods in a cloud.","","Electronic:978-1-4244-7640-4; POD:978-1-4244-7639-8","10.1109/COMPSYM.2010.5685500","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685500","authenticated key agreement;cloud computing;digital goods;keyword search;searchable encryption","Authentication;Cloud computing;Clouds;Electronic mail;Public key;Servers","cloud computing;cryptography;data privacy;electronic trading;information retrieval","authenticated key agreement;cloud computing;cloud server;encrypted digital good;keyword privacy;meta data;privacy protected digital good trading scheme;secured digital good trading scheme","","0","","17","","","16-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"A Comparison of Programming Skills by Genders of Hungarian Grammar School Students","G. Kiss","Dept. of Mechatron. & Cartechnics Eng., Obuda Univ., Budapest, Hungary","2010 7th International Conference on Ubiquitous Intelligence & Computing and 7th International Conference on Autonomic & Trusted Computing","20101213","2010","","","24","30","Experiences show that boys are developing programming skills easier than girls in higher education. An analysis of programming skills by gender in secondary grammar schools was made with the help of a web based Informatics Test. After composing an on-line test on the base of the National Curriculum I analysed how effectively can students of different grades answer questions dealing with different subjects. From different towns of Hungary over 60 teachers used the test to see the knowledge level of more than 1000 students having answered these questions. After the evaluation of the test results the correctness of the original presumption emerged. First the Kolmogorov-Smirnov-test was used to see if the groups showed standard normal distribution in answering the questions. The means of the correct answers by gender were examined using a Z-test with two parameters and the deviation quotient was to calculated revealing how much gender influences the difference of means. Significance level was 5% through the analysis. Significant divergence by gender was found regarding programming skills showing the hypothesis correct in this two area. Students have to put everything in source code when learning programming. It seems this method is more favourable for boys. Girls have problems finding syntax errors in source code or understand it at all. I looks it would be better to teach girls with different tools using primitive building elements to write programs so when changing the parameters of these building elements no syntax errors would occur.","","Electronic:978-0-7695-4272-0; POD:978-1-4244-9043-1","10.1109/UIC-ATC.2010.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5667105","Hungary;programming skills by gender;secondary grammar school","Databases;Educational institutions;Gaussian distribution;Programming profession;Text processing","computer aided instruction;computer science education;educational institutions;further education;gender issues;grammars;programming;question answering (information retrieval)","Hungarian grammar school students;Kolmogorov-Smirnov-test;Z-test;answer questions;genders;higher education;national curriculum;online test;programming skills;source code;syntax errors;web Informatics Test","","1","","7","","","26-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"A study of Web 2.0 based digital archives system using Kano Model","C. J. Chu; S. L. Wang; Y. C. Lai","Graduate School of Computer Science And Information Technology, NTIT, Taichung, Taiwan","2010 International Computer Symposium (ICS2010)","20110110","2010","","","171","176","Creative Economy has become the global trend, many advanced countries have to put great efforts on the promotion and application of digital archiving. In this study, we attempt to define the service quality factors of digital archiving e-service system and then identify the crucial factors for attracting more public users. In addition, through the applying of Kano Model, the service quality factors of Web2.0 digital archiving system are analyzed so as to design digital archiving e-service system that meets related service quality. However, this study hoped that more internet users can be encouraged to participate and share digital archiving content, and the wisdom of more people can be collected to create and promote the archiving content in the future.","","Electronic:978-1-4244-7640-4; POD:978-1-4244-7639-8","10.1109/COMPSYM.2010.5685524","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685524","Digital Archives;Kano Model;Web 2.0;Web Service Quality","Authorization;Indexes;Internet;Q factor;Technological innovation;Visualization;Web sites","Web services;information retrieval systems;records management","Kano Model;Web 2.0 based digital archiving e-service system;service quality factor","","1","","12","","","16-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"RIAs and OGC Web Services Based Geospatial Data Searching and Visualization","M. Huang; Y. Tian","Coll. of Hydropower & Inf. Eng., Huazhong Univ. of Sci. & Technol., Wuhan, China","2010 2nd International Conference on Information Engineering and Computer Science","20101230","2010","","","1","4","Large amounts of valuable geosciences data have been collected due to the advances in digital earth technology. How to provide an efficient way through which researchers can easily retrieve desired data to facilitate data analysis and system modeling poses great challenges to the geosciences community. This paper presents a Geo-web services based system aimed to enhance geospatial data searching and visualization. The system provides an interoperable way of searching and accessing high quality geospatial data from multi-source and multi-discipline geographic data repositories through the use of Open Geospatial Consortium (OGC) Web services. It is in conformity with OGC Catalog Service for the Web (CSW) specification to play a ""directory"" role that permits the registry, discovery and access of geospatial information resources distributing on the Internet. Moreover, by leveraging the Rich Internet Applications (RIAs) technologies, the system enables to seamlessly assemble multiple heterogeneous data from different sources into one single user interface for visualization. Two investigations were made to demonstrate how this system has been used to improve the efficiency of searching and collecting geospatial data for a particular research.","2156-7379;21567379","Electronic:978-1-4244-7941-2; POD:978-1-4244-7939-9","10.1109/ICIECS.2010.5678207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5678207","","Data visualization;Geology;Geospatial analysis;Portals;Protocols;Web services","Internet;Web services;cataloguing;data analysis;data visualisation;geographic information systems;information retrieval;user interfaces","Geo-Web services based system;OGC Web services;OGC catalog service;RIA;data analysis;digital earth technology;geographic data repositories;geosciences community;geospatial data searching;geospatial data visualization;open geospatial consortium;rich Internet applications;system modeling;user interface","","0","","5","","","25-26 Dec. 2010","","IEEE","IEEE Conference Publications"
"Logic vector analysis of associative tables","H. Vladimir; C. Svetlana; L. Eugenia","Computer Engineering Faculty, Kharkov National University of Radioelectronics, Lenin Ave. 14, Kharkov, Ukraine, 61166","2010 XIth International Workshop on Symbolic and Numerical Methods, Modeling and Applications to Circuit Design (SM2ACD)","20101217","2010","","","1","6","This article describes logical analysis infrastructure of associative tables (matrices), which enables to perform processing the interaction of the input vector with n-dimensional algebra-logical space, specified by using the ordered and structured tables of problem-oriented data, which represent the associative behavioral models of logical objects. To estimate the interaction of vectors in algebra-logical space the universal quality criterion is developed. It makes possible to find and evaluate the quasioptimal solution to the problems of associative logical information retrieval. Examples of the infrastructure and algebra-logical procedures, designed to solve the traditional logical analysis problems, which confirm the efficiency and practical orientation of algebraic models, are given.","","Electronic:978-1-4244-6817-1; POD:978-1-4244-6816-4","10.1109/SM2ACD.2010.5672300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672300","associative table;infrastructure;logic vector analysis","Analytical models;Arrays;Circuit faults;Conferences;Kernel;Numerical models","information retrieval;logic gates;matrix algebra;table lookup","associative tables;information retrieval;logic vector analysis;logical analysis infrastructure;logical objects;matrices;n-dimensional algebra-logical space;ordered tables;problem oriented data;quasioptimal solution;structured tables","","0","","14","","","4-6 Oct. 2010","","IEEE","IEEE Conference Publications"
"Method of rearranging watermarked pixels for printed and scanned watermarked documents","N. Mettripun; R. Lhawchaiyapurk; T. Amornraksa","Multimedia Communication Laboratory, Computer Engineering Department, Faculty of Engineering, King Mongkut's University of Technology Thunburi, 126 Pracha-uthit Rd., Bangmod, Thungkru, Bangkok, 10140, Thailand","2010 10th International Symposium on Communications and Information Technologies","20101210","2010","","","492","497","In this paper, we consider the problem of extracting the embedded watermark from the printed and scanned watermarked images. Since in a practical situation, the parameters settings in the printing and scanning processes between users are different, recovering the embedded watermark from the watermarked paper, after being scanned back to the computer, is difficult and contains high amount of errors. We hence propose a method of rearranging the printed and scanned watermarked pixels to implement with the pixel-wise based digital watermarking in order to improve the accuracy of the extracted watermark. The proposed method is simple, low complex, and possible for practical watermarking applications. With our proposed method, the watermarked paper can now be scanned back in various resolutions with small inclined angles. The experimental results show the improved performance in term of NC obtained from our method, compared to the lower accuracy from the previous method.","","Electronic:978-1-4244-7010-5; POD:978-1-4244-7007-5; USB:978-1-4244-7009-9","10.1109/ISCIT.2010.5664891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664891","","Accuracy;Hyperspectral imaging;Image resolution;Indexes;Pixel;Printing;Watermarking","document handling;image watermarking;information retrieval","digital watermarking;embedded watermark;scanning process;watermarked document;watermarked image;watermarked paper;watermarked pixel","","2","","12","","","26-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Depicting Educational Content Repurposing Context and Inheritance","E. Kaldoudi; N. Dovrolis; S. T. Konstantinidis; P. D. Bamidis","Medical Physics Laboratory, School of Medicine, Democritus University of Thrace, Alexandroupolis, Greece","IEEE Transactions on Information Technology in Biomedicine","20110106","2011","15","1","164","170","Educational content is often shared among different educators and is enriched, adapted, and, in general, repurposed so that it can be reused in different contexts. This paper discusses educational content and content repurposing in medical education, presenting different repurposing contexts. Finally, it proposes a novel approach to content repurposing via Web 2.0 social networking of learning resources. The proposed social network is augmented by a graphical representation module in order to capture and depict the relationships among different repurposed medical educational resources, based on educational resource “families” and inheritance. The ultimate goal is to provide a conceptually different approach to educational resource organization and retrieval via “social” associations among learning resources.","1089-7771;10897771","","10.1109/TITB.2010.2092442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5648462","Content repurposing;educational resource;medical education;social networking","Context;Education;Games;Ontologies;Organizations;Social network services;Standards organizations","Internet;biomedical education;computer aided instruction;content management;information resources;information retrieval;inheritance;medical computing;social networking (online)","Web 2.0 social networking;content repurposing;educational content;educational resource families;educational resource organization;graphical representation module;information retrieval;inheritance;learning resources;medical educational resources","Biomedical Research;Health Educators;Humans;Information Dissemination;Internet;Social Support;Software","5","","32","","20101203","Jan. 2011","","IEEE","IEEE Journals & Magazines"
"PervasiveCrystal: Asking and Answering Why and Why Not Questions about Pervasive Computing Applications","J. Vermeulen; G. Vanderhulst; K. Luyten; K. Coninx","Centre for Digital Media, Hasselt Univ., Diepenbeek, Belgium","2010 Sixth International Conference on Intelligent Environments","20101223","2010","","","271","276","Users often become frustrated when they are unable to understand and control a pervasive computing environment. Previous studies have shown that allowing users to pose why and why not questions about context-aware applications resulted in better understanding and stronger feelings of trust. Although why and why not questions have been used before to aid in debugging and to clarify graphical user interfaces, it is currently not clear how they can be integrated into pervasive computing systems. We explain in detail how we have extended an existing pervasive computing framework with support for why and why not questions. This resulted in PervasiveCrystal, a system for asking and answering why and why not questions in pervasive computing environments.","","Electronic:978-0-7695-4149-5; POD:978-1-4244-7836-1","10.1109/IE.2010.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5673822","Why questions;context;control;explanations;intelligibility","Cameras;Context;Crystals;Media;Motion pictures;Pervasive computing;User interfaces","question answering (information retrieval);ubiquitous computing","PervasiveCrystal:;context aware application;debugging aid;graphical user interface;pervasive computing;question answering;question asking","","2","","17","","","19-21 July 2010","","IEEE","IEEE Conference Publications"
"Poster: Translating cross-filtered queries into questions","M. Nafari; C. Weaver","School of Computer Science and Center for Spatial Analysis The University of Oklahoma","2010 IEEE Symposium on Visual Analytics Science and Technology","20101210","2010","","","245","246","Complex combinations of coordinated multiple views are increasingly used to design tools for highly interactive visual exploration and analysis of multidimensional data. While complex coordination patterns provide substantial utility through expressive querying, they also exhibit usability problems for users when learning required interaction sequences, recalling past queries, and interpreting visual states. As visual analysis tools grow more sophisticated, there is a growing need to make them more understandable as well. Our long-term goal is to exploit natural language familiarity and literacy to directly facilitate individual and collaborative use of visual analysis tools. In this poster, we present work in progress on an automatically generated query-to-question user interface to translate interactive states during visual analysis into an accompanying visual log of formatted text. Our effort currently focuses on a symmetric and thus relatively simple coordination pattern: cross-filtered views. We describe our current thinking about query-to-question translation in a typical cross-filtered visualization of movies, people, and genres in the Internet Movie Database.","","Electronic:978-1-4244-9487-3; POD:978-1-4244-9488-0","10.1109/VAST.2010.5650251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5650251","Coordinated multiple views;cross-filtered queries;interaction states;natural language generation;visual provenance","Data visualization;Encoding;Internet;Motion pictures;Natural languages;Visualization;Weaving","data analysis;data visualisation;information filtering;natural languages;query processing;question answering (information retrieval)","Internet movie database;coordinated multiple views;cross-filtered visualization;interaction sequences;learning;multidimensional data;natural language;query-to-question translation;query-to-question user interface;visual analysis tools;visual exploration;visual log;visual state interpretation","","0","","8","","","25-26 Oct. 2010","","IEEE","IEEE Conference Publications"
"Cluster tree based hybrid semantic similarity measure for social tagging systems","Changli Zhang; Jinjin Zhang; Maode Yan","School of Information Engineering, Chang'an University, Xi'an 710064, China","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","2","","1113","1116","As the social tagging systems becoming prevalent, it remains a critical question that how to make explicit the semantics for tags to fully facilitate Web2.0 applications. This paper establishes a cluster tree based semantic similarity measure for social tagging systems, combines it with traditional statistics based measures into a hybrid one, tailors the hybrid measure according to the effectiveness requirement of intelligent search application, and presents a case study using the empirical data retrieved from delicious website. Comparing to the traditional statistics based measures, our hybrid measure is capable of evaluating similarities between random tags even not co-occurred, can better reflect the structural influence of the network of tag co-occurrence, and is feasible for applications like intelligent search in user-centric Web2.0 environment.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5687995","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687995","Web2.0;cluster tree;folkosonomy;intelligent search;semantic similarity measure;small world;social tagging systems","TV","information retrieval;social networking (online);trees (mathematics)","Web2.0 applications;Website;cluster tree;hybrid semantic similarity measure;intelligent search application;social tagging systems","","0","","12","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"LJParser: LING-JOIN web search & text mining development platform","Y. Wang","Ling-Join Zhongke Software (Beijing) Co.Ltd, China","2010 4th International Universal Communication Symposium","20101213","2010","","","407","407","LJParser is a developing platform for web search and mining. It is a middleware by LING-JOIN Software, which is well known for over ten years of expertise in natural language understanding and web search. LJParser provides powerful modules including precise search for multiple language, new words detection, Chinese word segmentation and pas tagging, language modeling and term translation, text clustering, text categorization, text summarization, keywords identification in a single document and duplication detection. The application can invoke any module of LJParser in Windows and Linux using any language including C, C# and Java. LJParser related technology has licensed over 20,000 entities over the world.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666756","","","data mining;grammars;information retrieval;language translation;middleware;natural language processing;pattern clustering;text analysis;word processing","Chinese word segmentation;LING-JOIN Web search;LJParser;Linux;Windows;keywords identification;language modeling;middleware;multiple language search;natural language understanding;new words detection;pas tagging;term translation;text categorization;text clustering;text mining development platform;text summarization","","0","","","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"Study of agricultural search engine based on FAO agrovoc ontology and google API","C. Yunpeng; T. Peng; L. Shihong; S. Sufen","Key Laboratory of Digital Agricultural Early-warning Technology Ministry of Agriculture, The People's Republic of China, Beijing 100081, China","2010 World Automation Congress","20101210","2010","","","439","444","This paper introduces an application developed with FAO Agrovoc ontology and Google AJAX API. FAO Agrovoc ontology is not only an agricultural concepts collection but also the relationships among the concepts, Google API can be used to submit keywords to Google search engine and get the retrieval results from Google, the combination of these two things can help users in agriculture field find information they want to search better and navigate the knowledge in some degree.","2154-4824;21544824","Electronic:978-1-889335-42-1; POD:978-1-4244-9673-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5665350","","Agriculture;Computers;Google;Navigation;Ontologies;Search engines;Vocabulary","agricultural engineering;application program interfaces;information retrieval;ontologies (artificial intelligence);search engines","Agrovoc ontology;FAO;Google API;agricultural search engine;information retrieval","","2","","6","","","19-23 Sept. 2010","","IEEE","IEEE Conference Publications"
"Web 2.0 content extraction","M. Waqar; Z. S. Khan","Center of Excellence in Information Assurance, King Saud University, Riyadh, Saudi Arabia","2010 International Conference for Internet Technology and Secured Transactions","20101230","2010","","","1","3","This paper presents a simple, efficient and extendable solution for content extraction from web 2.0. Web 2.0 is perceived as the second generation of the web technologies. Web 2.0 has undoubtedly made significant impact in enriching the end-user experience and allowing programmers to write more interactive desktop-like applications for the web. However, it has also introduced some new issues for researchers in the field information retrieval and has made the job of information retrieval from web more difficult, time consuming and challenging. Web pages contain lot of clutter besides the original article. To extract the main content several methods have been developed. However, these methods were originally designed based on the traditional model of the web, and would fail to work on web 2.0 content. Due to evident popularity of web 2.0, the volume of the web 2.0 content on the Web will rise sharply in the coming years. In this paper we propose a new solution to this problem, based upon open source components, which will make the job of web 2.0 content extraction more efficient and will reduce the utilization of precious system resources. The paper also presents a high level logical design for the implementation of such system though available open source components.","","Electronic:978-0-9564263-6-9; POD:978-1-4244-8862-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5678554","","Browsers;Engines;HTML;IP networks;Loading;Presses;Servers","Internet;data mining;information retrieval","Web 2.0 content extraction;Web technology;high level logical design;information retrieval;open source component","","1","","5","","","8-11 Nov. 2010","","IEEE","IEEE Conference Publications"
"Text Retrieval Based on Semantic Relationship","G. Huang; X. Zhang","Electron. & Inf. Eng. Coll., Henan Univ. of Sci. & Technol., Luoyang, China","2010 International Conference on E-Product E-Service and E-Entertainment","20101210","2010","","","1","4","Expansion of query keywords based on semantic relationship is an effective approach to improve the performance of text retrieval. In this paper, a novel approach for text retrieval is presented. The principle of the approach is to construct a integrated semantic tree, and select candidate keywords from the tree. On the tree, all nodes are weighted based on synonymy, hypernymy, and Mutual Information. The weights of nodes will be used to supplement tfidf values in computing the similarity between query and documents. Experimental results demonstrate about 14.6% precision and 13.7% prec@20 improvement over the traditional tfidf-based method.","","Electronic:978-1-4244-7161-4; POD:978-1-4244-7159-1","10.1109/ICEEE.2010.5661531","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661531","","Context;Correlation;Information filters;Mutual information;Semantics","information retrieval;semantic networks;text analysis","query keywords;semantic relationship;semantic tree;text retrieval","","0","","8","","","7-9 Nov. 2010","","IEEE","IEEE Conference Publications"
"WISDOM: A web information analysis system","Y. Kato; S. Akamine; D. Kawahara; T. Nakagawa; Y. I. Leon-Suematsu; T. Kawada; K. Inui; S. Kurohashi; Y. Kidawara","National Institute of Information and Communications Technology, Tohoku University, Japan","2010 4th International Universal Communication Symposium","20101213","2010","","","406","406","We present an information analysis system, WISDOM (Web Information Sensibly and Discreetly Ordered and Marshaled), which assists users in assessing the credibility of information on the Web from multiple viewpoints. A vast amount of information is now accumulated on the Web and becoming increasingly influential in people's decision making. However, the Web contains a proliferation of false and misleading information. Thus, it is essential to study the methodologies and technologies that enable us to judge the credibility of information. It is for this reason that we have developed WISDOM, which organizes information on a given topic through the following three types of analysis: (1) extracting and contrasting important and controversial sentences around the points related to the topic, using semantics-oriented natural language processing (NLP) techniques; (2) identifying and classifying the authorship of each page; and (3) analyzing the appearance of each page, according to, for example, page design and writing style. WISDOM is in a state of continuous development, and in comparison to our previous demonstration at IUCS 2009, the current version of WISDOM is more advanced in the following respects. First, it extracts contrasting statements, in which statements contrasting the topic to other things, e.g., electric vehicles vs. hybrid electric vehicles. Second, it analyzes the expertise of information senders and indicates senders with high expertise with stars. Third, WISDOM analyzes a fresh 120 million Japanese Web pages; these pages are crawled and updated everyday by our crawler. WISDOM is available at http://wisdom-nict.go.jp/.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666786","","","decision making;information analysis;information retrieval;natural language processing;semantic Web","WISDOM;Web information analysis system;Web page;controversial sentence;decision making;semantics oriented natural language processing","","0","","","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"Fragment Maintenance in Distributed Storage Systems","X. Yang; S. Zhu","Key Lab. of Network & Inf. Security of APF, Eng. Coll. of APF, Xi'an, China","2010 International Conference on Multimedia Information Networking and Security","20101217","2010","","","123","126","How to efficiently enhance fault-tolerance and data access availability are the major problems to solve in distributed storage system. Data fragment maintenance is an essential part of distributed storage systems. Byzantine quorum system is a typical system model in maintaining data availability. The paper presents a novel fragment verifying and repairing algorithm built in Byzantine quorum system with the mechanism of fragment verifier generation and recovery. Different data redundancy schemes are considered when applying our algorithm. According to our analysis, the algorithm can greatly reduce computing complexity and network load in probing and returning an available quorum. More importantly, processing simplification is considered.","2162-8998;21628998","Electronic:978-1-5090-5632-3; POD:978-1-4244-8626-7; USB:978-0-7695-4258-4","10.1109/MINES.2010.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670931","Byzantine fault-tolerance;data repair;distributed storage system;quorum system;secret sharing scheme","Availability;Fault tolerant systems;Maintenance engineering;Protocols;Redundancy;Training","distributed processing;fault tolerant computing;information retrieval;redundancy;security of data","Byzantine quorum system;data access availability;data fragment maintenance;data redundancy;distributed storage system;fault tolerance;repairing algorithm","","0","","8","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"A Block Segmentation Based Approach for Web Information Extraction","C. Wang; C. Sun; L. Lin; X. Wang","Sch. of Comput. Sci. & Technol., Harbin Inst. of Technol., Harbin, China","2010 International Conference on Asian Language Processing","20110106","2010","","","154","157","This paper addresses the issue of web information extraction to support automatic teacher information management. We propose an effective approach based on block segmentation. First, the teacher introduction web pages are divided into independent blocks, where html tags and punctuation marks are used as segmentation criterion. Then CRF model is employed to label the text. We apply this approach on a teacher web page dataset collected from heterogeneous sources. Experimental results indicate that for basic info and contact info extraction our approach achieves an accurate result just using word level features. As extending value features related to education to block level, the performance of our system on the complex educational information extraction task is dramatically improved.","","Electronic:978-0-7695-4288-1; POD:978-1-4244-9063-9","10.1109/IALP.2010.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681602","CRF;block segmentation;information extraction","Data mining;Educational institutions;Feature extraction;HTML;Hidden Markov models;Tagging;Web pages","Internet;educational administrative data processing;information retrieval","CRF model;HTML tag;Web information extraction;automatic teacher information management;block segmentation;punctuation mark","","1","","18","","","28-30 Dec. 2010","","IEEE","IEEE Conference Publications"
"Study on Family Relations Reasoning Based on Automated Reasoning","Q. Ge; F. Zheng","Inst. of Data & Knowledge Eng., Henan Univ., KaiFeng, China","2010 International Conference on Computational Intelligence and Software Engineering","20101230","2010","","","1","4","Automated reasoning has become the research hotspot among researchers, and family relations are common logic knowledge, which can be reasoned. This paper presents four basic relations on family relations, which can deduce others new complex relations. The relation knowledge was stored in knowledge database as forms of basic relations. Some common questions could be deduced successfully and receive correct answers. The study gives an intelligent inference procedure on family relations and two algorithms, one algorithm is Positive Retrieving Information Algorithm (PRIA), and the other is Negative Recombination Information Algorithm (NRIA), which could be well programmed.","","Electronic:978-1-4244-5392-4; POD:978-1-4244-5391-7","10.1109/CISE.2010.5677058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5677058","","Cognition;Computers;Geometry;Inference algorithms;Knowledge engineering;Natural languages;Presses","inference mechanisms;information retrieval","automated reasoning;complex relations;family relation reasoning;intelligent inference procedure;knowledge database;logic knowledge;negative recombination information algorithm;positive retrieving information algorithm;relation knowledge","","0","","6","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Experiences and Observations from the NoAH Infrastructure","G. Kontaxis; I. Polakis; S. Antonatos; E. P. Markatos","Inst. of Comput. Sci., Found. for Res. & Technol. Hellas, Heraklion, Greece","2010 European Conference on Computer Network Defense","20101210","2010","","","11","18","Monitoring large chunks of unused IP address space yields interesting observations and useful results. However, the volume and diversity of the collected data makes the extraction of information a challenging task. Additionally, the maintenance of the monitoring infrastructure is another demanding and time-consuming effort. To overcome these problems, we present several visualization techniques that enable users to observe what happens in their unused address space over arbitrary time periods and provide the necessary tools for administrators to monitor their infrastructure. Our approach, which is based on open-source standard technologies, transforms the raw information at the network level and provides a customized and Web-accessible view. In this paper, we present the design, implementation and early experiences of the visualization techniques and tools deployed for the NoAH project, a large-scale honey pot-based infrastructure. Additionally, we provide a traffic analysis of data collected over a six month period of our infrastructure's operation. During the data collection period, we observed that the number of attackers continually increased as did the volume of traffic they generated. Furthermore, interesting patterns for specific types of traffic have been identified, such as the diurnal cycle of the traffic targeting TCP port 445 (Windows Directory Services), the port that receives the largest volume of attack traffic.","","Electronic:978-0-7695-4311-6; POD:978-1-4244-9377-7","10.1109/EC2ND.2010.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663312","","Availability;Data visualization;Grippers;IP networks;Monitoring;Sensors;Servers","IP networks;Internet;computer network security;data visualisation;information retrieval;public domain software;telecommunication traffic","IP address;NoAH infrastructure;Web-accessible view;information extraction;large-scale honeypot-based infrastructure;open-source standard technology;traffic analysis;visualization technique","","0","","15","","","28-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Holographic Versatile Disc: High speed information storage systems","A. Rana; O. Arora; N. Syal; P. Singh","Maharishi Markandeshwar Engineering College, Mullana, India","International Congress on Ultra Modern Telecommunications and Control Systems","20101230","2010","","","934","939","Holographic information storage systems (HISS) have been a good candidate for a volumetric recording technology due to their large storage capacities and high transfer rates. Recently, revival of activity in HISS has resulted from the dramatic developments in systems, such as laser technology, spatial light modulators (SLM) and complementary metal-oxide semiconductor (CMOS) image sensors. Holographic Versatile Disc (HVD) system using Collinear Technology, a new technology for HISS, is proposed and demonstrated by OPTWARE Corporation. This technology can produce a small, practical HISS more easily than conventional 2-axis holography.","2157-0221;21570221","Electronic:978-1-4244-7286-4; POD:978-1-4244-7285-7","10.1109/ICUMT.2010.5676486","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676486","Basics of Holographic Memory;Structure of HVD;What is HVD","DVD;Holographic optical components;Holography;Interference;Laser beams;Mirrors;Servomotors","data recording;digital versatile discs;holographic storage;information retrieval systems","HISS;collinear technology;holographic information storage systems;holographic versatile disc;volumetric recording technology","","0","","11","","","18-20 Oct. 2010","","IEEE","IEEE Conference Publications"
"What Makes a High-Quality User-Generated Answer?","B. M. John; A. Y. K. Chua; D. H. L. Goh","Nanyang Technological University","IEEE Internet Computing","20101223","2011","15","1","66","71","Community-driven question-answering (CQA) services on the Internet let users share content in the form of questions and answers. Usually, questions attract multiple answers of varying quality from other users. A new approach aims to identify high-quality answers from candidate answers to questions that are semantically similar to the new question. Toward that end, the authors developed and tested a quality framework comprising social, textual, and content-appraisal features of user-generated answers in CQA services. Logistic-regression analysis revealed that content-appraisal features were the strongest predictor of quality. These features include dimensions such as comprehensiveness, truthfulness, and practicality.","1089-7801;10897801","","10.1109/MIC.2011.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676167","Internet;quality framework;question answering","Accuracy;Feature extraction;Internet;Social network services;User interfaces;Web services","Internet;question answering (information retrieval);regression analysis;user interfaces","Internet;community-driven question-answering service;content-appraisal quality feature;high-quality user-generated answer;logistic-regression analysis;quality framework;social quality feature;textual quality feature","","12","","9","","","Jan.-Feb. 2011","","IEEE","IEEE Journals & Magazines"
"A novel approach for proper name transliteration verification","E. E. Jan; N. Ge; S. H. Lin; S. Roukos; J. Sorensen","IBM T.J Watson Research Center, Yorktown Heights, NY 10598, USA","2010 7th International Symposium on Chinese Spoken Language Processing","20110110","2010","","","89","94","Proper name transliteration, the pronunciation based translation of a proper name, is important to many multilingual natural language processing task, such as Statistical Machine Translation (SMT) and Cross Lingual Information Retrieval (CLIR). This task is extremely challenging due to the pronunciation difference between the source and target language. A given proper name can lead to many different transliterations. In the past, research efforts had demonstrated a 30-50% error using top-1 reference for transliteration. This error leads to performance degradation for many applications. In this paper, a novel approach to verify a given proper name transliteration pair using a discrete variant Hidden Markov Model (HMM) alignment is proposed. The state emission probabilities are derived from SMT phrase tables. The proposed method yields an Equal Error Rate (EER) of 3.73% on a 300 matched and 1000 unmatched name pairs test set. By comparison, the commonly used SMT framework yields 6.5% EER under the best configuration. The widely used edit distance approach has an EER of 22%. Our new method achieves high accuracy and low complexity, and provides an alternative for name transliteration in CLIR and other cross lingual natural language applications such as word alignment and machine translation.","","Electronic:978-1-4244-6246-9; POD:978-1-4244-6244-5","10.1109/ISCSLP.2010.5684842","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5684842","component;cross lingual IR;machine translation;translteration","Computational modeling;Decoding;Error analysis;Hidden Markov models;Kernel;Noise measurement;Training","hidden Markov models;information retrieval;language translation;natural language processing;probability","SMT phrase tables;cross lingual information retrieval;discrete variant hidden Markov model;equal error rate;multilingual natural language processing task;pronunciation based translation;proper name transliteration verification;state emission probabilities","","0","","22","","","Nov. 29 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Using Deep Web Technology in Scientific Data Sharing Platform","Y. Chen; Y. Wu; S. Guo","Sch. of Comput. Sci. & Eng., South China Univ. of Technol., Guangzhou, China","2010 International Conference on E-Product E-Service and E-Entertainment","20101210","2010","","","1","4","There's myriad of accessible information deposited in Deep Web, and the amount of the information is increasing rapidly. With the development of web application, there're more and more online databases, which make Deep Web a hot research topic. For the convenience of searching information in Scientific Data Sharing Platform, this paper does research of Deep Web application, and presents a system architecture of Deep Web data integration with details.","","Electronic:978-1-4244-7161-4; POD:978-1-4244-7159-1","10.1109/ICEEE.2010.5661565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661565","","Algorithm design and analysis;Data mining;Databases;Feature extraction;HTML;Semantics;Web pages","Internet;data integrity;information retrieval;online front-ends;scientific information systems","data integration;deep web technology;online database;scientific data sharing;system architecture","","0","","12","","","7-9 Nov. 2010","","IEEE","IEEE Conference Publications"
"A collaborative knowledge management system for product design based on folksonomy","Jinbo Sun; Suihuai Yu; Chang Ge; Chao Jiang","Key Laboratory of Contemporary Design and Integrated Manufacturing Technology, Northwestern Polytechnical University, Ministry of Education, Xi'an, China","2010 IEEE 11th International Conference on Computer-Aided Industrial Design & Conceptual Design 1","20110106","2010","2","","1385","1387","The aim of this research is to suggest folksonomy-based collaborative knowledge management system for designers in product development who collect, organize, analysis, presentation large quantity information. We performed field observation and studies to examination how designers in a group deal with information during the design process. We found that the traditional information organize methods have some problems like lack of collaboration and time consuming. Base on this research, we developed concept group work knowledge management application called FKP-PD. By implementing FKP-PD, we have showed the system reduces problems found from current process such as duplication of efforts and promiscuous information definition. In future study, we plan to evaluate the system further as well as adjust information input and output function which can be usefully applied to group design work.","","Electronic:978-1-4244-7974-0; POD:978-1-4244-7973-3","10.1109/CAIDCD.2010.5681950","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681950","Collaborative;Folksonomy;Knowledge Management;Product Design","Humans;Knowledge engineering","groupware;information retrieval;knowledge management;product design;production engineering computing","FKP-PD;collaborative knowledge management system;folksonomy;product design;product development","","1","","5","","","17-19 Nov. 2010","","IEEE","IEEE Conference Publications"
"A Multi-Information Fusion Approach to Unsupervised Chinese Event Extraction","R. Lin; J. Chen; H. Xu; X. Yang","Cognitive Sci. Dept., Xiamen Univ., Xiamen, China","2010 International Conference on E-Product E-Service and E-Entertainment","20101210","2010","","","1","5","In this paper, we propose a novel model for unsupervised Chinese event extraction. We use a multi-information fusion technique to combine two kinds of information for knowledge representation of event instances: language features and structure information. Then, we perform our proposed XLS-means Clustering Algorithm to group the candidate event instances into a ""natural"" number of clusters, which can fully take into account the similarity of both their language and structure information. The experimental results on ACE2005 Chinese corpus show that our model can achieve better performance than other unsupervised methods.","","Electronic:978-1-4244-7161-4; POD:978-1-4244-7159-1","10.1109/ICEEE.2010.5660873","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5660873","","Clustering algorithms;Data mining;Event detection;Feature extraction;Knowledge representation;Learning systems;Pattern matching","feature extraction;information retrieval;knowledge representation;natural languages;pattern clustering;sensor fusion;unsupervised learning","ACE2005 Chinese corpus;X<sup>LS</sup> clustering algorithm;event instance;knowledge representation;language feature;multiinformation fusion;structure information;unsupervised Chinese event extraction","","0","","13","","","7-9 Nov. 2010","","IEEE","IEEE Conference Publications"
"Web-based Image Scale dynamic partition","Jiang Ke; Wang Jing-jing","School of Electromechanical Engineering, Beijing Information Science & Technology University, China","2010 IEEE 11th International Conference on Computer-Aided Industrial Design & Conceptual Design 1","20110106","2010","1","","355","358","Image Scale, as a tool for product perceptual analysis, has been widely used in the actual design process. However, its object of study that is the psychological experience of people on products is a very vague and mutative notion, image scale is always considered to be instability and unreliability. Using web-based dynamic database can enhance amount of early collected data and summarize this data by the weighted method, stability and realiability of image scale can greatly improve, then helping designers obtain more accurate market information and users' needs conveniently.","","Electronic:978-1-4244-7974-0; POD:978-1-4244-7973-3","10.1109/CAIDCD.2010.5681335","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681335","image scale;product semantic;web-based;weighted method","Databases","Internet;information retrieval;product design;psychology;visual perception","Web based image scale dynamic partition;market information;product perceptual analysis;psychological experience;weighted method","","0","","6","","","17-19 Nov. 2010","","IEEE","IEEE Conference Publications"
"A novel similarity evaluating model based on RFCA and ICS","C. Shi; Z. Niu","School of Computer Science, Beijing Institute of Technology","2010 Fifth International Conference on Digital Information Management (ICDIM)","20101210","2010","","","114","119","In this paper, a similarity evaluating model based on rough formal concept analysis and information content similarity is proposed which evaluates the similarity degree between the concepts. We use the information content approach to automatically obtain part of similarity scores of two concepts which makes up the normal featural and structural evaluating models. Then through our model, the similarity of two concepts can be directly calculated from the lower object approximations and lower attribute approximations based on the rough formal concept analysis. An extensive experimental evaluation on two real datasets shows that when adjusting the influence from the object to certain degree, it outperforms other related works.","","Electronic:978-1-4244-7573-5; POD:978-1-4244-7572-8","10.1109/ICDIM.2010.5664235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664235","","Approximation methods;Computational modeling;Context;Databases;Integrated circuit modeling;Lattices;Semantics","data analysis;feature extraction;formal concept analysis;information retrieval","attribute approximation;featural evaluating model;information content similarity;object approximation;rough formal concept analysis;similarity degree;similarity evaluating model;similarity score;structural evaluating model","","0","","16","","","5-8 July 2010","","IEEE","IEEE Conference Publications"
"Evaluation of 1D barcode scanning on mobile phones","F. von Reischach; S. Karpischek; F. Michahelles; R. Adelmann","Information Management, ETH Z&#x00FC;rich, Scheuchzerstrasse 7, 8092 Zurich, Switzerland","2010 Internet of Things (IOT)","20101230","2010","","","1","5","1D or linear barcodes are the black-and-white-striped codes that can be found on most consumer products. This work evaluates existing 1D barcode scanners for mobile phones on their applicability towards consumers. The tested scanners identify the data stored in these codes, and thus enable users of mobile phones to conveniently access related information from the Internet on the go, without having to type in the name of a product. The work compares 11 state-of-the-art scanners in a user study with 20 consumers in a realistic shopping environment. It measures the time per scan, the reliability of the scanners, and performs a qualitative evaluation of the users' comments. The results indicate that, although most of the evaluated scanners are available already, still very few function reliably enough to be useful for consumers. General guidelines for the improvement of mobile 1D barcode scanners are derived.","","Electronic:978-1-4244-7415-8; POD:978-1-4244-7413-4","10.1109/IOT.2010.5678457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5678457","","Hardware;Internet;Mobile communication;Mobile handsets;Reliability;Software","Internet;information retrieval;mark scanning equipment;mobile computing;mobile handsets","1D barcode scanning;Internet;black and white striped code;consumer product;linear barcodes;mobile phone","","2","","8","","","Nov. 29 2010-Dec. 1 2010","","IEEE","IEEE Conference Publications"
"OSN: When Multiple Autonomous Users Disclose Another Individual's Information","C. Perez-Sola; J. Herrera-Joancomarti","Dept. d'Eng. de la Informacio i les Comunicacions, Univ. Autonoma de Barcelona, Barcelona, Spain","2010 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20110113","2010","","","471","476","Online Social Networks (OSNs) are becoming more important in the web 2.0 paradigm. Although most implementations of OSN are not distributed applications, users conforming an OSN work autonomously posting their information in the OSN and interacting among them. Users are responsible of the information they post in their profile and, in the vast majority of social networks, they can limit the disclosure degree of such data regarding the members of the social network. However, a part from data they provide, other related data can be obtained from users: the relations between them. By appropriately crawling the web, it is possible to obtain information from a single user without accessing to his profile. In this paper, we present an attack to users' privacy using a specific crawling algorithm that takes advantage of the network properties of OSNs.","","Electronic:978-0-7695-4237-9; POD:978-1-4244-8538-3","10.1109/3PGCIC.2010.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662587","privacy;social networks;web crawling","","Internet;data privacy;information retrieval;social networking (online)","OSN;Web 2.0 paradigm;crawling algorithm;multiple autonomous users;online social network;user information privacy","","1","","13","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"Acquirement of class relations for ontology based on language expression and knowledge structure","C. Chang; J. Zeng; W. Wu","Institute of Scientific and Technical Information of China, Beijing, 100038, China","2010 World Automation Congress","20101210","2010","","","429","432","Ontology plays an important role in information retrieval and organization, but it requires huge human labor in artificial construction, in particular it is even more labor-intensive and time intensive when determining concept class relation. The paper have put forward three methods to acquire class relations by machines, the first is based on terms co-occurrence, the second is based on term truncation, and the third is based on the meaning of terms. With these three methods, it is essential to acquire equivalent relations, sub-classes relations, and relevant relations by machine. Via artificial interference, these relations can be found in ontology or thesaurus. This work is of realistic significance in the construction of ontology and thesaurus and can save large quantities of labor and time.","2154-4824;21544824","Electronic:978-1-889335-42-1; POD:978-1-4244-9673-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5665359","Ontology;Relation;Terms co-occurrence","Frequency domain analysis;Humans;Hydraulic turbines;Hydroelectric power generation;Ontologies;Thesauri;Water resources","information retrieval;ontologies (artificial intelligence);thesauri","artificial construction;artificial interference;class relation;cooccurrence;human labor;information retrieval;knowledge structure;language expression;ontology;term truncation;thesaurus","","0","","8","","","19-23 Sept. 2010","","IEEE","IEEE Conference Publications"
"Web Information Extraction Algorithm Based on Ontology and DOM Tree","L. Liu; J. Shi; X. Liu","Sch. of Inf. Eng., Univ. of Sci. & Technol. Beijing, Beijing, China","2010 International Conference on Computational Intelligence and Software Engineering","20101230","2010","","","1","4","Due to the information on the Web being tremendous, dynamic and irregular, it is difficult to search and integrate information from the Web. This paper proposes a Web information extraction algorithm based on Ontology and DOM tree. The areas are accurately found out and the interested information is extracted exactly by information extraction rules generated by ontology. Furthermore this algorithm implements information extraction through traveling DOM tree. Finally, we implement information extraction system and test its performance on news site. Testing result shows that this algorithm doesn't rely on the page structure and it can increase the recall and precision of information extraction.","","Electronic:978-1-4244-5392-4; POD:978-1-4244-5391-7","10.1109/CISE.2010.5677052","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5677052","","Data mining;HTML;Heuristic algorithms;Navigation;Ontologies;Web pages;XML","Internet;information retrieval;ontologies (artificial intelligence);tree data structures","DOM tree;Web information extraction algorithm;news site;ontology","","0","","7","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"A compression method for inverted index and its FPGA-based decompression solution","J. Yan; N. Xu; Z. Xia; R. Luo; F. H. Hsu","Microsoft Research Asia, Beijing, China","2010 International Conference on Field-Programmable Technology","20110106","2010","","","261","264","Reconfigurable computing based on FPGA is a promising solution to accelerate applications for web search engines. Due to the challenge of such data-intensive applications, data compression has become much more important. This paper proposes a data compression method for inverted indices, which combines the bit-level compression method - Huffman coding and a coarse-grained compression method, to achieve a balanced performance in compression ratio and decompression speed. Because an inverted index is only compressed once, the compression speed is not the major measurement for a compression method. The proposed method shows good to 21.61% compression ratio on inverted indices from a commercial search engine. This compression ratio is better than results by other existing compression methods. We also develop an efficient FPGA-based hardware decompression module, which could provide up to 996 MBps input bandwidth for the accelerator system.","","Electronic:978-1-4244-8983-1; POD:978-1-4244-8980-0","10.1109/FPT.2010.5681488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681488","","Bandwidth;Hardware;Huffman coding;Indexes;Query processing;Search engines","Huffman codes;Internet;data compression;field programmable gate arrays;information retrieval;search engines","FPGA-based decompression solution;FPGA-based hardware decompression module;Web search engines;bit-level compression method-Huffman coding;coarse-grained compression method;data compression method;inverted index;reconfigurable computing","","0","","5","","","8-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"An automatic acquisition of domain knowledge from list-structrued text in Baidu encyclopedia","W. Wu; Liu Tao; H. Hu; X. Du","School of Information, Renmin University of China, Beijing 100872, China","2010 4th International Universal Communication Symposium","20101213","2010","","","291","298","We propose a novel method which can automatically extract new concepts and semantic relations between concepts, in order to support the domain ontology evolvement. We collect the corpus from a free Chinese encyclopedia called Baidu encyclopedia, which is similar to Wikipedia. We locate lists from the Baidu encyclopedia, and extract domain knowledge from the lists. Further more, we use a knowledge assessor to ensure the validity of extracted knowledge. In the experiments, we make a practical attempt to evolve the Chinese Law Ontology (CLO V0), and show that our method can improve the completeness and coverage of CLO V0.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666008","baidu encyclopedia;knowledge extraction;list wrapper","Data mining;Encyclopedias;HTML;Ontologies;Semantics;Web pages;World Wide Web","encyclopaedias;information retrieval;ontologies (artificial intelligence)","Baidu encyclopedia;Chinese encyclopedia;Chinese law ontology;Wikipedia;automatic acquisition;domain knowledge extraction;domain ontology evolvement;list-structrued text","","0","","41","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"Capability and Responsibility Balancing in Online Social Search","K. Xu; V. O. K. Li; J. Xie; G. H. Yang","Dept. of Electr. & Electron. Eng., Univ. of Hong Kong, Hong Kong, China","2010 IEEE Global Telecommunications Conference GLOBECOM 2010","20110110","2010","","","1","5","Online social search (OSS) brings forth a new way to harness the Internet for answers. In this paper, we study the balancing between OSS users' capabilities and responsibilities. Targeting a practical system design, we propose an analytical model that captures the heterogeneity of different referral sessions in OSS, and a distributed socio-aware referral strategy that can achieve the desired balance when the system reaches steady state. We show that configuring the strategy enables the system operator to control the flow of all posed questions in the system. We also discuss the implications of configuring the strategy from a gaming-strategy point of view.","1930-529X;1930529X","Electronic:978-1-4244-5638-3; POD:978-1-4244-5636-9","10.1109/GLOCOM.2010.5683297","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5683297","","Control systems;Convergence;IEEE Communications Society;Peer to peer computing;Probability distribution;Social network services;Steady-state","Internet;information retrieval;social networking (online)","Internet;OSS;distributed socio-aware referral strategy;online social search","","4","","12","","","6-10 Dec. 2010","","IEEE","IEEE Conference Publications"
"Ontology-based classification of unstructured information","S. Burger; B. Stieger","Eastern Michigan University, Department of Computer Science, Ypsilanti, Michigan, USA","2010 Fifth International Conference on Digital Information Management (ICDIM)","20101210","2010","","","254","259","The area of knowledge management (KM) has been addressed with a considerable amount of research in order to develop concepts and technologies for the retrieval of information and knowledge out of a set of heterogeneous data sources. Especially when we deal with files which contain unstructured information, i.e. documents, it is still a huge challenge to classify them automatically into certain domain-dependant categories. Therefore, this paper describes an application and the underlying concepts which are used for a classification based on the available metadata of files, whereas the classification categories can be found in form of ontology classes. This paper discusses experiences and challenges during the implementation with special regard to ontology-based classification algorithms, the underlying framework as well as the importance metadata quality.","","Electronic:978-1-4244-7573-5; POD:978-1-4244-7572-8","10.1109/ICDIM.2010.5664634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664634","","Business;Data mining;Indexes;Ontologies;Power supplies;Resource description framework;Semantics","classification;information retrieval;knowledge management;meta data;ontologies (artificial intelligence);text analysis","document handling;heterogeneous data sources;information retrieval;knowledge management;metadata;ontology-based classification;unstructured information","","0","","23","","","5-8 July 2010","","IEEE","IEEE Conference Publications"
"Multiple Factors-Based Opinion Retrieval and Coarse-to-Fine Sentiment Classification","S. Zhang; W. Jia; Y. Xia; Y. Meng; H. Yu","Fujitsu R&D Center, Inf. Technol. Lab., Beijing, China","2010 International Conference on Asian Language Processing","20110106","2010","","","199","202","Opinion mining is a growing interest task in both research and practical applications. It deals with the computational treatment of opinion, sentiment, and subjectivity in documents. This paper focuses on retrieving the opinion documents and giving their sentiment orientation. Mining and ranking the topic relevant opinion documents are implemented with a sentiment model, combining the existing knowledge and statistic information. Multi-level sentiment analysis approach is proposed to find the topic related sentiment information. Our experimental results on COAE show the effectiveness of the proposed techniques and the feasibility of classifying orientation at varying levels of granularity.","","Electronic:978-0-7695-4288-1; POD:978-1-4244-9063-9","10.1109/IALP.2010.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681623","opinion mining;opinion retrieval;sentiment classification","Blogs;Classification algorithms;Mathematical model;Semantics;Special issues and sections;Support vector machines;Thumb","data mining;information retrieval","coarse-to-fine sentiment classification;multilevel sentiment analysis approach;multiple factors-based opinion retrieval;opinion document retrieval;topic relevant opinion document mining;topic relevant opinion document ranking","","0","","14","","","28-30 Dec. 2010","","IEEE","IEEE Conference Publications"
"Removing non-informative blocks from the web pages","R. Gunasundari; S. Karthikeyan","Karpagam University, Coimbatore, India","2010 INTERNATIONAL CONFERENCE ON COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES","20101217","2010","","","810","814","With the enormous growth on the web, users get easily lost in the rich hyper structure. Thus developing user friendly and automated tools for providing relevant information without any redundant links to the users to cater to their needs is the primary task for the website owners. But user is interested only in the informative contents and not in non-informative content blocks. Web pages often contain navigation sidebars, advertisements, search blocks, copyright notices, etc which are not content blocks. The information contained in these noncontent blocks can harm web mining. So it is important to separate the informative primary content blocks from noninformative blocks. In this paper are proposed three different algorithms for removing non-content blocks from the web pages. Removal of non-informative content blocks from web pages can achieve significant storage and time saving.","","Electronic:978-1-4244-7770-8; POD:978-1-4244-7769-2","10.1109/ICCCCT.2010.5670731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670731","Web blocks;Web content mining;Web documents;noisy blocks","Algorithm design and analysis;Data mining;Entropy;Feature extraction;HTML;Web pages","Web services;Web sites;content management;data mining;information retrieval","Web blocks;Web mining;Web pages;Website;informative contents;noisy blocks;non-informative content","","0","","13","","","7-9 Oct. 2010","","IEEE","IEEE Conference Publications"
"A Novel Swarm Clustering Algorithm and its Application for CBR Retrieval","Z. j. Huang; B. q. Wang","Nat. Digital Switch Syst. Eng., Technol. R&D Center, Zhengzhou, China","2010 2nd International Conference on Information Engineering and Computer Science","20101230","2010","","","1","5","In CBR system, the case base is becoming increasingly larger with the incremental learning which results in the decline of case retrieval efficiency and its weaker performance. Aiming at such weakness of CBR system, this article proposes a novel case retrieval method based on Hybrid Ant-Fish Clustering Algorithm (HA-FC). At beginning of algorithm, we get rough cluster sets utilizing the advantage of Artificial Fish-school Algorithm which is insensitive to initial value and has high speed of searching optimizing. Then we use Ant Colony Optimization introduced the concept of Crowded Degree to avoid convergence too early and improve the ability of searching optimizing. Finally, apply this algorithm to case retrieval in order to reduce searching time and improve searching accuracy. The results of simulation demonstrate the effectiveness of this algorithm.","2156-7379;21567379","Electronic:978-1-4244-7941-2; POD:978-1-4244-7939-9","10.1109/ICIECS.2010.5678408","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5678408","","Algorithm design and analysis;Clustering algorithms;Convergence;Marine animals;Optimization;Search problems","case-based reasoning;information retrieval;optimisation;pattern clustering","CBR retrieval;ant colony optimization;case retrieval method;case-based reasoning;crowded degree concept;hybrid ant-fish clustering algorithm;swarm clustering algorithm","","0","","7","","","25-26 Dec. 2010","","IEEE","IEEE Conference Publications"
"Formalized answer extraction technology based on pattern learning","Li Peng; Teng Wen-Da; Zheng Wei; Zhang Kai-Hui","College of Computer Science and Technology, Harbin University of Science and Technology (HUST), China","International Forum on Strategic Technology 2010","20101213","2010","","","236","240","Open-domain Question Answering System is an interesting and challenging subject to research in the current field of natural language processing. The difference between QA system and the traditional text retrieval lies in the answer extraction module, which realizes the accurate answer extraction. The answer extraction on the basis of pattern matching is an efficient strategy, which focuses on displaying answers through formalized pattern. The most significant goal of the formalized answer extraction on basis of pattern matching strategy is to establish a complete pattern knowledge database. The automatic construction of formalized pattern for answer extraction is the future tendency of formalized extraction. Unfortunately, formalized answer extraction is still less effective than the extraction method based on statistical learning. This paper analyzes the following subjects: 1. Low coverage of questions. 2. Unreliability of pattern tag. 3. Difficulty in the assessment of pattern confidence. 4. Low level of pattern generalization. Based on the above four subjects, this thesis attempts to automatically construct pattern knowledge database through pattern learning and question sorting architecture based on answer types, use reliable pattern tag to process the formalization of pattern and dramatically increase coverage and accuracy. Furthermore, assess the pattern confidence in terms of coverage and accuracy. Finally, it will put forward pattern generalization technology based on the principle of unchanged pattern major elements, which observably enhances the pattern generalizing performance. Experimental results show that the average coverage of this paper reaches 57.2%, the average accuracy reaches 46.2%; major question accuracy is 80.8% and generalization technology increases accuracy nearly 6%. In sum, this paper realizes high extraction accuracy with simple methods. Especially in the issue of pattern matching on the case, can achieve high extraction accuracy.","","Electronic:978-1-4244-9037-0; POD:978-1-4244-9038-7","10.1109/IFOST.2010.5667981","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5667981","Answer Extraction;Pattern Learning;Question Answering","Accuracy;Bismuth;Feature extraction;Manuals;Organizations;Training","learning (artificial intelligence);natural language processing;question answering (information retrieval);statistical analysis;text analysis","formalized answer extraction technology;natural language processing;open-domain question answering system;pattern knowledge database;pattern learning;pattern matching;statistical learning;text retrieval","","0","","8","","","13-15 Oct. 2010","","IEEE","IEEE Conference Publications"
"InForCE: Forum data crawling with information extraction","C. Zhang; J. Zhang","Institute of Massive Computing, Software Engineering Institute, East China Normal University, Shanghai, China","2010 4th International Universal Communication Symposium","20101213","2010","","","367","373","Forum data acquisition is the prerequisite of forum data analysis, such as opinion analysis, on-line advertisement, and so on. Since the structure of forum data usually has casual relationships with the page structure, effective forum data acquisition requires the integration of Web pages crawling and information extraction. In this paper, we propose a system InForCE for this purpose. The system includes two parts. First, we download Web pages from different forums and generate HTML documents. Second, structured data are extracted from HTML documents in the light of user requirements. During the extraction process, a novel algorithm has been proposed to transform user requirement into XSLT automatically. Our experimental results show that structured data extraction is feasible and efficient.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666252","","Crawlers;Data analysis;Data mining;HTML;Transforms;Web pages;XML","Internet;data analysis;hypermedia markup languages;information retrieval","HTML document generation;InForCE;Web pages crawling;XSLT;forum data acquisition;forum data analysis;forum data crawling;information extraction;online advertisement;opinion analysis","","1","","20","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"Evidence based similarity for document categorization","R. Mohamed; J. Watada","Graduate school of information, production and systems Waseda University, Kitakyushu, Fukuoka, Japan","2010 World Automation Congress","20101210","2010","","","1","6","The failure of effective information management over the web does not influence only on by the speed of information retrieval; but also influenced by individual and organizational activities. Thus, the search engine of information retrieval plays a pivotal role in retrieving results that are relevant to users' query. Categorization is an optimist alternative to improve the accuracy and speed of information retrieval. This paper proposes a method using evidential reasoning based on similarity for text categorization. Term and frequency of term has influenced the process of deciding the document category. In order to define a new category for new document, our proposed method has taking degree similarities into consideration.","2154-4824;21544824","Electronic:978-1-889335-42-1; POD:978-1-4244-9673-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5665447","categorization;evidential reasoning;latent semantic analysis;similarity","","Internet;information retrieval;search engines;text analysis","Web;document categorization;evidence based similarity;information management;information retrieval;search engine;text categorization","","0","","17","","","19-23 Sept. 2010","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Study on Texture Information Extraction and Application of SPOT5 Basing on Wavelet Transform","C. Li; Z. Yang","Dept. of Resource & Environ., North China Inst. of water Conservancy & Hydroelectric Power, Zhengzhou, China","2010 2nd International Conference on Information Engineering and Computer Science","20101230","2010","","","1","4","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>In this paper, the method of texture information extraction based on wavelet transform is discussed in detail, then the Principle Component Analysis(PCA) is performed to SPOT5 image, using software MATLAB, the texture information extraction of the first principle component basing on wavelet transform is completed, and two type of texture information are achieved, they are mean texture image and standard deviation texture image. Through analysis of the texture information and band combinations, the selected bands with texture information are used in classification, the method of Maximum Likelihood Classification is executed in the study, comparing to the applying the spectral information only, the overall accuracy raises from 67.3% to 81.9%, and the kappa index raises from 0.676 to 0.764 when using texture information. The result showed that classification overall accuracy and kappa index are all improved in the study.","2156-7379;21567379","Electronic:978-1-4244-7941-2; POD:978-1-4244-7939-9","10.1109/ICIECS.2010.5677743","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5677743","","Accuracy;Data mining;Discrete wavelet transforms;Remote sensing;Wavelet analysis","information retrieval;maximum likelihood estimation;principal component analysis;wavelet transforms","SPOT5 image;band combinations;kappa index;maximum likelihood classification;mean texture image;principle component analysis;standard deviation texture image;texture information extraction;wavelet transform","","0","","9","","","25-26 Dec. 2010","","IEEE","IEEE Conference Publications"
"Combining Multi-features with Conditional Random Fields for Person Recognition","S. Zhang","Dept. of Electron. & Commun. Eng., North China Electr. Power Univ., Baoding, China","2010 International Conference on Asian Language Processing","20110106","2010","","","178","181","With the development of natural language processing (NLP) technology, the need for automatic named entity recognition (NER) is highlighted in order to enhance the performance of information extraction systems. In this paper, a hybrid model for Chinese person based on conditional random fields model is proposed, which fuses multiple features. It differentiates from most of the previous approaches, it use the same linguistics model to recognize Chinese person name and transliterated person name, where, combining multi-knowledge and multi-features, the inner-feature and its context information of person were considered. Analyzing context component of word information and inner particle information of entity, the multi-features can be integrated into a unified framework which includes the local feature, relation feature, globe feature and heuristic human knowledge. Based conditional random fields, the new linguistics model are built. And the performance were be improved, The experimental results show that the precision is 94.87%, the recall is 93.76% and the F-measure is 94.31% in People's Daily (January, 1998), And the experiments on MSAR corpus of the SIGHAN 2006 also confirm the better performance, which show that this hybrid model has consistence on different testing data sources. This can prove the validity of this approach.","","Electronic:978-0-7695-4288-1; POD:978-1-4244-9063-9","10.1109/IALP.2010.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681608","conditional random fields;information extraction;named entity recognition","Context;Data models;Feature extraction;Hidden Markov models;Semantics;Silicon;Training","information retrieval;natural language processing;random processes","automatic named entity recognition;conditional random fields;information extraction systems;linguistics model;multi-features;multi-knowledge;natural language processing;person recognition","","1","","8","","","28-30 Dec. 2010","","IEEE","IEEE Conference Publications"
"The Research on Concept Semantic Similarity Computing Based on Semantic Tree","W. Zhang; L. Duan; J. Chen","Comput. & Software Coll., Taiyuan Univ. of Technol., Taiyuan, China","2010 International Symposium on Intelligence Information Processing and Trusted Computing","20101210","2010","","","324","327","The concept semantic similarity computation has vast application in the question answering system field, semantic similarity is becoming the basis of semantic expansion in the question answering system, and influences the recall rate and precision rate of the question answering system immensely. After we analyze the traditional method of semantic similarity computation, we consider comprehensively the important influential factors: depth, density, strength of the edge and concept semantic overlap degree, concept level difference. The paper presents a semantic tree-based concept semantic similarity computation method, and verifies the algorithm's validity.","","Electronic:978-0-7695-4196-9; POD:978-1-4244-8148-4","10.1109/IPTC.2010.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663220","concept semantic similarity;question answering system;semantic distance","Calculators;Equations;Mathematical model;Ontologies;Semantics;Software algorithms","query formulation;query processing;question answering (information retrieval);semantic Web","concept semantic similarity computation;precision rate;question answering system;recall rate;semantic tree","","0","","3","","","28-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"An intelligent inter database retrieval system based on Multi-agent","H. Zhang; G. Yang; G. Li; B. Chen; X. Xiaoping","Hulunbuir Grassland Ecosystem Observation and Research Station, Beijing 100081, China","2010 World Automation Congress","20101210","2010","","","101","105","This paper demonstrates the design of inter database retrieval system based on Multi-Agent. Interface agent, cooperation agent, collection agent, retrieval agent are used to realize intelligence in this system. A mobile agent is adopted to communicate with other agents. They coordinate with each other to complete retrieval tasks. The system is an important research project in the field of Web database retrieval. It can meet the user's demand of inter database retrieval. At the same time the hotspot issues in the system are studied and discussed.","2154-4824;21544824","Electronic:978-1-889335-42-1; POD:978-1-4244-9673-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5665461","Cooperation Agent;Inter Database Retrieval;Interface Agent;Meta data;Search Engine","Artificial intelligence;Computational modeling;Computers;Databases;Multiagent systems;Object oriented modeling;Search problems","Internet;database management systems;information retrieval;mobile agents;multi-agent systems","Web database retrieval;collection agent;cooperation agent;intelligent inter database retrieval system;interface agent;mobile agent;multiagent;retrieval agent","","0","","13","","","19-23 Sept. 2010","","IEEE","IEEE Conference Publications"
"Overview of artificial emotion in music","Bin Zhu; ZhiCan Bai","College of information science of technology, Zhejiang Shuren University, Hangzhou, 310015, China","2010 IEEE 11th International Conference on Computer-Aided Industrial Design & Conceptual Design 1","20110106","2010","2","","1577","1581","Due to the essential features of music emotion, affective computing research in the field of music can accomplish much. And it is becoming a hot issue in the field of artificial intelligence and multimedia. This paper analyses the forms and contents of affective computing research, and focus on the content of the three specific researches: computer music emotion recognition, emotional semantic-driven music retrieval, emotional music synthesis technology. Finally, this paper concludes the possible future research directions.","","Electronic:978-1-4244-7974-0; POD:978-1-4244-7973-3","10.1109/CAIDCD.2010.5681904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681904","Affective computing;computer music emotion recognition;emotional music synthesis technology;emotional semantic-driven music retrieval","Computational modeling;Computers;Emotion recognition;Humans;Mathematical model;Music;Psychology","artificial intelligence;emotion recognition;information retrieval;multimedia systems;music","affective computing research;artificial emotion;artificial intelligence;computer music emotion recognition;emotional music synthesis technology;emotional semantic-driven music retrieval;multimedia","","0","","31","","","17-19 Nov. 2010","","IEEE","IEEE Conference Publications"
"A Multiplicative Weights Mechanism for Privacy-Preserving Data Analysis","M. Hardt; G. N. Rothblum","Dept. of Comput. Sci., Princeton Univ., Princeton, NJ, USA","2010 IEEE 51st Annual Symposium on Foundations of Computer Science","20101217","2010","","","61","70","We consider statistical data analysis in the interactive setting. In this setting a trusted curator maintains a database of sensitive information about individual participants, and releases privacy-preserving answers to queries as they arrive. Our primary contribution is a new differentially private multiplicative weights mechanism for answering a large number of interactive counting (or linear) queries that arrive online and may be adaptively chosen. This is the first mechanism with worst-case accuracy guarantees that can answer large numbers of interactive queries and is efficient (in terms of the runtime's dependence on the data universe size). The error is asymptotically optimal in its dependence on the number of participants, and depends only logarithmically on the number of queries being answered. The running time is nearly linear in the size of the data universe. As a further contribution, when we relax the utility requirement and require accuracy only for databases drawn from a rich class of databases, we obtain exponential improvements in running time. Even in this relaxed setting we continue to guarantee privacy for any input database. Only the utility requirement is relaxed. Specifically, we show that when the input database is drawn from a smooth distribution - a distribution that does not place too much weight on any single data item - accuracy remains as above, and the running time becomes poly-logarithmic in the data universe size. The main technical contributions are the application of multiplicative weights techniques to the differential privacy setting, a new privacy analysis for the interactive setting, and a technique for reducing data dimensionality for databases drawn from smooth distributions.","0272-5428;02725428","Electronic:978-0-7695-4244-7; POD:978-1-4244-8525-3","10.1109/FOCS.2010.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670948","","Accuracy;Data privacy;Databases;Histograms;Noise;Noise measurement;Privacy","data analysis;data privacy;query processing;question answering (information retrieval);statistical analysis","data dimensionality reduction;data universe;differentially private multiplicative weights mechanism;multiplicative weights mechanism;privacy-preserving data analysis;statistical data analysis","","32","","14","","","23-26 Oct. 2010","","IEEE","IEEE Conference Publications"
"AKSHR: A novel framework for a Domain-specific Hidden Web Crawler","K. K. Bhatia; A. K. Sharma; R. Madaan","Department of Computer Engineering, YMCA Institute of Engineering, Faridabad, India","2010 First International Conference On Parallel, Distributed and Grid Computing (PDGC 2010)","20110106","2010","","","307","312","Existing search engines crawl and index surface web, ignoring hidden web which otherwise contains more than 500 times of information than PIW. In this paper, a Domain-specific Hidden Web Crawler (AKSHR) is being proposed. The framework extracts hidden web pages by accruing benefits of its three unique features: 1) automatic downloading of search interfaces to crawl hidden web databases, 2) identification of semantic mappings between search interface elements by using a novel approach called DSIM (Domain-specific Interface Mapper), and 3) the capability to automatic filling of search interfaces. The effectiveness of proposed framework has been evaluated through experiments using real web sites and encouraging preliminary results were obtained.","","Electronic:978-1-4244-7674-9; POD:978-1-4244-7675-6","10.1109/PDGC.2010.5679916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5679916","Crawling;Hidden Web;search engine;search interfaces;semantic mapping","Crawlers;Data mining;Databases;Filling;Search engines;Semantics;Web pages","Web sites;information retrieval;search engines","AKSHR;Web sites;automatic downloading;crawl hidden Web database;domain-specific hidden Web crawler;domain-specific interface mapper;hidden Web pages;index surface Web;search engines crawl;search interfaces;semantic mapping","","3","","17","","","28-30 Oct. 2010","","IEEE","IEEE Conference Publications"
"Secure information extraction from clinical documents using SNOMED CT gazetteer and natural language processing","S. Hina; E. Atwell; O. Johnson","School of Computing, University of Leeds, UK","2010 International Conference for Internet Technology and Secured Transactions","20101230","2010","","","1","5","Patient Data is critical in healthcare domain and it should be secure, consistent and coded for the secure transfer from one potential user to another. SNOMED CT (Systematized Nomenclature of Medicine - Clinical Terms) is a standardized reference terminology that consists of millions of SNOMED CT concepts with SNOMED CT codes. This paper describes the extraction of natural language concepts from free text discharge summary reports and mapping with SNOMED CT codes. For the evaluation of the medical concepts, we selected 300 discharge summaries corpus provided by University of Pittsburgh Medical Centre, and compared it with the SNOMED CT concept file which is preprocessed and cleaned file listing SNOMED CT concepts. In this paper we present the ongoing research on SNOMED CT concept extraction from discharge summaries using natural language processing and introducing SNOMED CT core concepts as a gazetteer list for concept extraction. Out of 390023 concepts, 21563 concepts were found in the test set of discharge summaries from SNOMED CT core concepts gazetteer list.","","Electronic:978-0-9564263-6-9; POD:978-1-4244-8862-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5678112","","Data mining;Discharges;Logic gates;Medical diagnostic imaging;Medical services;Natural language processing","document handling;health care;information retrieval;medical information systems;natural language processing;security of data","SNOMED CT gazetteer;University of Pittsburgh medical centre;clinical documents;clinical terms;healthcare domain;natural language processing;patient data;secure information extraction;systematized nomenclature of medicine","","0","","16","","","8-11 Nov. 2010","","IEEE","IEEE Conference Publications"
"The NICT concept dictionary","S. S. De; T. Kenzaro; K. Jun'ichi; O. Kiyonori; V. Isrvan; Y. Yulan","National Institute of Information and Communications Technology, Japan","2010 4th International Universal Communication Symposium","20101213","2010","","","403","403","Summary form only given. In this demonstration we present a system that guides a user's information search (or knowledge discovery) by displaying, in a coordinated manner, many valuable keywords having important semantic relations to the user's topic of interest. For example, the system contains large-scale databases of typical and not-so-typical semantic relations like “object/troubles”, “troubles/preventions”, “cause/effects” or “foods/health effects”, and so on. Clicking these keywords issues a usual Web search or leads to further recursive exploration of the semantic relation space, enabling the discovery of valuable “unknown unknowns” for the user. The semantic relations in the system are automatically acquired from a large collection of Web documents using state-of-the-art knowledge acquisition methods. These methods require only minimal human intervention, so the system can be easily customized to obtain many different kinds of relations and adapted to new target domains. Additionally, we demonstrate the system's usefulnes for innovation support based on analogy and lexical word similarity. Finally, we demonstrate the system's recently developed speech interface, which enables the user to perform on-the-fly information extraction from 600 million Web pages using natural language questions, in the form of an speech-enabled question answering (QA) system.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666637","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666637","","","data mining;dictionaries;information retrieval;speech-based user interfaces","NICT concept dictionary;Web page;Web search;knowledge discovery;large-scale database;lexical word similarity;natural language question;on-the-fly information extraction;speech interface;speech-enabled question answering system;user information search","","0","","","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"Implementation of Intelligent Searching Using Self-Organizing Map for Webmining Used in Document Containing Information in Relation to Cyber Terrorism","Endy; C. lim; K. I. Eng; A. S. Nugroho","Dept. of Inf. Technol., Swiss German Univ., Tangerang, Indonesia","2010 Second International Conference on Advances in Computing, Control, and Telecommunication Technologies","20101223","2010","","","195","197","The terrorism activities are not only in real world as development of technology, but also in cyber world. Terrorism activities in cyber world are called cyber terrorism. One of methodology for cyber terrorism detection is by applying data mining algorithm to textual content of terrorism related web pages. Web mining is technology applied to extract information from the web. By using web mining, cyber terrorism information will be collected from internet. This research aims to use text cluster technique, by which the web documents are clustered using Self-Organizing Map algorithm based on number of occurrences of the certain words in documents that have relevance to cyber terrorism. The result shows mapping of the clustered documents that have performance 6.1 and 22.75 in term of vector quantization error (VQE). According this result, we concluded that Self-Organizing Map (SOM) is able to visualizethe topology of the data, by converting statistical relationship among the data into simple geometrical relationship of their image points in 2-dimensional grid.","","Electronic:978-0-7695-4269-0; POD:978-1-4244-8746-2","10.1109/ACT.2010.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5675810","Self-Organizing Map;cyber terrorism;intelligent searching","Computers;Government;Internet;Neurons;Terrorism;Vector quantization;Web mining","Internet;computer crime;data mining;information retrieval;pattern clustering;self-organising feature maps;terrorism;vector quantisation","Web documents;Web mining;Web pages;cyber terrorism detection;data mining algorithm;information extraction;intelligent searching;internet;selforganizing map algorithm;text cluster technique;vector quantization error","","2","","4","","","2-3 Dec. 2010","","IEEE","IEEE Conference Publications"
"Achieving design innovation in the new century","Yinan Li; Bin Jiang","School of Arts, Southeast University, Nanjing, Jiangsu Province, China","2010 IEEE 11th International Conference on Computer-Aided Industrial Design & Conceptual Design 1","20110106","2010","1","","571","574","In the new century, computer and network technology greatly extends the original boundaries of design, enriches and expands the design thinking and methods of artistic production. To design means both the “endless possibilities” and “everywhere”: Users can access to information easier than before, the ways to appreciate design are becoming increasingly diversified. No matter how well designed, creating new designs means that human spirit and emotional view can't be overlooked. Providing objective, rational look at the design of the new century, three aspects are explored - from cultural dimension, rhetorical dimension and dimension of games. It provides the emerging contemporary design innovations a new reference.","","Electronic:978-1-4244-7974-0; POD:978-1-4244-7973-3","10.1109/CAIDCD.2010.5681283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681283","Design Innovation;Dimensio;New Century","Cultural differences;Presses","art;design;information retrieval;innovation management","achieving design innovation;cultural dimension;game dimension;human spirit;information access;network technology;new century;production method;rhetorical dimension","","0","","5","","","17-19 Nov. 2010","","IEEE","IEEE Conference Publications"
"Research of PageRank Algorithm Based on Transition Probability","H. Ma; S. Chen; D. Wang","Software Inst., Dalian Jiaotong Univ., Dalian, China","2010 International Conference on Web Information Systems and Mining","20110113","2010","1","","153","155","In order to improve the veracity of the web search, this paper studies the PageRank algorithm, proposes a new method PBTP Algorithm (PageRank Based on Transition Probability), that is an improvement for the classical PageRank method. As forwarding links in a web page are different, the transition probability of a link to be clicked is different too. For the classical PageRank value, should assign more authority value to the page according to its clicking probability with high authority value, effectively to focus the authority value on more meaningful web page, finally extracts meaningful page with high authority value. This paper takes advantage of Web link structure, proposes an unequal way to treat the different pages when distributing authorities. And the experiment shows that PBTP can improve PageRank effectively.","","Electronic:978-0-7695-4224-9; POD:978-1-4244-8438-6","10.1109/WISM.2010.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662302","PBTP;PageRank;distributing authority;transition probability","","Web sites;information retrieval;probability","PageRank based on transition probability algorithm;Web link structure;Web page;Web search;authority value;clicking probability","","1","","4","","","23-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Expertise analysis of information senders of Web pages","Y. Kato; K. Inui; S. Kurohashi","National Institute of Information and Communications Technology, Seika, Kyoto, Japan 619-0289","2010 4th International Universal Communication Symposium","20101213","2010","","","135","140","In this study, we address the problem of searching experts in an arbitrary topic on the Web. In particular, we propose two methods that analyze the expertise of information senders of Web pages: 1) a method that computes expertise score based on hit count from a search engine (hit count method), and 2) a method that computes expertise score based on the number of documents that are attributed to an information sender (attribution count method). We evaluated both methods using a crawl and search infrastructure which indexes 120 million Japanese Web pages. The results show that the attribution count method outperforms hit count method in terms of precision and processing time.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666231","","Data mining;Electronic mail;Feature extraction;Organizations;Search engines;Web pages","Internet;information retrieval;search engines","Web pages;attribution count method;crawl-search infrastructure;expertise analysis;expertise score computation;hit count method;information sender;search engine","","0","","16","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"Quality benchmarking relational databases and Lucene in the TREC4 adhoc task environment","A. Arslan; O. Yilmazel","Anadolu University, Computer Engineering Department, Eskisehir, Turkey","Proceedings of the International Multiconference on Computer Science and Information Technology","20110106","2010","","","365","372","The present work covers a comparison of the text retrieval qualities of open source relational databases and Lucene, which is a full text search engine library, over English documents. TREC-4 adhoc task is completed to compare both search effectiveness and search efficiency. Two relational database management systems and four different well-known English stemming algorithms have been tried. It has been found that language specific preprocessing improves retrieval quality for all systems. The results of the English text retrieval experiments by using Lucene are at par with top six results presented at TREC-4 automatic adhoc. Although open source relational databases integrated full text retrieval technology, their relevancy ranking mechanisms are not as good as Lucene's.","2157-5525;21575525","Electronic:978-83-60810-27-9; POD:978-1-4244-6432-6","10.1109/IMCSIT.2010.5679643","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5679643","","Indexes;Libraries;Natural languages;Relational databases;Search engines","benchmark testing;database management systems;information retrieval;public domain software;relational databases;search engines;text analysis","Lucene;TREC4 adhoc task environment;english document;english stemming algorithm;english text retrieval;language specific preprocessing;open source relational databases;quality benchmarking relational database;relational database management system;retrieval quality;search engine library;text retrieval quality","","0","","20","","","18-20 Oct. 2010","","IEEE","IEEE Conference Publications"
"Chinese Scientific & Technical Vocabulary System for domain content computing","Y. Zhang; S. Xu; L. Zhu; X. Qiao; C. Xue; S. Jiao; Y. Yan","Institute of Scientific and Technical Information of China, Beijing, China","2010 4th International Universal Communication Symposium","20101213","2010","","","281","285","Chinese Scientific & Technical Vocabulary System (CSTVS) is a kind of knowledge organization systems for Chinese SCIENTIFIC & TECHNICAL information resources management and deep knowledge services that proposed by us. Now we provides the CSTVS as free semantic resources for research and education users all over the world. In this paper, knowledge infrastructure and related content computing tools are introduced. The related resources and tools of CSTVS in new energy vehicles domain (NEV-CSTVS) will provide as the first batch, which is used in some research projects. CSTVS will provide more semantic resources for domain content computing and that the uses of CSTVS will promote and improve the future large-scale practice.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666006","Chinese scientific & technical vocabulary system;content computing;knowledge organization system;new energy vehicles domain;semantic resources","Computers;Dictionaries;Organizations;Semantics;Thesauri;Vocabulary","information resources;information retrieval;vocabulary","Chinese scientific-technical information resources management;Chinese scientific-technical vocabulary system;deep knowledge services;domain content computing;knowledge infrastructure;knowledge organization systems","","0","","10","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"Offline web application and quiz synchronization for e-learning activity for mobile browser","R. M. Ijtihadie; Y. Chisaki; T. Usagawa; H. B. Cahyo; A. Affandi","Graduate School Of Science And Technology, Kumamoto University, Japan","TENCON 2010 - 2010 IEEE Region 10 Conference","20110113","2010","","","2402","2405","Rapid growing of internet applications and users has led the improvement of mobile web browser technology and standards such as HTML5. Recently, HTML5 is turning to be a de facto standard after some of its features has been implemented in major mobile web browsers. Moodle as a web based Learning Management System (LMS) has been popular in academic environment for supporting learning activities and allows teacher giving quiz online. However, some schools do not have an such expensive infrastructure to bring their LMS to the Internet. In addition, at home, some students may have difficulties to get online access. To address such problem, In this paper, we propose a prototype of offline web application and task synchronization in e-learning activity. This system utilizes the offline application capability and web storage of HTML5 enabled mobile web browser to bring an offline user interface to students. Using this system students are able synchronize their mobile phone with campus moodle for task retrieval/submission during their time in campus. and later doing the task at home without having to get online. Besides giving the concept, a prototype has been implemented to show its functionality.","2159-3442;21593442","Electronic:978-1-4244-6890-4; POD:978-1-4244-6889-8","10.1109/TENCON.2010.5685899","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685899","","","Internet;computer aided instruction;distance learning;information retrieval;mobile handsets;online front-ends;synchronisation;user interfaces","HTML5;Internet application;LMS;Web storage;academic environment;campus moodle;de facto standard;e-learning activity;learning management system;mobile Web browser technology;mobile phone;offline Web application;online access;quiz synchronization;task synchronization;user interface","","4","","12","","","21-24 Nov. 2010","","IEEE","IEEE Conference Publications"
"Narrowband information encryption using frequency and phase cipher","T. Yeminy; D. Sadot; Z. Zalevsky","Department of Electro, Optical Engineering, Ben Gurion University","2010 IEEE 26-th Convention of Electrical and Electronics Engineers in Israel","20101213","2010","","","000077","000080","In this paper, we propose a method for optical communication encryption, based on multi-sub carriers modulation, reducing the transmitted signal effectively below the noise level. The information reconstruction is possible only if the frequencies of the carriers, the phase distortion, and the sampling frequency at the transmitter are in hand. Sampling the signal before transmission improves the SNR after reconstruction, enabling to transmit a low power signal with a low SNR which results in a stealthy transmission.","","Electronic:978-1-4244-8682-3; POD:978-1-4244-8681-6","10.1109/EEEI.2010.5661917","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661917","","Bandwidth;Baseband;Frequency domain analysis;Phase distortion;Receivers;Signal to noise ratio;Wavelength division multiplexing","cryptography;information retrieval;optical modulation;optical transmitters;signal sampling","SNR;frequency cipher;information reconstruction;low power signal;multisubcarrier modulation;narrowband information encryption;optical communication encryption;phase cipher;phase distortion;sampling frequency;transmitter","","0","","6","","","17-20 Nov. 2010","","IEEE","IEEE Conference Publications"
"Flash memory SSD based DBMS for high performance computing embedded and multimedia systems","S. S. Rizvi; T. S. Chung","Department of Computer Science, Military College of Signals, National University of Sciences and Technology, Islamabad, Pakistan","The 2010 International Conference on Computer Engineering & Systems","20101223","2010","","","183","188","Flash memory based large capacity SSDs open the doors on high performance computing applications by offering remarkable throughput and amazing reliability. However, flash memory hardware characteristics like erase-before-write and limited endurance cycles do not allow disk based schemes implication directly. For employing such schemes, we need to revise them on some level to make them effective for flash media. Regarding, the researchers have devoted considerable efforts to implement the DBMSs on flash for fast retrieval of data that is bit indolent using file systems. However, previous techniques require huge main memory space and high computational power for data processing. This paper proposes an advanced DBMS architecture using key sequenced data set, virtual sequential access method and multilevel indexing for flash memory SSD based performance oriented embedded and multimedia applications. Basic database operations plus space reclamation and memory wear-leveling are achieved by taking flash characteristics into account carefully. Main memory based buffer management is implemented to increase throughput and for efficient media utilization. Comprehensive performance evaluations using two modern benchmarks prove less overhead with high reliability and outstanding throughput for flash SSD based DBMSs compare to HDD.","","Electronic:978-1-4244-7042-6; POD:978-1-4244-7040-2","10.1109/ICCES.2010.5674850","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674850","DBMS;embedded systems;flash memory SSD;high performance computing;multimedia applications;storage management","Flash memory;Indexes;Media;Memory management;Multimedia communication;Throughput","buffer storage;database indexing;embedded systems;flash memories;information retrieval;multimedia computing;multimedia databases;performance evaluation","DBMS architecture;buffer management;data retrieval;embedded systems;endurance cycles;erase-before-write;file systems;flash media;flash memory SSD;flash memory hardware characteristics;flash memory solid-state-drive;high performance computing;key sequenced data set;large capacity SSDs;memory wear-leveling;multilevel indexing;multimedia systems;performance evaluations;reliability;space reclamation;virtual sequential access","","0","","22","","","Nov. 30 2010-Dec. 2 2010","","IEEE","IEEE Conference Publications"
"Using Self Organizing Map to cluster Arabic crime documents","M. Alruily; A. Ayesh; A. Al-Marghilani","Software Technology Research Laboratory, De Montfort University, The Gateway, Leicester, LE1 9BH UK","Proceedings of the International Multiconference on Computer Science and Information Technology","20110106","2010","","","357","363","This paper presents a system that combines two text mining techniques; information extraction and clustering. A rule-based approach is used to perform the information extraction task, based on the dependency relation between some intransitive verbs and prepositions. This relationship helps in extracting types of crime from documents within the crime domain. With regard to the clustering task, the Self Organizing Map (SOM) is used to cluster Arabic crime documents based on crime types. This work is then validated through experiments, the results of which show that the techniques developed here are promising.","2157-5525;21575525","Electronic:978-83-60810-27-9; POD:978-1-4244-6432-6","10.1109/IMCSIT.2010.5679616","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5679616","","Context;Data mining;Data visualization;Grammar;Neurons;Organizing;Pragmatics","data mining;document handling;information retrieval;knowledge based systems;natural language processing;pattern clustering;self-organising feature maps;task analysis","Arabic crime document clustering;dependency relation;information clustering;information extraction task;intransitive prepositions;intransitive verbs;rule based approach;self organizing map;text mining","","5","","23","","","18-20 Oct. 2010","","IEEE","IEEE Conference Publications"
"Ocean observatories and social computing: Potential and progress","D. Owens; M. Best; E. Guillemot; R. Jenkyns; B. Pirenne","NEPTUNE Canada, PO Box 1700 STN CSC, Victoria, BC V8W2Y2 Canada","OCEANS 2010 MTS/IEEE SEATTLE","20101210","2010","","","1","9","In December 2009, after years of planning, preparations and extensive infrastructure deployment, the world's first regional-scale underwater ocean observatory was open for business. NEPTUNE Canada opened its instrument network and data archive to free and open access by anyone willing to register for an account. Thus, we have embarked on a journey to transform our observatory into an online platform for collaborative, multidisciplinary e-science. Four main areas of Internet-mediated activity characterize e-science: data provision, analysis & visualization, collaboration and publication. Data provision entails making our large and ever expanding data archive accessible and searchable through the Web. To support online analysis & visualization, tools must be developed, which allow scientists to display and manipulate a wide variety of data products derived from measurements gathered by the various instruments attached to the observatory. Virtual collaboration can be fostered by making it easy for groups of geographically or institutionally separated researchers to design experiments, control instruments, share analyses and discuss conclusions within a shared web-based workspace. Publication and dissemination of research findings can be supported by tools that help researchers manage and contribute to both informal outreach (e.g. blogs) and the iterative review and revision cycles required for formal manuscript authoring. E-science promises some tantalizing advantages over traditional approaches. By providing through-the-web access to a large multivariate data archive, researchers are freed from the burdens of data storage and management. Additionally, the archive can simultaneously serve multiple users at multiple institutions in widely separated locations. Community-driven development of analysis routines allows users to visualize the data using both existing and custom-created code. E-science also encourages higher levels of collaboration, allowing resea- chers to form virtual teams able to tackle complex problems, where expertise in a variety of disciplines is required. Finally, by opening new avenues for interaction between researchers and students or members of the general public, e-science can influence both the questions scientists choose to address and the scope of their investigations. Transforming the promise of e-science into reality, however, is fraught with both technical and organizational challenges. The sheer volume of data records (50+ Tb/year) and observation density pose significant challenges for observatory and researcher alike, requiring new data mining approaches to be developed. Evolving and sometimes competing data format standards must be grappled with. Questions of data reliability and security must be answered. New protocols for protecting intellectual property within an open data environment must be defined. Ground rules for providing equitable access to finite shared resources (eg. underwater camera control time) must be defined. Cultural, institutional and motivational barriers to distributed decision-making and virtual team coordination must be overcome. NEPTUNE Canada is working to address the many challenges of e-science through a wide range of possible solutions. To help researchers make more optimal use of our large and growing data archives, we are developing a facility that allows users to upload and run custom data analysis routines on NEPTUNE Canada servers. Code authors will be able to retain privacy of over their routines, or if desired, publish their code for sharing and possible additional development with the larger user community. NEPTUNE Canada is developing other tools in the form of web and mobile applications for data search and subscription, event detection, interactive data plotting and real-time collaborative multi-user device control. Other custom tools will give users the ability to search, browse and annotate streaming media, then integrate and compile playlists","0197-7385;01977385","Electronic:978-1-4244-4333-8; POD:978-1-4244-4332-1","10.1109/OCEANS.2010.5664303","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664303","","Cameras;Collaboration;Data visualization;Instruments;Observatories;Oceans;Streaming media","Internet;data analysis;data mining;data visualisation;decision making;geographic information systems;geophysics computing;groupware;industrial property;information retrieval systems;oceanographic techniques;protocols;real-time systems;security of data;social networking (online)","NEPTUNE Canada;annotate streaming media;data mining;data provision;data reliability;data security;data storage;decision making;intellectual property protection;interactive data plotting;manuscript authoring;multidisciplinary e-science;online data analysis;online data visualization;protocol;real time collaborative multiuser device control;regional scale underwater ocean observatory;social computing;virtual collaboration","","0","1","4","","","20-23 Sept. 2010","","IEEE","IEEE Conference Publications"
"Semantic data placement for power management in archival storage","A. Wildani; E. L. Miller","Storage Systems Research Center, University of California, Santa Cruz, USA","Petascale Data Storage Workshop (PDSW), 2010 5th","20101213","2010","","","1","5","Power is the greatest lifetime cost in an archival system, and, as decreasing costs make disks more attractive than tapes, spinning disks account for the majority of power drawn. To reduce this cost, we propose reducing the number of times disks have to spin up by grouping together files such that a typical spin-up handles several file accesses. For a typical system, we show that if only 30% of total accesses occur while disks are still spinning, we can conserve 12% of the power cost. We classify files according to directory structure and see access hit rates of up to 66% for a power savings of up to 52% of the power cost of spinning up for every read in easily-separable workloads.","2157-7242;21577242","Electronic:978-1-4244-8912-1; POD:978-1-4244-8913-8","10.1109/PDSW.2010.5668053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5668053","","Indexes;Internet;Mobile communication;Semantics;Servers;Spinning;Support vector machines","information retrieval;power aware computing;storage management","archival storage;directory structure;easily separable workload;file access;power management;semantic data placement;spin up handle;spinning disk","","10","","29","","","15-15 Nov. 2010","","IEEE","IEEE Conference Publications"
"Audio content-based feature extraction algorithms using J-DSP for arts, media and engineering courses","M. Shah; G. Wichern; A. Spanias; H. Thornburg","School of ECEE, SenSIP Center, Arizona State University","2010 IEEE Frontiers in Education Conference (FIE)","20101223","2010","","","T1F-1","T1F-6","J-DSP is a java-based object-oriented online programming environment developed at Arizona State University for education and research. This paper presents a collection of interactive Java modules for the purpose of introducing undergraduate and graduate students to feature extraction in music and audio signals. These tools enable online simulations of different algorithms that are being used in applications related to content-based audio classification and Music Information Retrieval (MIR). The simulation software is accompanied by a series of computer experiments and exercises that can be used to provide hands-on training. Specific functions that have been developed include modules used widely such as Pitch Detection, Tonality, Harmonicity, Spectral Centroid and the Mel-Frequency Cepstral Coefficients (MFCC). This effort is part of a combined research and curriculum program funded by NSF CCLI that aims towards exposing students to advanced multidisciplinary concepts and research in signal processing.","0190-5848;01905848","Electronic:978-1-4244-6262-9; POD:978-1-4244-6261-2","10.1109/FIE.2010.5673157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5673157","audio content search and classification;digital signal processing;feature extraction;online education;signals and systems education","Classification algorithms;Computational modeling;Feature extraction;Indexes;Multiple signal classification;Music;Speech","Java;audio signal processing;computer aided instruction;educational courses;feature extraction;information retrieval;interactive programming;music;object-oriented programming;pattern classification","Arizona State university;Java programming;audio signal;computer experiments;content-based audio classification;content-based feature extraction;curriculum program;graduate student;hands on training;interactive Java module;music information retrieval;object-oriented programming;online education;online programming;online simulation;signal processing;undergraduate student","","2","","21","","","27-30 Oct. 2010","","IEEE","IEEE Conference Publications"
"Medical Image Archiving, Processing, Analysis and Communication System for Teleradiology","P. Suapang; K. Dejhan; S. Yimmun","Department of Telecommunications Engineering, Faculty of Engineering, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand","TENCON 2010 - 2010 IEEE Region 10 Conference","20110113","2010","","","339","345","The design and implementation of Medical Image Archiving, Processing, Analysis and Communication System for Teleradiology which DICOM server was developed using software such as Borland Delphi 6.0, PHP and MySQL for image archive, image compression, image processing, image analysis and image transmission. The system provides the following facilities: (1) DICOM-format image archive. (2) Medical Image Compression. (3) DICOM viewer and Image processing, and (4) Image analysis. The results shown that (1) our system can also convert the image data both single frame and multiframes in normal or automatic DICOM process into the standard DICOM 3.0 format without altering the image data. (2) The resulting images are then compressed with two different techniques-JPEG and JPEG2000. The significant advantage of JPEG2000 over normal JPEG is that the error from JPEG2000 compression is smaller than the error from JPEG. Nevertheless, both methods share a similar mishap; when the compression ratio increases, they both generate more error than the processes on lower compression ratio. (3) our system can open single frame and multiframes such as DICOM, INTERFILE, BITMAP, JPEG and JPEG2000 each of which can exhibit information in. dcm file format with no distortion and image processing which has also the capabilities to zoom in/out and contrast/color map. And, (4) Image analysis sets ROI semi-automatically on region of expected disease based on geometric active contour model from edge of variance image and Canny edge detection. Thence, our system can calculate of Glomerular Filtration Rate (GFR), Effective Renal Plasma Flow (ERPF), and plot of the Time Activity Curve or Renogram The system has been developed and provided medical image services over long distance which showed the usefulness of our approach.","2159-3442;21593442","Electronic:978-1-4244-6890-4; POD:978-1-4244-6889-8","10.1109/TENCON.2010.5686025","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5686025","Image Analysis;Image Archiving;Image Compression;Image Processing;Teleradiology","","data compression;edge detection;image coding;information retrieval;medical image processing;radiology;visual communication","Canny edge detection;DICOM server;DICOM viewer;DICOM-format image archive;Glomerular filtration rate;JPEG2000 compression;Renogram;communication system;effective Renal plasma flow;geometric active contour model;image transmission;medical image analysis;medical image archiving;medical image compression;medical image processing;teleradiology;time activity curve;variance image","","1","","16","","","21-24 Nov. 2010","","IEEE","IEEE Conference Publications"
"Technology Navigator: A tool for zoning in","P. Wiesner; W. R. Tonti; A. Tear; P. Laplante; D. Patel; R. Sumner; H. Flescher","Future Directions, IEEE Technical Activities","2010 IEEE Frontiers in Education Conference (FIE)","20101223","2010","","","S1E-1","S1E-5","Technology Navigator is an online tool, developed by IEEE volunteers, which enables students, faculty and professionals in engineering and the sciences to discover engineering content and events relevant to them, including conferences, publications, standards, and published articles. Tags and related tags, often based on a shared “market language,” are filtered across multiple disciplines and industry sectors. This provides “contextualized discovery” for users to chart their path through the overwhelming amount of resources available through IEEE Xplore. For experienced professionals and volunteers, the Technology Navigator tool is useful in discovering gaps and convergences in areas of interest, which were previously hidden in discipline silos. It also points out opportunities for collaboration in emerging and expanding areas. This paper examines the rationale for this tool and its usefulness to students and faculty in light of ABET 2000 engineering accreditation requirements. It also focuses on the challenges data population and maintenance by IEEE volunteers.","0190-5848;01905848","Electronic:978-1-4244-6262-9; POD:978-1-4244-6261-2","10.1109/FIE.2010.5673368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5673368","","Collaboration;Conferences;Industries;Navigation;Standards;Visualization","Internet;information retrieval;user interfaces","IEEE volunteer;IEEE xplore;engineering accreditation requirement;engineering content;industry sector;online tool;published article;technology navigator","","0","","10","","","27-30 Oct. 2010","","IEEE","IEEE Conference Publications"
"Searching Social Media Streams on the Web","J. Park; Y. Shin; K. Kim; B. S. Chung","Seoul National University","IEEE Intelligent Systems","20101230","2010","25","6","24","31","FeedMil, a dedicated stream search engine, can help users retrieve dynamic real-time streams, focusing on quality and topic relevance rather than simple query matching.","1541-1672;15411672","","10.1109/MIS.2010.150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5678583","Social media;feed search;search engine;stream search","Blogs;Feature extraction;Feeds;Indexing;Media;Search engines;Twitter","information retrieval;search engines;social networking (online)","FeedMil;Web;dynamic real-time stream retrieval;search engine;social media stream searching","","5","","14","","","Nov.-Dec. 2010","","IEEE","IEEE Journals & Magazines"
"“Beautiful picture of an ugly place”. Exploring photo collections using opinion and sentiment analysis of user comments","S. Kisilevich; C. Rohrdantz; D. Keim","Department of Computer and Information Science, University of Konstanz, Germany","Proceedings of the International Multiconference on Computer Science and Information Technology","20110106","2010","","","419","428","User generated content in the form of customer reviews, feedbacks and comments plays an important role in all types of Internet services and activities like news, shopping, forums and blogs. Therefore, the analysis of user opinions is potentially beneficial for the understanding of user attitudes or the improvement of various Internet services. In this paper, we propose a practical unsupervised approach to improve user experience when exploring photo collections by using opinions and sentiments expressed in user comments on the uploaded photos. While most existing techniques concentrate on binary (negative or positive) opinion orientation, we use a real-valued scale for modeling opinion and sentiment strengths. We extract two types of sentiments: opinions that relate to the photo quality and general sentiments targeted towards objects depicted on the photo. Our approach combines linguistic features for part of speech tagging, traditional statistical methods for modeling word importance in the photo comment corpora (in a real-valued scale), and a predefined sentiment lexicon for detecting negative and positive opinion orientation. In addition, a semi-automatic photo feature detection method is applied and a set of syntactic patterns is introduced to resolve opinion references. We implemented a prototype system that incorporates the proposed approach and evaluates it on several regions in the World using real data extracted from Flickr.","2157-5525;21575525","Electronic:978-83-60810-27-9; POD:978-1-4244-6432-6","10.1109/IMCSIT.2010.5679726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5679726","","Blogs;Dictionaries;Feature extraction;Frequency measurement;Internet;Motion pictures;Syntactics","Internet;behavioural sciences computing;feature extraction;information retrieval;software prototyping;user modelling","Flickr;Internet services;binary opinion orientation;data extraction;linguistic features;photo collections;photo comment corpora;photo quality;practical unsupervised approach;predefined sentiment lexicon;prototype system;real-valued scale;semiautomatic photo feature detection method;speech tagging;syntactic patterns;traditional statistical methods;user attitudes;user experience;user opinions;word importance modeling","","2","","32","","","18-20 Oct. 2010","","IEEE","IEEE Conference Publications"
"Video acquisition, archiving, annotation and analysis: NEPTUNE Canada's real-time georeferenced library of deep sea video","M. Leslie; N. Scott; E. Guillemot; V. Auger","NEPTUNE Canada, PO Box 1700 Stn CSC, Victoria, B.C. V8W 2Y2 Canada","OCEANS 2010 MTS/IEEE SEATTLE","20101210","2010","","","1","9","Precise positioning of scientific instruments on an undersea cabled observatory is crucial for successful data collection. The majority of researchers for NEPTUNE Canada's 800km cabled ocean observatory are geographically diverse, and it is both expensive and time-consuming to be physically present during instrument deployment. We have developed an economical, scalable web application that allows researchers to interact, collaborate and review video collected during live ROV operations. For over 20 years ocean research vessels have been equipped with satellite uplink capability, allowing researchers on land to participate in observing live dive operations and ocean phenomena. Perhaps the most famous example is the JASON project, a collaboration started in 1989 between Robert Ballard, WHOI and National Geographic Society. There are significant costs associated to host the uplink and downlink, however, and researchers may not be able to easily communicate with the chief scientist on board the ship and with each other. Worse, the video footage may be archived with very little metadata, mission time or easy means of cataloguing and retrieval. These problems were addressed in a uniquely collaborative venture between NEPTUNE Canada, the Canadian Scientific Submersible Facility (CFFS) and Canada's Advanced Research & Innovation Network (CANARIE). In this paper we report on the development of software and infrastructure enabling live video observation, online annotation and archiving of instrument positioning on the NEPTUNE Canada ocean observatory. The paper will detail the software design, infrastructure and quality assurance processes used to deploy this innovative, cost effective solution which successfully addresses the needs of the ocean science and engineering communities.","0197-7385;01977385","Electronic:978-1-4244-4333-8; POD:978-1-4244-4332-1","10.1109/OCEANS.2010.5664305","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664305","","High definition video;Marine vehicles;Navigation;Oceans;Real time systems;Sensors;Streaming media","Internet;geographic information systems;groupware;information retrieval systems;marine engineering;software architecture;video databases;video signal processing","Canada;Canada's Advanced Research & Innovation Network;Canadian Scientific Submersible Facility;NEPTUNE;ROV operation;instrument positioning;metadata;ocean observatory;quality assurance process;software design;video acquisition;video analysis;video annotation;video archiving","","2","","18","","","20-23 Sept. 2010","","IEEE","IEEE Conference Publications"
"A recommendation model for personalized book lists","S. Maneewongvatana; S. Maneewongvatana","Department of Computer Engineering, King Mongkut's University of Technology Thonburi, Thailand","2010 10th International Symposium on Communications and Information Technologies","20101210","2010","","","389","394","In this study, we present a novel approach to recommend the personalized book lists for the university members. Our approach consists of clustering the university members into different clusters based on their recent circulation activities and discovering the interest patterns of members in the cluster. In the first step, we clustered members sharing the common interests to the same cluster by using K-means algorithm, after that we explored the possible interest patterns performed by members in each cluster by association rules. Finally, we provided the recommended book lists that satisfy their individual needs and interest patterns. A questionnaire survey was performed to evaluate the accuracy satisfaction of predicting the satisfy book list to an individual. The evaluation results reveal the possibility of using circulation activity history to predict the current interest of an individual member and construct the personalized book lists that satisfy their interests.","","Electronic:978-1-4244-7010-5; POD:978-1-4244-7007-5; USB:978-1-4244-7009-9","10.1109/ISCIT.2010.5664873","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664873","","Association rules;Books;Clustering algorithms;History;Itemsets;Libraries","data mining;information retrieval;pattern clustering;recommender systems;user interfaces","K-means algorithm;association rules;circulation activity history;pattern clustering;pattern discovery;personalized book list;recommendation model;university member","","4","1","9","","","26-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Advanced vocal web browser","M. Sazbon; Y. Haddad","School of Engineering, Computer Science & Networks Dept., Jerusalem College of Technology (JCT)","2010 IEEE 26-th Convention of Electrical and Electronics Engineers in Israel","20101213","2010","","","000732","000735","Nowadays, more than 2 billion people around the world have access to the Internet regularly, and the Internet is the most important platform for information, work and entertainment with more than 150 million active websites. However, these websites are accessible only through devices equipped with a screen and a Graphical User Interface (GUI). Furthermore, these devices need a network connection to access the internet. With the development of a Vocal User Interface (VUI), Artificial Intelligence (AI) and VoIP communication, we present in this article a system which allows browsing the Internet by using a standard phone only. The system works like an intelligent call routing mechanism that accepts vocal commands as input from the user, translates those commands into HTTP requests, sends them to the web server which processes it and finally returns the HTTP response translated back to the user in a vocally manner. To reach this goal the system implements Content Extraction (CE) algorithms over web content in order to analyze, classify and return relevant parts of web pages to the user. We conducted a series of experiments to evaluate the performance of the system. Our results show that the system offers a reliable and efficient web browsing experience in more than 80% of the websites tested. Its applications are numerous: for example helping the blind access the internet through speech and hearing, helping disabled people or young children unable to use a keyboard to “speak” their commands into the web, or, simply enabling any person to interface the web contents via oral commands, instead of a keyboard.","","Electronic:978-1-4244-8682-3; POD:978-1-4244-8681-6","10.1109/EEEI.2010.5662114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662114","","Browsers;HTML;Internet;Servers;Speech recognition;Visualization;Web pages","Internet;Web sites;graphical user interfaces;information retrieval;keyboards;online front-ends;speech-based user interfaces","HTTP requests;VoIP communication;artificial intelligence communication;content extraction algorithm;graphical user interface;intelligent call routing;keyboard;network connection;screen;vocal user interface;vocal web browser","","0","","4","","","17-20 Nov. 2010","","IEEE","IEEE Conference Publications"
"Anomaly detection in GPS data based on visual analytics","Z. Liao; Y. Yu; B. Chen","University of Illinois at Urbana-Champaign","2010 IEEE Symposium on Visual Analytics Science and Technology","20101210","2010","","","51","58","Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.","","Electronic:978-1-4244-9487-3; POD:978-1-4244-9488-0","10.1109/VAST.2010.5652467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5652467","Feature evaluation and selection;H.1.2 [Models and Principles]: User/Machine Systems-Human information processing;H.5.2 [Information Interfaces and Presentation]: User Interfaces-Graphics user interfaces;I.5.2 [Pattern Recognition]: Design Methodology-Pattern analysis","Data models;Data visualization;Global Positioning System;Histograms;Humans;Machine learning;Training","Global Positioning System;data analysis;data flow analysis;data visualisation;graphical user interfaces;human computer interaction;information retrieval;learning (artificial intelligence);visual databases","GPS Visual Analytics System;anomaly detection;conditional random field model;data driven modeling;domain specific expertise;high level intelligence;human computer interaction;information extraction;interactive user interface;machine learning;real time data behavior;visualization","","18","9","28","","","25-26 Oct. 2010","","IEEE","IEEE Conference Publications"
"Weak Signal De-noising Method Based on Accumulation in Frequency Domain and Wavelet Transform","W. Chongyu; Z. Weijuan","Qingdao Univ. of Sci. &amp; Technol., Qingdao, China","2010 Third International Symposium on Information Processing","20101217","2010","","","130","133","Bioradar echoes are often very weak and submerged in noise. The SNR of radar signal is very low. Therefore, echo signal denoising is indispensable for extracting life information. In this paper, the method of weak signal denoising based on the combination of accumulation in frequency domain and wavelet transform is proposed. First, the effectiveness of frequency domain in accumulation and wavelet transform in denoising is presented respectively. Then, the combination of two methods was used to remove noise and extract useful information on the situation of Gaussian white noise. Simulation results show that the method can restrain the noise and extract useful signal effectively in low SNR.","","Electronic:978-0-7695-4261-4; POD:978-1-4244-8627-4","10.1109/ISIP.2010.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669016","Accumulation in frequence doman;wavelet;weak signal denoising","Frequency domain analysis;Noise reduction;Signal to noise ratio;Wavelet domain;Wavelet transforms","Gaussian noise;echo;information retrieval;radar signal processing;signal denoising;wavelet transforms;white noise","Gaussian white noise;bioradar echo;echo signal denoising;frequency domain;information extraction;radar signal;wavelet transform","","1","","6","","","15-17 Oct. 2010","","IEEE","IEEE Conference Publications"
"The RDF-based Information Capturing System from Web Pages","T. Ushioda; S. Fujita","Grad. Sch. of Inf. & Comput. Sci., Chiba Inst. of Technol., Narashino, Japan","2010 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20110113","2010","","","201","206","It is an investigative purpose to acquire the event information in the municipality website and extraction information is converted into the XML form of the RDF model. There is a problem that the extraction performance is controlled by the structure of the HTML tag though there is Web-wrapper method that uses the HTML tag as an information extraction technique on the Web page. In this paper, we propose an extraction method from a HTML document based on dictionary. HTML tag is deleted from the HTML document and it converts it into the text. It proposes the method for extracting a target character string by comparing the text with the collection of words prepared beforehand. Finally, extraction information is converted into the XML form of the RDF model. The evaluation experiment was done to the municipality in 23 Tokyo district and 56 Chiba prefecture in Japan. The proposal method was able to extract event information on as a whole 73%. The LR-Wrapper was 52%. The Tree-Wrapper was 55%. The PLR-Wrapper was 32%. The proposal method confirmed event information was rating higher than an existing method extractive by the combination of a simple algorithm and the collection of words.","","Electronic:978-0-7695-4237-9; POD:978-1-4244-8538-3","10.1109/3PGCIC.2010.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662790","Morphological Analysis;Resource Description Framework;Text Mining;Web wrapper","","Internet;information retrieval systems","HTML document;LR-wrapper;PLR-wrapper;RDF-based information capturing system;Web pages;Web-wrapper method;information extraction;resource description framework;tree-wrapper","","0","","8","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"Improving Question Answering Based on Query Expansion with Wikipedia","Y. Miao; X. Su; C. Li","Sch. of Software, Tsinghua Univ., Beijing, China","2010 22nd IEEE International Conference on Tools with Artificial Intelligence","20101217","2010","2","","233","240","As an emerging area in information retrieval, question answering aims at retrieving answers to user-posted questions from a given sentence collection or text corpus. In question answering, the queries are usually submitted in the form of short sentences which are unable to represent user intentions sufficiently. In this study, we present a novel framework which improves question answering through query expansion. We enrich representation of queries with Wikipedia concepts generated by the proposed QRWiki retrieval model. Then the enriched queries are exploited to benefit the process of question answering. The experiments with benchmark datasets show that the proposed framework performs significantly better than the baseline system, and is effective in boosting the performance of question answering.","1082-3409;10823409","Electronic:978-0-7695-4263-8; POD:978-1-4244-8817-9","10.1109/ICTAI.2010.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5671408","Query Expansion;Question Answering;Wikipedia","Electronic publishing;Encyclopedias;Internet;Measurement;Power capacitors;Semantics","Web sites;query formulation;question answering (information retrieval);text analysis","QRWiki retrieval model;Wikipedia;answer retrieval;information retrieval;query expansion;query representation;question answering;sentence collection;short sentence;text corpus;user-posted question","","0","","17","","","27-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Exploring user-centric interpersonal relationships in social networks using information visualization techniques","Y. L. Ho; P. Y. Chang; I. X. Chen; C. Z. Yang","Department of Computer Science and Engineering, Yuan Ze University, Chungli, Taiwan","2010 International Computer Symposium (ICS2010)","20110110","2010","","","192","197","In the Web 2.0 era, many social networking services have rapidly emerged. For helping users interactively explore characteristics of these social communities, different visualization tools are proposed to present the social networks with a panoramic view. However, most visualization tools do not consider the issue of effectively exploring interpersonal relationships from a single user perspective. In this paper, we discuss this issue using various information visualization techniques to help end-users efficiently discover detailed individual information. To study the usability, we performed user studies to compare our system with a typical text-based interface. The preliminary experiment results show that our visualization design significantly reduces the searching time cost to help the subjects efficiently find information.","","Electronic:978-1-4244-7640-4; POD:978-1-4244-7639-8","10.1109/COMPSYM.2010.5685521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685521","focus+context;information visualization;interpersonal relationships;social networks","Color;Communities;Facebook;Filtering;Time measurement;Visualization","Internet;data visualisation;information retrieval;social networking (online);user interfaces","Web 2.0;information visualization technique;searching time cost;social networking;text based interface;user-centric interpersonal relationship","","0","","22","","","16-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Research on complex structure-oriented accurate web information extraction rules","Tao Xie; Shengsheng Shi; Fuliang Quan; Chunfeng Yuan; Yihua Huang","Department of Computer Science and Technology, Nanjing University, National Key Laboratory for Novel Software Technology, Nanjing University, 210093, China","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","1","","312","316","With the rapid growth of web information, there is an increasing need to easily and efficiently acquire accurate information from the massive and heterogamous web. Web information extraction is such a research area to meet these needs. In this paper, we analyze the shortcomings of related researches and systems and find that when extracting accurate web information with complex structures, few systems can do so without being too much of a burden to users. Aiming at overcoming this type of pitfalls, this paper will study and propose a comprehensive model and framework that can combine the automatic web data analysis and extraction with the user interaction-based semi-supervised web data extraction. The new model and framework has a good trade-off between the automatic generation of extraction rules and their expression capability towards the accurate information extraction. Based on this, we further present a multi-functional data extraction rule system that will use a variety of structural and textual extraction rules of different functions to achieve powerful expression capability. Furthermore, to offer powerful expression mechanism for data extraction, this paper will describe a well-designed, XML-based data extraction language which works well for rule generation based on both automatic web structure analysis and user interaction.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5687442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687442","accuracy web information extraction;extraction language;extraction rule model","Databases;HTML;Variable speed drives","Internet;information retrieval;user interfaces","Web information extraction;XML-based data extraction language;semi-supervised Web data extraction;structure-oriented information extraction;user interaction","","0","","12","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"A survey on recent progress in the ASAT/SIRKUS paradigm","S. M. Siniscalchi; T. Svendsen; C. H. Lee","Department of Telematics, University of Enna &#x201C;Kore&#x201D;, Italy","2010 7th International Symposium on Chinese Spoken Language Processing","20110110","2010","","","465","470","Automatic Speech Attribute Transcription (ASAT), an ITR project sponsored under the NSF grant (IIS-04-27113), and Spoken Information Retrieval by Knowledge Utilization in Statistical Speech Processing (SIRKUS), a project funded by the VERDIKT programme at the Research Council of Norway, are two research projects carried out at Georgia Institute of Technology and at Norwegian University of Science and Technology, respectively, with the purpose of investigating and developing new paradigms for speech recognition that have the capability of bridging the gap between machine and human performance. These projects approach speech recognition from a more linguistic perspective: unlike traditional ASR systems, humans detect acoustic and auditory cues, weigh and combine them to form theories, and then process these cognitive hypotheses until linguistically and pragmatically consistent speech understanding is achieved. A major goal of the ASAT/SIRKUS paradigms is to develop a detection-based approach to automatic speech recognition (ASR) based on attribute detection and knowledge integration. We report on progress of these two projects on two different tasks, namely the cross-language and language universal attribute/phone recognition task, and the language identification (LID) task.","","Electronic:978-1-4244-6246-9; POD:978-1-4244-6244-5","10.1109/ISCSLP.2010.5684480","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5684480","","Accuracy;Acoustics;Detectors;Hidden Markov models;Speech;Speech recognition;Training","cognitive systems;information retrieval;natural language processing;speech processing;speech recognition;statistical analysis","ASAT-SIRKUS Paradigm;Georgia Institute of Technology;ITR project;NSF grant;Norwegian University of Science and Technology;VERDIKT programme;attribute detection;automatic speech attribute transcription;automatic speech recognition;cognitive hypotheses;cross-language recognition task;knowledge integration;knowledge utilization;language identification task;language universal attribute-phone recognition task;speech recognition;spoken information retrieval;statistical speech processing","","0","","19","","","Nov. 29 2010-Dec. 3 2010","","IEEE","IEEE Conference Publications"
"Approximate Address Matching","D. Li; S. Wang; Z. Mei","Dept. of Comput. Sci., Univ. of Sherbrooke, Sherbrooke, QC, Canada","2010 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20110113","2010","","","264","269","Address management is a major challenge for many organizations, as errors occur frequently in the address capturing process, and address standards and usages may vary among different databases. Rather than comparing house number, street, city and province individually, we use a string similarity measurement to perform address comparison, which enables us to combine the edit distance with the vector space model to search for potentially matching address candidates by associating them with a similarity matching score. Upon evaluating the strengths and weaknesses of these techniques, we introduce an algorithm for effective address matching, called Term-Weighted Dissimilarity, which combines edit distance similarity with Term Frequency-Inverse Document Frequency weighting. We implement this algorithm in software and show its effectiveness via a real application for address matching and correction based on Canada Post's address standard.","","Electronic:978-0-7695-4237-9; POD:978-1-4244-8538-3","10.1109/3PGCIC.2010.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662779","Address matching;TF-IDF weight;address correction;address standardization;edit distance;string similarity;vector space model","","geographic information systems;information retrieval;string matching;text analysis","address capturing process;address comparison;address management;address matching;address standards;edit distance;string similarity measurement;term frequency-inverse document frequency weighting;term-weighted dissimilarity;vector space model","","1","","30","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"Review on Construction of Digital Archives in China","Q. Xiao","Sch. of Inf. Manage., Wuhan Univ. Wuhan, Wuhan, China","2010 International Conference on Computational Intelligence and Software Engineering","20101230","2010","","","1","4","This paper analyzes the main characteristics and typical mode of China digital archives (CDA) construction, discusses generation and character of China electronic records center (CERC) as well as its important functional supplement to CDA, and finally proposes several suggestions. Currently, CDA construction has five characteristics: relative independence, adherence to E-government, diversified modes, regional imbalance and progressive construction; Electronic Records Centers (ERC) acts as a bridge connecting digital archives (DA) and E-government system. ERC's main functions are online receiving and preserving current records produced in E-government activities as well as providing real-time use of these records, which are important supplements to the functions of DA; CDAs should be built based on the international standard of OAIS.","","Electronic:978-1-4244-5392-4; POD:978-1-4244-5391-7","10.1109/CISE.2010.5676788","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676788","","Automation;Buildings;Electronic government;Libraries","digital libraries;government data processing;information retrieval systems;records management","China;digital archives;e-government;electronic records center","","0","","10","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Research on User Requirements Elicitation Using Text Association Rule","L. Dong; X. Zhang; N. Ye; X. Wan","Coll. of Inf. & Control Eng., Xi'an Univ. of Archit. & Technol. Xi'an, Xi'an, China","2010 International Symposium on Intelligence Information Processing and Trusted Computing","20101210","2010","","","357","359","User requirements obtained through text data mining are very important to improve the competitiveness of enterprises. In this paper an algorithm of acquiring user requirements in machinery products by using text association rule is proposed. In the algorithm, the user requirement documents are represented by vector space model. The feature words matrix is obtained by transposing the documents matrix. An improved text association rule theory based on gray association rule is used to calculate the correlation degree between feature words and proper nouns of machinery industry. Then the matrix of candidates for proper noun is constructed by selecting a higher correlation degree word as a threshold. Finally, user requirements are obtained by using the weighted matrix. The experimental results suggest that the proposed method is feasible for user requirement elicitation.","","Electronic:978-0-7695-4196-9; POD:978-1-4244-8148-4","10.1109/IPTC.2010.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663251","gray association rule;mechanical products;text association rule;user requirements;vector space model","Association rules;Computational modeling;Computers;Correlation;Industries;Machinery","data mining;information retrieval;matrix algebra;text analysis;user interfaces;word processing","correlation degree;data mining;documents matrix;gray association rule;machinery industry;text association rule;user requirements elicitation;vector space model;words matrix","","0","","4","","","28-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"A Faceted-Navigation System for QCDml Ensemble XML Data","T. Amagasa; N. Ishii; T. Yoshie; O. Tatebe; M. Sato; H. Kitagawa","Center for Comput. Sci., Univ. of Tsukuba, Tsukuba, Japan","2010 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20110113","2010","","","132","139","In this paper we describe a faceted navigation system for QCDml ensemble XML data, which is an XML-based metadata format for ILDG (International Lattice Data Grid). A faceted navigation system allows a user to search for one's desired information in an exploratory way, thereby enabling the user to browse a set of XML data without using specialized query languages such as XPath and XQuery. However, designing a faceted navigation interface for XML data is not straightforward due to the tree and flexible, tree-like nature of XML. In this work, we attempt to design and implement a dedicated faceted navigation system for QCDml on top of an XML database. The interface is designed by taking the domain experts' usability into account. We also care about the system's performance. In general, the process of faceted navigation is computationally expensive because of the need for aggregate computation of each available facets. In order to alleviate this, we make use of a relational database system as the engine to speed up the aggregate computation. We finally demonstrate the implemented faceted navigation system, which has been made available on the Web.","","Electronic:978-0-7695-4237-9; POD:978-1-4244-8538-3","10.1109/3PGCIC.2010.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664692","ILDG;QCDml;XML;faceted navigation;metadata","","Internet;XML;grid computing;information retrieval;query languages;relational databases","ILDG;QCDml ensemble XML data;Web;XML database;XML-based metadata format;XPath;XQuery;faceted navigation system;international lattice data grid;query languages;relational database system","","0","","13","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"What makes helpful online interactions: A study of health information evaluation","Jiao Wu","Lubar School of Business, University of Wisconsin-Milwaukee, USA","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","2","","842","846","The purpose of this research is to develop an in-depth understanding of how online interactions help health information evaluation on e-healthcare social network websites. Using information integration theory (IIT), we consider two types of interactions (personal interaction with online peers and para-social interaction with information management technology artifact) to address the question how online interactions facilitate user's cognitive process of evaluating health information quality, which leads to suitable information adoption.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5687969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687969","information evaluation;online interaction;personality","Image sequences;Interpolation;Optical imaging;Signal resolution;Spatial resolution;Spatiotemporal phenomena","cognition;data integrity;health care;information retrieval;interactive systems;medical information systems;social networking (online)","cognitive process;e-healthcare social network websites;health information evaluation;information integration theory;information management technology artifact;online interactions","","0","","27","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Searching XML data by SLCA on a MapReduce cluster","M. Zhou; H. Hu; M. Zhou","Institute of Massive Computing, East China Normal University, Shanghai Key Laboratory of Trustworthy Computing, China","2010 4th International Universal Communication Symposium","20101213","2010","","","84","89","XML keyword search is a popular topic in research field, and the Smallest Lowest Common Ancestor (SLCA) concept is fundamental for XML keyword search algorithms. With the rapid growth of XML data in internet, we are confronted with big data issues, it's becoming a new research direction for managing massive XML data now. Conventional centralized data management technologies are limited in the aspects of efficiency, throughout and maintenance cost. MapReduce framework is a recent trend to process large-scale data. It is implemented on clusters built by numbers of business machines, to conquer limitations mentioned above by parallel computation. In this paper, we provide a SLCA-based keyword search implementation for large-scale XML data sets on a MapReduce cluster. Main steps of our implementation include XML data partition, parse and sort, index setup and SLCA computation. We conduct some experiments to evaluate the effectiveness of the proposed method.","","Electronic:978-1-4244-7820-0; POD:978-1-4244-7821-7","10.1109/IUCS.2010.5666766","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5666766","Hadoop;MapReduce;SLCA;XML Keyword Search","Clustering algorithms;Data processing;Distributed databases;Indexes;Keyword search;Partitioning algorithms;XML","Internet;XML;information retrieval","MapReduce cluster;SLCA;XML data partition;XML data searching;XML keyword search algorithm;business machines;centralized data management technologies;internet;smallest lowest common ancestor concept","","4","","16","","","18-19 Oct. 2010","","IEEE","IEEE Conference Publications"
"The research of label-mapping-based entity attribute extraction","Huilin Liu; Chen Chen; Liwei Zhang; Guoren Wang","College of Information Science and Engineering, Northeastern University, Shenyang, China","2010 IEEE International Conference on Progress in Informatics and Computing","20110113","2010","1","","635","639","With the rapid development of new media, such as computer and Internet, extract valuable entity attribute information from Web text can be significant. Aiming at this problem, this paper puts forward SALmap, this model calls seed method at first, which will create common candidate attribute label sets by defining data format rules. Then we construct the mapping relationship between the attributes and the labels using attribute value information and the maximum entropy model, and label the entity instance as well. Finally, hidden Markov model is applied to the relevant entity attribute extraction. Experiments prove SALmap model can significantly improve the precision and performance of entity attribute extraction.","","Electronic:978-1-4244-6789-1; POD:978-1-4244-6788-4","10.1109/PIC.2010.5687859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5687859","attribute extraction;attribute values;hidden Markov model;label mapping;maximum entropy model","Artificial neural networks;Books;Computational modeling;Entropy;Hidden Markov models;Information filters","Internet;data mining;entropy;hidden Markov models;information retrieval;set theory","SALmap;Web text;attribute value information;data format rule;entity attribute information;hidden Markov model;mapping relationship;maximum entropy model","","0","","12","","","10-12 Dec. 2010","","IEEE","IEEE Conference Publications"
"Web Data Extraction Based on Tree Structure Analysis and Template Generation","H. Hong; X. Chen; G. Wu; J. Li","Sch. of Software Eng., Beijing Univ. of Posts & Telecommun., Beijing, China","2010 International Conference on E-Product E-Service and E-Entertainment","20101210","2010","","","1","5","This paper studies the problem of extracting data from large numbers of semi-structured web pages. The fact that many websites have enormous pages generated dynamically from a underlying structured source like a database makes it feasible to induct a common template for similar web pages and then extract data accordingly. Previous work on this problem has limited practical utility because of either requiring significant human efforts or basing on several brittle assumptions. We propose a three-step approach, including template generation, template detection and data extraction, with a little human intervention in template edit. The core algorithm is based on two highly efficient tree structure analysis techniques. Experimental results show that our approach can extract web data in a high accuracy and flexibility.","","Electronic:978-1-4244-7161-4; POD:978-1-4244-7159-1","10.1109/ICEEE.2010.5661561","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661561","","Clustering algorithms;Data mining;HTML;Humans;Web pages;XML","Internet;Web sites;data handling;information retrieval;tree data structures","Web data extraction;Website;human intervention;semistructured web page;template detection;template generation;tree structure analysis","","0","","13","","","7-9 Nov. 2010","","IEEE","IEEE Conference Publications"
"The Field of Automatic Entity Relation Extraction Based on Binary Classifier and Reasoning","C. y. Lei; J. y. Guo; Z. t. Yu; S. m. Zhang; C. l. Mao; C. s. Zhang","Sch. of Inf. Eng. & Autom., Kunming Univ. of Sci. & Technol., Kunming, China","2010 Third International Symposium on Information Processing","20101217","2010","","","327","331","To solve the difficulty of the field of Automatic Entity Relation Extraction, in this paper, a method that used binary classification thinking, meanwhile combined with reasoning rules to extract the field of entity relation is proposed. considering comprehensively the context information of entity, entity type and their combination of characteristics to construct the feature set, which in order to build the Binary Classifier of entity relation extraction, then taking full advantage of the field characteristics of entity relation, further combine reasoning rules to obtain the type of the field of entity relation. Doing our experiment on the artificial collection of 600 corpuses for tourism field, experimental result shows the method of Binary Classifier combining Reasoning is better than Multiple Classifiers, the F-score is improved 3%.","","Electronic:978-0-7695-4261-4; POD:978-1-4244-8627-4","10.1109/ISIP.2010.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669065","binary classifier;features;filed of entity relation;multiple classifier;reasoning","Classification algorithms;Cognition;Data mining;Entropy;Feature extraction;Snow;Training","feature extraction;inference mechanisms;information retrieval;pattern classification","automatic entity relation extraction;binary classifier;feature set;reasoning rules","","0","","12","","","15-17 Oct. 2010","","IEEE","IEEE Conference Publications"
"INFOMAT-E - public information system for people with sight and hearing dysfunctions","W. Górka; A. Piasecki; B. Sitek; M. Socha","Instytut Technik, Innowacyjnych EMAG, Katowice, Poland","Proceedings of the International Multiconference on Computer Science and Information Technology","20110106","2010","","","593","597","The article features the results of two initial stages of the Infomat-E project. The project is to provide access to information to people with sight and hearing dysfunctions through a hardware-software solution. So far, a number of analyses have been conducted within the project with respect to the method in which the contents of information is presented as well as interaction with the devices that present this information. These included the analysis of suitable colours, font sizes, ergonomic layout of screen menu bars, and ergonomic keyboards - to make them most convenient for people with sight and hearing dysfunctions. There were also analyses conducted how written texts are understood, especially in the case of the deaf. The project assumes integration of elements which were results of separate research projects. Within the project, the following will be used: speech synthesis, speech analysis, presentation of ideas with the use of the sign language. The project will result in the Infomat-E system which will present information in kiosks specially designed to suit the needs of people with sight and hearing dysfunctions. The article features the results of the conducted analytical works which lay at the basis of the technical concept of the system. This concept is presented in the article too.","2157-5525;21575525","Electronic:978-83-60810-27-9; POD:978-1-4244-6432-6","10.1109/IMCSIT.2010.5680027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680027","","Computer science;Information systems;Information technology","ergonomics;gesture recognition;handicapped aids;information retrieval;keyboards;public information systems;speech synthesis;text analysis","Infomat-E project;deaf;ergonomic keyboard;ergonomic layout;hardware-software solution;hearing dysfunction;information access;information kiosks;public information system;screen menu bar;sight dysfunction;sign language;speech analysis;speech synthesis;written text","","0","","8","","","18-20 Oct. 2010","","IEEE","IEEE Conference Publications"
"Characteristics and Uses of Labeled Datasets - ODP Case Study","D. Zhu; H. Dreher","Sch. of Inf. Syst., Curtin Univ., Perth, WA, Australia","2010 Sixth International Conference on Semantics, Knowledge and Grids","20110113","2010","","","227","234","Labeled datasets are essential for text categorization. They are used to train a classifier, or as a benchmark collection to evaluate categorization algorithms. However, labeling a large-scale document set is extremely expensive because it involves much human labour, and the labeling process itself is subjective rather than objective. Therefore, labels assigned to documents by only one human editor in some existing labeled document sets may be of limited use and may prove problematic for training a classifier or evaluating categorization algorithms. This research explores socially constructed Web directory, the Open Directory Project (ODP), to generate a series of labeled document sets by extracting semantic characteristics from the ODP categories which are annotated by a list of indexed Websites. The generated document sets are used to classify Web search results and the results are encouraging.","","Electronic:978-0-7695-4189-1; POD:978-1-4244-8125-5","10.1109/SKG.2010.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5663513","","","Web sites;information retrieval;pattern classification;text analysis","ODP case study;Web directory;Web sites;categorization algorithm evaluation;labeled datasets;open directory project;semantic characteristic extraction;text categorization","","1","","15","","","1-3 Nov. 2010","","IEEE","IEEE Conference Publications"
"Anaphora Resolution of Malay Text: Issues and Proposed Solution Model","N. K. M. Noor; S. A. Noah; M. J. A. Aziz; M. P. Hamzah","Fac. of Comput. Syst. & Software Eng., Univ. Malaysia Pahang, Kuantan, Malaysia","2010 International Conference on Asian Language Processing","20110106","2010","","","174","177","Anaphora resolution (AR) is a process to identify the appropriate antecedent with its anaphor which occur before the anaphor. AR able to improve most of the NLP applications such as question answering, short answer examination system and information extraction. Most of AR systems are deal with English language. Thus, in 1990's the research on AR has been applied for other language, such as Arabic, Chinese, Hindi and Norwegian. There are however limited or no effort in dealing with Malay text. The AR systems for one language cannot be simply adapted to use in other languages. This is due to the fact that different languages have different set of rules relating to syntax and semantic to respective language. This paper proposed a model for resolving anaphora phenomena in Malay text. The model consists of three elements consisting of anaphora resolution process, syntactic knowledge process and semantic-world knowledge process. The elements are defined based on the observable fact occurring in Malay language.","","Electronic:978-0-7695-4288-1; POD:978-1-4244-9063-9","10.1109/IALP.2010.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5681607","Malay text;model of anaphora resolution;natural language processing;poor-knowledge anaphora resolution","Animals;Computational linguistics;Computational modeling;Electronic mail;Humans;Semantics;Syntactics","natural language processing;question answering (information retrieval);text analysis","Malay Text;Malay text;anaphora resolution process;information extraction;question answering;semantic-world knowledge process;short answer examination system;syntactic knowledge process","","2","","10","","","28-30 Dec. 2010","","IEEE","IEEE Conference Publications"
"Event Element Identify of Internet Context","F. Chen","Dept. of Comput. Sci. & Technol., Beijing Foreign Studies Univ., Beijing, China","2010 International Conference on Multimedia Information Networking and Security","20101217","2010","","","85","88","Information on Internet is so huge,and increases quickly. A huge information pool is coming up on the Internet. And much important information can be found on the Internet. Internet is really an important source of information. So extract the key words from the pages on Internet is so important. A page description model based on undirection graph is proposed and then a entity ranking algorithm named ER is proposed too. The inspiration of ER come from the PR algorithm. And the experiment with ACECrop2005 show that the algorithm has a high efficiency.","2162-8998;21628998","Electronic:978-1-5090-5632-3; POD:978-1-4244-8626-7; USB:978-0-7695-4258-4","10.1109/MINES.2010.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670923","","Algorithm design and analysis;Context;Data mining;Erbium;Internet;Machine learning;Web pages","Internet;directed graphs;feature extraction;information retrieval","Internet context;entity ranking algorithm;event element identification;key words extraction;page description model;undirection graph","","0","","8","","","4-6 Nov. 2010","","IEEE","IEEE Conference Publications"
"Web Content Information Extraction Approach Based on Removing Noise and Content-Features","D. Yang; J. Song","Dept. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China","2010 International Conference on Web Information Systems and Mining","20110113","2010","1","","246","249","This paper presents an improved approach to extract the main content from web pages. There are a good many financial news pages which have so many links that the algorithms mainly based on link density have poor performance in extracting main content. To solve this problem, we put forward an extracting main content method which firstly removes the usual noise and the candidate nodes without any main content information from web pages, and makes use of the relation of content text length, the length of anchor text and the number of punctuation marks to extract the main content. In this paper, we focus on removing noise and utilization of all kinds of content-characteristics, experiments show that this approach can enhance the universality and accuracy in extracting the body text of web pages.","","Electronic:978-0-7695-4224-9; POD:978-1-4244-8438-6","10.1109/WISM.2010.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662320","information extraction;removing noise content;web page content extraction","","Internet;information retrieval","Web content information extraction;Web pages;anchor text length;content text length;extracting main content method;financial news pages;link density;noise content removal;punctuation mark","","6","","11","","","23-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Click2Annotate: Automated Insight Externalization with rich semantics","Y. Chen; S. Barlowe; J. Yang","Department of Computer Science UNC Charlotte","2010 IEEE Symposium on Visual Analytics Science and Technology","20101210","2010","","","155","162","Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search.","","Electronic:978-1-4244-9487-3; POD:978-1-4244-9488-0","10.1109/VAST.2010.5652885","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5652885","Annotation;Decision Making;Insight Management;Multidimensional Visualization;Visual Analytics","Automation;Book reviews;Compounds;Context;Mice;Prototypes;Semantics","data mining;data visualisation;decision making;information retrieval;problem solving;user interfaces","Click2Annotate;decision making;insight browsing;insight externalization;insight management activity;insight retrieval;problem solving","","6","1","18","","","25-26 Oct. 2010","","IEEE","IEEE Conference Publications"
"A SOA Based Domain-Specific Chinese QA System","J. Zhou","ZhenJiang Vocational Tech. Coll., Zhenjiang, China","2010 Ninth International Conference on Grid and Cloud Computing","20110113","2010","","","467","471","With the blast of information available on the web and the relevant documents set returned by search engineer can not meet the user's needs, the question answer system research is promoted. In this paper, we introduce the structure of Question Answer system based on SOA, define the structure of the dictionary of Keywords and searching template, the word segmentation algorithm based on the dictionary of keyword, the storage of searching template and the algorithm of template matching. On the foundation, we implement a QA system for Railway domain application, the experimental result show that QA system based on techniques we employed has high accuracy and recognition rate.","2160-4908;21604908","Electronic:978-0-7695-4313-0; POD:978-1-4244-9334-0","10.1109/GCC.2010.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662703","Question Answering system;SOA;Searching Template;Template Matching","","Internet;image matching;information retrieval;software architecture","SOA;World Wide Web;documents set;domain-specific Chinese QA system;question answer system;railway domain application;searching template;template matching;word segmentation","","0","","9","","","1-5 Nov. 2010","","IEEE","IEEE Conference Publications"
