"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7748851,7748932,7745313,7742085,7746323,7746058,7745452,7539616,7744833,7386634,7600368,7737462,7737693,7739703,7738815,7737904,7739638,7734115,7726897,7727286,7730421,7726863,7726116,7727819,7730427,7726973,7729939,7727500,7733045,7732034,7732139,7732397,7730544,7726937,7727353,7727188,7726132,7726117,7724485,7724297,7724487,7724956,7725307,7724255,7723676,7724235,7724445,7724676,7724677,7724823,7724494,7724801,7603880,7603361,7603123,7604557,7603407,7604595,7603410,7603414,7603245,7577785,7600312,7600183,7592701,7591526,7591233,7298458,7585228,7584763,7584772,7587864,7586377,7585537,7587638,7585742,7416213,7583975,7583967,7583563,7581672,7582810,7581585,7581680,7584972,7584979,7583941,7583980,7579691,7583910,7584961,7523913,7577585,7577051,7579385,7577653,7574754,7576543,7574920,7563341",2017/05/04 22:09:35
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Low power CAM design using modified SCN based classifier","A. R. Preethee; V. Bharathi","ECE Department, Sri Manakula Vinayagar Engineering College, Puducherry, India","2016 10th International Conference on Intelligent Systems and Control (ISCO)","20161103","2016","","","1","5","A Content Addressable Memory is a memory unit which compares input search data against a table of stored data and returns the address of the matching data which is retrieved within single clock cycle. The CAM consumes more power due to parallel search operation and the designing issues of the CAM are to reduce the power consumption, area and to improve performance. The proposed architecture is based on a recently developed sparse clustered network which eliminates most of the parallel comparisons performed during a search operation. In order to reduce power in search operation NAND type CAM is used in which the CAM cell is XNOR type. For best search performance the NOR type CAM is used which is XOR type. Today the challenging issue is to reduce area and power consumption in CAM. The existing CAM cell is made of 10T and 9T. In this paper we are designing 4T CAM cells which have low power and high performance.","","","10.1109/ISCO.2016.7726973","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726973","CAM cell;Content Addressable Memory;Sparse Clustered Networks","Associative memory;Computer architecture;Impedance matching;Microprocessors;Power demand;Random access memory;Transistors","content-addressable storage;information retrieval;pattern classification;power consumption","CAM cell;SCN based classifier;XNOR type;content addressable memory;input search data;low power CAM design;matching data address;parallel search operation;power consumption reduction;search operation NAND type CAM;single clock cycle;sparse clustered network;stored data","","","","","","","7-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Web service-based SMAP soil moisture data visualization, dissemination and analytics based on vegscape framwork","Z. Yang; L. Hu; G. Yu; R. Shrestha; L. Di; C. Boryan; R. Mueller","National Agricultural Statistics Service, USDA, Washington DC, 20250, USA","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","3624","3627","Timely, frequent, crop vegetation condition information, with complete geospatial coverage acquired throughout the growing season is critical for public and private sector decision making that concerns agricultural policy, production, food security, and food prices. The NASA Soil Moisture Active and Passive (SMAP) mission provides such a reliable data source for cropland soil moisture assessment. This paper presents a prototype of an interactive Web service based SMAP soil moisture visualization, dissemination and analytics system for US soil moisture monitoring based on the VegScape framework. This system automatically retrieves and preprocesses SMAP soil moisture data for US cropland soil moisture condition monitoring and assessment. The prototype takes advantage of the VegScape's service oriented architecture and adds a new component for SMAP soil moisture. It reuses existing VegScape visualization, dissemination and analytical functionalities and tools. The prototype inherits the capabilities of interactive map operations, data dissemination, statistical tabulating and charting, comparison analysis, and various Web services.","","","10.1109/IGARSS.2016.7729939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729939","SMAP;VegScape;Web service;analytics;dissemination;online visualization;soil moisture","Agriculture;Data visualization;Geospatial analysis;Monitoring;Prototypes;Soil moisture;Web services","Web services;agricultural engineering;crops;data analysis;data visualisation;geophysics computing;information dissemination;information retrieval;interactive systems","DATA ANALYTICS;DATA DISSEMINATION;VEGSCAPE FRAMWORK;WEB SERVICE-BASED SMAP SOIL MOISTURE DATA VISUALIZATION;crop vegetation condition information;geospatial coverage","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Sequential Discrete Hashing for Scalable Cross-Modality Similarity Retrieval","L. Liu; Z. Lin; L. Shao; F. Shen; G. Ding; J. Han","School of Computer and Information Science, Southwest University, Chongqing, China","IEEE Transactions on Image Processing","20161114","2017","26","1","107","118","With the dramatic development of the Internet, how to exploit large-scale retrieval techniques for multimodal web data has become one of the most popular but challenging problems in computer vision and multimedia. Recently, hashing methods are used for fast nearest neighbor search in large-scale data spaces, by embedding high-dimensional feature descriptors into a similarity preserving Hamming space with a low dimension. Inspired by this, in this paper, we introduce a novel supervised cross-modality hashing framework, which can generate unified binary codes for instances represented in different modalities. Particularly, in the learning phase, each bit of a code can be sequentially learned with a discrete optimization scheme that jointly minimizes its empirical loss based on a boosting strategy. In a bitwise manner, hash functions are then learned for each modality, mapping the corresponding representations into unified hash codes. We regard this approach as cross-modality sequential discrete hashing (CSDH), which can effectively reduce the quantization errors arisen in the oversimplified rounding-off step and thus lead to high-quality binary codes. In the test phase, a simple fusion scheme is utilized to generate a unified hash code for final retrieval by merging the predicted hashing results of an unseen instance from different modalities. The proposed CSDH has been systematically evaluated on three standard data sets: Wiki, MIRFlickr, and NUS-WIDE, and the results show that our method significantly outperforms the state-of-the-art multimodality hashing techniques.","1057-7149;10577149","","10.1109/TIP.2016.2619262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600368","Cross-modality retrieval;bitwise;discrete optimization;hashing;unified hash code","Binary codes;Boosting;Data structures;Electronic mail;Optimization;Quantization (signal);Semantics","Internet;binary codes;data handling;information retrieval;learning (artificial intelligence);minimisation","CSDH;Internet;MIRFlickr data sets;NUS-WIDE data sets;Wiki data sets;boosting strategy;cross-modality sequential discrete hashing;discrete optimization scheme;empirical loss minimization;high-dimensional feature descriptors;high-quality binary codes;large-scale data spaces;large-scale retrieval;multimodal Web data;nearest neighbor search;quantization errors reduction;scalable cross-modality similarity retrieval;sequential learning;similarity preserving Hamming space;supervised cross-modality hashing framework;unified binary codes;unified hash codes","","1","","","","20161019","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Detecting formula based on Stroke Width Transform for online Chinese examination question retrieval","Y. Sun; W. Wang; H. Zhang; Z. Ma","Pattern Recognition and Intelligent System lab, Beijing University of Posts and Telecommunications, China","2016 Digital Media Industry & Academic Forum (DMIAF)","20160926","2016","","","143","147","More and more students prefer to submit the questions captured by cell phone to the image recognition and retrieval system to find the answers when they are self-taught. In this paper, we propose a new method to detect formulas in text lines captured by cell phone in natural conditions for online Chinese examination question retrieval. First, we use the stroke width transform algorithm to get the initial text lines. Second, we take an improved measure to merge these initially scattered text lines into principal text lines, which can be used for the following operation. Next, characters in the text lines are segmented by projection method and marked as Chinese character or non-Chinese-character automatically by some features. If the neighboring characters match the limit conditions, they will be detected as a formula and be extracted. Since some formulas are higher than the localized text lines which they belong to, an extension operation will be done to the extracted formula in the vertical direction to get the complete formula. We tested our method on some data sets, and the result shows that our method is satisfactory for various subjects.","","","10.1109/DMIAF.2016.7574920","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574920","","Algorithm design and analysis;Cellular phones;Education;Feature extraction;Image segmentation;Merging;Transforms","computer aided instruction;image recognition;image retrieval;image segmentation;natural language processing;question answering (information retrieval);text detection","cell phone;extension operation;formula detection;image recognition;image retrieval system;initially scattered text line merging;localized text lines;online Chinese examination question retrieval;principal text lines;projection method;stroke width transform;text line segmentation","","","","","","","4-6 July 2016","","IEEE","IEEE Conference Publications"
"Learning a dual-language vector space for domain-specific cross-lingual question retrieval","G. Chen; C. Chen; Z. Xing; B. Xu","School of Computer Science and Engineering, Nanyang Technological University, Singapore","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","20161006","2016","","","744","755","The lingual barrier limits the ability of millions of non-English speaking developers to make effective use of the tremendous knowledge in Stack Overflow, which is archived in English. For cross-lingual question retrieval, one may use translation-based methods that first translate the non-English queries into English and then perform monolingual question retrieval in English. However, translation-based methods suffer from semantic deviation due to inappropriate translation, especially for domain-specific terms, and lexical gap between queries and questions that share few words in common. To overcome the above issues, we propose a novel cross-lingual question retrieval based on word embed-dings and convolutional neural network (CNN) which are the state-of-the-art deep learning techniques to capture word- and sentence-level semantics. The CNN model is trained with large amounts of examples from Stack Overflow duplicate questions and their corresponding translation by machine, which guides the CNN to learn to capture informative word and sentence features to recognize and quantify semantic similarity in the presence of semantic deviations and lexical gaps. A uniqueness of our approach is that the trained CNN can map documents in two languages (e.g., Chinese queries and English questions) in a dual-language vector space, and thus reduce the cross-lingual question retrieval problem to a simple k-nearest neighbors search problem in the dual-language vector space, where no query or question translation is required. Our evaluation shows that our approach significantly outperforms the translation-based method, and can be extended to dual-language documents retrieval from different sources.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582810","Convolutional Neural Network;Cross-lingual question retrieval;Dual-Language Vector Space;Word embeddings","Context;Convolution;Google;Inspection;Neural networks;Predictive models;Semantics","language translation;learning (artificial intelligence);natural language processing;neural nets;query processing;question answering (information retrieval);search problems;text analysis","CNN model training;Chinese queries;English questions;Stack Overflow;convolutional neural network;deep learning technique;document mapping;domain-specific cross-lingual question retrieval;domain-specific terms;dual-language document retrieval;dual-language vector space;k-nearest neighbor search problem;lexical gap;lingual barrier;machine translation;monolingual question retrieval;nonEnglish speaking developers;semantic deviation;semantic similarity;sentence-level semantics capture;translation-based method;word embeddings;word-level semantics capture","","","","","","","3-7 Sept. 2016","","IEEE","IEEE Conference Publications"
"Online and offline electronic question and answer system: Quick question","J. J. Y. Hwan; W. C. Chia; L. S. Yeong; S. I. Ch'ng","Department of Computing and Information Systems, Sunway University, Bandar Sunway, Malaysia","2016 11th International Conference on Computer Science & Education (ICCSE)","20161006","2016","","","228","233","Asian students with conservative behaviors tend to feel embarrassed and reluctant to ask questions in large classrooms. This paper proposed a mobile-compatible web-based question and answer application to address the aforementioned problem. This proposed web application is known as Quick Question (QQ). QQ is designed to allow students to post questions anonymously and rapidly during class hours. QQ can be accessed online from a web hosting server, or offline from a Raspberry Pi without Internet access. QQ can run on multiple platforms with different screen sizes and capable of serving 250 concurrent users while using the Raspberry Pi. QQ also includes a profanity filter that censor bad words with an accuracy of 86.11%. Furthermore, a term extraction and learning mechanism is implemented to help in grouping and sorting questions posted by students in a class.","","","10.1109/ICCSE.2016.7581585","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581585","e-learning tool;interaction;large classroom;question and answer;raspberry pi","Electronic mail;Information filters;Internet;Mobile applications;Servers;Sorting","Internet;behavioural sciences computing;computer aided instruction;mobile computing;question answering (information retrieval);sorting;student experiments","Asian students;Internet access;QQ;Quick Question;Web hosting server;conservative behaviors;electronic question and answer system;mobile-compatible Web-based question and answer application;sorting questions","","","","","","","23-25 Aug. 2016","","IEEE","IEEE Conference Publications"
"A novel approach for precise search results retrieval based on semantic web technologies","U. Yadav; G. S. Narula; N. Duhan; V. Jain","CDAC Noida","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","1357","1362","Web documents are growing exponentially and the results retrieved by traditional search engines are marked by irrelevant and inconsistent results. In order to alleviate this problem and increase degree of relevance, there is need to move towards development of semantic search engines. Such engines produce results by focusing on meaning of context rather than structure of content. The paper describes proposed architecture of semantic search engine that takes web search results as input and refines them with notion of semantics. The output produced would be precise and relevant results in context of user's query.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724487","Knowledge Retrieval;Ontology;Search engines;Semantic web and Semantic similarity","Google;Ontologies;Resource description framework;Search engines;Semantics;XML","document handling;information retrieval;search engines;semantic Web","Web documents;Web search;precise search;semantic Web technologies;semantic search engines;user query","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Tag correlation and user social relation based microblog recommendation","H. Ma; M. Jia; X. Lin; F. Zhuang","College of Computer science and engineering, Northwest Normal University, Lanzhou, Gansu 730070, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","2424","2430","A microblog recommendation method based on tag correlation and user social relation is proposed via analyzing microblog features and the deficiencies of existing microblog recommendation algorithm. Specifically, a tag retrieval strategy is established to add tags for unlabeled users and users with few tags, and the user-tag matrix is then built and user-tag weights are then obtained. In order to solve the problem of sparsity of the matrix, the correlation between the tags is investigated to update the user-tag matrix. Considering the significance of user social relation for microblog recommendation, a user-user social relation similarity matrix is constructed and a mechanism is designed to iteratively obtain user interest. Experimental results show that the algorithm is effective for microblog recommendation.","","","10.1109/IJCNN.2016.7727500","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727500","Microblog Recommendation;Tag Correlation;Tag Retrieval;User-Tag Matrix;User-Tag Weight;User-User Social Relation Similarity Matrix","Algorithm design and analysis;Computer science;Correlation;Electronic mail;Joining processes;Semantics;Social network services","information retrieval;matrix algebra;recommender systems;social networking (online)","microblog feature analysis;tag correlation;tag retrieval;unlabeled users;user interest;user social relation based microblog recommendation;user-tag matrix;user-tag weights;user-user social relation similarity matrix","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"A multi-touch based file navigation interface","Z. Chen; X. Gao; W. Yang; G. Zhang; J. Lin; L. Xiang","Software School, Xiamen University, Fujian, P.R. China","2016 11th International Conference on Computer Science & Education (ICCSE)","20161006","2016","","","779","783","File retrieval is a frequently adopted primitive operation for most computer users. As the dominant way for file retrieval, file navigation is yet quite inefficient. Lots Efforts have been made to either enhance the navigation interface or provide alternative. However, they all suffer from the challenge of switching users from their preferred interface to a totally unfamiliar new one. In this paper, we try to avoid such switch by incorporating multi-touch interface into file navigation. We provide a rich set of gestures to support various navigation actions. The natural and comfortable manner of multi-touch can help user to get started much more easily.","","","10.1109/ICCSE.2016.7581680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581680","File retrieval;Layout;Multi-touch","Computers;Human factors;Layout;Navigation;Software;Switches;Three-dimensional displays","haptic interfaces;information retrieval","file retrieval;multitouch based file navigation interface","","","","","","","23-25 Aug. 2016","","IEEE","IEEE Conference Publications"
"Design and development of an intelligent agent based framework for predictive analytics","D. Bhargava; R. C. Poonia; U. Arora","Amity Institute of Information Technology, Amity University Rajasthan, Jaipur, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","3715","3718","The arrival of World Wide Web has led to the explosive growth of information on the web. There is a sudden boom in quality of raw data/information, which is commonly referred as Big Data. Very often, this raw information contains very useful insights which are ignored most of the time and are difficult to analyze due to the enormous size of these datasets. The feasibility for human to extract this information from the vast web and build useful application on the top of it, is very low. Hence to create predictive models, there is a huge need for intelligent and autonomous software agents which can procure useful information from the large datasets of raw information. Predictive analytics models can be created from these datasets which can be further used for various applications in security, future prediction etc. This research paper gives an overview of how these software agents will become the most important tools in coming days for building predictive models.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724956","Intelligent Agents;Predictive Analytics;Software Agents","Analytical models;Conferences;Data mining;Intelligent agents;Market research;Predictive models","Big Data;Internet;information retrieval;software agents;statistical analysis","Big Data;World Wide Web;autonomous software agents;information extraction;information growth;intelligent software agent based framework;predictive analytics models;raw data quality;raw information quality","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Better performing keywords cover search","P. Mahure","Computer Science and Engineering Department, Yeshwantrao Chavan College of Engineering, Nagpur, India","2016 World Conference on Futuristic Trends in Research and Innovation for Social Welfare (Startup Conclave)","20161006","2016","","","1","5","Finding relevant information is a big challenge in today's information retrieval domain. Various applications need to find objects closest to the mentioned location that has a set of keywords. In a spatial dataset, objects are linked with some keyword(s) which specify their features. Closest Keywords is a method to query objects, using keyword cover. Algorithm based on Closest Keywords Search which exhaustively combines objects from different query keywords for generating candidate keyword covers. The increasing importance of keyword rating in object evaluation helps for the better decision making. This triggers to generate Best Keyword Cover which mainly considers inter-objects distance as well as the keyword rating of objects. When the number of query keywords gets increases, the performance of the closest keyword cover search algorithm drops significantly as a result of huge candidate keyword covers generated. To overcome this drawback, much more scalable algorithm known as keyword nearest neighbor expansion (keyword-NNE) has been proposed. Keyword-NNE algorithm significantly reduces number of candidate keyword covers generated.","","","10.1109/STARTUP.2016.7583975","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583975","Spatial database;keyword cover;keyword rating;keywords","Algorithm design and analysis;Indexes;Keyword search;Market research;Search engines;Spatial databases","decision making;information retrieval;query processing","Keyword-NNE algorithm;closest keyword search;decision making;information retrieval;keyword cover search;keyword nearest neighbor expansion;keyword set;query keywords;query objects","","","","","","","Feb. 29 2016-March 1 2016","","IEEE","IEEE Conference Publications"
"Study on air-ground amphibious agricultural information collection robot","W. Wang; C. y. Li; L. h. Chu; C. y. Qu","Mechanical and Electrical Engineering Institute, Northeast Forestry University, Harbin, 150040, China","2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","20161107","2016","","","938","944","The popularization of internet brought new opportunity to the development of agriculture informatization and put forward new requirements to the collection technology of agriculture information and its equipment. Considering the problems remained in current agriculture information collection technology and pattern, in order to obtain a more accurate and comprehensive information of the farmland environment and crops growth condition and advance the development of internet agriculture, this research developed an robot with dual functions both in air and on earth to collect agriculture information. Firstly, adapting to the complex terrain of the farmland, ground running gear and flight facility of the robot were designed. Secondly,according to the requirements of agriculture information collection, farmland information collection system and flight attitude monitoring system were designed. Finally, based on above research, robot prototype was made and being tested. The test result shows that the robot has a good and satisfying capacity for information collection both in intelligent inside flight and at farmland operation. It can accurately measure the temperature and humidity in the intelligent greenhouse and its picture processing result well explained the crops' growth condition.","","","10.1109/URAI.2016.7734115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7734115","Agricultural Information Collection;Air-ground Dual Use;Image Processing;Internet of Things;Robot","Agriculture;Green products;Legged locomotion;Prototypes","Internet;agriculture;control engineering computing;information retrieval;robots","Internet;agriculture information collection technology;agriculture informatization;air-ground amphibious agricultural information collection robot;crops growth condition;farmland environment;farmland information collection system;farmland terrain;flight attitude monitoring system","","","","","","","19-22 Aug. 2016","","IEEE","IEEE Conference Publications"
"GS1 Connected Car Using EPCIS-ONS System","B. Sohn; S. Woo; J. Han; H. Cho; J. Byun; D. Kim","Sch. of Comput., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","426","429","Recently, a number of car companies focus on collecting and analyzing data from connected car to provide accurate and variety of integrated information services to users. To provide integrated connected car services, however, there are still two main problems in existing systems. First, there are not well-defined standard car-related data models for data sharing which is basic prerequisite of integrated service. Second, each company stores the data to the closed server and blocks the access so that the data is available only inside the respective data silos. Because of these reasons, it is hard to combine various data to provide integrated information service. To solve the problems, we propose two solutions. 1) Define events of the car life cycle, and data models for data sharing. 2) Establish open system for data sharing and service registration based on GS1 standard. Upon proposed models and system, we have implemented an example service, traffic light control, as a third party service to show the feasibility of our system. Therefore, this research enables to provide open system to car companies and third party service providers to make services associated with the connected car.","","","10.1109/BigDataCongress.2016.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584972","Connected car;EPCIS;GS1;ONS;Smart car","Automobiles;Companies;Data models;Servers;Standards","automobile industry;automobiles;data analysis;information retrieval;information services;product codes;standardisation;traffic engineering computing","EPCIS-ONS system;GS1 connected car;car companies;car life cycle;data access;data analysis;data sharing;electronic product code information services;integrated connected car services;object name service;open system;service registration;standard car-related data models;traffic control;user integrated information services","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Designing affordances for navigating information spaces in code editors","A. Z. Henley","Department of Computer Science, University of Memphis, Memphis, Tennessee 38152-3240","2016 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)","20161110","2016","","","254","255","Navigating information spaces is a fundamental yet challenging task for software developers. For example, one study found that programmers spend 35% of their time on the mechanics of navigating [7]. In another study, programmers spent 38-71% of their time foraging for information during debugging tasks [9]. This is further complicated by programmers' rapidly changing information goals [9] and mental models of the information as they navigate [6].","","Electronic:978-1-5090-0252-8; POD:978-1-5090-0253-5","10.1109/VLHCC.2016.7739703","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7739703","","Aerospace electronics;Computer bugs;Debugging;History;Human factors;Navigation;Visualization","information retrieval;software engineering","code editors;information space navigation;software development","","","","","","","4-8 Sept. 2016","","IEEE","IEEE Conference Publications"
"Detection of crackle events using a multi-feature approach","L. Mendes; I. M. Vogiatzis; E. Perantoni; E. Kaimakamis; I. Chouvarda; N. Maglaveras; J. Henriques; P. Carvalho; R. P. Paiva","CISUC, Department of Informatics Engineering, University of Coimbra, Portugal","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","3679","3683","The automatic detection of adventitious lung sounds is a valuable tool to monitor respiratory diseases like chronic obstructive pulmonary disease. Crackles are adventitious and explosive respiratory sounds that are usually associated with the inflammation or infection of the small bronchi, bronchioles and alveoli. In this study a multi-feature approach is proposed for the detection of events, in the frame space, that contain one or more crackles. The performance of thirty-five features was tested. These features include thirty-one features usually used in the context of Music Information Retrieval, a wavelet based feature as well as the Teager energy and the entropy. The classification was done using a logistic regression classifier. Data from seventeen patients with manifestations of adventitious sounds and three healthy volunteers were used to evaluate the performance of the proposed method. The dataset includes crackles, wheezes and normal lung sounds. The optimal detection parameters, such as the number of features, were chosen based on a grid search. The performance of the detection was studied taking into account the sensitivity and the positive predictive value. For the conditions tested, the best results were obtained for the frame size equal to 128 ms and twenty-seven features.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591526","","Diseases;Electronic mail;Entropy;Feature extraction;Fractals;Hospitals;Lungs","diseases;entropy;information retrieval;lung;patient monitoring;pneumodynamics;regression analysis;wavelet transforms","Teager energy;adventitious lung sounds;alveoli;automatic detection;bronchioles;chronic obstructive pulmonary disease;crackle event detection;entropy;logistic regression classifier;music information retrieval;normal lung sounds;optimal detection parameters;respiratory disease monitoring;small bronchi;wavelet based feature;wheezes","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"An eye movement study on scientific papers using wearable eye tracking technology","S. S. Mozaffari Chanijani; M. Al-Naser; S. S. Bukhari; D. Borth; S. E. M. Alleny; A. Denge","German Research Center for Artificial Intelligence, DFKI GmbH","2016 Ninth International Conference on Mobile Computing and Ubiquitous Networking (ICMU)","20161117","2016","","","1","6","In this study, we started to investigate the impact of different layouts in scientific papers using eye tracking technology. At this stage, we limit our study to the comparison between layout formats inside the Computer Science Community. Association for Computing Machinery (ACM) proceeding as the double-column format and Springer Lecture Notes in Computer Science (LNCS) as the single-column format have been selected for investigation and will be presented in this paper. We employed a wearable eye tracker instead of a remote desk-mounted eye tracker. Due to their mobility and flexibility, this technology has been selected to simulate real-world environment while reading printed documents. Data acquired by a wearable head-mounted eye trackers is based on the gaze position with respect to the video recorded by the embedded camera. Hence, the coordinate of the gaze must be mapped to the corresponding document so that it enables us to investigate eye tracking data analysis techniques. In order to perform this task, we adopted a robust document retrieval technique called Locally Likely Arrangement Hashing (LLAH) to our data. Briefly, the scenario of the process is as follows: First, participants read the print-out scientific papers with the eye tracker. Then, gaze data maps to the corresponding original document in our retrieval database. Finally, the gaze analysis system extracts the intended information for statistical evaluation. Our findings show subjects are more fluent and faster in the double-column proceeding format as compared to the single-column.","","Electronic:978-4-9076-2630-3; POD:978-1-5090-1742-3","10.1109/ICMU.2016.7742085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7742085","","Calibration;Cameras;Computer science;Feature extraction;Gaze tracking;Layout;Mobile computing","data analysis;document image processing;gaze tracking;information retrieval","Association for Computing Machinery;LLAH;Springer Lecture Notes in Computer Science;double-column format;embedded camera;eye movement;eye tracking data analysis;gaze analysis system;locally likely arrangement hashing;robust document retrieval technique;scientific papers;single-column format;wearable eye tracking technology;wearable head-mounted eye trackers","","","","","","","4-6 Oct. 2016","","IEEE","IEEE Conference Publications"
"Performance analysis of the method for social search of information in university information systems","G. P. Dimitrov; G. Panayotova; I. Garvanov; B. Os; P. Petrov; A. Angelov","University of Library Studies and Information Technologies Sofia, Bulgaria","2016 Third International Conference on Artificial Intelligence and Pattern Recognition (AIPR)","20161013","2016","","","1","5","In this article the effectiveness of one of the main methods for assisting the information search in large data sets is analyzed, namely the method based on the social approach. This method analyzes the behavior of multiple users when searching for information, particularly the keywords they use. Based on the obtained results, the relevant algorithms in the searching engines of the organizations can be optimized. The studies are based on data extracted from the databases of two relatively large information systems based at the University in Library Studies and Information Technologies in Sofia, Bulgaria and University of Economics in Varna, Bulgaria. The numerical and experimental results are analyzed and discussed.","","","10.1109/ICAIPR.2016.7585228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585228","data sets optimization;databases;information systems;search methods","Arrays;Dispersion;Information systems;Information technology;Libraries;Search methods;Symmetric matrices","data analysis;educational institutions;information retrieval;information systems","data analysis;data extraction;information search;performance analysis;social approach;university information system","","","","","","","19-21 Sept. 2016","","IEEE","IEEE Conference Publications"
"Can We Use Programmer's Knowledge? Fixing Parameter Configuration Errors in Hadoop through Analyzing Q&A Sites","J. Tong; L. Ying; T. Hongyan; W. Zhonghai","Sch. of Software & Microelectron., Peking Univ., Beijing, China","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","478","484","Configuration errors are common in software systems, especially in cloud systems with plenty of components and configuration files. In this paper, we propose a fully automatic approach to fixing parameter configuration errors via analyzing Q&A sites. We analyze the pages and retrieve a list of question answers. Then we generate edit scripts through answer posts in question pages automatically. Experiment results show that our approach is able to generate fixing scripts, and these scripts can accurately reflect solutions buried in natural language of answer posts with 83.60% ratio.","","","10.1109/BigDataCongress.2016.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584979","cloud;configuration error;hadoop;parameter","Cloud computing;Computer crashes;Context;Feature extraction;HTML;Web pages","cloud computing;configuration management;natural language processing;parallel processing;question answering (information retrieval)","Hadoop;Q&A sites analysis;answer posts natural language;cloud systems;configuration files;fixing script generation;page analysis;parameter configuration error fixing;question answer list retrieval;software systems","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"A Computational and Inferential Method for Analyzing the Semantics of Phrase and Sentence in Vietnamese Question Answering System Model (VietQASM)","S. T. Pham; D. T. Nguyen","Dept. of Inf. Sci. & Eng., Vietnam Nat. Univ. - Ho Chi Minh City, Ho Chi Minh City, Vietnam","2015 9th Asia Modelling Symposium (AMS)","20161031","2015","","","107","112","Based on the Reading Answering System (RAS) in S. T. Pham and D. T. Nguyen (2013), this paper aims to present a novel computational and inferential method for computing the semantics of phrase and sentence in Vietnamese in order to build the textual knowledge base of Vietnamese Question Answering System Model (VietQASM). The VietQASM is a Vietnamese question answering system model, which is capable to answer many types of questions about series of events and questions having many interrogative objects. The VietQASM composes three main elements: i) a set of semantic models for phrases, ii) a set of semantic models for sentences, iii) a semantic processing mechanism for analyzing sentences.","","","10.1109/AMS.2015.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725307","Computational Semantics;Inferrable Semantics;Question Answering System;Reading Answering System;Semantic Model;Semantic Representation;Vietnamese","Analytical models;Asia;Computational modeling;Information technology;Knowledge discovery;Semantics;Urban areas","natural language processing;question answering (information retrieval);text analysis","RAS;VietQASM;Vietnamese question answering system model;computational method;inferential method;phrase semantics analysis;reading answering system;semantic processing mechanism;sentence semantics analysis","","","","","","","7-9 Sept. 2015","","IEEE","IEEE Conference Publications"
"A review on an approach to infer user search goals for optimize result","D. Ingale; M. M. Kshirsagar","Department of Computer Technology, Yeshwantrao Chavan College of Engineering, Nagpur, Maharashtra, India","2016 World Conference on Futuristic Trends in Research and Innovation for Social Welfare (Startup Conclave)","20161006","2016","","","1","4","Nowadays, Internet is widely used by users to satisfy their various information needs. Whenever a user submits any query/topic/keyword to search engine, it provides a long list of results for same query. As a consequence of this, users have to spend a lot of time in searching information of his/her interest. Most of the time it has been seen that, search engine does not deliver most relevant information, and hence information need of user does not get satisfied. Hence to provide best results, an analysis of user search goal behind searching is essential. Inference and analysis of user search goals can help to get relevant and refined results from a search engine and to provide better user experience. In this paper, main focus is on survey of infer user search goal approaches in prior studies which would help researchers to retrieve efficient results and information.","","","10.1109/STARTUP.2016.7583941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583941","User search goals;feedback sessions;page rank;search engine;user click-through logs","Conferences;Market research;Optimization;Search engines;Web pages;Web search","Internet;inference mechanisms;information retrieval;search engines","Internet;inference;information needs;search engine;user search goals","","","","","","","Feb. 29 2016-March 1 2016","","IEEE","IEEE Conference Publications"
"Analytics-Driven Visualization on Digital Directory via Screen-Smart Device Interactions","M. Cheung; J. She; S. Park","Electronic and Computer Engineering Department, Hong Kong University of Science and Technology, Hong Kong, China","IEEE Transactions on Multimedia","20161020","2016","18","11","2303","2314","Informative directories have always responded to a fundamental need of humanity: providing available information around people. However, the escalating amount of content to be visualized on directories makes relevant information search extremely time-consuming. Meanwhile, digital displays based on screen-smart device interaction become an emerging interface of smart services to deal with daily-life challenges like information seeking. Also, multimedia content, such as movies, can be understood by multimedia analytics for recommendation, but there is no effective way to visualize the content of a directory. This paper proposes a novel directory visualization framework, called analytics-driven dynamic visualization on digital directory (AVDD): understanding user preferences via smartphone-based interaction and optimizing visualization by visual analytics in terms of high content relevancy and screen utilization for advanced directories. With experiments in laboratory and real-world settings, AVDD is proven to be effective for visualizing directory with screen utilization over 98% and the score for Likert-scale surveys achieving 73% on average in a movie directory.","1520-9210;15209210","","10.1109/TMM.2016.2614222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577785","Customized visualization;directory;multimedia;screen-smart device interaction","Data visualization;Mobile communication;Multimedia communication;Smart phones;Social network services;Visualization","data analysis;data visualisation;human computer interaction;information retrieval;screens (display);smart phones","AVDD;Likert-scale surveys;analytics-driven dynamic visualization on digital directory;content relevancy;digital displays;directory visualization framework;information search;information seeking;informative directories;movie directory;screen-smart device interactions;smartphone-based interaction;user preferences;visual analytics","","","","","","20160927","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Knowledge Management as a Service (KMaaS)","P. Balco; M. Drahoov√°","Dept. of Inf. Syst., Comenius Univ., Bratislava, Slovakia","2016 IEEE 4th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW)","20161018","2016","","","57","62","The issue of knowledge management is crucial for any organization. Convenient access to the requested content is creating a competitive advantage for different types of decisions. Today, when we are inundated with large volumes of information it is essential to use technological solutions that enable flexible storage, retrieval, processing and interpreting information. One of approach, which is communicated a few years, but it implementation is hampered by distrust are solutions based on cloud technology. Their potential grow particularly in an environment where individual skills are shared to a large number of users.","","","10.1109/W-FiCloud.2016.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592701","","Cloud computing;Companies;Computational modeling;Knowledge management;Software as a service","cloud computing;information retrieval;knowledge management","KMaaS;cloud technology;information processing;information retrieval;information storage;knowledge management as a service;technological solutions","","","","","","","22-24 Aug. 2016","","IEEE","IEEE Conference Publications"
"Semantic searching technique based on ontology","R. Aravazhi; M. F. Dayana","A.V.V.M Sri Pushpam College, Poondi, Thanjavur, Tamilnadu, India","2016 International Conference on Emerging Trends in Engineering, Technology and Science (ICETETS)","20161024","2016","","","1","6","Real recuperation of the maximum applicable Records on the subject of attention from the Network is troublesome due to the expansive sum of Data in all sorts of layouts. Concentrates on have been directed on methods to progress the productivity of Data recuperation (IR) schemes. To arrive to appropriate arrangements in IR schemes, machines want extra semantic Data that makes a contrast in accepting Web papers. In this paper, the semantic IR prototypical is examined, arranged to the abuse of field cosmology and WordNet to provision semantic IR capacities in Web documents, pushing on the utilization of ontologies in the semantic-based viewpoint. The scheme; called SPIRS, that employments Semantic Web and specialists to provision more sensitive inquiries and additional exact outcomes is planned. The investigation of the planned Framework is achieved by a test that is based on importance based assessment and Client fulfillment based estimation. The fallouts of the test appears that the proposed scheme, which is based on Semantic Web and agent, can progress the precision and adequacy for recovering applicable Web Records in particular field.","","","10.1109/ICETETS.2016.7603123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603123","Customized Retrieval;Ontology;Semantic Data Retrieval;Semantic Web","Crawlers;Estimation;Indexing;Ontologies;Productivity;Semantic Web;Semantics","information retrieval;ontologies (artificial intelligence);semantic Web","SPIRS;Web documents;WordNet;information recuperation;ontologies;semantic IR;semantic Web;semantic searching technique","","","","","","","24-26 Feb. 2016","","IEEE","IEEE Conference Publications"
"Speeding-Up Association Rule Mining With Inverted Index Compression","J. M. Luna; A. Cano; M. Pechenizkiy; S. Ventura","Department of Computer Science and Numerical Analysis, University of C&#x00F3;rdoba, C&#x00F3;rdoba, Spain","IEEE Transactions on Cybernetics","20161115","2016","46","12","3059","3072","The growing interest in data storage has made the data size to be exponentially increased, hampering the process of knowledge discovery from these large volumes of high-dimensional and heterogeneous data. In recent years, many efficient algorithms for mining data associations have been proposed, facing up time and main memory requirements. Nevertheless, this mining process could still become hard when the number of items and records is extremely high. In this paper, the goal is not to propose new efficient algorithms but a new data structure that could be used by a variety of existing algorithms without modifying its original schema. Thus, our aim is to speed up the association rule mining process regardless the algorithm used to this end, enabling the performance of efficient implementations to be enhanced. The structure simplifies, reorganizes, and speeds up the data access by sorting data by means of a shuffling strategy based on the hamming distance, which achieve similar values to be closer, and considering both an inverted index mapping and a run length encoding compression. In the experimental study, we explore the bounds of the algorithms' performance by using a wide number of data sets that comprise either thousands or millions of both items and records. The results demonstrate the utility of the proposed data structure in enhancing the algorithms' runtime orders of magnitude, and substantially reducing both the auxiliary and the main memory requirements.","2168-2267;21682267","","10.1109/TCYB.2015.2496175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7386634","Association rule mining (ARM);data access;data structure;index compression","Association rules;Computer science;Data structures;Indexes;Memory management;Yttrium","data compression;data mining;data structures;database indexing;distributed databases;information retrieval","data association rule mining process;data size;data storage;data structure;heterogeneous data;high-dimensional data;inverted index compression;inverted index mapping;knowledge discovery;memory requirements;run length encoding compression","","2","","","","20160119","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"Survey on incremental and iterative models in big data mining environment","P. Joseph; J. C. M. J. Pamila","Department of CSE, GCT, Coimbatore-13, India","2016 3rd International Conference on Advanced Computing and Communication Systems (ICACCS)","20161010","2016","01","","1","5","It has become increasingly popular to mine big data in order to gain insights to help business decisions or to provide more desirable personalized, higher quality services. They usually include data sets with sizes beyond the ability of commonly used software tools to retrieve, manage, and process data within an adequate elapsed time. So there is big demand for distributed computing framework. As new data and updates are constantly arriving, the results of data mining applications become incomplete over time. In such situations it is desirable to periodically refresh the mined data in order to keep it up-to-date. This paper describes the existing approaches to big data mining which uses these frameworks in an incremental approach that saves and reuses the previous states of computations. It also explores several enhancements introduced in this same framework with iterative mapping characteristics. Gaps in the current methods are identified in this literature review.","","","10.1109/ICACCS.2016.7586377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586377","Big data mining;Incremental data;Iterative computation","Big data;Communication systems;Computational modeling;Data mining;Data models;Pipelines;Servers","Big Data;data mining;distributed processing;electronic commerce;information retrieval;iterative methods;software tools","big data mining environment;business decisions;data management;data processing;data retrieval;data sets;distributed computing framework;e-commerce;incremental model;iterative mapping characteristics;iterative model;software tools","","","","","","","22-23 Jan. 2016","","IEEE","IEEE Conference Publications"
"Providing FAQ lists based on ontology","M. Pourreza-Shahri; M. Kahani; H. R. Ekbia","Faculty of Engineering, Ferdowsi University of Mashhad Mashhad, Iran","2016 24th Iranian Conference on Electrical Engineering (ICEE)","20161010","2016","","","305","310","Researchers have been fascinated in FAQ (Frequently Asked Questions) management systems in recent years. These systems have reduced the cost of supporting productions. The goal of this research is to implement a Persian FAQ generator in PC domain based on ontology. There are several steps for implementation. First, all slangs are converted into formal Persian phrases. Second, our proposed similarity method measures similarity between questions. After creating question similarity matrix, similar questions are gathered in the same clusters. FAQ lists are created based on clusters which have the most number of members. Evaluations indicates that our proposed similarity matrix generates the best results in comparison with Lin, MCS, and LSA matrices. Moreover, our proposed clustering method provides better results compared to hierarchical complete-linkage, hierarchical single-linkage, and Kmeans methods.","","","10.1109/IranianCEE.2016.7585537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585537","Clustering;FAQ list generation;Frequently Asked Questions;Ontology;Persian FAQ","Clustering algorithms;Clustering methods;Databases;Electrical engineering;Matrix converters;Ontologies;Semantics","cost reduction;natural language processing;ontologies (artificial intelligence);pattern clustering;question answering (information retrieval)","FAQ list generation;PC domain;Persian FAQ;clustering;cost reduction;formal Persian phrases;frequently asked question management systems;ontology;similarity matrix","","","","","","","10-12 May 2016","","IEEE","IEEE Conference Publications"
"Secure multi-keyword search supporting dynamic update and ranked retrieval","J. Yan; Y. Zhang; X. Liu","State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an 710071, Shaanxi Province, China","China Communications","20161103","2016","13","10","209","221","As cloud computing is becoming prevalent, data owners are motivated to delegate complex data managements to the commercial cloud for economic savings. Sensitive data is usually encrypted before being uploaded to the cloud, which unfortunately makes the frequently-used search function a challenging problem. In this paper, we present a new multi-keyword dynamic search scheme with result ranking to make search over encrypted data more secure and practical. In the scheme, we employ a powerful function-hiding inner product encryption to enhance the security by preventing the leakage of search pattern. For the concern of efficiency, we adopt a tree-based index structure to facilitate the searching process and updating operations. A comprehensive security analysis is provided and experiments over the real world data show that our scheme is efficient.","1673-5447;16735447","","10.1109/CC.2016.7733045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7733045","cloud computing;dynamic update;ranked search;secure search","Cloud computing;Encryption;Indexes;Search problems;Servers","cloud computing;information retrieval;trees (mathematics)","cloud computing;complex data managements;dynamic update;powerful function-hiding inner product encryption;ranked retrieval;secure multikeyword dynamic search scheme;tree-based index structure","","","","","","","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Large-Scale Cross-Modality Search via Collective Matrix Factorization Hashing","G. Ding; Y. Guo; J. Zhou; Y. Gao","School of Software, Tsinghua University, Beijing, China","IEEE Transactions on Image Processing","20160926","2016","25","11","5427","5440","By transforming data into binary representation, i.e., Hashing, we can perform high-speed search with low storage cost, and thus, Hashing has collected increasing research interest in the recent years. Recently, how to generate Hashcode for multimodal data (e.g., images with textual tags, documents with photos, and so on) for large-scale cross-modality search (e.g., searching semantically related images in database for a document query) is an important research issue because of the fast growth of multimodal data in the Web. To address this issue, a novel framework for multimodal Hashing is proposed, termed as Collective Matrix Factorization Hashing (CMFH). The key idea of CMFH is to learn unified Hashcodes for different modalities of one multimodal instance in the shared latent semantic space in which different modalities can be effectively connected. Therefore, accurate cross-modality search is supported. Based on the general framework, we extend it in the unsupervised scenario where it tries to preserve the Euclidean structure, and in the supervised scenario where it fully exploits the label information of data. The corresponding theoretical analysis and the optimization algorithms are given. We conducted comprehensive experiments on three benchmark data sets for cross-modality search. The experimental results demonstrate that CMFH can significantly outperform several state-of-the-art cross-modality Hashing methods, which validates the effectiveness of the proposed CMFH.","1057-7149;10577149","","10.1109/TIP.2016.2607421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7563341","Hashing;collective matrix factorization;cross-modality search;multimodal data;optimization;scalability","Algorithm design and analysis;Binary codes;Databases;Hamming distance;Matrix decomposition;Optimization;Semantics","information retrieval;matrix decomposition;multimedia databases","binary representation;collective matrix factorization hashing;large-scale cross-modality search;shared latent semantic space","","1","","","","20160908","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Does everybody lie? characterizing answerers in health-related CQA","A. Belobordov; P. Braslavski","Ural Federal University, Yekateringburg, Russia","2016 International FRUCT Conference on Intelligence, Social Media and Web (ISMW FRUCT)","20161013","2016","","","1","6","The study described in the paper aims at multi-faceted characterization of active community question answering (CQA) users who provide answers to health-related questions. The study employs various research techniques - both qualitative (surveys) and quantitative. With two online surveys we get insights into 1. perception of online health-related information and its use by patients by medical professionals and 2. motivtion of most active CQA answerers, a significant share of which apparently constitute users with medical education. In the second series of experiments we apply topic modeling to a yearly collection of questions and answers from a popular Russian CQA servce in order to find users focused on a particular topic. Further, we attempt to find users with professional medical backround based on the lexis of their answers. The obtained results provide a beter understanding of motivation and backround of CQA users and can be used for the improvement of CQA services, as well as for solving problems such as CQA content quality evaluation, expert search, and question routing, etc.","","","10.1109/FRUCT.2016.7584763","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584763","","","health care;medical information systems;question answering (information retrieval)","Russian CQA service;active community question answering;health-related CQA;multifaceted characterization;online health-related information;professional medical backround","","","","","","","Aug. 28 2016-Sept. 4 2016","","IEEE","IEEE Conference Publications"
"Identifying a group of subject experts using formal concept analysis","V. Boeva; M. Angelova; L. Boneva; E. Tsiporkova","Computer Systems and Technologies Department, Technical University of Sofia, branch Plovdiv, Bulgaria","2016 IEEE 8th International Conference on Intelligent Systems (IS)","20161110","2016","","","464","469","Expertise retrieval has already gained significant interest in the area of information retrieval due to multitude of concrete application contexts where search for specific experts is required. In this paper, we introduce a formal concept analysis approach for clustering of a group of experts with respect to given subject areas. Initially, the domain of interest is presented at some level of abstraction by partitioning the domain to a number of subject areas. Next each expert is represented by a vector of contributions of the expert to the different areas. This defines an overlapping partition, which is further analyzed and refined into a disjoint one by applying Formal Concept Analysis. In this way a hierarchical conceptual structure is automatically derived. It consists of concepts where each one represents a subset of experts belonging to a number of subject areas. The set of all derived concepts partitions the experts into a set of disjoint expert areas.","","Electronic:978-1-5090-1354-8; POD:978-1-5090-1355-5; USB:978-1-5090-1353-1","10.1109/IS.2016.7737462","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737462","data mining;expert finding;formal concept analysis;health science;knowledge management","Context;Data mining;Electronic mail;Formal concept analysis;Lattices;LinkedIn;Semantics","data mining;formal concept analysis;information retrieval;pattern clustering","data mining;domain partitioning;expert finding;expertise retrieval;experts clustering;formal concept analysis;hierarchical conceptual structure;information retrieval;overlapping partition;subject experts identification","","","","","","","4-6 Sept. 2016","","IEEE","IEEE Conference Publications"
"Efficient data search using map reduce framework","P. P. Dhekale; N. Jichkar","Dept. of Computer Science and Engg., Yashwantrao Chavan College of Engineering, Hingna Road, Nagpur-41110, India","2016 World Conference on Futuristic Trends in Research and Innovation for Social Welfare (Startup Conclave)","20161006","2016","","","1","4","In data centric organization, cloud is used as a computational and storage purpose. But the main problem of this organization is data retrieving in efficient manner. To solve this problem a framework is required to retrieve data from thousands of machine. The main purpose is to design a web server in the map phase which will give a fast and efficient way of retrieving data. In Hadoop architecture, MapReduce is a programming model and HDFS is a file system which is used for storing large data.","","","10.1109/STARTUP.2016.7583980","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583980","Hadoop;MapReduce;indexing;jetty server","Cloud computing;Computer architecture;File systems;Indexing;Web servers","Internet;data handling;file organisation;information retrieval;parallel programming","HDFS;Hadoop architecture;Map Reduce framework;Web server;data centric organization;data retrieval;data search;file system;programming model","","","","","","","Feb. 29 2016-March 1 2016","","IEEE","IEEE Conference Publications"
"CRATS: An LDA-Based Model for Jointly Mining Latent Communities, Regions, Activities, Topics, and Sentiments from Geosocial Network Data","J. D. Zhang; C. Y. Chow","Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong","IEEE Transactions on Knowledge and Data Engineering","20161005","2016","28","11","2895","2909","Geosocial networks like Yelp and Foursquare have been rapidly growing and accumulating plenty of data such as social links between users, user check-ins to venues, venue geographical locations, venue categories, and user textual comments on venues. These data contain rich knowledge on the user's social interactions in communities, geographical mobility patterns between regions, categorical preferences on activities, aspect interests in topics, and opinion expressions for sentiments. Such knowledge is essential for two key applications, namely, text sentiment classification and venue recommendations, which will be developed in this paper. To extract the knowledge from the data, the key task is to discover the latent communities, regions, activities, topics, and sentiments of users. However, these latent variables are interdependent, e.g., users in the same community usually travel on nearby regions and share common activities and topics, which renders a big challenge for modeling these latent variables. To tackle this challenge, in this study, we propose an LDA-based model called CRATS that jointly mines the latent Communities, Regions, Activities, Topics, and Sentiments based on the important dependencies among these latent variables. To the best of our knowledge, this is the first study to jointly model these five latent variables. Finally, we conduct a comprehensive performance evaluation for CRATS in different applications, including text sentiment classification and venue recommendations, using three large-scale real-world geosocial network data sets collected from Yelp and Foursquare. Experimental results show that CRATS achieves significantly superior performance against other state-of-the-art techniques.","1041-4347;10414347","","10.1109/TKDE.2016.2594772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523913","Geosocial network;collapsed Gibbs sampling;generative probabilistic model;latent Dirichlet allocation;text sentiment classification;topic modeling;venue recommendation","Atmosphere;Data mining;Data models;Probabilistic logic;Resource management;Semantics;Urban areas","data mining;information retrieval;pattern classification;recommender systems;sentiment analysis;social networking (online);statistical analysis","CRATS model;Foursquare;LDA;Latent Dirichlet allocation;Yelp;communities regions activities topics and sentiments;data mining;geographical mobility pattern;geosocial network data;knowledge extraction;text sentiment classification;user social interaction;venue recommendation","","","","","","20160727","Nov. 1 2016","","IEEE","IEEE Journals & Magazines"
"Coupled feature mapping and correlation mining for cross-media retrieval","Mengdi Fan; W. Wang; Ronggang Wang","School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Lishui Road 2199, Nanshan District, China 518055","2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","20160926","2016","","","1","6","Cross-media retrieval aims to integrate and analyze the features of various modalities (e.g., text, image and video) to mine their potential semantic information. In this paper, we propose a novel cross-media retrieval framework, which performs coupled feature mapping and correlation mining successively. Our method first learns two projection matrices to map the multimodal features into a common category space, in which homo- and hetero-correlation techniques can be applied easily. Homo-correlation focuses on the semantic category information within the same media type, while hetero-correlation focuses on the semantic category information between different media types. The two could complement and reinforce each other. Experiments on two different datasets, Wikipedia dataset and Pascal Voc dataset, demonstrate that the proposed framework gives promising results compared to the related state-of-the-art approaches.","","","10.1109/ICMEW.2016.7574754","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574754","Cross-media retrieval;feature mapping;hetero-correlation;homo-correlation","Correlation;Data mining;Media;Semantics;Silicon;Testing;Training","information retrieval;matrix algebra;semantic networks","Pascal Voc dataset;Wikipedia dataset;correlation mining;coupled feature mapping;cross-media retrieval framework;hetero-correlation techniques;homo-correlation techniques;multimodal features;potential semantic information;projection matrices;semantic category information","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Graph pattern matching: A brief survey of challenges and research directions","K. Singh; V. Singh","National Institute of Technology, Kurukshetra, Haryana, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","199","204","Due to tremendous intensification of Internet, most of the data is archived and analyzed in graph-structured database. Graph Database is a collection of operational data objects, mapped into huge labeled graph or a set of labeled directed graphs. In recent years, modeling data in graph structure becomes evident and effective for processing in some of the prominent application area like social analytics etc. Graph databases are mapped into data graphs for further computing or processing. Graphs are one of the dominant data modeling tool used in many application areas. Hence, there is a demand for proficient querying techniques on such large data graphs. The user query is mapped into pattern graph, which is constructed by connecting nodes based on links/relationships required by user. The primary objective of graph pattern matching (GPM) is to determine all the candidates matching to a pattern query in a large data graph. This survey paper discusses various graph pattern matching approaches, used by researchers in recent year for query processing. Further, we also highlight the various challenges imposed by modern day computing and possible future research directions in query processing using graph pattern matching.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724255","Big Data Analytics;Graph Data;Graph Mining;Graph Pattern Matching;Query Processing","Complexity theory;Computational modeling;Data models;Pattern matching;Query processing;Semantics","Internet;database management systems;directed graphs;information retrieval systems;pattern matching;query processing","GPM;Internet;data archives;data modeling tool;directed graphs;graph pattern matching;graph-structured database;large data graphs;operational data objects;query processing","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"A Model for Preserving the Electronic Records Event History Metadata in Malaysia Government Agencies","A. a. Bunawan; S. Nordin; H. Haron","Fac. of Comput. & Math. Sci., Univ. Teknol. MARA, Shah Alam, Malaysia","2015 Seventh International Conference on Computational Intelligence, Modelling and Simulation (CIMSim)","20161006","2015","","","29","34","This paper highlighted the study on preserving the e-records event history metadata. This study is currently conducted in identified the actual model that should be used in preserving the e-records metadata in Malaysia Government Agencies. In preliminary stages, the interview session has been conducted with staffs from Malaysia Government Agencies and National Archives of Malaysia (NAM) in order to identify the actual problem occur in preserving the e-records metadata. This paper also reviewed four (4) theoretical metadata models and expert validation to firmly come out with a concrete model that can give the solution to the existing problem. The models are Open Archival Information System (OAIS), Preservation Metadata: Implementation Strategies (PREMIS), ISO/TS 23081 and Encoded Archival Description (EAD). Furthermore, in this early stage of data collection and validation, there are four (4) NAM branches have been involved for the in-depth discussion on the proposed model. Based on the discussion, they determinedly that the proposed model are important for safeguarding the preservation of e-records event history metadata in terms of evidence and security purposes.","","","10.1109/CIMSim.2015.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7579691","E-Governement; Model; E-Records; Preservation; Event history; Metadata","Computational modeling;Government;History;Mathematical model;Metadata;Standards","government data processing;information retrieval systems;meta data","EAD;Malaysia government agencies;NAM;National Archives of Malaysia;OAIS;PREMIS;electronic records event history metadata;encoded archival description;open archival information system;preservation metadata-implementation strategies;security purposes","","","","","","","27-29 July 2015","","IEEE","IEEE Conference Publications"
"A Generic Framework for Biomedical Snippet Retrieval","Y. Li; X. C. Yin; B. W. Zhang; T. T. Liu; Z. J. Zhang; H. W. Hao","Sch. of Comput. & Commun. Eng., Univ. of Sci. & Technol. Beijing, Beijing, China","2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)","20161024","2015","","","91","95","In the biomedicine domain, a large number of papers are published every day, which is crucial to search for the relevant answers for the user's query. However, documents are not exactly what the users want. Instead, snippets, small segments from the documents, are more proper to meet the requirement of the users. Hence, this paper proposes a biomedical snippet retrieval framework to exactly locate the answers (snippets) for the biomedical questions (queries) from the users. In our framework, word embeddings with biomedical meanings are trained for query expansion. Then, the expansion query is used to retrieve the relevant snippets from the candidate documents using the sequential dependence model which can benefit retrieval results. Finally, our proposed framework is evaluated on the BioASQ 2014 task datasets, and has the best performance (MAP@100) compared to state-of-the-art systems. Moreover, our framework has competitive results on the BioASQ 2015 task.","","","10.1109/AIMS.2015.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7604557","BioASQ;Biomedical Literature;Query Expansion;Snippet Retrieval;Word Embeddings","Artificial intelligence;Biological system modeling;Computational modeling;Natural languages;Semantics;Testing;Training","medical computing;query processing;question answering (information retrieval)","BioASQ 2014 task datasets;biomedical question answering;biomedical snippet retrieval framework;query expansion;sequential dependence model;user query;word embeddings","","","","","","","2-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"Keyword extraction method over blog community","Y. Wei; Y. Zhizhuo","School of Educational Technology and Communication, ShanXi Normal University, LinFen, ShanXi, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1553","1556","Existing methods for Blog keyword extraction usually exploit the context in the specified blog. In this paper, we propose to provide a knowledge context by using small number of nearest neighbor blogs to improve keyword extraction performance. Specifically, knowledge context is build by adding several topic related blogs closed to the specified blog, and then the manifold ranking model is used on the knowledge context to make use of both knowledge contained in the specified blog and knowledge contained in the neighbor blogs. Experimental results show that this method can significantly outperform the baseline method, and also obtains improvement over existing method.","","","10.1109/FSKD.2016.7603407","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603407","keyword extraction blog expansion;manifold ranking;neighborhood knowledge;similarity measure","Blogs;Context;Context modeling;Data mining;Manifolds;Probability;Semantics","Web sites;information retrieval","blog community;blog keyword extraction;knowledge context;manifold ranking model;nearest neighbor blogs","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Entropy based informative content density approach for efficient web content extraction","M. Annam; G. P. Sajeev","Dept of Computer Science and Engineering, Amrita School of Engineering, Amritapuri, Amrita Vishwa Vidyapeetham, Amrita University, India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20161103","2016","","","118","124","Web content extraction is a popular technique for extracting the main content from web pages and discards the irrelevant content. Extracting only the relevant content is a challenging task since it is difficult to determine which part of the web page is relevant and which part is not. Among the existing web content extraction methods, density based content extraction is one popular method. However density based methods, suffer from poor efficiency, especially when the pages containing less information and long noise. We propose a web content extraction technique build on Entropy based Informative Content Density algorithm (EICD). The proposed EICD algorithm initially analyses higher text density content. Further, the entropy-based analysis is performed for selected features. The key idea of EICD is to utilize the information entropy for representing the knowledge that correlates to the amount of informative content in a page. The proposed method is validated through simulation and the results are promising.","","","10.1109/ICACCI.2016.7732034","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732034","EICD;Information Entropy;Text Density;Web Content Extraction;Weighted DOM","Data mining;Entropy;Feature extraction;HTML;Information entropy;Vegetation;Web pages","Internet;Web sites;entropy;feature selection;information retrieval;knowledge representation;text analysis","EICD;Web content extraction methods;Web pages;density based content extraction;entropy based informative content density algorithm;entropy based informative content density approach;entropy-based analysis;feature selection;information entropy;text density content","","","","","","","21-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Document Recommendation System Using a Document-Similarity Ontology","R. Vences Nava; V. H. Menendez Dominguez; J. Gomez Montalvo","","IEEE Latin America Transactions","20161010","2016","14","7","3329","3334","In this paper, we present a proposal for searching, retrieving and recommending documents, based on the similarity of their content, using an ontology of the type ‚ÄúFriend of a Friend‚Äù that establishes, if it is the case, the transitivity of similarity between the document selected by the user and the other documents in the repository. Document similarity is calculated as the cosine of the angle between the vectors of terms that represent them. The Vector Space Model is used for representing the documents and the weight of the terms is obtained by using the TF-IDF metric. The architecture that implements the proposal is presented as well as experimental results.","1548-0992;15480992","","10.1109/TLA.2016.7587638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7587638","Cosine Similarity;FOAF Ontology;Recommender Systems;TF-IDF","Computer architecture;Internet;Measurement;Ontologies;Proposals;Recommender systems;Silicon compounds","information retrieval;ontologies (artificial intelligence);pattern matching;recommender systems","TF-IDF metric;document recommendation system;document representation;document retrieval;document similarity;document-similarity ontology;vector space model","","","","","","","July 2016","","IEEE","IEEE Journals & Magazines"
"Word prediction algorithm in resolving ambiguity in Malay text","S. S. Sazali; Z. A. Bakar; J. Jaafar","Faculty of Computer and Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Selangor, Malaysia","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","1347","1352","Word prediction algorithms are widely used in aiding disables by recommending the next potential word to be used. In this paper, the word prediction algorithm, n-gram, is used to resolve ambiguity in Malay text to retrieve relevant information. The test collection consists of Malay translated Al-Quran and Hadith. Initial experiment is conducted using the keyword madu that retrieved 72 Hadiths and 3 translated Al-Quran documents. Experiments are conducted on these retrieved documents using bigram and trigram. Result shows that trigram gives better prediction and retrieved relevant documents compared to the bigram.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724485","Al-Quran;Hadith;Malay text;ambiguous word;bigram;n-gram;trigram;word prediction","Conferences;Decision support systems;Handheld computers","information retrieval;natural language processing;prediction theory;text analysis","Hadith documents;Malay text ambiguity;Malay translated Al-Quran documents;bigram;information retrieval;keyword;trigram;word prediction algorithm","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Semantically annotated corpus model of Indonesian Translation of Quran: An effort in increasing question answering system performance","H. T. Sukmana; R. H. Gusminta; Y. Durachman; A. F. Firmansyah","Dept. Informatics Engineering, Syarif Hidayatullah State Islamic University, Jakarta, Indonesia","2016 4th International Conference on Cyber and IT Service Management","20160929","2016","","","1","5","This paper presents our work in defining a model to build a semantic-based corpus of Indonesian Translation of the Quran. This task was being an effort to increase Question Answering System (QAS) performance on Indonesian Translation of the Quran that has been developed in 2013[1]. As the QAS run on three kinds of question type i.e. Siapa (Who), Kapan (When), and Di mana (Where), this model designed specifically to deal with those question types. The model is ready to be implemented and evaluated. Since we want to measure how significance semantic approach is on QAS performance, evaluation will be conducted by using the same scheme used. Furthermore, our model also will be assessed by comparing it with other corpus developed by using graph database model.","","","10.1109/CITSM.2016.7577585","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577585","Indonesian Translation Quran;Question Answering;semantic-based corpus","Knowledge discovery;Morphology;Ontologies;Semantics;Sociology;Statistics;Syntactics","language translation;natural language processing;question answering (information retrieval)","Di mana;Indonesian translation;Kapan;QAS performance;Quran;Siapa;graph database model;question answering system performance;semantic-based corpus","","","","","","","26-27 April 2016","","IEEE","IEEE Conference Publications"
"Web data extraction techniques: A review","N. V. Kamanwar; S. G. Kale","Dept. of Information Technology, Y.C.C.E., Hingna Road, Wanadongari, Nagpur - 441110, India","2016 World Conference on Futuristic Trends in Research and Innovation for Social Welfare (Startup Conclave)","20161006","2016","","","1","5","Web data extraction is the process of extracting user required information from websites. The web document contains data which is not in structured format. From the word web data extraction, we mean the extraction of data that is present in the web documents in HTML format. Then removing the unwanted stuff such as tags, advertisements, videos and so on. Then learning the information or patterns or features present in that data. Today, most researchers uses web data extractors because the internet contains huge data which makes the process of manual information extraction from the web documents complicated. In this paper, we have studied about different techniques for data extraction used by different authors that takes the user required data from a set of web pages. A comparative analysis of web data extraction techniques is given.","","","10.1109/STARTUP.2016.7583910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583910","Data Path;Hadoop;MapReduce;Trinity;Unsupervised learning;Web Data Extraction;alignment;subject detection;visual features;wrapper","Algorithm design and analysis;Clustering algorithms;Data mining;Feature extraction;HTML;Visualization;Web pages","Internet;Web sites;document handling;hypermedia markup languages;information retrieval","HTML format;Internet;Web data extraction techniques;Web document;Web pages;Web sites;structured format;user required information extraction","","","","","","","Feb. 29 2016-March 1 2016","","IEEE","IEEE Conference Publications"
"Gene Network Inference Using Forward Backward Pairwise Granger Causality","M. S. Furqan; M. Y. Siyal","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore","2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)","20161024","2015","","","321","324","Discovery of temporal dependence is the basic idea for evaluating gene networks using Granger causality. However, with the advancement of technology, now we can analyze multiple genes simultaneously that result in high dimensional data. Recent studies suggest that more causal information can be retrieved if we reverse the time stamp of time series data along with standard time series data. Based on these findings, we are proposing a new method called Forward Backward Pair wise Granger Causality. The results how that our method can handle high dimensional data and can extract more causal information compared to the standard ordinary least squares method. We have performed a comparison of proposed and existing method using simulated data and then used the proposed method on real Hela cell data and mapped the 19 genes that are commonly present in cancer.","","","10.1109/AIMS.2015.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7604595","Gene Network;Granger causality","Biological system modeling;Computational modeling;Data mining;MATLAB;Mathematical model;Standards;Time series analysis","biology computing;causality;data handling;data mining;genetics;inference mechanisms;information retrieval","causal information extraction;data handling;forward backward pairwise Granger causality;gene network inference;temporal dependence discovery","","","","","","","2-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"An empirical semi-supervised machine learning approach on extracting and ranking document level multi-word product names using improved C-value approach","R. Sivashankari; B. Valarmathi","School of Information Technology and Engineering, VIT University, Vellore, India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20161103","2016","","","770","775","In recent years, the volume of data submissions (E-Commerce data) in online on products, service, and organizations is increasing exponentially. This online data is abundantly unstructured; extracting knowledge from that huge volume of data is a non-trivial task. In recent years, extracting product names become a very popular approach and also one of the important methods in sentiment analysis. This product name extraction is very useful in E-commerce, because it helps in identifying people interest on products, generation of reviews' metadata and identification of product attributes, etc. The existing approaches in product name extraction are capable of extracting single word product names. However, the product names can be a sequence of words, which is also called multi-word product names that cannot be obtained automatically by the existing methods. In this paper, a combined approach of semi-supervised machine learning and improved C-value approach is proposed to discover the multi-word product names, ranking those product names and identifying a dominant product in review documents.","","","10.1109/ICACCI.2016.7732139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732139","POS Tagging;Sentiment analysis;document-level mining;machine learning;text mining","Artificial neural networks;DVD;Data mining;Feature extraction;Informatics;Organizations;Tagging","document handling;information retrieval;learning (artificial intelligence);natural language processing","document level multiword product name extraction;document level multiword product name ranking;improved C-value approach;semisupervised machine learning approach","","","","","","","21-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Data analysis and visualization of sales data","K. Singh; R. Wajgi","Department of Computer Technology, YCCE, Nagpur, India","2016 World Conference on Futuristic Trends in Research and Innovation for Social Welfare (Startup Conclave)","20161006","2016","","","1","6","Data is being generated very rapidly due to increase in information in everyday life. Huge amount of data get accumulated from various organizations that is difficult to analyze and exploit. Data created by an expanding number of sensors in the environment such as traffic cameras and satellites, internet activities on social networking sites, healthcare database, government database, sales data etc., are example of huge data. Processing, analyzing and communicating this data are a challenge. Online shopping websites get flooded with voluminous amount of sales data every day. Analyzing and visualizing this data for information retrieval is a difficult task. Therefore a system is required which will effectively analyze and visualize data. This paper focuses on a system which will visualize sales data which will help users in applying intelligence in business, revenue generation, and decision making, managing business operation and tracking progress of tasks.","","","10.1109/STARTUP.2016.7583967","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583967","Analysis;Report generation;Sales data;Visualization","Data mining;Data visualization;Databases;Image color analysis;Market research;Shape;Technological innovation","business data processing;data analysis;data visualisation;information retrieval","business intelligence;business operation management;data analysis;decision making;information retrieval;online shopping websites;revenue generation;sales data visualization","","","","","","","Feb. 29 2016-March 1 2016","","IEEE","IEEE Conference Publications"
"Semantic computation in geography question answering","S. Zhao; Y. Zheng; C. Zhu; T. Zhao; S. Li","School of Computer Science and Technology, Harbin Institute of Technology, HIT, Harbin, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1572","1576","In this paper, we develop a question answering system for solving single-option geography questions. The system is built in two directions. One computes semantic similarity between two questions. The other converts the task into question sentence binary-classification by generating the distributed representation of sentence semantic. When computing semantic similarity, we first implement a basic framework based on bag-of-words (BOW), and then extend the framework to Edit Distance variant and BM25 variant. On the other hand, we use convolutional neural network and stacked denoising auto-encoder to generate the distributed representation of sentence semantic respectively. Given the semantic representation of sentence, a logistic regression classifier is employed to classify the sentence. The dataset we use is a large scale Chinese college entrance examination question set of geography, which is clawed from the internet. Experiment results show that the performance of CNN can answer the single-option geography questions with high accuracy, which can achieve 0.7310.","","","10.1109/FSKD.2016.7603410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603410","BM25;CNN;SDA;single-option question","Computational modeling;Feature extraction;Geography;Knowledge discovery;Machine learning;Rocks;Semantics","Internet;geophysics computing;neural nets;pattern classification;question answering (information retrieval);regression analysis","BM25 variant;CNN;Chinese college entrance examination question set;Internet;convolutional neural network;edit distance variant;geography question answering;logistic regression classifier;question sentence binary-classification;semantic computation;semantic sentence representation;single-option geography questions;stacked denoising auto-encoder","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Parallel Computation of Reverse PageRank Problem with Evaluating Single Page","S. Lai; Y. Yang; M. Guo; X. Lin","Sch. of Data & Comput. Sci., Sun Yat-sen Univ., Guangzhou, China","2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)","20161031","2016","","","75","80","PageRank is a core component in search engine. In a wide range of PageRank applications, only few pages often need to be evaluated in some scenarios. In this paper, we propose Markov chain Monte Carlo (MCMC) method for solving reverse PageRank problem. Different from the previous MCMC method that solves the problem via simulating surfing the internet forward, we adopt MCMC method to solve PageRank problem via simulating surfing the internet backward, called reverse PageRank. For a selected page, the MCMC method can be used to simulate the network to find all the possible paths from any other page to the selected page. The major advantage of the proposed method is that only one page is evaluated, instead of computing the whole pages. Following this method, we can independently evaluate the importance of the selected page. As MCMC method has parallelism and robustness in nature, it is suitable to be implemented and optimized on GPU. We have simulated the real world networks to evaluate the performance of the method. The results demonstrate that our MCMC method can be implemented efficiently on GPU and outperforms the other existing methods when few pages are evaluated. We then discuss and analyze the important properties of the MCMC method for reverse PageRank problem based on the experiment results.","","","10.1109/BDCloud-SocialCom-SustainCom.2016.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723676","GPU;Monte Calro method;PageRank;paralleling;reverse","Complexity theory;Finite wordlength effects;Graphics processing units;Internet;Markov processes;Upper bound","Internet;Markov processes;Monte Carlo methods;graphics processing units;information retrieval;parallel processing","GPU;Internet;MCMC method;Markov chain Monte Carlo method;graphics processing unit;page evaluation;parallel computation;reverse PageRank problem","","","","","","","8-10 Oct. 2016","","IEEE","IEEE Conference Publications"
"Automating Management of Resources on Desktop Machines","M. G. Lim; F. Wang; N. Jiang","Future Comput. Group, Univ. of Kent, Medway, UK","2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim)","20160926","2015","","","188","191","Two challenges that affect retrieval tasks in a typical computer desktop user environment are the speed and accuracy of accessing information such as documents and media files. Generating a common model to fit patterns of use with a reasonable level of prediction is challenging. This is as the individual usage patterns on the desktop is assumed to vary largely depending on the context of task. In this paper, we propose a lightweight learning framework, Usage Provenance and Prediction (UPP) model, which traces the user's mouse input and predicts the associated application with the media content. We disseminate the architecture of our tracing framework that is embedded on modern operating systems and show that this model adapts and improves data seeking experience at a user level. Our UPP framework achieves 96.70% accuracy with average application speed improvements of up to 32.92% over standard application launches. The results are encouraging and supports the potential of automating resources through the application of tracing usage patterns.","","","10.1109/UKSim.2015.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576543","intelligent systems; tracing;passive association; cloud computing; data mining; HCI; virtual data management; scalable user systems","Context;Decision trees;Electronic mail;Indexing;Learning systems;Mice;Real-time systems","cloud computing;data mining;information retrieval;learning (artificial intelligence);microcomputers;operating systems (computers);resource allocation","UPP model;cloud computing;computer desktop user environment;data mining;data seeking experience;desktop machines;information retrieval tasks;lightweight learning framework;modern operating systems;mouse input tracing;resource management automation;usage pattern tracing;usage provenance and prediction model","","","","","","","25-27 March 2015","","IEEE","IEEE Conference Publications"
"Design and implementation of Android-based health and healthcare system","H. Deng; S. Chen","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2016 International Wireless Communications and Mobile Computing Conference (IWCMC)","20160929","2016","","","164","169","Facing today's increasingly serious health problems, we designed and implemented an Android-based health and healthcare system, with a view to helping mobile users develop healthy living habits and enhance their health awareness. The system uses C/S mode and HTTP protocol as the communication protocol. The client consists of five functional modules and uses Volley to access network. The data of client is stored by SQLite and XML files. Server uses the classic JavaEE three-tier architecture and the overall framework is realized by Spring framework. Specifically, the persistent (data access) layer uses Hibernate secondary cache technology, being responsible for data persistence. The business layer uses Hibernate search technology, providing the core business logic implementation. The Web layer is implemented by SpringMVC, providing the RESTful interface. The functional test shows that the system meets the design requirements.","","","10.1109/IWCMC.2016.7577051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577051","Android;REST;Spring;health awareness;healthcare;healthy living habits","Databases;Meteorology;Protocols;Registers;Search problems;XML","Android (operating system);Java;Web services;XML;cache storage;health care;information retrieval;mobile computing;transport protocols","C/S mode;HTTP protocol;Hibernate search technology;Hibernate secondary cache technology;JavaEE three-tier architecture;RESTful interface;SQLite;SpringMVC;Web layer;XML files;android-based health system;communication protocol;core business logic implementation;data access;health awareness;healthcare system;healthy living habits;mobile users","","","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Research on collaboration patterns of ICMSE conference coauthors network","X. L. Pang; W. Jiang","School of Economics and Business Administration, Hei Long Jiang University, P.R. China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1594","1599","Fistly, IEEE database is utilized to retrieve ICMSE conference data from 2006 to 2013 to build the conference coauthors network, then use social network analysis methods to analyze the scientific status of cooperation between scholars. Secondly, in the analysis of Cohesive Subgroup, we analyze and compare the two larger network from the core node centrality, the correlation between code centrality and the amount of published articles, the team themes and small-world phenomenon, then show the evolution of the largest subnet, finding cooperative law among subgroups members. Finally, we get the journal posting agency statistics, further revealed the law of the journal, which provide some suggestions for journal further development and support for the cooperation of this field.","","","10.1109/FSKD.2016.7603414","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603414","Coauthor Net-work;Component analysis;ICMSE;Social Network Analysis","Business;Collaboration;Conferences;Correlation;Correlation coefficient;Economics;Social network services","data analysis;electronic publishing;information retrieval","Cohesive Subgroup;ICMSE conference coauthors network;ICMSE conference data retrieval;collaboration patterns;cooperative law;core node centrality;journal posting agency statistics;published articles;social network analysis;team themes","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"A HMM-based approach for historic and up-to-date land cover mapping through Landsat time-series in the state of Sao Paulo, Brazil","L. Iannini; R. Molijn; A. Mousivand; R. Hanssen; R. Lamparelli","Delft University of Technology, Netherlands","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","5457","5460","The paper debates a novel approach for land cover (LC) mapping based on the Hidden Markov Model. The proposed methodology is aimed to address both the urgent demand of off-line (or historic) LC information retrieval and of near-real time LC monitoring. The discrete-time model employs short steps of 16 days, that conveniently fits the Landsat revisit time while providing a continuous and temporally dense representation of the land cover dynamics. Two temporal pattern typologies were identified and modeled within the proposed Markov chain architecture: a seasonal and synchrounous behavior which can be associated to the observables of LC classes such as forest and grasses, and a highly asynchronous behaviour, which characterizes the crop observables. The first typology is addressed by introducing time-dependency in state output probabilities, whereas the latter is rendered through a sequence of (sub-class) states interlinked by means of a `left-right' based model. Such model inherently incorporates crop growth tracking functionalities as an added value. In this paper the methodology has been tailored to Sao Paulo state (Brazil) scenario, showing overall accuracy above 80% on the test sample. A particular emphasis is attributed to the identification of sugarcane plantations, that are indeed responsible for major land use changes.","","","10.1109/IGARSS.2016.7730421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730421","Land cover;Landsat time-series;change detection;classification;crop growth tracking;hidden markov models","Agriculture;Calibration;Earth;Hidden Markov models;Mathematical model;Remote sensing;Satellites","geophysical techniques;hidden Markov models;information retrieval;land cover;remote sensing;time series","Brazil;Landsat time-series;Markov chain;Sao Paulo;hidden Markov model;information retrieval;land cover mapping;near-real time land cover monitoring;sugarcane plantations","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Stratified locality-sensitive hashing for accelerated physiological time series retrieval","Y. B. Kim; E. Hemberg; U. M. O'Reilly","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","2479","2483","We introduce stratified locality-sensitive hashing (SLSH) for retrieving similar physiological waveform time series. SLSH further accelerates the sublinear retrieval time obtained by the standard locality-sensitive hashing (LSH) method. The standard family of locality-sensitive hash functions is limited to provide only a single perspective on the data due to its one-to-one relationship to a distinct distance function for measuring similarity. SLSH incorporates multiple locality-sensitive hash families with various distance functions enabling it to examine the data with more diverse and refined perspectives. We provide the procedures of SLSH with locality-sensitive hash families for the l<sub>1</sub> and the cosine distances, and compare its performance to the standard LSH on an arterial blood pressure time series data extracted from the physiological waveform repository of the MIMIC2 database. The time to retrieve five most similar waveforms by SLSH is 14 times faster than the linear search and 1.7 times faster than the standard LSH when we allow 5% decrease in accuracy as a trade-off.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591233","","Acceleration;Arterial blood pressure;MIMICs;Physiology;Shape;Standards;Time series analysis","blood pressure measurement;file organisation;information retrieval;medical information systems;time series","MIMIC2 database;accelerated physiological time series retrieval;arterial blood pressure time series data;locality-sensitive hash families;physiological waveform repository;stratified locality-sensitive hashing method","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"DEPTA: An efficient technique for web data extraction and alignment","A. Manjaramkar; R. L. Lokhande","Dept of IT, SGGSIE&T, Nanded-431606(M. S), India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20161103","2016","","","2307","2310","Many web databases contains the data in the form of structured, semi structured and in unstructured format. This paper studies the issue of extracting these data records from online web database. The main motto of this paper is to recognize the data region which contains the data records, divide these data records, mine the data value from them and keep these extracted record in a structured format. This arrangement of extracted data is useful for many application like knowledge discovery purpose etc. Existing system has some data records arrangement problem which does not arrange dynamically generated web data properly. The proposed system is based on identification of data records, extraction of data values and arranging these data values in a database. The proposed system uses the partial tree alignment method for giving the better alignment outcome.","","","10.1109/ICACCI.2016.7732397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732397","Data Records;Record Extraction and Records Arrangement;Tag Tree Structure","Buildings;Data mining;Databases;HTML;Informatics;Web pages","Internet;data mining;database management systems;information retrieval;tree data structures","DEPTA;Web data alignment;Web data extraction;data mining;data record arrangement;data region;online Web database;partial tree alignment method","","","","","","","21-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Semantic pheromone walking: A semantic clue discovering scheme based on concept relatedness in open domain knowledge network","Z. Bo; H. Sihui; P. Ruxiang; L. Yajun","College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai 200234, China","2016 IEEE 11th Conference on Industrial Electronics and Applications (ICIEA)","20161024","2016","","","1807","1812","Semantic clue discovering has been a significant issue for mining the form of correlation among concepts or things(Knowledge Entities). The correlation is seen as an important reference for improving information retrieval, knowledge reasoning or making decisions. At present, most searches on semantics focused on semantic relatedness computing rather than semantic clues discovering. To discover semantic clues, we propose a novel semantic clues discovering method, named as Semantic Pheromone Walking (SPW) that utilizes the strategies of pheromone in ant colony algorithm and random walk algorithm to discover close semantic clues among knowledge entities. Our proposed SPW comprises two aspects: concept network construction and semantic clue discovering. Firstly, constructing a weighted network model named Concept Network (CN), the link weights of which are determined in accordance with the hyperlink structure and semantic relatedness of text data in ODKN contains abundant semantic information. Then, a concept network based Semantic Pheromone Walking method is addressed to discover semantic clues between knowledge entities by using Semantic Pheromone (SP) which is a digital signal reflecting the compactness of concept correlation, as heuristic information. Finally, the experimental results show that: the human cognitive information contained in the knowledge network can meet the need of the exploration of correlation form between things and our solution could find reasonable semantic clues based it.","","","10.1109/ICIEA.2016.7603880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603880","Semantic clue;pheromone;random walk;semantic intensity;semantic relatedness","Cognition;Correlation;Dictionaries;Knowledge engineering;Legged locomotion;Reliability;Semantics","ant colony optimisation;data mining;information retrieval;random processes","ODKN;SPW;ant colony algorithm;concept correlation;concept network construction;concept relatedness;decision making;human cognitive information;hyperlink structure;information retrieval;knowledge entities;knowledge reasoning;open domain knowledge network;random walk algorithm;semantic clue discovering scheme;semantic pheromone walking;text data semantic relatedness;weighted network model","","","","","","","5-7 June 2016","","IEEE","IEEE Conference Publications"
"PLACE: Physical Layer Cardinality Estimation for Large-Scale RFID Systems","Y. Hou; J. Ou; Y. Zheng; M. Li","School of Computer Engineering, Nanyang Technological University, Singapore","IEEE/ACM Transactions on Networking","20161013","2016","24","5","2702","2714","Estimating the number of RFID tags is a fundamental operation in RFID systems and has recently attracted wide attentions. Despite the subtleties in their designs, previous methods estimate the tag cardinality from the slot measurements, which distinguish idle and busy slots and based on that derive the cardinality following some probability models. In order to fundamentally improve the counting efficiency, in this paper we introduce PLACE, a physical layer based cardinality estimator. We show that it is possible to extract more information and infer integer states from the same slots in RFID communications. We propose a joint estimator that optimally combines multiple sub-estimators, each of which independently counts the number of tags with different inferred PHY states. Extensive experiments based on the GNURadio/USRP platform and the large-scale simulations demonstrate that PLACE achieves approximately 3 ~ 4√ó performance improvement over state-of-the-art cardinality estimation approaches.","1063-6692;10636692","","10.1109/TNET.2015.2481999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298458","RFID;cardinality estimation;physical layer","Accuracy;Backscatter;Detection algorithms;Estimation;Noise;Physical layer;Radiofrequency identification","inference mechanisms;information retrieval;probability;radiofrequency identification;telecommunication computing","GNURadio platform;PHY state inference;PLACE;RFID communications;RFID tag number estimation;USRP platform;busy slots;counting efficiency improvement;idle slots;information retrieval;integer state inference;large-scale RFID systems;physical layer cardinality estimation;probability models;tag cardinality estimation","","","","","","20151014","October 2016","","IEEE","IEEE Journals & Magazines"
"An intelligent learning system for supporting interactive learning through student engagement study","Y. Liu; Z. Xie; J. Chen","Faculty of Information Engineering, China University of Geosciences, Wuhan, China 430074","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","618","623","Interactive learning in class or off-class is crucial to teaching and learning. In this paper, we propose an intelligent learning system for supporting student interactive learning through engagement study, which is based on three modules, i.e., attendance management, teacher-student (T&S) communication, visual focus of attention(VFOA) recognition. Attendance management matches the student's identity and locates his/her profile. T&S communication provides an additional channel of Question and Answer (Q&A) between a teacher and students. VFOA recognition captures student's attention on different learning targets based on the estimated head poses, visual environment cues and prior state in class. Student engagement is analyzed based on multiple cues of one's attendance, class communication and VFOA. The experimental results suggest that an intelligent learning system is benefit to improve interactive learning and enhance learning efficiency.","","","10.1109/FSKD.2016.7603245","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603245","Engagement study;Intelligent Learning system;Technology-enhanced learning;VFOA recognition","Cameras;Clothing;Face;Face recognition;Feature extraction;Learning systems","intelligent tutoring systems;interactive systems;pose estimation;question answering (information retrieval);teaching","VFOA recognition;attendance management;head pose estimation;intelligent learning system;interactive learning;question and answer channel;student engagement study;student identity;teacher-student communication;teaching;visual environment cues;visual focus of attention recognition","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Social data-based user profile enrichment","A. Hannech; M. Adda; H. Mcheick","Computer Science Department, University of Quebec At Chicoutimi, 555, Boulevard de l'Universit&#x00E9;, Canada, G7H-2B1","2016 IEEE 7th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)","20161117","2016","","","1","7","In this paper, we present a generic model to enrich user profiles by means of contextual and temporal information. This reflecting the current interests of these users in every period of time defined by a search session, and infers data freshness. We argue that the annotation of resources gives more transparency on users' needs. Based on this idea, we integrate social tagging in order to exploit part of the social user's behavior to enrich his profile. The enriched profiles are then integrated to a recommendation system to assist users when seeking information.","","Electronic:978-1-5090-0996-1; POD:978-1-5090-0997-8","10.1109/IEMCON.2016.7746323","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7746323","association rules;contextual information;data freshness;data of usage;data recommendation;folksonomies;topical ontology;user profiles","Computers;Context;Correlation;History;Ontologies;Semantics;Tagging","data mining;inference mechanisms;information retrieval;recommender systems","IR;association rule;data freshness inference;information retrieval;information seeking;recommendation system;social data;social tagging;social user behavior;user profile enrichment","","","","","","","13-15 Oct. 2016","","IEEE","IEEE Conference Publications"
"Distributed retrieval for massive remote sensing image metadata on spark","F. Wang; X. Wang; W. Cui; X. Xiao; Y. Zhou; J. Li","Computer Network Information Center, Chinese Academy of Sciences, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","5909","5912","The massive data is constantly and rapidly growing in remote sensing field. How to achieve efficient storage and rapid retrieval of massive remote sensing image metadata is a difficult problem. Big Data technologies provide convenient and fast tools for the storage, retrieval and analysis of remote sensing image metadata. According to the feature of remote sensing image metadata, we first give new concepts of fat grid and thin grid and propose a grid indexing method called Spark-Fat-Thin-Grid-Index (SFTGridIndex). In SFTGridIndex, the index file and partitions files are stored in HDFS. We then design an optimized retrieval method based on SFTGrid-Index. The method can avoid the intersection computing of a large number of polygons. This research can ensure efficient storage and fast query of massive remote sensing image metadata and has good scalability.","","","10.1109/IGARSS.2016.7730544","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730544","Geographical Information System;Grid index;SFTGridIndex;Spark;Spatial index","Fats;Metadata;Remote sensing;Sparks;Spatial databases;Spatial indexes","grid computing;information retrieval;meta data;remote sensing","SFTGridIndex;grid indexing method;massive remote sensing image metadata;metadata distributed retrieval;remote sensing image metadata;spark-fat-thin-grid-index","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"Preventing unnecessary interests retransmission in named data networking","S. Mejri; H. Touati; F. Kamoun","Hatem Bettaher IResCoMath Research Unit, University of Gabes, Tunisia","2016 International Symposium on Networks, Computers and Communications (ISNCC)","20161117","2016","","","1","6","Named Data Networking (NDN) is an Information-Centric Networking architecture that has recently attracted significant attention. NDN rethinks the Internet communication paradigm around the name of the data instead of its location. In Content-Oriented architectures, in-network caching enables data retrieval from different network nodes and may result in frequent data sources changes and wide RTT fluctuations during a flow. Since NDN architectures use Interest retransmission timer at the scale of network RTT estimations, this would generate erroneously premature timeouts events resulting in unnecessary Interests retransmission. In this paper, we tackle the Interest retransmission problem. We first analyze the impact of temporary caches on the number of timeouts events. Then we introduce ‚ÄúSource Change Notification‚Äù to address this issue. A preliminary evaluation has been conducted by means of the ndnSIM simulator. Our evaluation results show that our proposal succeeds in preventing unnecessary Interest retransmission when data providers change.","","Electronic:978-1-5090-0284-9; POD:978-1-5090-0285-6","10.1109/ISNCC.2016.7746058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7746058","In-network caching;Interest timeout;NDN;Simulation;Source change notification","Computer architecture;Delays;Estimation;Iterative closest point algorithm;Proposals;Receivers;Topology","Internet;computer networks;information retrieval","Interest retransmission timer;Internet communication;NDN architectures;RTT fluctuations;content-oriented architectures;data retrieval;in-network caching;information-centric networking architecture;named data networking;ndnSIM simulator;source change notification;unnecessary interest retransmission prevention","","","","","","","11-13 May 2016","","IEEE","IEEE Conference Publications"
"Some observations on migration from data mining to web mining","S. Singh; M. S. Aswal","Gurukul Kangri Vishwavidyalaya, Haridwar, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","100","105","Web pages on the World Wide Web are increasing day by day with tremendous growth, due to this web mining becomes fertile area of the research. The extraction of the useful and relevant information from web documents is becoming a challenging task day by day. In this paper we explore and observe the various factors affecting the evolvement of web mining. This paper also works on the identification of various facts and issues that are not resolved by the traditional techniques and algorithms of data mining. The work also describes need for some modification and adaptation into the traditional techniques and algorithms of data mining and into the existing web mining techniques also.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724235","Data Pre-processing;Data mining;Web challenges;Web mining;World Wide Web","Conferences;Decision support systems;Handheld computers;Regression tree analysis","Internet;Web sites;data mining;information retrieval","Web mining;Web page;World Wide Web;data mining;information extraction","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Review of Web Document Clustering algorithms","S. K. Sahu; S. Srivastava","Dept. of Computer Science, Utkal University, Bhubaneswar, Odisha, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","1153","1155","Users of search engines are fond of accurate and fast results. Web is now overloaded with lots of pages or documents dealing with same topic. Thus they are often forced to surf through the large and irrelevant set of results. This has forced the IR community to explore such document clustering techniques capable of providing fast and accurate results. Even after being a very effective solution, clustering is yet not deployed on the major search engines. This paper will articulate the requirements of Web Document Clustering and reports on the clustering methods belonging in this domain. The focus of ours is on; these methods create their clusters based on the characters or individual terms rather than showcasing them as a single phrase with a meaning and sequence of words. Paper will be reporting general term based and phrase based techniques and will provide conclusion based on their individual efficiency to work with their key methods.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724445","Clustering;DIG;HAC;K-NN;K-means;NLP;STC;STD;VSD","Algorithm design and analysis;Clustering algorithms;Conferences;Indexes;Matrix decomposition;Search engines;Web pages","Internet;document handling;information retrieval;pattern clustering;search engines","IR community;Web document clustering algorithms;phrase-based techniques;search engines;term-based techniques","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"A framework for extraction of journal information from scientific publishers web site","U. Kumaresan; K. Ramanujam","Dept. of CSE, Pondicherry Engineering College, Pondicherry, India","2016 10th International Conference on Intelligent Systems and Control (ISCO)","20161103","2016","","","1","5","World Wide Web is a huge repository of information and the information is presented in the disparate formats which make automated processing a cumbersome task. Search engines are used to query the WWW. Students and scholars find it difficult to determine the appropriate journals for the research article publication since performing a keyword search using search engines like Google, Yahoo etc. presents them with a list of publication site where the user need to click through a series of link to reach the journal web site and go through the details of the journals like Impact Factor, SNIP etc. manually. Suppose if a publication web site is linked to hundreds of journal web sites matching the user's topic of interest, it poses a serious problem on part of the user to manually determine the most reputed journal for the publication of his/her research article. This paper proposes a framework for extraction of Journal information in a single interaction with the system.","","","10.1109/ISCO.2016.7726937","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726937","data extraction;impact factor;template generated pages;unsupervised","Bibliometrics;Data mining;Databases;Uniform resource locators;Web pages;World Wide Web","Internet;Web sites;electronic publishing;information retrieval;search engines","WWW query;World Wide Web;journal information extraction;keyword search;research article publication;scientific publishers Web site;search engines","","","","","","","7-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Question Answering with DBpedia Based on the Dependency Parser and Entity-centric Index","H. Li; F. Xu","Sch. of Comput. Sci. & Eng., Southeast Univ. Nanjing, Nanjing, China","2016 International Conference on Computational Intelligence and Applications (ICCIA)","20161020","2016","","","41","45","The emerging Linked Open Data provides an opportunity to answer the natural language question based on knowledge bases (KB). This study proposes an approach to question answering (QA) on the DBpedia dataset. After parsing the question by a dependency parser, we locate the entity mention and property mention with predefined templates. We propose an entity-centric indexing model to help search referent entities in KB. After obtaining the referent entities, we expand the property mention with WordNet and ConceptNet to find the referent properties of the returned entities. The values of the referent property are then considered the answer to the question. Evaluations are performed on DBpedia version 2015. Results show that our approach reaches 46% precision when the top-10 entities are returned in the final QA stage. The evaluation tests show that our approach is promising in dealing with QA in Linked Data.","","","10.1109/ICCIA.2016.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600312","","Indexes;Knowledge based systems;Knowledge discovery;Natural languages;Resource description framework;Search problems;Semantics","Web sites;grammars;indexing;knowledge based systems;natural language processing;question answering (information retrieval)","ConceptNet;DBpedia dataset;KB;Linked Open Data;QA stage;WordNet;dependency parser;entity mention;entity-centric indexing model;knowledge bases;natural language question answering;predefined templates;property mention;referent entities;referent property;returned entities","","","","","","","27-29 Aug. 2016","","IEEE","IEEE Conference Publications"
"Surfacing collaborated networks in dark web to find illicit and criminal content","A. T. Zulkarnine; R. Frank; B. Monk; J. Mitchell; G. Davies","International CyberCrime Research Center (ICCRC), School of Criminology, Simon Fraser University, Burnaby, Canada","2016 IEEE Conference on Intelligence and Security Informatics (ISI)","20161117","2016","","","109","114","The Tor Network, a hidden part of the Internet, is becoming an ideal hosting ground for illegal activities and services, including large drug markets, financial frauds, espionage, child sexual abuse. Researchers and law enforcement rely on manual investigations, which are both time-consuming and ultimately inefficient. The first part of this paper explores illicit and criminal content identified by prominent researchers in the dark web. We previously developed a web crawler that automatically searched websites on the internet based on pre-defined keywords and followed the hyperlinks in order to create a map of the network. This crawler has demonstrated previous success in locating and extracting data on child exploitation images, videos, keywords and linkages on the public internet. However, as Tor functions differently at the TCP level, and uses socket connections, further technical challenges are faced when crawling Tor. Some of the other inherent challenges for advanced Tor crawling include scalability, content selection tradeoffs, and social obligation. We discuss these challenges and the measures taken to meet them. Our modified web crawler for Tor, termed the ‚ÄúDark Crawler‚Äù has been able to access Tor while simultaneously accessing the public internet. We present initial findings regarding what extremist and terrorist contents are present in Tor and how this content is connected to each other in a mapped network that facilitates dark web crimes. Our results so far indicate the most popular websites in the dark web are acting as catalysts for dark web expansion by providing necessary knowledgebase, support and services to build Tor hidden services and onion websites.","","Electronic:978-1-5090-3865-7; POD:978-1-5090-3866-4","10.1109/ISI.2016.7745452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745452","Criminal Network;Dark Web;Social Network Analysis;Tor Network;Web Crawler;Web Graph","Crawlers;Databases;Drugs;Internet;Law enforcement;Terrorism;Weapons","Internet;computer crime;information retrieval;social networking (online);text analysis","Dark Crawler;Tor crawling;Tor functions;Tor hidden services;Tor network;Web crawler;automatic Web site searching;child exploitation images;child exploitation videos;child sexual abuse;collaborated networks;content selection;criminal content;dark Web crimes;drug markets;espionage;extremist contents;financial frauds;hyperlinks;illegal activities;illegal services;illicit content;knowledge base;law enforcement;onion Web sites;public Internet;social obligation;socket connections;terrorist contents","","","","","","","28-30 Sept. 2016","","IEEE","IEEE Conference Publications"
"Query expansion for exploratory search with subtopic discovery in Community Question Answering","L. Gao; Y. Lu; Q. Zhang; H. Yang; Y. Hu","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","4715","4720","Exploratory search is cumbersome with today's search engines, where a user aims to better understand complex concepts. Query expansions techniques have been widely used in exploratory search. However, query expansions often recommend queries that differ from the user's search intentions due to different contexts. Yet, many of users' needs could be addressed by asking people via popular Community Question Answering (CQA) services. In this paper, we investigate query expansion techniques for exploratory search using the resources of CQA to discover the user's search intentions. Specifically, we denote the explicit intuition as the subtopic that supports the user's exploratory task. We propose the method CqaQuExp to mine the subtopics, which mainly contains three subtask: Question retrieval, where we extract the questions and corresponding answers from CQA; subtopic mining, where we discover the subtopics based on the extracted information; Candidate concepts discovery, where we select the candidate concepts from the discovered subtopics for query expansion. Experimental results on real-world data from Yahoo! Answers demonstrate the effectiveness of the proposed methods.","","","10.1109/IJCNN.2016.7727819","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727819","Community Question Answering;Exploratory search;Query expansion;Subtopic mining","Data mining;Electronic publishing;Encyclopedias;Indexes;Internet;Knowledge discovery","data mining;query processing;question answering (information retrieval);text analysis","CQA services;CqaQuExp;candidate concepts discovery;community question answering;exploratory search;query expansion;query recommendation;question retrieval;search engines;subtopic discovery;subtopic mining;user needs;user search intentions","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Building mutually beneficial relationships between question retrieval and answer ranking to improve performance of community question answering","Man Lan; Guoshun Wu; Chunyun Xiao; Yuanbin Wu; Ju Wu","Department of Computer Science and Technology, East China Normal University, Shanghai, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","832","839","In community-based question answering (CQA) domain, there are two main tasks, i.e., question retrieval and answer ranking. Previous studies addressed these two tasks in an independent manner or in a sequential fashion without information communication. In this work we propose a novel method to improve the performance of CQA by mutually promoting the two tasks with the help of each other. Specifically, we propose two methods to improve question retrieval task by utilizing the rank of answers or extracting novel features from Q-A pairs respectively. Meanwhile, to improve answer ranking, we also present novel features with the help of similar questions. Experimental results on benchmark dataset showed that this mutually beneficial strategy between question retrieval and answer ranking not only improved the individual performance of these two tasks but also improved the overall performance of CQA through reducing errors propagating from question retrieval to answer ranking.","","","10.1109/IJCNN.2016.7727286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727286","","Estimation;Manuals","feature extraction;question answering (information retrieval)","CQA;answer ranking;community question answering;feature extraction;question retrieval","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"An ontology approach to storing educational information","A. Vatian; N. Gusarova; G. Artemova; N. Dobrenko","ITMO University, Saint Petersburg, Russia Federation","2016 International FRUCT Conference on Intelligence, Social Media and Web (ISMW FRUCT)","20161013","2016","","","1","9","The modern educational process is characterized by the fact that the competencies and the content of education quickly change and dynamically vary depending on the needs of the specific groups of students. Especially strongly it is shown in the professional education, for example in information technologies. The teacher should have an opportunity to quickly and effectively arrange the content of education for the parameters of a specific course (for instance: type of group, periods of training, etc.) In these conditions, the traditional method of storing the information, such as the relational data model, seems difficult and inconvenient to manage with the permanently and dynamically changing structure of data. In this regard, the use of network models of data structure is required. In this paper, we present an ontological model for an information system for storning educational information. The authors propose the use of a wiki-engine for building an information system- and the SCORM-based organization of the training material. The experimental results have shown that the ontological approach for storing the educational information tends to cover the needs of the teachers in universities.","","","10.1109/FRUCT.2016.7584772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584772","","","computer aided instruction;data structures;educational courses;information retrieval;ontologies (artificial intelligence);storage management","SCORM-based organization;data structure;educational information storage;information system;information technologies;modern educational process;ontology approach;professional education;relational data model;training material;universities;wiki-engine","","","","","","","Aug. 28 2016-Sept. 4 2016","","IEEE","IEEE Conference Publications"
"Detection of largest possible repeated patterns in Indian audio songs using spectral features","M. Thomas; Y. V. S. Murthy; S. G. Koolagudi","Department of CSE, National Institute of Technology Karnataka, Surathkal - 575 025, India","2016 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","20161103","2016","","","1","5","In the field of Content Based Music Information Retrieval (CB-MIR), researchers are always looking for better ways to classify songs aside from the existing classifiers such as genre, mood, scale, tempo, etc. By determining a way to isolate and extract maximum length repeating patterns (MLRPs) in a music file, we can analyze them in order to describe another potential classifier: complexity. Extraction of repeating patterns would also allow users to easily extract ringtones from their favorite songs. In this paper, an effort has been made to describe a method to extract repeating patterns from a given music file through direct signal level as well as feature level comparison. These extracted patterns can be used as ringtones, or for analysis to determine complexity. Features such as mel-frequency cepstral coefficients (MFCCs), modulation spectral features (MSFs) and jitter are computed to reduce the computational time observed in signal level comparison.","","","10.1109/CCECE.2016.7726863","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726863","Maximal length repeating patterns;Similarity measures and Modulation spectral features;Song complexity analysis","Complexity theory;Databases;Feature extraction;Fractals;Mel frequency cepstral coefficient;Modulation;Spectrogram","audio signal processing;cepstral analysis;information retrieval;jitter;music","CB-MIR;Indian audio song;MFCC;MLRP;MSF;computational time;content based music information retrieval;direct signal level;feature level;jitter;largest possible repeated pattern detection;maximum length repeating pattern;mel-frequency cepstral coefficient;modulation spectral feature;music file;repeating pattern extraction;ringtone;spectral feature","","","","","","","15-18 May 2016","","IEEE","IEEE Conference Publications"
"Distributed Top-k Keyword Search over Very Large Databases with MapReduce","Z. Yu; X. Yu; Y. Chen; K. Ma","Sch. of Inf. Sci. & Eng., Univ. of Jinan, Jinan, China","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","349","352","In the last decade, keyword search over relational databases has been extensively studied because it promises to allow users lacking knowledge of structured query languages or unaware of the database schema to query the database in an intuitive way. The existing works about keyword search on databases proposed many approaches and have gain remarkable results. However, most of these approaches are designed for the centralized setting where keyword search is processed by only a single server. In reality, the scale of databases increases sharply and centralized methods hardly can handle keyword queries over these large databases. Moreover, processing keyword search over relational databases is a very time-consuming task, and the efficiency of the existing centralized approaches will degrade notably because the single server cannot provide enough computation power for the keyword search over very large databases. To address these challenges, we propose a distributed keyword search (DKS) approach with MapReduce and this approach can be well deployed on a cluster of servers to deal with keyword search over large databases in a parallel way.","","","10.1109/BigDataCongress.2016.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584961","Distributed;Keyword search;MapReduce;data graph","Distributed databases;Keyword search;Relational databases;Search problems;Servers;Steiner trees","information retrieval;parallel processing;relational databases;very large databases","DKS approach;MapReduce;centralized methods;database scale;distributed top-k keyword search;server cluster;very large databases","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Personalized scientific literature recommendation based on user's research interest","P. Guan; Y. Wang","School of Economics & Management, Nanjing University of Science & Technology, Nanjing, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1273","1277","As the rapid growth of digital scientific and technical literatures, the scientific researchers need personalized retrieval to satisfy their research interests urgently. Unlike previous methods that just use simple keyword matching, we strengthen the semantic information of scientific literature by merging metadata such as title, keywords, abstract and citation in this dissertation. Then we use vector space model with tf-idf value of each term to model each scientific literature. We structure user's interest model by subject term vector with different weight. Different weight means different concern degree to each subject term by user. To emphasize the quality of recommended literature, we not only calculate the similarity between user's research interest and literatures, but also consider the total times cited of recommended literatures. As experimental dataset, we collect literatures from Web of Science under the topic of ‚Äúpressure sensor‚Äù. The experimental results show that this recommendation method could well indentify user's research interest. So, it can improve efficiency of user literature retrieval and increase the accuracy of the literature recommendation.","","","10.1109/FSKD.2016.7603361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603361","metadata;personalized recommendation;scientific literature;similarity","Magnetic field measurement;Metadata;Optical variables measurement;Pressure measurement;Pressure sensors;Temperature measurement;Temperature sensors","human factors;information retrieval;merging;meta data;recommender systems;scientific information systems","Web of Science;metadata merging;personalized retrieval;personalized scientific literature recommendation;pressure sensor;semantic information;tf-idf value;user research interest;vector space model","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Multipitch estimation using multiple transformation analysis","K. Rychlicki-Kicior; B. Stasiak; M. Yatsymirskyy","Institute of Information Technology, Lodz University of Technology, Wolczanska St. 215, 90-924 &#x0141;&#x00F3;d&#x017A;, Poland","2016 IEEE First International Conference on Data Stream Mining & Processing (DSMP)","20161006","2016","","","299","304","Multipitch estimation, also known as multiple fundamental frequency (Fo) estimation, is an important part of the Music Information Retrieval (MIR) field. The usual approach to this problem consists of two basic steps - transforming the source sound signal from time domain to a different form and using a certain method of analysis to obtain the frequencies of musical notes recognized in the signal. Our approach extends this scheme, introducing multiple different sound transforms and different analysis methods, as well as a novel method of merging individual results which leads to better outcome than single-method approach (88% for two-voiced polyphony, 83% for three-voice polyphony, 73% for four-voice polyphony).","","","10.1109/DSMP.2016.7583563","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583563","MIR;fundamental frequency estimation;multi F0;multipitch;polyphony","Cepstrum;Discrete Fourier transforms;Estimation;Harmonic analysis;Music;Power harmonic filters","acoustic signal processing;frequency estimation;information retrieval;music","MIR;four-voice polyphony;multipitch estimation;multiple fundamental frequency estimation;multiple transformation analysis;music information retrieval;musical note frequencies;source sound signal transformation;three-voice polyphony;two-voiced polyphony","","","","","","","23-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"Match memory recurrent networks","S. Samothrakis; T. Vodopivec; M. Fasli; M. Fairbank","Institute for Analytics and Data Science, University of Essex, Wivenhoe Park, Colchester CO4 3SQ, UK","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","1339","1346","Imbuing neural networks with memory and attention mechanisms allows for better generalisation with fewer data samples. By focusing only on the relevant parts of data, which is encoded in an internal ‚Äúmemory‚Äù format, the network is able to infer better and more reliable patterns. Most neuronal attention mechanisms are based on internal networks structures that impose a similarity metric (e.g., dot-product), followed by some (soft-)max operator. In this paper, we propose a novel attention method based on a function between neuron activities, which we term a ‚Äúmatch function‚Äù, which is augmented by a recursive softmax function. We evaluate the algorithm on the bAbI question answering dataset and show that it has stronger performance when only one memory hop is used in both terms of average score and in terms the number of solved questions. Furthermore, with three memory hops, our algorithm can solve 12/20 benchmark questions using 1000 training samples per task. This is an improvement on the previous state of the art of 9/20 solved questions, which was held by end-to-end memory networks.","","","10.1109/IJCNN.2016.7727353","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727353","","Artificial intelligence;Benchmark testing;Dairy products;Electronic mail;Neural networks;Training","question answering (information retrieval);recurrent neural nets","attention mechanisms;bAbI question answering dataset;data samples;end-to-end memory networks;internal memory format;internal networks structures;match function;match memory recurrent networks;memory mechanisms;neural networks;neuron activities;recursive softmax function;soft-max operator","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"A comparative study of Soft Computing software for enhancing the capabilities of business document management systems","R. Romero-Cordoba; F. P. Romero; J. A. Olivas; J. Serrano-Guerrero; A. Peralta","Dept. of Information Systems and Technologies, University of Castilla-La Mancha, Ciudad Real, Spain","2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20161110","2016","","","241","248","There are several types of business documents, ranging from brief accounting documents to complex legal agreements. Companies extensively use such documents to communicate, transact business and analyse their productivity. This results in the generation of a large number of documents daily, and small- and medium-sized enterprises are easily overwhelmed by this situation. Given this background, companies require software solutions which provide all of the features required by users for optimal document management, as well as optimising management processes and automating the extraction of relevant information from the documents. Open-source software provides these organizations with low-cost, high-quality software which incorporates an array of advanced features that extend beyond only storage solutions. In this study, we test several computational-intelligence open-source software tools in order to enhance the information-retrieval capabilities in small business document-management systems. We implement a prototype to test these Natural Language Processing (NLP) tools and Machine-Learning techniques in a business environment, with the aim of choosing the best alternative for each process.","","Electronic:978-1-5090-0626-7; POD:978-1-5090-0627-4; USB:978-1-5090-0625-0","10.1109/FUZZ-IEEE.2016.7737693","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737693","","Companies;Contracts;Open source software;Tagging","accounts data processing;business data processing;document handling;information retrieval;learning (artificial intelligence);natural language processing;public domain software;small-to-medium enterprises;software tools","accounting documents;business document management systems;business environment;complex legal agreements;computational-intelligence open-source software tools;information-retrieval capabilities;low-cost high-quality software;machine-learning techniques;natural language processing tools;open-source software;optimal document management;relevant information extraction;small-and medium-sized enterprises","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Retrieving Resource Availability Insights from Event Logs","N. Martin; F. Bax; B. Depaire; A. Caris","Hasselt Univ., Diepenbeek, Belgium","2016 IEEE 20th International Enterprise Distributed Object Computing Conference (EDOC)","20160929","2016","","","1","10","Resources are a critical component of a business process as they execute the activities. These resources, especially human resources, are not permanently available and tend to be involved in multiple processes. However, a company might wish to analyze or model a single process. To this end, insights need to be gathered on the availability of a resource for a particular process. This paper presents a procedure to retrieve daily availability records from an event log, which express a resource's availability for the process under analysis while taking into account (i) the temporal dimension of availability and (ii) intermediate availability interruptions. Both the daily availability records themselves and the resource availability metrics that are introduced allow managers and employees to gain understanding in resource allocation to a process. The outlined procedure and metrics are applied to a real-life call center log, showing the need to post-process the daily availability records. Post-processing increases their comprehensiveness and is required to obtain meaningful values for particular metrics.","","","10.1109/EDOC.2016.7579385","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7579385","","Analytical models;Benchmark testing;Companies;Measurement;Resource management;Schedules","business data processing;call centres;information retrieval;resource allocation","business process;call center log;critical component;daily availability record retrieval;human resources;intermediate availability interruptions;resource allocation;resource availability metrics;resource availability retrieval","","","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Traffic information extraction and classification from Thai Twitter","S. Klaithin; C. Haruechaiyasak","Speech Processing Technology Laboratory (SPT), National Electronics and ComputerTechnology Center (NECTEC), National Science and Technology Development Agency (NSTDA), Klong Luang, Pathumthani 12120, Thailand","2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20161121","2016","","","1","6","Twitter is a one of the most popular microblogging service. It is broadly used in communication. Besides, it provides up-to-date real-time traffic information source. Various information contained in tweets are such as accident, road name, and place name. In this paper, we extract and classify tweets by tagging traffic information. They were extracted into 12 tags and classified into 6 categories. Our study indicate that 3 significant components were information of road, information of location, and traffic status. Furthermore, the classification accuracy achieved with the testing data was 76.4%. The average accuracy of information extraction is about 88.42%. The two high accuracy of information extraction were location (LOC) and time (TIM), which found that nearly 99.42% and 97.09% of all categories respectively.","","Electronic:978-1-5090-2033-1; POD:978-1-5090-2034-8","10.1109/JCSSE.2016.7748851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748851","Classification;Information Extraction;Thai language;Traffic report;Twitter","Accidents;Data mining;Dictionaries;Roads;Support vector machines;Twitter","information retrieval;pattern classification;social networking (online);traffic information systems","Thai Twitter;location information;microblogging service;road information;traffic information classification;traffic information extraction;traffic information source;traffic status","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Detecting trends in twitter time series","T. De Bie; J. Lijffijt; C. Mesnage; R. Santos-Rodr√≠guez","Data Science Lab, Ghent University - iMinds, Belgium","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Detecting underlying trends in time series is important in many settings, such as market analysis (stocks, social media coverage) and system monitoring (production facilities, networks). Although many properties of the trends are common across different domains, others are domain-specific. In particular, modelling human activities such as their behaviour on social media, often leads to sharply defined events separated by periods without events. This paper is motivated by time series representing the number of tweets per day addressed to a specific Twitter user. Such time series are characterized by the combination of (1) an underlying trend, (2) concentrated bursts of activity that can be arbitrarily large, often attributable to an event, e.g., a tweet that goes viral or a real-world event, and (3) random fluctuations/noise. We present a new probabilistic model that accurately models such time series in terms of peaks on top of a piece-wise exponential trend. Fitting this model can be done by solving an efficient convex optimization problem. As an empirical validation of the approach, we illustrate how this model performs on a set of Twitter time series, each one addressing a particular music artist, which we manually annotated with events as a reference.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738815","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738815","Trend detection;convexity;time series","Graphical models;Market research;Maximum likelihood estimation;Probabilistic logic;Time measurement;Time series analysis;Twitter","convex programming;information retrieval;music;probability;random noise;social networking (online);time series","Twitter time series;convex optimization;human activities;music artist;piece-wise exponential trend;probabilistic model;random fluctuations;random noise;trend detection","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Software Defined Networking, Caching, and Computing for Green Wireless Networks","R. Huo; F. R. Yu; T. Huang; R. Xie; J. Liu; V. C. M. Leung; Y. Liu","","IEEE Communications Magazine","20161115","2016","54","11","185","193","Recent advances in networking, caching, and computing will have a profound impact on the development of next generation green wireless networks. Nevertheless, these three important areas have traditionally been addressed separately in existing works. In this article, we propose a novel framework that jointly considers networking, caching, and computing techniques in a systematic way to naturally support energy-efficient information retrieval and computing services in green wireless networks. This integrated framework can enable dynamic orchestration of different resources to meet the requirements of next generation green wireless networks. Simulation results are presented to show the effectiveness of the proposed framework. In addition, we discuss a number of challenges in implementing the proposed framework in next generation green wireless networks.","0163-6804;01636804","","10.1109/MCOM.2016.1600485CM","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744833","","Cloud computing;Green computing;Green design;Mobile communication;Next generation networking;Software defined networking;Wireless networks","cache storage;energy conservation;information networks;information retrieval;next generation networks;software defined networking;telecommunication power management","computing services;computing techniques;energy-efficient information retrieval;green wireless networks;next generation wireless networks;software defined networking","","","","","","","November 2016","","IEEE","IEEE Journals & Magazines"
"Question systematization using templates","U. Shrawankar; K. Pawar","G. H. Raisoni College of Engineering, Nagpur, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","2316","2320","Question is a crucial construct of natural language. Systematic, error free question is a basic need of different applications of natural language. Many research works have been focused on `statement' formation but the issue of `systematic question' formation is less focused. This research work resolves above issue through systematization process using Template based approach which is accompanied by Dictionary approach and powerful NLP technique like Maximum Entropy based POS Tagging technique. Systematization process aims to reform proper flawless question from the erroneous input question by removing existing errors present in order of words, word spelling and removing ambiguous synonyms of the words. This work deals with domain specific WH-questions of English language. Additionally it also works on imperative questions. Template based approach is supported with a key concept of `Question Templates' which are designed with human intelligence keeping detail knowledge of various lingual constructs, their grammar and domain specific questionnaire. This work is useful in various fields, for example in academics to set question papers, to assist English learners, to produce intermediate output for complex systems like question-answering system to retrieve correct answer from a huge dataset.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724676","POS tagger;WH-questions;question templates;systematization;template based approach","Conferences;Decision support systems;Handheld computers","natural language processing;question answering (information retrieval)","English language;English learners;NLP technique;POS tagging technique;complex systems;dictionary approach;domain specific questionnaire;maximum entropy;question systematization;question-answering system;systematic question formation;template based approach","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"HindSight: Encouraging Exploration through Direct Encoding of Personal Interaction History","M. Feng; C. Deng; E. M. Peck; L. Harrison","Worcester Polytechnic Institute","IEEE Transactions on Visualization and Computer Graphics","20161117","2017","23","1","351","360","Physical and digital objects often leave markers of our use. Website links turn purple after we visit them, for example, showing us information we have yet to explore. These ‚Äúfootprints‚Äù of interaction offer substantial benefits in information saturated environments - they enable us to easily revisit old information, systematically explore new information, and quickly resume tasks after interruption. While applying these design principles have been successful in HCI contexts, direct encodings of personal interaction history have received scarce attention in data visualization. One reason is that there is little guidance for integrating history into visualizations where many visual channels are already occupied by data. More importantly, there is not firm evidence that making users aware of their interaction history results in benefits with regards to exploration or insights. Following these observations, we propose HindSight - an umbrella term for the design space of representing interaction history directly in existing data visualizations. In this paper, we examine the value of HindSight principles by augmenting existing visualizations with visual indicators of user interaction history (e.g. How the Recession Shaped the Economy in 255 Charts, NYTimes). In controlled experiments of over 400 participants, we found that HindSight designs generally encouraged people to visit more data and recall different insights after interaction. The results of our experiments suggest that simple additions to visualizations can make users aware of their interaction history, and that these additions significantly impact users' exploration and insights.","1077-2626;10772626","","10.1109/TVCG.2016.2599058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539616","History;Interaction;Visualization","Context;Data analysis;Data visualization;Encoding;History;Human computer interaction;Visualization","Web sites;data visualisation;graphical user interfaces;human computer interaction;information retrieval","HCI;HindSight designs;HindSight principles;Website links;data visualization;digital objects;direct encoding;information saturated environments;interaction footprints;personal interaction history;physical objects;user exploration;user insights;user interaction history;visual channels;visual indicators;visualization augmentation","","","","","","20160810","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Personalized search in smart indoor environments: Combining a formal location model, user preferences and semantic similarity","W. Xu; C. Marsala","Sorbonne Universit&#x00E9;s, UPMC Univ Paris 06, CNRS, LIP6, UMR7606, 4 place Jussieu, 75005, France","2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20161110","2016","","","1768","1775","In the web of things (WOT) paradigm, it is possible for users to have access to a big amount of connected objects to fulfil their requests. However, finding the right object is a difficult task as the search should take into account not only the functionalities of the objects but also their physical localisation and their distance from the user. In this paper, a new approach to build a WOT search engine is introduced. A new semantic similarity is proposed to compare objects in ontology. To answer a user's request, the proposed model recommends objects according to both their geo-localisation and capabilities. Moreover, the search of objects takes into account the user's profile and expectations. The solution we proposed relies on fuzzy rule engines and a formal location model that characterise the search space in which relevant connected objects are selected.","","Electronic:978-1-5090-0626-7; POD:978-1-5090-0627-4; USB:978-1-5090-0625-0","10.1109/FUZZ-IEEE.2016.7737904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737904","","Buildings;Context;Indoor environments;Ontologies;Search engines;Search problems;Semantics","Internet of Things;information retrieval;ontologies (artificial intelligence)","WOT paradigm;WOT search engine;Web of things;formal location model;fuzzy rule engines;ontology;personalized search;semantic similarity;smart indoor environment;user preference","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"Performance Analysis of Multimedia Retrieval Workloads Running on Multicores","Y. Lu; X. Wang; W. Zhang; H. Chen; L. Peng; W. Zhao","Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China","IEEE Transactions on Parallel and Distributed Systems","20161007","2016","27","11","3323","3337","Multimedia data has become a major data type in the Big Data era. The explosive volume of such data and the increasing real-time requirement to retrieve useful information from it have put significant pressure in processing such data in a timely fashion. However, while prior efforts have done in-depth analysis on architectural characteristics of traditional multimedia processing and text-based retrieval algorithms, there has been no systematic study towards the emerging multimedia retrieval applications. This may impede the architecture design and system evaluation of these applications. In this paper, we make the first attempt to construct a multimedia retrieval benchmark suite (MMRBench for short) that can be used to evaluate architectures and system designs for multimedia retrieval applications. MMRBench covers modern multimedia retrieval algorithms with different versions (sequential, parallel and distributed). MMRBench also provides a series of flexible interfaces as well as certain automation tools. With such a flexible design, the algorithms in MMRBench can be used both in individual kernel-level evaluation and in integration to form a complete multimedia data retrieval infrastructure for full system evaluation. Furthermore, we use performance counters to analyze a set of architecture characteristics of multimedia retrieval algorithms in MMRBench, including the characteristics of core level, chip level and inter-chip level. The study shows that micro-architecture design in current processor is inefficient (both in performance and power) for these multimedia retrieval workloads, especially in core resources and memory systems. We then derive some insights into the architecture design and system evaluation for such multimedia retrieval algorithms.","1045-9219;10459219","","10.1109/TPDS.2016.2533606","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416213","Multimedia retrieval;architectural characteristics;benchmarks","Algorithm design and analysis;Benchmark testing;Computer architecture;Feature extraction;Multimedia communication;Streaming media","Big Data;information retrieval;multimedia computing;multiprocessing systems;software architecture;software performance evaluation;text analysis;user interfaces","Big Data;MMRBench;architecture design;multicore processor;multimedia retrieval benchmark suite;multimedia retrieval workload;performance analysis;system evaluation;text-based retrieval algorithm;user interface","","2","","","","20160223","Nov. 1 2016","","IEEE","IEEE Journals & Magazines"
"Fengyun-3 Series Meteorological Satellite Data Archiving and Service System","Z. Xu; J. Qian; D. Xian; Y. Qi","CMA/National Satellite Meteorological Center, No.46, Zhongguancun Nandajie, Haidian District, Beijing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","20161103","2016","","","5477","5480","This paper introduces the characteristics and the new technologies applied in Fengyun-3 Series Meteorological Satellite Data Archiving and Service System. The system integrates several high-performance servers, high availability disk array, large-scale automated tape library as well as operation system, database, storage software and application software, all of which constitutes archive and service application clusters. The application of configured dynamic load container technology and multi-server processing load balancing and parallel computing technology makes the cluster a highly scalable, available, efficient operational system to realize all levels of satellite data archiving, customization, retrieval, dynamic information release, operation monitoring, management, and other functions. Internet-based full dataset sharing, distributed file system, spatiotemporal integration of database storage, WebGIS global satellite image distribution, visual processing and display technology are adopted in the system to improve data sharing and service. Completion of the system meets the needs of operational meteorological satellite, achieving daily 4 TB data storing and daily 1 TB data download service. The system running in NSMC/CMA is the first one to provide internet-based full archive dataset (online, nearline and offline) sharing service in the area of Chinese civil remote sensing satellite data services.","","","10.1109/IGARSS.2016.7730427","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730427","","Arrays;Databases;Image resolution;Real-time systems;Satellite broadcasting;Satellites;Servers","Internet;data integration;distributed databases;file servers;geographic information systems;geophysics computing;information retrieval systems;meteorology;storage management","Fengyun-3 series meteorological satellite;Internet-based full dataset sharing;WebGIS global satellite image distribution;application software;data archiving;data service system;disk array;display technology;distributed file system;high-performance server;operation system;spatiotemporal integration;storage software;system database;tape library;visual processing","","","","","","","10-15 July 2016","","IEEE","IEEE Conference Publications"
"A novel web caching scheme using hybrid least frequently used and support vector machine","P. Aimtongkham; C. So-In; S. Sanguanpong","Applied Network Technology, Department of Computer Science, Faculty of Science, Khon Kaen University 123 Mitaparb Rd., Maung, Khon Kaen, Thailand, 40002","2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20161121","2016","","","1","6","The gargantuan uses of web access in various types of applications, such as text, image, audio, and video, across the globe have caused the limitation for service providers to optimally make use of Internet infrastructure. The advance of web proxy/caching has recently been in place to mitigate this phenomenon using the concept of locality and proximity. There exist some traditional caching schemes, such as FIFO, LFU, LRU, and Size, but with key limitations on the precision. On the other hands, soft computing has recently been investigated due to its advantage of high precision. Thus, this paper proposes a novel caching method by integrating these twos. SVM was first used for classification, to divide the caching probability - to be replaced or else. Then, LFU was applied for the actual replacement given new web objects (if cache full); and these are Hybrid LFU-SVM. Its performance is practically confirmed from our intensive evaluation against SVM-LRU and its traditional schemes like LFU and LRU in order of 14% to 52.3% and 18% to 63.2%, for hit and byte hit rate, respectively, using a standard NLANR dataset.","","Electronic:978-1-5090-2033-1; POD:978-1-5090-2034-8","10.1109/JCSSE.2016.7748932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748932","Hybrid Caching;Least Frequency Used;Proxy;Replacement;Soft Computing;Support Vector Machine;Web Caching;Web Proxy","Artificial neural networks;Fuzzy logic;Internet;Kernel;Radio frequency;Support vector machines;Training","Internet;cache storage;information retrieval;pattern classification;support vector machines","FIFO;Internet infrastructure;NLANR dataset;SVM-LRU;Web access;Web caching scheme;Web objects;Web proxy;caching probability;hybrid LFU-SVM;hybrid least frequently used;locality concept;proximity concept;service providers;support vector machine","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"Multidimensional scaling based knowledge provision for new questions in community Question Answering systems","Siqi Xiang; Wenge Rong; Yikang Shen; Yuanxin Ouyang; Zhang Xiong","School of Computer Science and Engineering, Beihang University, Beijing 100191, China","2016 International Joint Conference on Neural Networks (IJCNN)","20161103","2016","","","115","122","Community-based Question Answering (CQA) sites have become popular since they allow users to get answers to complex, detailed and personal question from other users directly. However, since answering a question depends on the ability and willingness of other users to address the askers' real needs, a significant fraction of the questions remain unanswered. To decrease the unanswered question rate and then improve the user experience, in this paper, a multidimensional scaling (MDS) based data reorganization method is proposed. By using this method, the CQA system can predict the askers' intention and accordingly provide related previous question/answer pairs to help them find useful information. The method has been evaluated on an off-line dataset extracted from Baidu Zhidao and the result has shown its promising potential in knowledge management in CQA systems.","","","10.1109/IJCNN.2016.7727188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727188","Community-based Question Answering;Knowledge Management;Multidimensional Scaling","Calibration;Estimation;History;Knowledge discovery;Search engines;Semantics","data handling;knowledge management;question answering (information retrieval)","Baidu Zhidao;CQA system;MDS;community question answering systems;data reorganization method;knowledge management;multidimensional scaling","","","","","","","24-29 July 2016","","IEEE","IEEE Conference Publications"
"A partial-duplicate image retrieval method using color-based SIFT","A. Pourreza; K. Kiani","Department of Electrical & Computer Engineering, Semnan University, Semnan, Iran","2016 24th Iranian Conference on Electrical Engineering (ICEE)","20161010","2016","","","1410","1415","Many partial-duplicate image retrieval systems use the whole image for features extraction, while there is only a small duplicate region between the partial-duplicate images. On the other hand, many researchers consider the SIFT (Scale-Invariant Feature Transform) feature as an important descriptor in image retrieval systems, whereas it is independent of color and just describes the local gradient distribution, so, false-positive matches may occur in the matching task. To solve the problems, we propose a color-based SIFT matching method for partial-duplicate image retrieval that extracts the region with abundant visual content from image as a salient region. Then, keypoints are achieved from the region by applying SIFT, and color histogram is computed for each of them to improve the accuracy of image matching results. Our extensive experiments on IPDID and INSTRE datasets with 79% and 52% MAP measure respectively indicate the excellent performance of our method.","","","10.1109/IranianCEE.2016.7585742","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585742","color-based SIFT;images matching;partial-duplicate images;salient region","Electrical engineering;Feature extraction;Histograms;Image color analysis;Image retrieval;Image segmentation","feature extraction;gradient methods;image colour analysis;image matching;image retrieval;information retrieval systems;transforms","INSTRE dataset;IPDID dataset;MAP measure;color histogram;color-based SIFT matching method;color-based scale-invariant feature transform matching method;false-positive matches;features extraction;local gradient distribution;partial-duplicate image retrieval method;region extraction;visual content","","","","","","","10-12 May 2016","","IEEE","IEEE Conference Publications"
"Implementing Cost-Effective Data Collection and Extraction Processes with CollaMine","K. Z. M. Lu; B. Heng","Sch. of Inf. Technol., Nanyang Polytech., Singapore, Singapore","2016 International Conference on Cloud Computing Research and Innovations (ICCCRI)","20161020","2016","","","92","99","We present the CollaMine framework which aims to reduce the cost of data collection and data extraction. The framework consists of two keysolutions, namely, a collaborative system for web crawlers, and an automated regular expression diagnosis system for web content extractors. The empirical results show that the systems help to reduce the costs of data collection and extraction.","","","10.1109/ICCCRI.2016.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600183","automation;data extraction;data scraping;regular expression;web crawler","Business;Crawlers;Data mining;HTML;Layout;Machine learning algorithms;Uniform resource locators","Internet;cost reduction;groupware;information retrieval","CollaMine framework;Web content extractors;Web crawlers;automated regular expression diagnosis system;collaborative system;cost reduction;cost-effective data collection;cost-effective data extraction process","","","","","","","4-5 May 2016","","IEEE","IEEE Conference Publications"
"A Survey on Frameworks and Methods of Question Answering","Y. Liu; X. Yi; R. Chen; Y. Song","Sch. of Inf. Sci. & Technol., Dalian Maritime Univ., Dalian, China","2016 3rd International Conference on Information Science and Control Engineering (ICISCE)","20161103","2016","","","115","119","Question Answering provides a new manner for information query. Compared to existed search engines, Q&A systems are able to return answer for the questions represented by natural language. Hence, Q&A is always one of core reseraches in the field of information processing. In this paper, we present survey targets the state of the art in Q&A under systems and approaches. Firstly, we introduce the basic architecture of a typical Q&A system. Then, we present ten typical Q&A systems in different views including developer, supporting language, information source, answer type, etc. In detail, we investigate the key research endeavors on Q&A. We summary the exploited approaches to questions classification, questions similarity, answer extraction, answer sorting and question translation. Finally, we will also present our perspective on future directions of Q&A.","","","10.1109/ICISCE.2016.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726132","Answer Extraction;Natural Language Processing;Question Answering;Sentence Translation","Data mining;Feature extraction;Knowledge discovery;Natural languages;Semantic Web;Semantics;Sorting","classification;natural language processing;query processing;question answering (information retrieval);sorting","answer extraction;answer sorting;information processing;information query;natural language;question answering;question translation;questions classification;questions similarity;search engines","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"Construction of news headline from detailed news article","U. Shrawankar; K. Wankhede","G.H. Raisoni College of Engineering, Nagpur, MS, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","2321","2325","Usually long news article contains large amount of information. Many a times due to lack of time people are unable to read whole news article. Therefore, headline is required in order to get complete idea of news without reading whole news article. The extractive and abstractive approaches are conventionally used for news headline generation. In this paper, a combinational approach is used for headline construction by using keywords/keyphrases along with parsing technique of Natural Language Processing (NLP). The Keyphrase Extraction Algorithm (KEA) is used to extract keyphrases from input news text. Respective news domain word thesaurus and some other approaches are used for retrieving keywords from news text. Proper headline syntax can be constructed by using parsing technique. Headline is useful to reduce the reading and interpretation time for getting the complete idea of entire news article. The objective is to save reader's time and effort in finding the useful information in a detail news article.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724677","Headline Construction;Keyphrase Extraction Algorithm (KEA);Keyword Extraction;Natural Language Processing (NLP);Parse Tree Generation","Conferences;Decision support systems;Handheld computers","computational linguistics;grammars;information retrieval;natural language processing;publishing;word processing","KEA;NLP;abstractive approach;combinational approach;detailed news article;extractive approach;headline syntax construction;information finding;keyphrase extraction algorithm;keywords/keyphrases usage;natural language processing;news domain word thesaurus;news headline generation;news text keyword retrieval;parsing technique","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Embedding Pub/Sub mechanism into OGC web services to augment agricultural crop monitoring","Z. Sun; L. Di; H. Fang; C. Zhang; E. Yu; L. Lin; X. Tan; P. Yue","Center for Spaital Information Science and Systems, George Mason University, Fairfax, VA, USA","2016 Fifth International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","20160929","2016","","","1","4","The Pub/Sub, short for Publish-Subscribe, is a flexible mechanism perferred by many users who'd like to passively know the changes of situation. Once a new message is published by a provider, all the subscribers to the specific kind of messages will receive the message and make corresponding responses. In agricultural crop monitoring, such mechanism is very helpful in enhancing the efficiency of message spreading and farmers responding to sudden events. Thus, this paper tries to embed Pub/Sub mechanism into OGC web services which have been used in agricultural crop monitoring to search, access, describe and process the related data and information. This paper presents an initial framework to enable Pub/Sub in OGC web services via external supports. A Pub/Sub registry center is established for OGC web services and service users to subscribe and publish. Changes in OGC web services will be published as new messages to the registry. The registry will notify all the subscribers under the same theme with the message. A prototype is implemented for the framework. Some tests are made on a WCS, WMS and WFS. The results shows that through the prototype system, farmers or agricultural department can be timely notified about the changes such as new added remote sensing products about agricultural fields.","","","10.1109/Agro-Geoinformatics.2016.7577653","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577653","OGC;Pub/Sub;agricultural crop monitoring;geospatial web services;remote sensing","Agriculture;Monitoring;Optical wavelength conversion;Prototypes;Remote sensing;Standards;Web services","Web services;agricultural engineering;crops;information retrieval;message passing;middleware","OGC Web services;agricultural crop monitoring;information access;information process;information search;message spreading;pub-sub mechanism;pub-sub registry center;publish-subscribe mechanism;service users","","","","","","","18-20 July 2016","","IEEE","IEEE Conference Publications"
"The role of sparsity and dynamics in extracting information sparsely encoded in very large data sets","O. Camps; C. Lagoa; M. Sznaier","ECE Dept., Northeastern University, Boston, MA, 02115, United States of America","2016 IEEE Conference on Control Applications (CCA)","20161013","2016","","","398","409","The past few years have seen an exponential growth in data collection capabilities. Unfortunately, the ability to process this vast amount of data has not kept pace with this growth. Taking full advantage of these increased capabilities requires scalable, computationally efficient algorithms to timely and robustly extract actionable information from the very large data sets generated by the sensors. The goal of this tutorial paper is to illustrate the central role that tools originally developed in the context of systems theory, can play in accomplishing this task. Specifically, we show that many of these problems can be recast into an identification form that exhibit a sparse underlying structure. In turn, this sparsity can be exploited to recast the problem into a convex optimization form that can be efficiently solved with first order methods.","","","10.1109/CCA.2016.7587864","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7587864","","Atomic measurements;Context;Data mining;Data models;Linear systems;Optimization;Sensors","convex programming;data handling;information retrieval;very large databases","convex optimization;data collection capabilities;dynamics role;first order methods;identification form;sparse encoded information extraction;sparsity role;systems theory;very large data sets","","","","","","","19-22 Sept. 2016","","IEEE","IEEE Conference Publications"
"Web documents prioritization using genetic algorithm","S. K. Gupta; D. Singh; A. Doegar","KIET, Ghaziabad","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","3042","3047","As the technology advances more and more information are getting accumulated in the form of web sites in the internet. Web mining is a technique of extracting information from the internet which helps the users in finding quality pages. The main problem is that search engines are not capable enough to provide the relevant data. They fail to index all the information available on the web. Web mining is the application of data mining techniques on the web to solve the problem of extracting useful information. User get uninteresting document from huge web data source, as a result of simple search. It results in time wastage by browsing to unnecessary links. Web mining is the technique to retrieve relevant data. This work proposes an approach for web mining based on Genetic algorithm.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724823","Genetic algorithm;Web mining","Decision support systems","Internet;Web sites;data mining;document handling;genetic algorithms;information retrieval","Internet;Web document prioritization;Web mining;Web site;data retrieval;genetic algorithm;information extraction","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Methods to access structured and semi-structured data in bioinformatics databases: A perspective","R. A. Moftah; A. M. Maatuk; R. White","Faculty of Information Technology, Benghazi University, Libya","2016 International Conference on Engineering & MIS (ICEMIS)","20161117","2016","","","1","5","There are several methods proposed to extract data from biological databases developed by bioinformatics experts. These methods retrieve bioinformatics information through the use of structured and semi-structured data tools from remote database servers. This paper investigates and evaluates the performance of these methods in terms of their ability to gain access to a cross representation of bioinformatics databases efficiently using web-based interfaces provided by bioinformatics organizations. The investigation distinguishes these approaches and tools. We have used the Sequence Retrieval System and Entrez search tools for structured data, and the Perl and BioPerl for semi-structured data to retrieve complex queries data and a combination of text and numeric information. The use of semi-structured data tools for accessing bioinformatics databases has been found viable alternative to the structured approach.","","Electronic:978-1-5090-5579-1; POD:978-1-5090-5580-7","10.1109/ICEMIS.2016.7745313","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745313","BioPerl;Entrez;Perl;Sequence Retrieval System","Bioinformatics;Data mining;Databases;Internet;Proteins;Servers","Internet;bioinformatics;data structures;information retrieval;performance evaluation;query processing","BioPerl;Entrez search tools;Perl;Web-based interfaces;bioinformatics databases;bioinformatics information retrieval;bioinformatics organizations;biological databases;complex query data retrieval;performance evaluation;remote database servers;semistructured data tools;sequence retrieval system;structured data tools","","","","","","","22-24 Sept. 2016","","IEEE","IEEE Conference Publications"
"Feasibility analysis for popularity prediction of stack exchange posts based on its initial content","D. Phukan; A. K. Singha","Department of Software Engineering, SRM University, Chennai, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","1397","1402","In technology related question and answer websites, people working on corresponding technologies post questions about the problems that they encounter and seek answers to them. The popular posts having greater views that stay active for longer periods of time are the ones that occur commonly for many users. The objective of this paper is to predict such posts at its arrival time. Using the prediction results, the problems that will gain popularity over time can be addressed before they become very common. The posts in question and answer websites have a longer lifespan than other online content such as news articles which are short lived and have a high user activity at the beginning that decrease with time. This indicates that the user activity in question and answer websites is not an accurate measure of popularity in an early stage. In this paper, we have used the initial content in a post as the predictors of popularity rather than using conventional methods such as shares, comments etc. We used three models to predict the popularity using the dataset of android.stackexchange.com, a popular question and answer website for android developers.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724494","Classification;Linear Models;Machine learning;Popularity;Prediction;Predictive models;Question and Answer websites","Electronic mail;Niobium;Smoothing methods;Social network services;Software engineering;Support vector machines;Training","Android (operating system);Web sites;question answering (information retrieval)","android developers;android.stackexchange.com;feasibility analysis;initial content;online content;popularity prediction;question and answer Web sites;stack exchange posts","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"A page prefetching technique utilizing semantic information of links","S. Setia; Jyoti; N. Duhan","Computer Engineering, YMCAUST, Faridabad, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","2934","2939","A large growth of web uses on the Internet causes latency perceived by the user. Prefetching is a good solution to this problem. Web page content provides the meaningful data to predict the coming requests in future. This paper presents a semantic prefetching technique which uses the content of the web page. The proposed technique works on the semantic preferences of the anchor text associated with the URL. This technique also uses the semantic information, explicitly embedded with each link, for more accurate predictions. It also computes the semantic association in order to improve the prediction accuracy. This prefetching technique would be more effective for long sessions and will achieve good hit rate.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724801","Content based prefetching;Pprediction;Semantic Prefetching;Semantic association;Semantic information;Web Prefetching","Cache storage;Conferences;Decision support systems;Handheld computers;Prefetching;Semantics;Web pages","content management;information retrieval;semantic Web;storage management","Internet;URL;Web page content;anchor text;semantic link information;semantic prefetching technique","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Semi supervised soft label propagation algorithm for CBIR","S. Janarthanam; S. Sukumaran","Computer Science, Gobi Arts and Science College, Gobichettipalayam, Erode, India","2016 10th International Conference on Intelligent Systems and Control (ISCO)","20161103","2016","","","1","5","The increase popularity of using huge image databases in various image retrieval applications construct a need to develop an efficient and robust system provides the output in the form of similar images with respect to the input or query image. Also to carry out its management and retrieval, Content-Based Image Retrieval is an effective method in retrieval system, as well as key technologies. In addition to Compare the shortcoming feature is used in the traditional system, this paper introduces a method that combines color, texture and shape for image retrieval and shows its advantage. But dealing with pattern recognition and machine learning a major problem occur on dimension. Among the dimensionality reduction techniques, Linear Discriminant Analysis is one of the popular methods, but LDA neglect the unlabeled samples. The proposed method propagates the label information from the labeled set to unlabeled set with label propagation process and compare with robust local binary pattern. Further the extensive simulations are conducted on two datasets are Corel 1000 and Brodatz texture database under different noise condition. The results after investigation show a significant improvement in terms of average retrieval precision (ARP) and average retrieval recall (ARR) as compared.","","","10.1109/ISCO.2016.7726897","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726897","content based image retrieval;labelpropagation;linear discriment-analysis;localbinarypattern;pattern recognition","Image retrieval;Pattern recognition;Support vector machines;Training;Visualization","data reduction;image processing;image retrieval;information retrieval;learning (artificial intelligence);pattern recognition","ARP;ARR;Brodatz texture database;CBIR;Corel 1000;LDA;average retrieval precision;average retrieval recall;content-based image retrieval;dimensionality reduction techniques;image databases;image retrieval applications;label information propagation;linear discriminant analysis;local binary pattern;machine learning;pattern recognition;query image;retrieval system;semisupervised soft label propagation algorithm","","","","","","","7-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"A Fused Multi-feature Based Co-training Approach for Document Clustering","Y. Wang; W. Wang; W. Dai; P. Jiao; W. Yu","Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China","2016 3rd International Conference on Information Science and Control Engineering (ICISCE)","20161103","2016","","","38","43","Document clustering is a popular topic in data mining and information retrieval. Most models and methods for this problem are based on computing the similarity between pair documents modeled in a space of all terms, or a new feature space obtained by applying a topic modeling technique for a given corpus. In this paper, we regard these two ideas as clustering on term feature and on semantic feature, and have an assumption that they can contribute to each other in clustering. Also, we propose a co-training approach for spectral clustering taking two features into account. Experiments on four real-world datasets show the feasibility and efficacy of our proposed approach compared with a number of the baseline methods.","","","10.1109/ICISCE.2016.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726116","co-training;document clustering;multi-feature;spectral clustering","Classification algorithms;Clustering algorithms;Feature extraction;Kernel;Large scale integration;Matrix decomposition;Semantics","data mining;document handling;information retrieval;pattern clustering;sensor fusion","data mining;document clustering;fused multifeature based cotraining;information retrieval;spectral clustering;topic modeling","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"Data retrieval mechanism using Amazon simple storage service and Windows Azure","P. Subhashini; S. Nalla","Osmania University, M.V.S.R Engineering College, Hyderabad, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","20161031","2016","","","412","414","Cloud computing has great potential of providing robust computational power to the society at reduced cost. It enables customers with limited computational resources to outsource their large computation workloads to the cloud, and economically enjoy the massive computational power, bandwidth, storage, and even appropriate software that can be shared in a pay-per-use manner. Several vendors such as Amazon, Microsoft and Google came up with several cloud solutions that let people and organizations gain access to huge computational resources in pay per use manner. Many a times, the data stored in Cloud is in the form of Tables, Files, Pictures, Documents, etc. across various virtual machines. Full-Text Search is a very powerful feature that can be used for a wide range of business scenarios such as building a search engine but most of current Cloud Solutions do not support Full Text Search. In this scenario, retrieving the required information or document has become very difficult task now a days. In view of this we propose a solution to explore various ways of retrieval mechanism in Cloud Environment using Amazon simple storage service and Windows Azure.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724297","Amazon s3;cloud computing;windows azure","Decision support systems;Handheld computers","cloud computing;information retrieval;search engines;storage management;virtual machines","Amazon simple storage service;Google;Microsoft;Windows Azure;business scenarios;cloud computing;cloud solutions;computation workloads;data retrieval mechanism;full-text search;pay per use manner;search engine;virtual machines","","","","","","","16-18 March 2016","","IEEE","IEEE Conference Publications"
"Optimization of data access in tiered storage","T. Sergii; B. Maksym","Faculty of Informatics and Computer Engineering, NTUU &#x201C;KPI&#x201D;, Kyiv, Ukraine","2016 International Conference Radio Electronics & Info Communications (UkrMiCo)","20161110","2016","","","1","4","The specifics of data access in multi-tiered data storage are considered. The problem of data blocks optimal allocation with taking in consideration the technical characteristics of storage tiers and applications requirements is formulated. Three models for different variants of data storage types, user requests and expenses minimization policies are proposed. Methods for solving these problems were described. The variant of genetic algorithm to determine the optimal allocation of data blocks onto different tiers of data storage is developed. Principles of implementation for cases with file system virtualization and databases with and without table partitioning are described.","","Electronic:978-1-5090-4409-2; POD:978-1-5090-4410-8","10.1109/UkrMiCo.2016.7739638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7739638","data access;optimization;tiered storage","Data models;Databases;File systems;Memory;Optimization;Resource management;Virtualization","database management systems;genetic algorithms;information retrieval","data access optimization;data blocks optimal allocation;expenses minimization policies;genetic algorithm;multitiered data storage","","","","","","","11-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Kind of Efficient Data Archiving Method for Historical Sensor Data","Q. Yan; Y. Y. Wang","Inst. of Software, Beijing, China","2016 3rd International Conference on Information Science and Control Engineering (ICISCE)","20161103","2016","","","44","48","Nowadays there are more than 10 billion sensors in the Internet of Things. These sensors will produce a mass of historical data as time goes on. And these data are useful in data mining and may create great value for human. However, historical sensor data are hard to archive because they have the characteristics of mass, complexity, isomerism and dynamic nature. Therefore, how to archive historical sensor data to storage efficiently is a meaningful issue deserved to study. In this paper, an efficient data archiving method is proposed. It mainly focuses on three aspects: memory allocation strategy, data compression technique and data storage structure. This method not only considers the efficiency of each aspect but also the combination of each aspect in order to ensure the high efficiency of whole data archiving method.","","","10.1109/ICISCE.2016.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7726117","data archiving method;data compression technique;data storage structure;historical sensor data;memory allocation strategy","Companies;Data compression;Indexes;Marine vehicles;Memory;Resource management;Silicon","Internet of Things;data compression;information retrieval systems;storage management","Internet of Things;data archiving method;data compression technique;data storage structure;historical sensor data;memory allocation strategy","","","","","","","8-10 July 2016","","IEEE","IEEE Conference Publications"
"The application of system integration technology in the process of integrating electronic resources of library","T. Zhu; L. Zhang","Library, Changchun Institute of Technology, Changchun, China","2016 11th International Conference on Computer Science & Education (ICCSE)","20161006","2016","","","738","740","With the System Integration Technology, this paper integrated some library electronic resources from the perspective of protocol standard, portal, database and retrieval method, aiming to provide an integrated platform and solutions for Cross-platform heterogeneous search among multiple databases of libraries, which can maximally keep the integrity of the knowledge system and improve the retrieval and utilization of electronic resources in college library.","","","10.1109/ICCSE.2016.7581672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581672","System integration;resource integration;unified retrieval platform","Databases;Electronic publishing;Google;Libraries;Portals;System integration","academic libraries;database management systems;digital libraries;information retrieval;portals","college library;digital library;information retrieval;library database;library electronic resource;portal;protocol standard;system integration technology","","","","","","","23-25 Aug. 2016","","IEEE","IEEE Conference Publications"
